{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constitution of a corpus of NLP papers from two sources: ACL Anthology and ArXiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this Notebook**: We will create two `Corpus` objects and populate them with `Paper`(s), whose content will be further investigated. We use two sources of papers (XML format) and metadata: [the ACL Anthology](#a-acl-corpus) and [ArXiv](#b-arxiv-corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "from typing import Tuple, List\n",
    "import pickle\n",
    "import re\n",
    "import tqdm\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import sys\n",
    "sys.path.insert(0, '../') # add parent directory (containing the util module) to path\n",
    "import utils.Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. ACL corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initial data inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source: [ACL Anthology corpus](https://github.com/shauryr/ACL-anthology-corpus) by Shaurya Rohatgi (metadata + grobid extractions as XML files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML_FILES_DIR = \"../data/acl/tei.xml/\"\n",
    "# METADATA_PATH = \"../data/acl/acl-publication-info.74k.v3.full-sections-partial-topic-labels.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the complete metadata provided in Shaurya Rohatgi's corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle(METADATA_PATH)\n",
    "# print(df.shape)\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"year\"] = df[\"year\"].astype(int)\n",
    "# df[\"year\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also check that for every article mentionned in the metadata, we have the corresponding XML file stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for every acl_id, check that the xml file exists\n",
    "# for acl_id in tqdm.tqdm(list(df[\"acl_id\"])):\n",
    "#     path = f\"{XML_FILES_DIR}/{acl_id}.tei.xml\"\n",
    "#     if not os.path.exists(path):\n",
    "#         print(f\"File {path} does not exist\")\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for attributes with missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df.columns:\n",
    "#     none_rows = df[df[col].isnull()].shape[0]\n",
    "#     if none_rows > 0:\n",
    "#         print(f\"No {col}: {none_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can directly exclude papers that are explicitly not in English, and posters (at least, papers whose id contains \"poster\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len([id_ for id_ in list(df[\"acl_id\"].values) if \"poster\" in id_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get rid of the non-english papers\n",
    "# df_c = df[(df[\"language\"] == \"English\") | (df[\"language\"].isnull())]\n",
    "\n",
    "# # get rid of the posters\n",
    "# for i, row in df_c.iterrows():\n",
    "#     if \"poster\" in df_c.loc[i, \"acl_id\"]:\n",
    "#         df_c.drop(i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save in pickle format\n",
    "# df_c.to_pickle(\"acl-metadata-full-en_no-p.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create `Corpus` object and extract papers content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we create a `Corpus` and provide it with the paths to find useful XML papers and metadata. When calling `load_papers`, we extract the content of all the XML files in the corpus to create some `Paper` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "XML_FILES_DIR = \"../data/acl/tei.xml/\"\n",
    "METADATA_PATH = \"../data/acl/acl-metadata-full-en_no-p.pkl\"\n",
    "\n",
    "corpus_ACL = utils.Corpus.Corpus(xml_dir_path= XML_FILES_DIR,\n",
    "                    metadata_path = METADATA_PATH,\n",
    "                    name = \"ACL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_ACL.load_papers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the method `preprocess_papers` will sort sentences from `Paper` objects into two categories: candidates (for containing claims) and non candidates, based on the section that they belong to (e.g the sentences of a section named \"Experimental setup\" will be considered as non candidates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_ACL.preprocess_papers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # serialize the corpus for later access\n",
    "# with open(\"../data/acl/corpus_ACL.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(corpus_ACL, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.Corpus.Corpus at 0x1f132bdf310>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/acl/corpus_ACL.pkl\", \"rb\") as f:\n",
    "    corpus_ACL = pickle.load(f)\n",
    "\n",
    "corpus_ACL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Corpus content inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the encountered errors (e.g a `Paper` object couldn't be correctly initialized because the corresponding XML file is not well-structured) are stored for later analysis. Plus, the \"correct\" and \"incorrect\" `Paper` objets are stored separately into `Corpus` attributes `papers` and `papers_with_errors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60725\n",
      "10828\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus_ACL.papers))\n",
    "print(len(corpus_ACL.papers_with_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can know more about these errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus 'ACL' was filled with 71553 papers:\n",
      "  - 60725 papers were successfully loaded\n",
      "  - 10828 papers could not be loaded\n",
      "\n",
      "Errors:\n",
      "  - Parsing error: XML file not well formed : 5523\n",
      "  - Parsing error: no abstract found : 3163\n",
      "  - Noisy data: wrong language (sk) : 8\n",
      "  - Noisy data: wrong language (sq) : 34\n",
      "  - parsing error: not enough paper content found (<2 distinct sections) : 715\n",
      "  - Noisy data: wrong language (da) : 155\n",
      "  - Noisy data: wrong language (de) : 76\n",
      "  - Noisy data: wrong language (fr) : 636\n",
      "  - Noisy data: wrong language (sl) : 8\n",
      "  - Noisy data: wrong language (hr) : 4\n",
      "  - Noisy data: wrong language (so) : 21\n",
      "  - Noisy data: wrong language (tr) : 11\n",
      "  - Noisy data: wrong language (pl) : 21\n",
      "  - Noisy data: wrong language (pt) : 124\n",
      "  - Noisy data: wrong language (af) : 1\n",
      "  - Noisy data: wrong language (et) : 3\n",
      "  - Noisy data: wrong language (no) : 40\n",
      "  - Noisy data: wrong language (nl) : 8\n",
      "  - Noisy data: wrong language (vi) : 26\n",
      "  - Noisy data: wrong language (es) : 10\n",
      "  - Noisy data: wrong language (zh-tw) : 148\n",
      "  - Noisy data: wrong language (bn) : 6\n",
      "  - Noisy data: wrong language (ru) : 1\n",
      "  - Noisy data: wrong language (hu) : 10\n",
      "  - Noisy data: wrong language (fi) : 12\n",
      "  - Noisy data: wrong language (it) : 12\n",
      "  - Noisy data: wrong language (ro) : 2\n",
      "  - Noisy data: wrong language (sv) : 38\n",
      "  - Noisy data: wrong language (cs) : 5\n",
      "  - Noisy data: wrong language (ja) : 1\n",
      "  - Noisy data: wrong language (lt) : 1\n",
      "  - Noisy data: wrong language (hi) : 1\n",
      "  - Noisy data: wrong language (id) : 2\n",
      "  - Noisy data: wrong language (zh-cn) : 1\n",
      "  - Noisy data: wrong language (sw) : 1\n"
     ]
    }
   ],
   "source": [
    "corpus_ACL.describe(error_verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # collect the encountered errors\n",
    "# errors = [[pe.id, pe.init_error, pe.title, pe.abstract, pe.year] for pe in corpus_ACL.papers_with_errors]\n",
    "# df_errors = pd.DataFrame(errors, columns=[\"id\", \"error\", \"title\", \"abstract\", \"year\"])\n",
    "# df_errors.to_csv(\"../data/acl/acl-init-errors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>error</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L02-1310</td>\n",
       "      <td>Parsing error: XML file not well formed</td>\n",
       "      <td>Bootstrapping Large Sense Tagged Corpora</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L02-1309</td>\n",
       "      <td>Parsing error: XML file not well formed</td>\n",
       "      <td>Proposal of a very-large-corpus acquisition me...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L02-1313</td>\n",
       "      <td>Parsing error: XML file not well formed</td>\n",
       "      <td>Enhanced {J}apanese Electronic Dictionary Look-up</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L02-1314</td>\n",
       "      <td>Parsing error: XML file not well formed</td>\n",
       "      <td>Evaluation of a Vector Space Similarity Measur...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L02-1315</td>\n",
       "      <td>Parsing error: XML file not well formed</td>\n",
       "      <td>Corpora as Object-Oriented System. From {UML}-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                    error  \\\n",
       "0  L02-1310  Parsing error: XML file not well formed   \n",
       "1  L02-1309  Parsing error: XML file not well formed   \n",
       "2  L02-1313  Parsing error: XML file not well formed   \n",
       "3  L02-1314  Parsing error: XML file not well formed   \n",
       "4  L02-1315  Parsing error: XML file not well formed   \n",
       "\n",
       "                                               title abstract  year  \n",
       "0           Bootstrapping Large Sense Tagged Corpora      NaN  2002  \n",
       "1  Proposal of a very-large-corpus acquisition me...      NaN  2002  \n",
       "2  Enhanced {J}apanese Electronic Dictionary Look-up      NaN  2002  \n",
       "3  Evaluation of a Vector Space Similarity Measur...      NaN  2002  \n",
       "4  Corpora as Object-Oriented System. From {UML}-...      NaN  2002  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_errors = pd.read_csv(\"../data/acl/acl-init-errors.csv\")\n",
    "df_errors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Paper` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S07-1055\n",
      "{OE}: {WSD} Using Optimal Ensembling ({OE}) Method\n",
      "Optimal ensembling (OE) is a word sense disambiguation (WSD) method using word-specific training factors (average positive vs negative training per sense, posex and negex) to predict best system (classifier algorithm / applicable feature set) for given target word. Our official entry (OE1) in Senseval-4 Task 17 (coarse-grained English lexical sample task) contained many design flaws and thus failed to show the whole potential of the method, finishing -4.9% behind top system (+0.5 gain over best base system). A fixed system (OE2) finished only -3.4% behind (+2.0% net gain). All our systems were 'closed', i.e. used the official training data only (average 56 training examples per each sense). We also show that the official evaluation measure tends to favor systems that do well with high-trained words.\n",
      "2007\n"
     ]
    }
   ],
   "source": [
    "# an example of a Paper object\n",
    "p = corpus_ACL.papers[123]\n",
    "\n",
    "# some metadata\n",
    "print(p.id)\n",
    "print(p.title)\n",
    "print(p.abstract)\n",
    "print(p.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<utils.Corpus.Corpus object at 0x000001F132BDF310>\n",
      "ACL\n"
     ]
    }
   ],
   "source": [
    "# the Corpus to which the Paper belongs\n",
    "print(p.corpus)\n",
    "print(p.corpus.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<utils.Author.Author object at 0x000001F1D09F5950>]\n",
      "['Saarikoski', 'Harri M. T.'] ['Saarikoski', 'Harri M. T.']\n"
     ]
    }
   ],
   "source": [
    "# the authors of the paper\n",
    "print(p.authors)\n",
    "for auth in p.authors:\n",
    "    print(auth.names, auth.norm_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More importantly, we have access to the content of the Paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>section</th>\n",
       "      <th>candidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Optimal ensembling (OE) is a word sense disamb...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Our official entry (OE1) in Senseval-4 Task 17...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A fixed system (OE2) finished only -3.4% behin...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>All our systems were 'closed', i.e.</td>\n",
       "      <td>abstract</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>used the official training data only (average ...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>In other words, the official measure does not ...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>Therefore, it can be said that the official me...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>Since OE is a generic method that can be appli...</td>\n",
       "      <td>Conclusion and Further Work</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>With remaining open questions resolved (optimi...</td>\n",
       "      <td>Conclusion and Further Work</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>Though OE systems run the risk that OE may in ...</td>\n",
       "      <td>Conclusion and Further Work</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                           sentence  \\\n",
       "0    0  Optimal ensembling (OE) is a word sense disamb...   \n",
       "1    1  Our official entry (OE1) in Senseval-4 Task 17...   \n",
       "2    2  A fixed system (OE2) finished only -3.4% behin...   \n",
       "3    3                All our systems were 'closed', i.e.   \n",
       "4    4  used the official training data only (average ...   \n",
       "..  ..                                                ...   \n",
       "90  90  In other words, the official measure does not ...   \n",
       "91  91  Therefore, it can be said that the official me...   \n",
       "92  92  Since OE is a generic method that can be appli...   \n",
       "93  93  With remaining open questions resolved (optimi...   \n",
       "94  94  Though OE systems run the risk that OE may in ...   \n",
       "\n",
       "                        section  candidate  \n",
       "0                      abstract       True  \n",
       "1                      abstract       True  \n",
       "2                      abstract       True  \n",
       "3                      abstract       True  \n",
       "4                      abstract       True  \n",
       "..                          ...        ...  \n",
       "90                   Discussion       True  \n",
       "91                   Discussion       True  \n",
       "92  Conclusion and Further Work       True  \n",
       "93  Conclusion and Further Work       True  \n",
       "94  Conclusion and Further Work       True  \n",
       "\n",
       "[95 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can separately look at the candidate sentences (potential claims) and the non candidate ones (those who belong to a section which should, a priori, not contain claims)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>section</th>\n",
       "      <th>candidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Optimal ensembling (OE) is a word sense disamb...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Our official entry (OE1) in Senseval-4 Task 17...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A fixed system (OE2) finished only -3.4% behin...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>All our systems were 'closed', i.e.</td>\n",
       "      <td>abstract</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>used the official training data only (average ...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>In other words, the official measure does not ...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>Therefore, it can be said that the official me...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>Since OE is a generic method that can be appli...</td>\n",
       "      <td>Conclusion and Further Work</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>With remaining open questions resolved (optimi...</td>\n",
       "      <td>Conclusion and Further Work</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>Though OE systems run the risk that OE may in ...</td>\n",
       "      <td>Conclusion and Further Work</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                           sentence  \\\n",
       "0    0  Optimal ensembling (OE) is a word sense disamb...   \n",
       "1    1  Our official entry (OE1) in Senseval-4 Task 17...   \n",
       "2    2  A fixed system (OE2) finished only -3.4% behin...   \n",
       "3    3                All our systems were 'closed', i.e.   \n",
       "4    4  used the official training data only (average ...   \n",
       "..  ..                                                ...   \n",
       "90  90  In other words, the official measure does not ...   \n",
       "91  91  Therefore, it can be said that the official me...   \n",
       "92  92  Since OE is a generic method that can be appli...   \n",
       "93  93  With remaining open questions resolved (optimi...   \n",
       "94  94  Though OE systems run the risk that OE may in ...   \n",
       "\n",
       "                        section  candidate  \n",
       "0                      abstract       True  \n",
       "1                      abstract       True  \n",
       "2                      abstract       True  \n",
       "3                      abstract       True  \n",
       "4                      abstract       True  \n",
       "..                          ...        ...  \n",
       "90                   Discussion       True  \n",
       "91                   Discussion       True  \n",
       "92  Conclusion and Further Work       True  \n",
       "93  Conclusion and Further Work       True  \n",
       "94  Conclusion and Further Work       True  \n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.content[p.content[\"candidate\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>section</th>\n",
       "      <th>candidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>We extracted three contextual feature sets fro...</td>\n",
       "      <td>Feature Set (Fset) Selection</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>We also used three 'multifsets' (1g-2g, 1g-pos...</td>\n",
       "      <td>Feature Set (Fset) Selection</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>We designed and ran two systems: OE1 (official...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Selection of c(omplexity) parameter for SVM wa...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>This is based on accounts by e.g.</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Vapnik (1995) that lower c value makes the cla...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>We learned the best-system predictor model usi...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>For 70 words where two fsets performed within ...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>OE2 (unofficial): This system incorporated the...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>We only used two machines strongest in 10CV ru...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>This resulted in a 2 * 2 = 4-system ensemble.</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Best fset was still selected on the basis of 1...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>As training data for the best-machine predicto...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>We decided to use only two prediction factors ...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>This was because previously we had found these...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>(For illustration of the predictor model with ...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>As to reasons for such a performance differenc...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>Difference in the best-system predictions of t...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>Only 27 words kept the same machine in same co...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>We can therefore call OE2 a substantial revisi...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>In both OEs, the mach-fset combination predict...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>In case of 'multifsets', each single fset had ...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>Brill Tagger (Brill, 1995) was used for extrac...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>Weka library of classifiers (Witten, 2005) was...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>As usual, the sense with highest probability w...</td>\n",
       "      <td>System Descriptions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                           sentence  \\\n",
       "18  18  We extracted three contextual feature sets fro...   \n",
       "19  19  We also used three 'multifsets' (1g-2g, 1g-pos...   \n",
       "20  20  We designed and ran two systems: OE1 (official...   \n",
       "21  21  Selection of c(omplexity) parameter for SVM wa...   \n",
       "22  22                  This is based on accounts by e.g.   \n",
       "23  23  Vapnik (1995) that lower c value makes the cla...   \n",
       "24  24  We learned the best-system predictor model usi...   \n",
       "25  25  For 70 words where two fsets performed within ...   \n",
       "26  26  OE2 (unofficial): This system incorporated the...   \n",
       "27  27  We only used two machines strongest in 10CV ru...   \n",
       "28  28      This resulted in a 2 * 2 = 4-system ensemble.   \n",
       "29  29  Best fset was still selected on the basis of 1...   \n",
       "30  30  As training data for the best-machine predicto...   \n",
       "31  31  We decided to use only two prediction factors ...   \n",
       "32  32  This was because previously we had found these...   \n",
       "33  33  (For illustration of the predictor model with ...   \n",
       "34  34  As to reasons for such a performance differenc...   \n",
       "35  35  Difference in the best-system predictions of t...   \n",
       "36  36  Only 27 words kept the same machine in same co...   \n",
       "37  37  We can therefore call OE2 a substantial revisi...   \n",
       "38  38  In both OEs, the mach-fset combination predict...   \n",
       "39  39  In case of 'multifsets', each single fset had ...   \n",
       "40  40  Brill Tagger (Brill, 1995) was used for extrac...   \n",
       "41  41  Weka library of classifiers (Witten, 2005) was...   \n",
       "42  42  As usual, the sense with highest probability w...   \n",
       "\n",
       "                         section  candidate  \n",
       "18  Feature Set (Fset) Selection      False  \n",
       "19  Feature Set (Fset) Selection      False  \n",
       "20           System Descriptions      False  \n",
       "21           System Descriptions      False  \n",
       "22           System Descriptions      False  \n",
       "23           System Descriptions      False  \n",
       "24           System Descriptions      False  \n",
       "25           System Descriptions      False  \n",
       "26           System Descriptions      False  \n",
       "27           System Descriptions      False  \n",
       "28           System Descriptions      False  \n",
       "29           System Descriptions      False  \n",
       "30           System Descriptions      False  \n",
       "31           System Descriptions      False  \n",
       "32           System Descriptions      False  \n",
       "33           System Descriptions      False  \n",
       "34           System Descriptions      False  \n",
       "35           System Descriptions      False  \n",
       "36           System Descriptions      False  \n",
       "37           System Descriptions      False  \n",
       "38           System Descriptions      False  \n",
       "39           System Descriptions      False  \n",
       "40           System Descriptions      False  \n",
       "41           System Descriptions      False  \n",
       "42           System Descriptions      False  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.content[p.content[\"candidate\"] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some corpus Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# boxplot of the number of sentences per paper in the corpus\n",
    "sentences_per_paper = [len(p.content.sentence) for p in corpus_ACL.papers]\n",
    "plt.boxplot(sentences_per_paper)\n",
    "plt.title(\"Number of sentences per paper in the ACL corpus\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# boxplot of the ratio candidate sentences / total sentences per paper in the corpus\n",
    "ratios = [p.content[p.content[\"candidate\"] == True].shape[0] / len(p.content.sentence) for p in corpus_ACL.papers]\n",
    "plt.boxplot(ratios)\n",
    "plt.title(\"Ratio of candidate sentences per paper in the ACL corpus\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of years of the papers in the corpus\n",
    "years = [int(p.year) for p in corpus_ACL.papers]\n",
    "plt.hist(years, bins=range(min(years), max(years) + 1))\n",
    "plt.title(\"Distribution of years of papers in the ACL corpus\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now: draw a small sample as a toy corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample = df.sample(1000, random_state = 23)\n",
    "# df_sample.to_pickle(\"../data/acl/acl-metadata-sample-1000.pkl\")\n",
    "df = pd.read_pickle(\"../data/acl/acl-metadata-sample-1000.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. ArXiv corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initial corpus inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the initial metadata of the entire ArXiv corpus, available on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2445865it [03:57, 10305.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# data = []\n",
    "# with open(\"../data/arxiv/arxiv-metadata-oai-snapshot.json\", \"r\", errors = \"ignore\", encoding = \"utf-8\") as f:\n",
    "#     for line in tqdm.tqdm(f):\n",
    "#         data.append(json.loads(line))\n",
    "\n",
    "# df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2445865, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journal-ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>report-no</th>\n",
       "      <th>categories</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>Pavel Nadolsky</td>\n",
       "      <td>C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>37 pages, 15 figures; published version</td>\n",
       "      <td>Phys.Rev.D76:013009,2007</td>\n",
       "      <td>10.1103/PhysRevD.76.013009</td>\n",
       "      <td>ANL-HEP-PR-07-12</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>None</td>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 2 Apr 2007...</td>\n",
       "      <td>2008-11-26</td>\n",
       "      <td>[[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0002</td>\n",
       "      <td>Louis Theran</td>\n",
       "      <td>Ileana Streinu and Louis Theran</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>To appear in Graphs and Combinatorics</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math.CO cs.CG</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
       "      <td>2008-12-13</td>\n",
       "      <td>[[Streinu, Ileana, ], [Theran, Louis, ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0003</td>\n",
       "      <td>Hongjun Pan</td>\n",
       "      <td>Hongjun Pan</td>\n",
       "      <td>The evolution of the Earth-Moon system based o...</td>\n",
       "      <td>23 pages, 3 figures</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>physics.gen-ph</td>\n",
       "      <td>None</td>\n",
       "      <td>The evolution of Earth-Moon system is descri...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Apr 2007...</td>\n",
       "      <td>2008-01-13</td>\n",
       "      <td>[[Pan, Hongjun, ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0004</td>\n",
       "      <td>David Callan</td>\n",
       "      <td>David Callan</td>\n",
       "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
       "      <td>11 pages</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math.CO</td>\n",
       "      <td>None</td>\n",
       "      <td>We show that a determinant of Stirling cycle...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[[Callan, David, ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0005</td>\n",
       "      <td>Alberto Torchinsky</td>\n",
       "      <td>Wael Abu-Shammala and Alberto Torchinsky</td>\n",
       "      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n",
       "      <td>None</td>\n",
       "      <td>Illinois J. Math. 52 (2008) no.2, 681-689</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math.CA math.FA</td>\n",
       "      <td>None</td>\n",
       "      <td>In this paper we show how to compute the $\\L...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 2 Apr 2007...</td>\n",
       "      <td>2013-10-15</td>\n",
       "      <td>[[Abu-Shammala, Wael, ], [Torchinsky, Alberto, ]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           submitter  \\\n",
       "0  0704.0001      Pavel Nadolsky   \n",
       "1  0704.0002        Louis Theran   \n",
       "2  0704.0003         Hongjun Pan   \n",
       "3  0704.0004        David Callan   \n",
       "4  0704.0005  Alberto Torchinsky   \n",
       "\n",
       "                                             authors  \\\n",
       "0  C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...   \n",
       "1                    Ileana Streinu and Louis Theran   \n",
       "2                                        Hongjun Pan   \n",
       "3                                       David Callan   \n",
       "4           Wael Abu-Shammala and Alberto Torchinsky   \n",
       "\n",
       "                                               title  \\\n",
       "0  Calculation of prompt diphoton production cros...   \n",
       "1           Sparsity-certifying Graph Decompositions   \n",
       "2  The evolution of the Earth-Moon system based o...   \n",
       "3  A determinant of Stirling cycle numbers counts...   \n",
       "4  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
       "\n",
       "                                  comments  \\\n",
       "0  37 pages, 15 figures; published version   \n",
       "1    To appear in Graphs and Combinatorics   \n",
       "2                      23 pages, 3 figures   \n",
       "3                                 11 pages   \n",
       "4                                     None   \n",
       "\n",
       "                                 journal-ref                         doi  \\\n",
       "0                   Phys.Rev.D76:013009,2007  10.1103/PhysRevD.76.013009   \n",
       "1                                       None                        None   \n",
       "2                                       None                        None   \n",
       "3                                       None                        None   \n",
       "4  Illinois J. Math. 52 (2008) no.2, 681-689                        None   \n",
       "\n",
       "          report-no       categories  \\\n",
       "0  ANL-HEP-PR-07-12           hep-ph   \n",
       "1              None    math.CO cs.CG   \n",
       "2              None   physics.gen-ph   \n",
       "3              None          math.CO   \n",
       "4              None  math.CA math.FA   \n",
       "\n",
       "                                             license  \\\n",
       "0                                               None   \n",
       "1  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    A fully differential calculation in perturba...   \n",
       "1    We describe a new algorithm, the $(k,\\ell)$-...   \n",
       "2    The evolution of Earth-Moon system is descri...   \n",
       "3    We show that a determinant of Stirling cycle...   \n",
       "4    In this paper we show how to compute the $\\L...   \n",
       "\n",
       "                                            versions update_date  \\\n",
       "0  [{'version': 'v1', 'created': 'Mon, 2 Apr 2007...  2008-11-26   \n",
       "1  [{'version': 'v1', 'created': 'Sat, 31 Mar 200...  2008-12-13   \n",
       "2  [{'version': 'v1', 'created': 'Sun, 1 Apr 2007...  2008-01-13   \n",
       "3  [{'version': 'v1', 'created': 'Sat, 31 Mar 200...  2007-05-23   \n",
       "4  [{'version': 'v1', 'created': 'Mon, 2 Apr 2007...  2013-10-15   \n",
       "\n",
       "                                      authors_parsed  \n",
       "0  [[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...  \n",
       "1           [[Streinu, Ileana, ], [Theran, Louis, ]]  \n",
       "2                                 [[Pan, Hongjun, ]]  \n",
       "3                                [[Callan, David, ]]  \n",
       "4  [[Abu-Shammala, Wael, ], [Torchinsky, Alberto, ]]  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(df.shape)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that it is very large, but we will only keep the articles having the cs.CL category (Computational Linguistics), possibly among others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59167, 14)\n"
     ]
    }
   ],
   "source": [
    "# df_NLP = df[df[\"categories\"].str.contains(\"cs.CL\")]\n",
    "# print(df_NLP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journal-ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>report-no</th>\n",
       "      <th>categories</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>0704.2083</td>\n",
       "      <td>Hassan Satori</td>\n",
       "      <td>H. Satori, M. Harti and N. Chenfour</td>\n",
       "      <td>Introduction to Arabic Speech Recognition Usin...</td>\n",
       "      <td>4 pages, 3 figures and 2 tables, was in Inform...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.CL cs.AI</td>\n",
       "      <td>None</td>\n",
       "      <td>In this paper Arabic was investigated from t...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Tue, 17 Apr 200...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[[Satori, H., ], [Harti, M., ], [Chenfour, N., ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>0704.2201</td>\n",
       "      <td>Hassan Satori</td>\n",
       "      <td>H. Satori, M. Harti and N. Chenfour</td>\n",
       "      <td>Arabic Speech Recognition System using CMU-Sph...</td>\n",
       "      <td>5 pages, 3 figures and 2 tables, in French</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.CL cs.AI</td>\n",
       "      <td>None</td>\n",
       "      <td>In this paper we present the creation of an ...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Tue, 17 Apr 200...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[[Satori, H., ], [Harti, M., ], [Chenfour, N., ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>0704.3662</td>\n",
       "      <td>Tian-Jian Jiang</td>\n",
       "      <td>Mike Tian-Jian Jiang, James Zhan, Jaimie Lin, ...</td>\n",
       "      <td>An Automated Evaluation Metric for Chinese Tex...</td>\n",
       "      <td>8 pages</td>\n",
       "      <td>Jiang, Mike Tian-Jian, et al. \"Robustness anal...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.HC cs.CL</td>\n",
       "      <td>None</td>\n",
       "      <td>In this paper, we propose an automated evalu...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Fri, 27 Apr 200...</td>\n",
       "      <td>2013-10-29</td>\n",
       "      <td>[[Jiang, Mike Tian-Jian, ], [Zhan, James, ], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3664</th>\n",
       "      <td>0704.3665</td>\n",
       "      <td>Tian-Jian Jiang</td>\n",
       "      <td>Mike Tian-Jian Jiang, Deng Liu, Meng-Juei Hsie...</td>\n",
       "      <td>On the Development of Text Input Method - Less...</td>\n",
       "      <td>10 pages</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.CL cs.HC</td>\n",
       "      <td>None</td>\n",
       "      <td>Intelligent Input Methods (IM) are essential...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Fri, 27 Apr 200...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[[Jiang, Mike Tian-Jian, ], [Liu, Deng, ], [Hs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>0704.3708</td>\n",
       "      <td>Bernat Corominas-Murtra BCM</td>\n",
       "      <td>Bernat Corominas-Murtra</td>\n",
       "      <td>Network statistics on early English Syntax: St...</td>\n",
       "      <td>New abstract. Due to a mistake, abstract from ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>None</td>\n",
       "      <td>This paper includes a reflection on the role...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Fri, 27 Apr 200...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[[Corominas-Murtra, Bernat, ]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                    submitter  \\\n",
       "2082  0704.2083                Hassan Satori   \n",
       "2200  0704.2201                Hassan Satori   \n",
       "3661  0704.3662              Tian-Jian Jiang   \n",
       "3664  0704.3665              Tian-Jian Jiang   \n",
       "3707  0704.3708  Bernat Corominas-Murtra BCM   \n",
       "\n",
       "                                                authors  \\\n",
       "2082                H. Satori, M. Harti and N. Chenfour   \n",
       "2200                H. Satori, M. Harti and N. Chenfour   \n",
       "3661  Mike Tian-Jian Jiang, James Zhan, Jaimie Lin, ...   \n",
       "3664  Mike Tian-Jian Jiang, Deng Liu, Meng-Juei Hsie...   \n",
       "3707                            Bernat Corominas-Murtra   \n",
       "\n",
       "                                                  title  \\\n",
       "2082  Introduction to Arabic Speech Recognition Usin...   \n",
       "2200  Arabic Speech Recognition System using CMU-Sph...   \n",
       "3661  An Automated Evaluation Metric for Chinese Tex...   \n",
       "3664  On the Development of Text Input Method - Less...   \n",
       "3707  Network statistics on early English Syntax: St...   \n",
       "\n",
       "                                               comments  \\\n",
       "2082  4 pages, 3 figures and 2 tables, was in Inform...   \n",
       "2200         5 pages, 3 figures and 2 tables, in French   \n",
       "3661                                            8 pages   \n",
       "3664                                           10 pages   \n",
       "3707  New abstract. Due to a mistake, abstract from ...   \n",
       "\n",
       "                                            journal-ref   doi report-no  \\\n",
       "2082                                               None  None      None   \n",
       "2200                                               None  None      None   \n",
       "3661  Jiang, Mike Tian-Jian, et al. \"Robustness anal...  None      None   \n",
       "3664                                               None  None      None   \n",
       "3707                                               None  None      None   \n",
       "\n",
       "       categories license                                           abstract  \\\n",
       "2082  cs.CL cs.AI    None    In this paper Arabic was investigated from t...   \n",
       "2200  cs.CL cs.AI    None    In this paper we present the creation of an ...   \n",
       "3661  cs.HC cs.CL    None    In this paper, we propose an automated evalu...   \n",
       "3664  cs.CL cs.HC    None    Intelligent Input Methods (IM) are essential...   \n",
       "3707        cs.CL    None    This paper includes a reflection on the role...   \n",
       "\n",
       "                                               versions update_date  \\\n",
       "2082  [{'version': 'v1', 'created': 'Tue, 17 Apr 200...  2007-05-23   \n",
       "2200  [{'version': 'v1', 'created': 'Tue, 17 Apr 200...  2007-05-23   \n",
       "3661  [{'version': 'v1', 'created': 'Fri, 27 Apr 200...  2013-10-29   \n",
       "3664  [{'version': 'v1', 'created': 'Fri, 27 Apr 200...  2007-05-23   \n",
       "3707  [{'version': 'v1', 'created': 'Fri, 27 Apr 200...  2007-05-23   \n",
       "\n",
       "                                         authors_parsed  \n",
       "2082  [[Satori, H., ], [Harti, M., ], [Chenfour, N., ]]  \n",
       "2200  [[Satori, H., ], [Harti, M., ], [Chenfour, N., ]]  \n",
       "3661  [[Jiang, Mike Tian-Jian, ], [Zhan, James, ], [...  \n",
       "3664  [[Jiang, Mike Tian-Jian, ], [Liu, Deng, ], [Hs...  \n",
       "3707                     [[Corominas-Murtra, Bernat, ]]  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_NLP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NLP.to_csv(\"../data/arxiv/arxiv-metadata-nlp.csv\", index = False)\n",
    "df_NLP = pd.read_csv(\"../data/arxiv/arxiv-metadata-nlp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we remove papers having a journal ref or a DOI, indicating that they have been published."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50857, 14)\n"
     ]
    }
   ],
   "source": [
    "unpublished_NLP = df_NLP[df_NLP[\"journal-ref\"].isnull() & df_NLP[\"doi\"].isnull()]\n",
    "print(unpublished_NLP.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case the paper has been published after being first put in arXiv, and the authors haven't updated its information, we will check that the title of the paper is not already in the ACL Anthology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'introductiontoarabicspeechrecognitionusingcmusphinxsystem'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather all (supposedly) unpublished titles from the arxiv NLP corpus\n",
    "all_unpublished_titles = []\n",
    "for t in list(unpublished_NLP[\"title\"]):\n",
    "    #t = utils.Author.Author.normalize_str(t).lower()\n",
    "    nt = re.sub(re.compile('[^a-z]'), \"\", t.lower())\n",
    "    all_unpublished_titles.append((t, nt))\n",
    "\n",
    "all_unpublished_titles[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'@inproceedings{zhu-etal-2024-resolving,    title = \"Resolving Transcription Ambiguity in {S}panish: A Hybrid Acoustic-Lexical System for Punctuation Restoration\",    author = \"Zhu, Xiliang  and      Chang, Chia-Tien  and      Gardiner, Shayna  and      Rossouw, David  and      Robertson, Jonas\",    editor = \"Pyatkin, Valentina  and      Fried, Daniel  and      Stengel-Eskin, Elias  and      Stengel-Eskin, Elias  and      Liu, Alisa  and      Pezzelle, Sandro\",    booktitle = \"Proceedings of the Third Workshop on Understanding Implicit and Underspecified Language\",    month = mar,    year = \"2024\",    address = \"Malta\",    publisher = \"Association for Computational Linguistics\",    url = \"https://aclanthology.org/2024.unimplicit-1.3\",    pages = \"33--41\",'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the full acl anthology to gather all acl papers titles and authors\n",
    "with open(\"C:/Users/cleme/Documents/STAGE/claims-in-NLP/data/acl/anthology.bib\", \"r\", encoding=\"utf-8\", errors = \"ignore\") as f:\n",
    "    antho = str(f.read())\n",
    "\n",
    "papers = [p.replace(\"\\n\", \"\") for p in antho.split(\"\\n}\\n\")]\n",
    "print(len(papers))\n",
    "papers[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Resolving Transcription Ambiguity in {S}panish: A Hybrid Acoustic-Lexical System for Punctuation Restoration']\n",
      "['Zhu, Xiliang  and      Chang, Chia-Tien  and      Gardiner, Shayna  and      Rossouw, David  and      Robertson, Jonas']\n",
      "['https://aclanthology.org/2024.unimplicit-1.3']\n"
     ]
    }
   ],
   "source": [
    "# example on one paper\n",
    "tp = re.compile(r\" title = \\\"(.*?)\\\",\")\n",
    "ap = re.compile(r\" author = \\\"(.*?)\\\",\")\n",
    "lp = re.compile(r\" url = \\\"(.*?)\\\",\")\n",
    "\n",
    "print(re.findall(tp, papers[14]))\n",
    "print(re.findall(ap, papers[14]))\n",
    "print(re.findall(lp, papers[14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all the titles and authors of the papers in the anthology\n",
    "import utils.Author\n",
    "antho_papers = []\n",
    "\n",
    "for p in papers:\n",
    "\n",
    "    # catch the title\n",
    "    t = re.findall(tp, p)\n",
    "    if len(t) > 0:\n",
    "        #t = utils.Author.Author.normalize_str(t[0]).lower()\n",
    "        nt = re.sub(re.compile('[^a-z]'), \"\", t[0].lower())\n",
    "    else:\n",
    "        nt = \"\"\n",
    "\n",
    "    # catch the authors\n",
    "    authors = re.findall(ap, p)\n",
    "    if len(authors) > 0:\n",
    "        al = []\n",
    "        als = authors[0].replace(\"\\n\", \"\").split(\" and \")\n",
    "        for a in als:\n",
    "            names = a.split(\",\")\n",
    "            ao = utils.Author.Author(names = [n.strip() for n in names])\n",
    "            ao.normalize_names()\n",
    "            al.append(ao)\n",
    "    else:\n",
    "        al = []\n",
    "\n",
    "    # catch the url\n",
    "    url = re.findall(lp, p)\n",
    "    if len(url) > 0:\n",
    "        u = url[0]\n",
    "    else:\n",
    "        u = \"\"\n",
    "\n",
    "    antho_papers.append(((t, nt), al, u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('resolving transcription ambiguity in {s}panish: a hybrid acoustic-lexical system for punctuation restoration', 'resolvingtranscriptionambiguityinspanishahybridacousticlexicalsystemforpunctuationrestoration')\n",
      "[<utils.Author.Author object at 0x0000021A0AE35910>, <utils.Author.Author object at 0x0000021A0AE36710>, <utils.Author.Author object at 0x0000021A0AE37090>, <utils.Author.Author object at 0x0000021A0AE36810>, <utils.Author.Author object at 0x0000021A0AE35FD0>]\n",
      "https://aclanthology.org/2024.unimplicit-1.3\n",
      "['Zhu', 'Xiliang']\n",
      "['Chang', 'Chia-Tien']\n"
     ]
    }
   ],
   "source": [
    "print(antho_papers[14][0])\n",
    "print(antho_papers[14][1])\n",
    "print(antho_papers[14][2])\n",
    "print(antho_papers[14][1][0].norm_names)\n",
    "print(antho_papers[14][1][1].norm_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the arxiv papers whose title is already found in the ACL Anthology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'jointpropjointsemisupervisedlearningforentityandrelationextractionwithheterogeneousgraphbasedpropagation'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ACL_titles = [t_and_a[0][1] for t_and_a in antho_papers]\n",
    "inter = set([t[1] for t in all_unpublished_titles]).intersection(set(all_ACL_titles))\n",
    "print(len(inter))\n",
    "list(inter)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33817, 14)\n"
     ]
    }
   ],
   "source": [
    "# # remove from the arxiv NLP corpus the papers that are already in the intersection\n",
    "# unpublished_NLP = unpublished_NLP[~unpublished_NLP[\"title\"].str.lower().str.replace(re.compile('[^a-z]'), \"\", regex = True).isin(inter)]\n",
    "# # reset the index\n",
    "# unpublished_NLP.reset_index(drop = True, inplace = True)\n",
    "# unpublished_NLP.to_csv(\"../data/arxiv/arxiv-metadata-nlp-unpublished.csv\", index = False)\n",
    "unpublished_NLP = pd.read_csv(\"../data/arxiv/arxiv-metadata-nlp-unpublished.csv\")\n",
    "print(unpublished_NLP.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check using the editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://aclanthology.org/2024.wnut-1.0'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antho_papers[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO BE RAN LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "introductiontoarabicspeechrecognitionusingcmusphinxsystem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 146/33817 [06:20<24:22:09,  2.61s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line -1\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import editdistance\n",
    "\n",
    "antho_titles = [t[0][1] for t in antho_papers]\n",
    "all_unpublished_titles = [re.sub(re.compile('[^a-z]'), \"\", t.lower()) for t in unpublished_NLP[\"title\"]]\n",
    "print(all_unpublished_titles[0])\n",
    "\n",
    "ambig = []\n",
    "\n",
    "for i, t in tqdm.tqdm(enumerate(all_unpublished_titles), total = len(all_unpublished_titles)):\n",
    "    for j, t_antho in enumerate(antho_titles):\n",
    "        ed = editdistance.eval(t, t_antho.lower())\n",
    "        if ed <= 5:\n",
    "            print(t, \"\\n\", t_antho, \"\\n\")\n",
    "            ambig.append([i, unpublished_NLP.at[i, \"id\"], t, t_antho, antho_papers[j][2], ed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambig_df = pd.DataFrame(ambig, columns = [\"index\", \"arxiv_id\", \"arxiv_title\", \"antho_title\", \"antho_url\", \"edit_distance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editdistance.eval(\"multispeech\", \" multispeecher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33817it [06:51, 82.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ambig = []\n",
    "\n",
    "# for i, aset_arxiv in tqdm.tqdm(enumerate(all_arxiv_authors_fn)):\n",
    "#     for j, aset_acl in enumerate(all_ACL_authors_fn):\n",
    "#         if aset_arxiv == aset_acl:\n",
    "#             arxiv_row = unpublished_NLP.loc[i]\n",
    "#             ambig.append((arxiv_row[\"id\"], arxiv_row[\"title\"], arxiv_row[\"authors_parsed\"], arxiv_row[\"abstract\"], antho_papers[j][0], antho_papers[j][1], antho_papers[j][2]))\n",
    "\n",
    "# print(len(ambig)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Trop de bruit avec la stratégie des auteurs, pas possible de vérifier 25k articles, voir si on utilise les commentaires, voir si on exclut les articles trop récents (e.g TBP in LREC-Coling 2024)  \n",
    "EN ATTENDANT: on reste sur la liste des 33 817 articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14 pages, 5 figures, unpublished',\n",
       " 'unpublished manuscript',\n",
       " '5 pages, 1 figure, unpublished',\n",
       " '21 pages, 4 figures, 5 tables. Old (2012) unpublished manuscript',\n",
       " 'unpublished',\n",
       " '8 pages, 2010, unpublished',\n",
       " '12 pages, 2014, unpublished',\n",
       " 'Reprint of an unpublished 2010 Working Note',\n",
       " '17 pages, 4 figures, 3 tables, unpublished (comments welcome)',\n",
       " 'unpublished preprint',\n",
       " '8 pages; unpublished contribution to the PharmaCoNER shared task held\\n  as part of BioNLP-OST 2019',\n",
       " 'unpublished short paper',\n",
       " 'An unpublished survey',\n",
       " '2021, non-print, unpublished version',\n",
       " 'Technical report, unpublished']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(c) for c in unpublished_NLP[\"comments\"].values if \"unpublished\" in str(c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10 pages, 1 figure, 3 tables, in Russian, short version of the paper\\n  to be published in Proceedings of the Wiki-Conference 2007, Russia, St.\\n  Petersburg, October 27-28. http://tinyurl.com/2czd6e ; v3: +figure; v4: typo\\n  in Table 3; v5: +desc (res_hypo formula); v6: typo',\n",
       " 'latex2e, 8 pages, 1 figure, published in the Proceedings of\\n  Cross-Language Knowledge Induction Workshop, 2005 Cluj-Napoca, held during\\n  the summer school EUROLAN 2005',\n",
       " \"13 pages, to be presented at QI'11, to be published in LNCS\\n  (Springer)\",\n",
       " '11 pages, 2 figures. To be published in the proceedings of Quantum\\n  Interaction 2011',\n",
       " '10 pages, 3 figures, 3 tables, short paper version published in JCDL\\n  2011',\n",
       " '14 pages, 14 figures, published in IJWEST Journal',\n",
       " 'This version supercedes the short version of this paper published in\\n  the proceedings of WWW 2012',\n",
       " \"Draft of the chapter published In: Explorations Across Languages and\\n  Corpora. PALC 2009, ed. by S. Go\\\\'zd\\\\'z-Roszkowski, Peter Lang, 2011, p.\\n  123-133\",\n",
       " \"This is a draft of a book chapter to be published in 2014 by\\n  Scarecrow Press. Please cite as: Yasseri T., Spoerri A., Graham M., and\\n  Kert\\\\'esz J., The most controversial topics in Wikipedia: A multilingual and\\n  geographical analysis. In: Fichman P., Hara N., editors, Global\\n  Wikipedia:International and cross-cultural issues in online collaboration.\\n  Scarecrow Press (2014)\",\n",
       " 'To be published in Journal of the American Society for Information\\n  Science and Technology',\n",
       " '37 pages, 8 figures A short version of this paper was already\\n  published at ECML/PKDD 2012',\n",
       " 'to be published in: Proceedings of the Sixth Text Analysis Conference\\n  (TAC 2013)',\n",
       " '12 pages with 3 figures, to be published in \"International Conference\\n  on Foundations of Computer Science & Technology (CST 2014), Zurich,\\n  Switzerland - January 2014 Proceedings, AIRCC\"',\n",
       " '9 pages, published on International Journal on Computational Sciences\\n  & Applications (IJCSA) Vol.3, No.6, December 2013',\n",
       " 'Presented at Russian Summer School in Information Retrieval (RuSSIR\\n  2014). To be published in Springer Communications in Computer and Information\\n  Science series',\n",
       " 'This paper have been presented and published in 10th International\\n  Conference on Terminology and Artificial Intelligence Proceedings',\n",
       " '10 pages, 2 figures, published at ICLR 2015',\n",
       " '12 pages, published as conference paper at ICLR 2015',\n",
       " '47 pages; 3 figures; 25 tables. Also published as ICSI Technical\\n  Report TR-15-001',\n",
       " '4 pages, 4 figures, not published',\n",
       " 'To be published in the INTERSPEECH 2015 proceedings',\n",
       " 'Conflict between recently published and arxiv versions',\n",
       " '10 pages, published as a conference paper at ICLR 2016',\n",
       " 'To be published in the proceedings of INTERSPEECH 2016',\n",
       " '6 pages, 3 figures, published at IEEE SLT 2016. arXiv admin note:\\n  text overlap with arXiv:1610.05812',\n",
       " 'Re-written abstract and intro, other minor changes throughout. This\\n  version published at AAAI 2017',\n",
       " 'paper accepted on Cicling 2016 conference, will be published in\\n  Springer',\n",
       " 'This is the non-final version of the paper. The final version is\\n  published in the IC3INA 2016 Conference (3-5 Oct. 2016,\\n  http://situs.opi.lipi.go.id/ic3ina2016/). All citation should be directed to\\n  the final version',\n",
       " 'Further experiments were performed on the model using LibriVox speech\\n  dataset and it was found that a Time Distributed CRNN model performed better\\n  and represented our initial ideas about the speaker recognition task better.\\n  The dataset contains speech in three languages - English, Spanish and Czech.\\n  A report on our findings along with experimental results will be published\\n  soon',\n",
       " '30 pages, Accepted to be published in \"Applications of Comparable\\n  Corpora\", Berlin: Language Science Press',\n",
       " '16 pages, accepted to be published in \"Applications of Comparable\\n  Corpora\", Berlin: Language Science Press',\n",
       " \"4 pages, 1 figure, published at ICWSM'17\",\n",
       " \"10 pages, published at ICWSM'17\",\n",
       " 'This paper was published at ICWSM 2017 as a full paper, Proc. of the\\n  11th International AAAI Conference on Web and Social Media (ICWSM 2017).\\n  Montreal, Canada. 2017',\n",
       " '34 pages. 9 page version of this paper published at EMNLP 2017',\n",
       " 'Accepted to be published at The 26th ACM International Conference on\\n  Information and Knowledge Management (CIKM2017)',\n",
       " 'A paper with a similar method has been published earlier at\\n  arXiv:1706.04815 The authors believe there is no need for a separate\\n  publication',\n",
       " '7 pages, 3 figures, camera-ready version published on AAAI 2016',\n",
       " 'To be published in the proceedings of NIPS 2017',\n",
       " '5 pages conference paper accepted to IEEE ASRU 2017. Will be\\n  published in December 2017',\n",
       " '6 pages, published in Workshop on Learning with Limited Labeled Data\\n  co-held with NIPS 2017',\n",
       " '6 pages, 3 figures, published at IEEE ASRU 2017',\n",
       " '5 pages conference paper accepted to IEEE ASRU 2017. Will be\\n  published in December 2017',\n",
       " 'To be published at AAAI 2018',\n",
       " 'to be published at the 3rd conference of the association of Digital\\n  Humanities in the Nordic Countries (DHN), 2018',\n",
       " 'A short version of this paper has been published in Proc. 21st\\n  Workshop on the Semantics and Pragmatics of Dialogue (SemDial/SaarDial)',\n",
       " 'This paper is published on the 12th ACM Conference on Recommender\\n  Systems, Vancouver, Canada, 2nd-7th October 2018',\n",
       " 'Correction (bug fix) of a published ODYSSEY 2018 publication with the\\n  same title and author list; more details in footnote in page 1',\n",
       " 'This is an updated version of the paper that has been accepted at\\n  Speech Prosody 2018 and published on the ISCA archive. The updates consist of\\n  minor corrections that do not change the main conclusions in this work',\n",
       " '9 pages, 4 figures. This paper has been published by AAAI2018',\n",
       " 'To appear in Proc. of Semantic Web for Social Good Workshop of the\\n  Int. Semantic Web Conf., Oct 2018 and published as part of the book \"Emerging\\n  Topics in Semantic Technologies. ISWC 2018 Satellite Events\", E. Demidova,\\n  A.J. Zaveri, E. Simperl (Eds.), ISBN: 978-3-89838-736-1, 2018, AKA Verlag\\n  Berlin, (edited authors)',\n",
       " 'Paper: 18 pages, 5 figures, 5 tables. Supplementary material: 3\\n  pages, 1 figure, 1 table. To be published in VLEASE ECCV 2018 workshop',\n",
       " \"6 pages article, published in LTC'17 The 8th Language & Technology\\n  Conference, Poznan, Poland\",\n",
       " 'The paper was published in SLT 2018 conference',\n",
       " 'To be published in AAAI 2019',\n",
       " 'Accepted at the 26th Irish Conference on Artificial Intelligence and\\n  Cognitive Science. This paper is an extended version of a poster published at\\n  the 12th ACM Conference on Recommender Systems, Proceedings of the 26th Irish\\n  Conference on Artificial Intelligence and Cognitive Science (AICS). Dublin,\\n  Ireland 2018',\n",
       " 'Chapter 5 of this memoir has been augmented and published at\\n  COLING2018 under the reference: Butterfly Effects in Frame Semantic Parsing:\\n  impact of data processing on model ranking',\n",
       " 'The paper is accepted to be published in IJCNN 2019',\n",
       " '4 pages, 2 figures, published in anlp.jp 2019',\n",
       " '10 pages, 2 figures, 2 tables. To be published in the Proceedings of\\n  the Thirteenth International Workshop on Juris-informatics (JURISIN 2019),\\n  hosted by JSAI-isAI2019',\n",
       " 'to be published in Proceedings of International Conference on Machine\\n  Learning 2020 (ICML)',\n",
       " 'This short article is obsolete, as its content is contained in the\\n  full paper arXiv:1908.11046, which will also be published by AAAI 2020',\n",
       " 'Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\\n  Abstract The original paper was published in December 2019. After\\n  publication, we identified a bug in our code that resulted in an error in our\\n  reported results. This version of the paper corrects that error and clarifies\\n  some of our descriptions of the experiments',\n",
       " 'To be published in the proceedings of the 33rd Conference on Neural\\n  Information Processing Systems (NeurIPS 2019), Vancouver, Canada',\n",
       " '2 figures, 12 pages. Presented at the 32nd International Conference\\n  on Legal Knowledge and Information Systems (JURIX 2019) and to be published\\n  in the CEUR Workshop Proceedings',\n",
       " '12 pages, 3 figures and 3 tables. Accepted in 20th International\\n  Conference on Intelligent Text Processing and Computational Linguistics,\\n  CICLing 2019. To be published in Springer LNCS volume',\n",
       " 'To be published in FLAIRS33 (https://www.flairs-33.info/) and appear\\n  in he proceedings of AAAI',\n",
       " 'To be published in FLAIRS33 (https://www.flairs-33.info/) and appear\\n  in he proceedings of AAAI',\n",
       " 'Also published in ICLR2020\\n  https://openreview.net/forum?id=BJlguT4YPr&noteId=BJlguT4YPr',\n",
       " 'To be published in: Lecture Notes in Artificial Intelligence, 1st\\n  International Conference on Artificial Intelligence in HCI, AI-HCI, Held as\\n  Part of HCI International 2020, Kopenhagen, Denmark, July 19-24, Springer',\n",
       " \"This is the author's prefinal version be published in conference\\n  proceedings: 4th International Conference on Natural Language Processing and\\n  Information Retrieval, Sejong, South Korea, 26-28 June, 2020, ACM\",\n",
       " 'To be published in The 24th Pacific-Asia Conference on Knowledge\\n  Discovery and Data Mining (PAKDD 2020)',\n",
       " '8 pages, 5 figures, published in AAAI 2020',\n",
       " 'To be published in IEEE conference proceedings: International\\n  Conference on Artificial Intelligence in Information and Communication,\\n  ICAIIC 2020',\n",
       " 'To be published in CogSci 2020',\n",
       " \"This paper was officially published at the 'Language Learning for\\n  Artificial Agents (L2A2) Symposium' of the 2019 Artificial Intelligence and\\n  Simulation of Behaviour (AISB) Convention\",\n",
       " 'To be published in: Annotations in Scholarly Editions and Research:\\n  Functions, Differentiation, Systematization (2020), Julia Nantke and Frederik\\n  Schlupkothen (editors). De Gruyter. In print',\n",
       " '26 pages, 14 Figures, to be published in Mathematical Problems in\\n  Engineering',\n",
       " 'This paper was published at the LDA 2019 workshop in the JURIX 2019\\n  conference',\n",
       " 'Work done by Maharshi R. Pandya and Jessica Reyes as IBM interns\\n  under leadership of Bob Vanderheyden. Article to be published',\n",
       " '10 pages, Abstract published in A2IC 2018\\n  (https://www.premc.org/doc/A2IC2018/A2IC2018_Book_Of_Abstracts.pdf)',\n",
       " 'To be published in Proceedings of the the 21st International\\n  Conference on Artificial Intelligence in Education (AIED 2020)',\n",
       " '2 pages, 1 figure, to be published in conference JNIC 2020',\n",
       " '4 pages, 2 figures, to be published in conference JNIC 2020',\n",
       " 'Some computational errors corrected. The final version of this draft\\n  was published in Jpurnal of Logic and Computation, Oxford University press',\n",
       " 'To be published in the proceedings of the 2020 Annual Meeting of the\\n  Cognitive Science Society (COGSCI). Supplemental materials available at\\n  https://osf.io/qse7y/',\n",
       " 'Please cite the published version, see proceedings of ICWSM 2020',\n",
       " '6 pages, Accepted and to be published in AFRICON 2021',\n",
       " '9 pages, published at ICLR 2021',\n",
       " 'Paper published in TMLR',\n",
       " 'Paper has been published in the AAAI2021 conference',\n",
       " '12 pages, ICACIE 2020, Will be published by Advances in Intelligent\\n  Systems and Computing (AISC) series of Springer',\n",
       " 'This paper was originally submitted to EMNLP 2015 and has not been\\n  previously published',\n",
       " 'Changed title and few more changes. This version will be published in\\n  SemEval2020. Added code Link',\n",
       " 'To be published in the proceedings of the ACM/IEEE Joint Conference\\n  on Digital Libraries (JCDL 2020)',\n",
       " 'To be published in Proceedings of SPECOM 2020',\n",
       " 'First published in the Workshop on Algorithmic Foundations of\\n  Robotics 2020, and extended version invited to a Special Issue in the\\n  International Journal of Robotics Research',\n",
       " 'Parts of content are published on CIKM 2020',\n",
       " 'To be published in the Proceedings of AMIA 2020 Annual Symposium',\n",
       " 'To be published at INTERSPEECH 2021, Brno, Czechia',\n",
       " '12 pages, 3 figures, paper to be published in 20th International\\n  Conference on Computational Linguistics and Intelligent Text Processing\\n  (CICLing 2019)',\n",
       " '10 pages, to be published at Proceedings of IJCAI-2021',\n",
       " '11 pages, 12 figures, to be published in IEEE Transactions on\\n  Visualization and Computer Graphics',\n",
       " 'A revised version of this work has been published in AAAI-2021 with\\n  title: \"Lifelong and Continual Learning Dialogue Systems: Learning during\\n  Conversation\". Please use this revised AAAI-21 version for citation',\n",
       " 'To be published in the proceedings of Ivannikov Memorial Workshop\\n  2020',\n",
       " '5 pages, to be published in Interspeech 2020',\n",
       " '9 pages, published at the CMLA 2020 conference',\n",
       " 'First published in 2020. Accepted at Machine Learning for Healthcare\\n  (MLHC) 2022',\n",
       " '5 pages, to be published in Interspeech 2020',\n",
       " '5 pages, published in ICASSP 2020',\n",
       " 'Paper accepted - to be published',\n",
       " '18 pages, 2 figures, to be published in SALT 30',\n",
       " '18 pages, 4 figures, published in JWS',\n",
       " '27 pages, 5 figures, 19 tables. To be published in the 34th\\n  conference on Neural Information Processing Systems (NeurIPS 2020). The first\\n  two authors contributed equally to this work',\n",
       " 'Also be published in JURISIN2020',\n",
       " 'Chapter published in the book Maschinelle \\\\\"Ubersetzung f\\\\\"ur\\n  \\\\\"Ubersetzungsprofis (pp. 276-295). J\\\\\"org Porsiel (Ed.), BD\\\\\"U Fachverlag,\\n  2020. ISBN 978-3-946702-09-2',\n",
       " 'PhD thesis submitted at Heriot-Watt University. Contains previously\\n  published work (see the list in Section 1.4)',\n",
       " '17 pages, 4 figures, to be published in Advances in Intelligent\\n  Systems and Computing, Appendixed by Vivek Khetan',\n",
       " '23 pages, 4 main figures, 10 appendix figures; published as a\\n  conference paper at ICLR 2021',\n",
       " 'To be published in Proceedings of ACM SIGIR Workshop on eCommerce\\n  (SIGIR eCom 20) 2020',\n",
       " '8 pages, published in The 2020 IEEE/WIC/ACM International Joint\\n  Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT 2020)',\n",
       " '10 pages, 1 figure, to be published in Proceedings of the 8th\\n  International Workshop on News Recommendation and Analytics (INRA 2020)',\n",
       " 'To be published in: FIRE (Working Notes) 2020, Hate Speech and\\n  Offensive Content Identification in Indo-European Languages, HASOC 2020',\n",
       " 'To be published in: Proceedings of the First Workshop on Combating\\n  Online Hostile Posts in Regional Languages during Emergency Situation\\n  (CONSTRAINT) at AAAI 2021',\n",
       " 'to be published in Constraint-2021 Workshop @ AAAI',\n",
       " '11 pages, 2 figures. Presented the paper at Third International\\n  Conference on Soft Computing and Signal Processing (ICSCSP 2020) and is\\n  currently in production. It will soon be published in springer Advances in\\n  Intelligent Systems and Computing (AISC) series',\n",
       " 'To be published in the 15th IEEE International Conference on Semantic\\n  Computing',\n",
       " 'This article is a preprint version of the article published in\\n  Computer Speech & Language, Volume 72, March 2022, 101317',\n",
       " '6 pages, 2 figures, to be published in 25th International Conference\\n  on Pattern Recognition, ICPR2020',\n",
       " '6 pages, 4 figures, to be published in 25th International Conference\\n  on Pattern Recognition, ICPR 2020',\n",
       " '7 pages, 1 figure, to be published in 25th International Conference\\n  on Pattern Recognition, ICPR 2020',\n",
       " '16 pages, 5 figures. To be published in EPJ Data Science',\n",
       " 'This paper has been published in the Proceedings of the Seventh\\n  Italian Conference on Computational Linguistics, CLiC-it 2020',\n",
       " '17 pages, 4 tables, 7 figures, published in the conference proceeding',\n",
       " '8 pages, 15 pages supplementary, 12 figures. To be published in CVPR\\n  2021',\n",
       " '16 pages (without references). To be published in PBML 116',\n",
       " 'This document was originally published as a blog post on the web site\\n  of GeBNLP 2020',\n",
       " 'It is accepted to be published in Journal of Healthcare Informatics\\n  Research',\n",
       " '9 pages, 2 figures, 6 tables, accepted in 20th International\\n  Conference on Intelligent Text Processing and Computational Linguistics,\\n  CICLing 2019. To be published in Springer LNCS volume',\n",
       " 'This paper was published out of a shallow and simple idea. Now I find\\n  that the research is still not detailed enough. So I submit withdrawal',\n",
       " 'This work was presented at ICAAIML2020 and will be published in\\n  Lecture Notes in Electrical Engineering',\n",
       " '2 pages, 1 figure, 1 table. To be published in Phonetics and\\n  Phonology in Europe 2021',\n",
       " 'To be published at ICDAR 2021',\n",
       " '9 pages, original work published in AAAI 2019',\n",
       " 'to be published in INTERSPEECH2021',\n",
       " 'To be published in: \"32. GI-Workshop Grundlagen von Datenbanken\"',\n",
       " 'to be published in SwissText 2021',\n",
       " 'to be published at INTERSPEECH 2021',\n",
       " \"Also published in COLIEE 2021's Proceeding\",\n",
       " \"Also published in COLIEE 2021's proceeding\",\n",
       " '5 Pages, original work published at ICASSP 2021',\n",
       " 'To be published in GeBNLP 2021 conference proceedings',\n",
       " 'Outdated. Superseded by arXiv:2112.05224 and published at IEEE S&P\\'22\\n  with title: \"Spinning Language Models: Risks of Propaganda-As-A-Service and\\n  Countermeasures\"',\n",
       " 'Will be published in Interspeech 2021',\n",
       " '6 pages, Accepted and to be published in AFRICON 2021',\n",
       " 'Paper published at Symposium in Information and Human Language\\n  Technology (STIL 2021)',\n",
       " 'To be published on ICCV 2021. Webpage is at\\n  https://airbert-vln.github.io/ linking to our dataset, codes and models',\n",
       " '8 pages, 3 figures, To be published in: Translation Inference Across\\n  Dictionaries 2021 Shared Task, Language Data and Knowledge 2021',\n",
       " 'To be published in Computer Speech and Language Journal',\n",
       " '16 pages, 1 figure, in French, published in CORIA 2015 (Paris,\\n  France, 18th-20th March 2015)',\n",
       " 'To be published in SPECOM & ICR 2021 Electronic Proceedings by the\\n  Springer Nature',\n",
       " 'To be published in 22nd International Conference on Web Information\\n  Systems Engineering (WISE2021)',\n",
       " 'This is an extended version of a paper published in CLiC-it 2021 -\\n  Italian Conference on Computational Linguistics 2021 - Proceedings of the\\n  Eighth Italian Conference on Computational Linguistics Milan, Italy, January\\n  26-28, 2022. Edited by Elisabetta Fersini, Marco Passarotti, Viviana Patti.\\n  CEUR-WS.org, ISSN 1613-0073',\n",
       " \"7 pages, to be published in 36th IEEE/ACM International Conference on\\n  Automated Software Engineering Workshops (ASEW'21), November 15-19, 2021\",\n",
       " 'To be published in IEEE ICDM 2021',\n",
       " 'To be published in the 2022 IEEE Spoken Language Technology Workshop\\n  (SLT) (SLT 2022)',\n",
       " 'Accepted in PodRecs 2021, a RecSys workshop. The dataset has been\\n  published at https://zenodo.org/record/5765655#.YbFhS33MJTY',\n",
       " '40 pages, to be published in Information Processing and Management',\n",
       " '15 pages, 8 tables, 5 figures, published at Advances in Neural\\n  Information Processing Systems (NeurIPS), 2021',\n",
       " '5 pages, minor changes for camera ready version, to be published in\\n  IEEE ICASSP 2022',\n",
       " 'The result in this paper are obtained under a bug. Because we train\\n  our model under an evaluation setting (dropout and batch normalization are\\n  0.), but the dropout in our paper is 0.1. So, there is a big mistake in our\\n  paper and is not appropriate to published',\n",
       " '10 pages, 7 figures, 1 appendix, to be published in Neurips 2021',\n",
       " 'Paper was published at EMNLP 2022',\n",
       " '16 pages, 10 tables, 2 Figures. The DeBERTaV3 model significantly\\n  improves performance of the downstream NLU tasks over models with a similar\\n  structure, e.g. DeBERTaV3 large achieves 91.37% average GLUE score which is\\n  1.37% over DeBERTa large. XSmall has only 22M backbone parameters, but\\n  significantly outperforms RoBERTa/XLNet-base. Paper is published as a\\n  conference paper at ICLR 2023',\n",
       " 'Disclaimer: Cedric M\\\\\"oller, Jens Lehmann, Ricardo Usbeck, 2021. The\\n  definitive, peer reviewed and edited version of this article is published in\\n  the Semantic Web Journal, Special issue: Latest Advancements in Linguistic 3\\n  Linked Data, 2021',\n",
       " 'CVPR2022. The final published version of the proceedings will be\\n  available on IEEE Xplore',\n",
       " '6 pages, 2 figures, 6 tables. Accepted and presented at IEEE Latin\\n  American Conference on Computational Intelligence (LA-CCI 2021), but not yet\\n  published',\n",
       " 'To be published in the proceedings of the International Conference on\\n  Asian Language Information Processing',\n",
       " '19 pages. Under Review. Please cite published version, if available',\n",
       " 'Accepted as a book chapter in \"Cybersecurity & High-Performance\\n  Computing Environments: Integrated Innovations, Practices, and Applications\",\\n  published by Taylor and Francis. arXiv admin note: substantial text overlap\\n  with arXiv:2102.04081',\n",
       " '12 pages. To be published in proceedings of the AIST 2021 conference',\n",
       " 'To be published in Winter Conference on Applications of Computer\\n  Vision 2022',\n",
       " '23 pages, This paper is an extended version of a paper that will be\\n  published at the 36th AAAI Conference on Artificial Intelligence, to beheld\\n  in Vancouver, BC, Canada, February 22 - March 1, 2022',\n",
       " 'to be published at the AAAI-22 Workshop on Scientific Document\\n  Understanding',\n",
       " '10 pages, 1 figure, 3 tables. Accepted at International Conference on\\n  the Computational Processing of Portuguese (PROPOR 2022), but not yet\\n  published',\n",
       " 'To be published as a conference paper at ICLR 2022',\n",
       " '6 pages, published in the 2021 ASE RAISE workshop',\n",
       " 'This paper was published at NeurIPS 2022',\n",
       " 'To be published in AAAI 2022',\n",
       " 'To appear in AI Magazine (AAAI), 2023. This draft is an extended and\\n  revised version of the previous work - \"Self-initiated Open World Learning\\n  for Autonomous AI Agents\" arXiv preprint arXiv:2110.11385 (2021), which was\\n  published in AAAI 2022 Spring Symposium Series',\n",
       " 'A revised version of the one published at INTERSPEECH2022. The\\n  following parts have been modified: Section 2.2.2. The variance for screening\\n  paraphrases from 1.5 to 1.6 and the number of speech data and recorders;\\n  Section 2.4. The number of paraphrases from 1698 to 1697; Section 3, Table2.\\n  Values in two cells (Negation, P from 0.14 to 0.12) and (Leftward, P from\\n  0.10 to 0.12)',\n",
       " '46 pages, 11 figures, to be published in Journal of Business &\\n  Economic Statistics',\n",
       " 'Accepted to be published in the Proceedings of Interspeech 2022',\n",
       " 'To be published in the 2022 IEEE Spoken Language Technology Workshop\\n  (SLT) (SLT 2022)',\n",
       " 'The paper is published as part of TOTH 2020 proceedings\\n  (https://btk.univ-smb.fr/livres/toth-2020/)',\n",
       " 'This is the accepted version of the paper published at IEEE Spoken\\n  Language Technology (SLT) Workshop 2022',\n",
       " 'Accepted to be published in the Proceedings of Interspeech 2022',\n",
       " 'First three authors contributed equally; published at ISCA 2022',\n",
       " 'Accepted at 6th International Workshop on Health Intelligence,\\n  AAAI-2022. To appear in as a book chapter published by Springer in Studies in\\n  Computational Intelligence',\n",
       " 'To be published in 2022 Americas Conference on Information Systems',\n",
       " '25 pages, 7 figures, to be published in HCI International 2022 - Late\\n  Breaking Papers',\n",
       " '5 pages, to be published in IEEE ICASSP 2022',\n",
       " 'to be published in the Proceedings of the 15th International\\n  Conference on Educational Data Mining; 8 pages, 5 figures, 3 tables',\n",
       " 'To be published at ACM FAccT 2022',\n",
       " 'Camera-Ready Version of this paper published at ACL 2023\\n  (https://aclanthology.org/2023.acl-long.217/)',\n",
       " 'To be published at ACM FAccT 2022',\n",
       " 'Studies and Practices for Advancement in Open and Distance Education,\\n  edited by: Kam Cheong Li and Kin Sun Yuen, published by: Open University of\\n  Hong Kong. Pages: 222-234. Standard: 978-988-8238-13-2',\n",
       " '12pages, To be published in proceedings of AIED2022',\n",
       " 'To be published in AIED Late Breaking Results 2022',\n",
       " 'Accepted to be published in the Proceedings of InterSpeech 2022',\n",
       " 'Accepted to be published in the Proceedings of InterSpeech 2022',\n",
       " '12 pages, 9 tables, 2 figures, published in PST2022',\n",
       " 'To be published in the International Journal of Asian Language\\n  Processing. arXiv admin note: substantial text overlap with arXiv:2112.06462',\n",
       " 'Please cite the published version with the following information:\\n  @incollection{warstadt2022artificial, title={What artificial neural networks\\n  can tell us about human language acquisition}, author={Warstadt, Alex and\\n  Bowman, Samuel R.}, booktitle={Algebraic Structures in Natural Language},\\n  pages={17--60}, year={2022}, publisher={CRC Press} }',\n",
       " '10 pages, 2 figures, 7 tables. As published (with minor corrections)\\n  in the BioASQ 10 Workshop, Proceedings of the Working Notes of CLEF 2022 -\\n  Conference and Labs of the Evaluation Forum',\n",
       " 'To be published in the 19th International Conference on Artificial\\n  Intelligence and Law - ICAIL 2023',\n",
       " \"To be published in RecSys in HR'22\",\n",
       " 'Accepted to ACIIDS 2022. The proceedings of ACIIDS 2022 will be\\n  published by Springer in series Lecture Notes in Artificial Intelligence\\n  (LNAI) and Communications in Computer and Information Science (CCIS)',\n",
       " 'To be published in Baltic HLT 2022',\n",
       " '8 pages, 5 figures, published at 2023 IEEE 17th International\\n  Conference on Semantic Computing (ICSC)',\n",
       " 'Preprint version of the paper to be published in The International\\n  Conference and Workshop on Agglutinative Language Technologies as a challenge\\n  of Natural Language Processing (ALTNLP), June 6, 2022, Koper, Slovenia',\n",
       " 'Preprint of the paper to be published at The International Conference\\n  and Workshop on Agglutinative Language Technologies as a challenge of Natural\\n  Language Processing (ALTNLP), June 6, 2022, Koper, Slovenia',\n",
       " 'To be published in proceedings of IEEE International Conference on\\n  Machine Learning Applications IEEE ICMLA 2022',\n",
       " 'The Paper has been ACCEPTED at the \"2nd International Conference on\\n  Computing and Communication Networks(ICCCN-2022)\". This paper will be\\n  published by AIP publishing and DOI will be issued later on',\n",
       " 'This is a preprint of an article published in the Journal of\\n  Intelligent Information Systems, Springer. The final authenticated version is\\n  available online at\\n  https://link.springer.com/article/10.1007/s13278-022-00906-8',\n",
       " 'To be published in AAAI-23 Workshop on Uncertainty Reasoning and\\n  Quantification in Decision Making',\n",
       " '6 pages, to be published in Proceedings of ISP RAS Open Conference\\n  2022',\n",
       " '13 pages, 6 figures, published to AAAI',\n",
       " 'accepted to and published at \"A Participatory Approach to AI for\\n  Mental Health (PAI4MH)\" workshop, co-located with NeurIPS 2022',\n",
       " '22 pages, 12 figures, To be published in the proceedings of the 37th\\n  Conference on Neural Information Processing Systems (NeurIPS 2023), New\\n  Orleans, USA',\n",
       " '13 pages, 3 figures; to be published at the Second Workshop on\\n  Multimodal Fact-Checking and Hate Speech Detection (DEFACTIFY 2023) at the\\n  AAAI 2023 Conference, February 14, 2023, Washington, D.C',\n",
       " \"This is the accepted version of the paper that has been presented and\\n  published in the 20th IEEE Conference, OCIT'22. The final published version\\n  is copyright-protected by the IEEE. The paper consists of 5 pages, and it\\n  includes 5 figures and 1 table\",\n",
       " 'Technical Report. The contents are published in two separate papers\\n  in EMNLP 2023 (arXiv:2310.06374) and LREC-COLING 2024 (arXiv:2402.14052)',\n",
       " 'Will be published in PACM HCI, CSCW1, April 2023 issue',\n",
       " 'Book Chapter (3rd Chapter in \"Computational Intelligence Applications\\n  for Text and Sentiment Data Analysis\" published by Elsevier)',\n",
       " '2 pages, 5 figures, to be published in AAAI-23 Student Abstract and\\n  Poster Program',\n",
       " 'This book has been accepted by Springer Nature and will be published\\n  as an open access monograph. https://link.springer.com/book/9783031231896. It\\n  is licensed under the CC BY-NC-SA license\\n  (https://creativecommons.org/licenses/by-nc-sa/4.0/), except for the material\\n  included from other authors, which may have different licenses',\n",
       " '5 pages, 3 figures, published to ICASSP 2023',\n",
       " '9 pages, 3 Tables, To be published as a part of Proceedings of the\\n  37th AAAI Conference on Artificial Intelligence',\n",
       " 'The associated model is published on HuggingFace:\\n  https://huggingface.co/etamin/Letz-Translate-OPUS-LB-EN The Dictionary used\\n  in this paper is available in Github:\\n  https://github.com/Etamin/Ltz_dictionary',\n",
       " '9 pages, 3 figures. To be published in the 11th International\\n  Conference on Learning Representations, ICLR 2023, Conference Track\\n  Proceedings',\n",
       " \"To be published in the Proceedings of the 2023 SIAM International\\n  Conference on Data Mining (SDM'23)\",\n",
       " 'To be published in Proceedings of ISWC 2023, 22nd International\\n  Semantic Web Conference',\n",
       " 'Report (14 p. + 10 p. app) written for a submission in Jan 2021 (now\\n  with added explanation of relation with subsequent work that was published\\n  earlier) concerning the crucial observation underlying the crystallization\\n  process in arXiv:2209.12188 version 2: extension of Prop. 2.12 to \"under star\\n  1-free\" expressions, and correction in its proof (added termination subterm\\n  to extraction function)',\n",
       " 'A short version of this paper has been published at the 21st\\n  International Conference on Artificial Intelligence in Medicine (AIME 2023)',\n",
       " 'To be published on the INLG2023 conference website',\n",
       " 'Extended Abstract accepted to the 32nd International Joint Conference\\n  on Artificial Intelligence (IJCAI 2023); special journal track for authors of\\n  published JAIR 2022 and AIJ 2022 papers. 6 pages, 2 figures. arXiv admin\\n  note: substantial text overlap with arXiv:2106.13948',\n",
       " '8 pages, 3 figures. To be published in Proceedings of the 2023\\n  Conference on Innovation and Technology in Computer Science Education V. 1',\n",
       " 'To be published in the ICLR TinyPaper track',\n",
       " 'To be published in 21st International Conference on Applied\\n  Cryptography and Network Security, ACNS 2023',\n",
       " '3 pages, published in RNAAS',\n",
       " 'Accepted to AIED Late Breaking Results 2023 - to be published in\\n  their proceedings',\n",
       " 'To be published in the ICLR TinyPaper track',\n",
       " 'To be published in ACM FAccT 23',\n",
       " '6 pages, 1 figure, 4 tables, conference paper, published in the 20th\\n  International Conference on Informatics and Information Technologies (CIIT\\n  2023)',\n",
       " '14 pages, 11 figures, to be published in the proceedings of IDETC-CIE\\n  2023',\n",
       " 'Accepted and to be published in Proceedings of ADBIS 2023 as short\\n  paper (https://www.essi.upc.edu/dtim/ADBIS2023/index.html)',\n",
       " 'To be published in TACL (pre-MIT Press publication version)',\n",
       " 'to be published in \"Beyond Quantity: Research with Subsymbolic AI\"\\n  (11/2023)',\n",
       " '7 pages, 5 figures. To be published in the Proceedings of the 61st\\n  Annual Meeting of the Association for Computational Linguistics, 9-14 July\\n  2023, Toronto, Canada',\n",
       " 'To be published in The International AAAI Conference on Web and\\n  Social Media (ICWSM) 2023',\n",
       " 'To be published in the Journal of Chemical Information and Modeling',\n",
       " 'This is the original manuscript that was submitted to LREV. The final\\n  version was published recently and can be found at: https://rdcu.be/ddEa6.\\n  Language Resources and Evaluation, https://doi.org/10.1007/s10579-023-09664-1',\n",
       " 'To be published in Interspeech 2023 - Show and Tell Demonstrations',\n",
       " '26 pages, 15 figures, published in Transactions on Machine Learning\\n  Research (TMLR)',\n",
       " 'Updated sections on prompt engineering. Expanded sections 4.1 and 4.2\\n  and appendix. Included additional references. Work published at the ICML 2023\\n  (Neural Conversational AI TEACH) workshop',\n",
       " 'To be published in the KDD 2023 proceedings as a full paper',\n",
       " '10 pages and 2 figures. To be published in the Proceedings of the\\n  Seventeenth International Workshop on Juris-informatics (JURISIN 2023),\\n  hosted by JSAI International Symposia on AI 2023',\n",
       " 'Preprint. We published an earlier version of this paper\\n  (arXiv:2203.11131) under a different title. Both versions consider the\\n  conceptualization of explainable metrics and are overall similar. However,\\n  the new version puts a stronger emphasis on the survey of approaches for the\\n  explanation of MT metrics including the latest LLM based approaches',\n",
       " 'This is a preprint of an article to be published at the Int. Conf. on\\n  Artificial Intelligence in Education (AIED, 2023)',\n",
       " 'to be published in AIED 2023',\n",
       " 'To be published in the Proceedings of the International Society for\\n  Music Information Retrieval Conference (ISMIR)',\n",
       " \"39 pages, 9 figures, authors' manuscript approved for publication in\\n  Target International Journal of Translation published by John Benjamins\",\n",
       " 'To be published in Interspeech 2023, 5 pages, 1 figure',\n",
       " 'Accepted @ \"3rd Workshop on Bias and Fairness in AI\" (co-located with\\n  ECML PKDD 2023). This is the author\\'s version of the work. The definite\\n  version of record will be published in the proceedings',\n",
       " 'This manuscript is pre-print and in peer review. Supplementary\\n  materials will be published later',\n",
       " 'To be published in Translation, Cognition and Behavior: \"Translation\\n  and cognition in the 21st century: Goals met, goals ahead\", John Benjamins',\n",
       " 'to be published in AIIDE 2023',\n",
       " \"10 pages, 3 figures, to be published in Proceedings of the 11th\\n  International Conference on Human-Agent Interaction (ACM HAI'23)\",\n",
       " '8 pages, 4 figures, one table, to be published in VIS 2023 (Vis +\\n  Prov) x Domain',\n",
       " '6 pages, 2 figures, published in ICME2023',\n",
       " 'To be published in Proceedings of Machine Learning Research Volume\\n  219; accepted to the Machine Learning for Healthcare 2023 conference',\n",
       " \"3 pages, 1 figure, 1 table, to be published in Proceedings of the\\n  11th International Conference on Human-Agent Interaction (ACM HAI'23)\",\n",
       " '15 pages, 9 figures, to be published In Proceedings of International\\n  Conference of Computer Vision(ICCV), 2023',\n",
       " 'To be published in SEMANTICS 2023 poster track proceedings. SEMANTICS\\n  2023 EU: 19th International Conference on Semantic Systems, September 20-22,\\n  2023, Leipzig, Germany',\n",
       " 'This was published in TMLR in 2024, on January 24th',\n",
       " 'Paper has been presented at ICCCNT 2023 and the final version will be\\n  published in IEEE Digital Library Xplore',\n",
       " 'to be published in LREC-COLING 2024',\n",
       " \"To be published at 21st Int'l Conference on Service-Oriented\\n  Computing (ICSOC 2023), Rome, Italy, November 28-December 1, 2023, ser. LNCS,\\n  F. Monti, S. Rinderle-Ma, A. Ruiz Cortes, Z. Zheng, M. Mecella, Eds.,\\n  Springer, 2023\",\n",
       " '19 pages, 8 Figures, to be published in a journal (Journal TBD), All\\n  Authors contributed equally and were Supervised by Chandra Dhakal',\n",
       " 'Accepted @ \"1st Workshop on Biased Data in Conversational Agents\"\\n  (co-located with ECML PKDD 2023). This is the author\\'s version of the work.\\n  The definite version of record will be published in the proceedings',\n",
       " \"8 pages, 2 tables. To be published in Proceedings of the 2024\\n  Technical Symposium on Computer Science Education (SIGCSE'24)\",\n",
       " 'Preprint of an article published in Pacific Symposium on Biocomputing\\n  copyright 2024 World Scientific Publishing Co., Singapore,\\n  http://psb.stanford.edu/',\n",
       " '24 pages, 13 figures, to be published in NeurIPS 2023',\n",
       " 'To be published in the Proceedings of the 22nd IEEE International\\n  Conference on Machine Learning Applications (ICMLA 2023)',\n",
       " '21 pages, 14 figures, preprint to be published in HCI INTERNATIONAL\\n  2023 25TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION proceedings',\n",
       " 'Selected for publication in the AI Ethics Journal published by the\\n  Artificial Intelligence Robotics Ethics Society (AIRES)',\n",
       " 'Include wrong information in comment. Should be 7 pages and not\\n  published yet',\n",
       " 'Published at Information Fusion, Volume 101, 2024, 101988, ISSN\\n  1566-2535. The equal contribution mark is missed in the published version due\\n  to the publication policies. Please contact Prof. Erik Cambria for details',\n",
       " 'The paper is planned to be published in a reputable journal',\n",
       " 'To be published in GEM workshop. Conference on Empirical Methods in\\n  Natural Language Processing (EMNLP). 2023',\n",
       " 'To be published in the proceedings of the 36th International\\n  Conference on Legal Knowledge and Information Systems (JURIX 2023). Code and\\n  prompt available at https://github.com/samyarj/JCAPG-JURIX2023',\n",
       " 'To be published in EMNLP 2023 GEM Workshop',\n",
       " 'The initial work was published in the ICMLA 2019 conference',\n",
       " 'To be published in the Proceedings of the OSM Science 2023',\n",
       " '9 pages, 1 figure, 1 table, to be published in the proceedings of the\\n  Northern Lights Deep Learning Conference 2024',\n",
       " 'To be published in the Proceedings of the 3rd Machine Learning for\\n  Health symposium, Proceedings of Machine Learning Research (PMLR)',\n",
       " 'to be published in EMNLP Findings',\n",
       " \"I will not add others' names since this work has not been published\",\n",
       " '14 pages, 3 figures. Accepted Working Notes at HASOC-FIRE 2023, to be\\n  published in CEUR Working Notes of FIRE',\n",
       " '6 pages, 5 figures, 2023 IEEE International Conference on Big Data\\n  (BigData), to be published',\n",
       " 'To be published in the AAAI 2024 Proceedings Main Track',\n",
       " '4 pages, 1 figure, model is available at\\n  https://huggingface.co/universeTBD, published in RNAAS',\n",
       " \"This is the author's version of the work. The definitive version is\\n  published in: Proceedings of the 46th European Conference on Information\\n  Retrieval} (ECIR '24), March 24--28, 2024, Glasgow, Scotland\",\n",
       " \"This is the author's version of the work. The definitive version is\\n  published in: Proceedings of the 46th European Conference on Information\\n  Retrieval (ECIR '24), March 24-28, 2024, Glasgow, Scotland\",\n",
       " 'Originally published at the Generation, Evaluation & Metrics (GEM)\\n  Workshop at EMNLP 2023. We are awaiting the release of the proceedings which\\n  we will reference here',\n",
       " '8 pages, 3 figures, 5 tables, To be published in 2024 AAAI workshop\\n  on Responsible Language Models (ReLM)',\n",
       " \"18 pages, 4 figures, to be published in ICLR'24, Code available at\\n  https://github.com/ibraheem-moosa/mt-ranker\",\n",
       " 'The current submission is the first draft, published for the sole\\n  purpose of sharing an idea and encouraging community effort. A more\\n  consolidated version may come later',\n",
       " '10 pages, 6 figures, 4 tables. To be published in the Proceedings of\\n  the 38th Annual AAAI Conference on Artificial Intelligence (AAAI-24)',\n",
       " 'Will be published as findings paper at EACL2024 - 18th Conference of\\n  the European Chapter of the Association for Computational Linguistics',\n",
       " 'To be published in ECIR 2024 proceedings',\n",
       " \"This is just an initial idea and it's implementation. The results are\\n  computed for the first 100 data points. Detailed results will be published\\n  with the actual paper\",\n",
       " \"6 pages, 2 figures, published to DAC 2024: 61st IEEE/ACM Design\\n  Automation Conference. (DAC'24)\",\n",
       " 'To be published in AAAI 24',\n",
       " '24 pages, 2 figures, to be published in NLP for Requirements\\n  Engineering Book',\n",
       " '5 pages, 1 figures, published to ICASSP 2024',\n",
       " 'This preprint has not undergone peer review or any post-submission\\n  improvements or corrections. The Version of Record of this contribution is\\n  published in Advances in Information Retrieval, 46th European Conference on\\n  Information Retrieval, ECIR 2024. 16 pages, 4 figures',\n",
       " '10 pages; 2 figures; to be published in the <Programming> 2024\\n  Conference Companion',\n",
       " '4 pages, 2 figures, published in the WWW 2024 Short Papers Track',\n",
       " 'Accepted to be published at the 21st IEEE/ACM International\\n  Conference on Mining Software Repositories (MSR 2024)',\n",
       " 'To be published in LREC-COLING 2024',\n",
       " '28 pages, 11 figures, not published yet',\n",
       " '5 pages, Macintosh Postscript, published in COLING-94, pp. 278-282',\n",
       " '30 pages, also published in the University of Tuebingen Technical\\n  Report Series',\n",
       " 'latex source with a4 style, 15 pages, to be published in computer\\n  processing of oriental language journal',\n",
       " '51 pages, Postscript. To be published in Journal of Artificial\\n  Intelligence Research 6(1), 1997',\n",
       " \"12 pages, 3 figures, published in the proceedings of NLDB'01\",\n",
       " \"to be published in the Proceedings of the 7th International\\n  Conference on User Modeling (UM'99); uses llncs.cls,um97.sty\"]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(c) for c in unpublished_NLP[\"comments\"].values if \" published\" in str(c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>arxiv_title</th>\n",
       "      <th>arxiv_authors</th>\n",
       "      <th>arxiv_abstract</th>\n",
       "      <th>acl_title</th>\n",
       "      <th>acl_authors</th>\n",
       "      <th>acl_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.3886</td>\n",
       "      <td>A Note on Ontology and Ordinary Language</td>\n",
       "      <td>[['Saba', 'Walid S.', '']]</td>\n",
       "      <td>We argue for a compositional semantics groun...</td>\n",
       "      <td>towardsontologicallygroundedandlanguageagnosti...</td>\n",
       "      <td>[&lt;utils.Author.Author object at 0x000002355DDF...</td>\n",
       "      <td>https://aclanthology.org/2023.iwcs-1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.3886</td>\n",
       "      <td>A Note on Ontology and Ordinary Language</td>\n",
       "      <td>[['Saba', 'Walid S.', '']]</td>\n",
       "      <td>We argue for a compositional semantics groun...</td>\n",
       "      <td>towardsacognitivelyplausiblemodelforquantifica...</td>\n",
       "      <td>[&lt;utils.Author.Author object at 0x000002356E70...</td>\n",
       "      <td>https://aclanthology.org/P95-1051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0705.1161</td>\n",
       "      <td>IDF revisited: A simple new derivation within ...</td>\n",
       "      <td>[['Lee', 'Lillian', '']]</td>\n",
       "      <td>There have been a number of prior attempts t...</td>\n",
       "      <td>enhancingtextcomprehensionforquestionanswering...</td>\n",
       "      <td>[&lt;utils.Author.Author object at 0x00000235609B...</td>\n",
       "      <td>https://aclanthology.org/2023.repl4nlp-1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0705.1161</td>\n",
       "      <td>IDF revisited: A simple new derivation within ...</td>\n",
       "      <td>[['Lee', 'Lillian', '']]</td>\n",
       "      <td>There have been a number of prior attempts t...</td>\n",
       "      <td>promptbasedlearningfortextreadabilityassessment</td>\n",
       "      <td>[&lt;utils.Author.Author object at 0x000002354F5A...</td>\n",
       "      <td>https://aclanthology.org/2023.findings-eacl.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0705.1161</td>\n",
       "      <td>IDF revisited: A simple new derivation within ...</td>\n",
       "      <td>[['Lee', 'Lillian', '']]</td>\n",
       "      <td>There have been a number of prior attempts t...</td>\n",
       "      <td>lftkhandcraftedfeaturesincomputationallinguistics</td>\n",
       "      <td>[&lt;utils.Author.Author object at 0x000002355277...</td>\n",
       "      <td>https://aclanthology.org/2023.bea-1.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    arxiv_id                                        arxiv_title  \\\n",
       "0  0704.3886           A Note on Ontology and Ordinary Language   \n",
       "1  0704.3886           A Note on Ontology and Ordinary Language   \n",
       "2  0705.1161  IDF revisited: A simple new derivation within ...   \n",
       "3  0705.1161  IDF revisited: A simple new derivation within ...   \n",
       "4  0705.1161  IDF revisited: A simple new derivation within ...   \n",
       "\n",
       "                arxiv_authors  \\\n",
       "0  [['Saba', 'Walid S.', '']]   \n",
       "1  [['Saba', 'Walid S.', '']]   \n",
       "2    [['Lee', 'Lillian', '']]   \n",
       "3    [['Lee', 'Lillian', '']]   \n",
       "4    [['Lee', 'Lillian', '']]   \n",
       "\n",
       "                                      arxiv_abstract  \\\n",
       "0    We argue for a compositional semantics groun...   \n",
       "1    We argue for a compositional semantics groun...   \n",
       "2    There have been a number of prior attempts t...   \n",
       "3    There have been a number of prior attempts t...   \n",
       "4    There have been a number of prior attempts t...   \n",
       "\n",
       "                                           acl_title  \\\n",
       "0  towardsontologicallygroundedandlanguageagnosti...   \n",
       "1  towardsacognitivelyplausiblemodelforquantifica...   \n",
       "2  enhancingtextcomprehensionforquestionanswering...   \n",
       "3    promptbasedlearningfortextreadabilityassessment   \n",
       "4  lftkhandcraftedfeaturesincomputationallinguistics   \n",
       "\n",
       "                                         acl_authors  \\\n",
       "0  [<utils.Author.Author object at 0x000002355DDF...   \n",
       "1  [<utils.Author.Author object at 0x000002356E70...   \n",
       "2  [<utils.Author.Author object at 0x00000235609B...   \n",
       "3  [<utils.Author.Author object at 0x000002354F5A...   \n",
       "4  [<utils.Author.Author object at 0x000002355277...   \n",
       "\n",
       "                                           acl_url  \n",
       "0          https://aclanthology.org/2023.iwcs-1.11  \n",
       "1                https://aclanthology.org/P95-1051  \n",
       "2       https://aclanthology.org/2023.repl4nlp-1.7  \n",
       "3  https://aclanthology.org/2023.findings-eacl.135  \n",
       "4            https://aclanthology.org/2023.bea-1.1  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambig_df = pd.DataFrame(ambig, columns = [\"arxiv_id\", \"arxiv_title\", \"arxiv_authors\", \"arxiv_abstract\", \"acl_title\", \"acl_authors\", \"acl_url\"])\n",
    "ambig_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpublished_NLP.to_csv(\"../data/arxiv/arxiv-metadata-nlp-unpublished.csv\", index = False)\n",
    "# unpublished_NLP = pd.read_csv(\"../data/arxiv/arxiv-metadata-nlp-unpublished.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6384, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journal-ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>report-no</th>\n",
       "      <th>categories</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>pdf_stored</th>\n",
       "      <th>xml_stored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704.2083</td>\n",
       "      <td>Hassan Satori</td>\n",
       "      <td>H. Satori, M. Harti and N. Chenfour</td>\n",
       "      <td>Introduction to Arabic Speech Recognition Usin...</td>\n",
       "      <td>4 pages, 3 figures and 2 tables, was in Inform...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL cs.AI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this paper Arabic was investigated from t...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Tue, 17 Apr 200...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[['Satori', 'H.', ''], ['Harti', 'M.', ''], ['...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.2201</td>\n",
       "      <td>Hassan Satori</td>\n",
       "      <td>H. Satori, M. Harti and N. Chenfour</td>\n",
       "      <td>Arabic Speech Recognition System using CMU-Sph...</td>\n",
       "      <td>5 pages, 3 figures and 2 tables, in French</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL cs.AI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this paper we present the creation of an ...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Tue, 17 Apr 200...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[['Satori', 'H.', ''], ['Harti', 'M.', ''], ['...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>704.3665</td>\n",
       "      <td>Tian-Jian Jiang</td>\n",
       "      <td>Mike Tian-Jian Jiang, Deng Liu, Meng-Juei Hsie...</td>\n",
       "      <td>On the Development of Text Input Method - Less...</td>\n",
       "      <td>10 pages</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL cs.HC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Intelligent Input Methods (IM) are essential...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Fri, 27 Apr 200...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[['Jiang', 'Mike Tian-Jian', ''], ['Liu', 'Den...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>704.3708</td>\n",
       "      <td>Bernat Corominas-Murtra BCM</td>\n",
       "      <td>Bernat Corominas-Murtra</td>\n",
       "      <td>Network statistics on early English Syntax: St...</td>\n",
       "      <td>New abstract. Due to a mistake, abstract from ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This paper includes a reflection on the role...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Fri, 27 Apr 200...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[['Corominas-Murtra', 'Bernat', '']]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704.3886</td>\n",
       "      <td>W Saba</td>\n",
       "      <td>Walid S. Saba</td>\n",
       "      <td>A Note on Ontology and Ordinary Language</td>\n",
       "      <td>19 pages, 1 figure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.AI cs.CL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We argue for a compositional semantics groun...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 30 Apr 200...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[['Saba', 'Walid S.', '']]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                    submitter  \\\n",
       "0  704.2083                Hassan Satori   \n",
       "1  704.2201                Hassan Satori   \n",
       "2  704.3665              Tian-Jian Jiang   \n",
       "3  704.3708  Bernat Corominas-Murtra BCM   \n",
       "4  704.3886                       W Saba   \n",
       "\n",
       "                                             authors  \\\n",
       "0                H. Satori, M. Harti and N. Chenfour   \n",
       "1                H. Satori, M. Harti and N. Chenfour   \n",
       "2  Mike Tian-Jian Jiang, Deng Liu, Meng-Juei Hsie...   \n",
       "3                            Bernat Corominas-Murtra   \n",
       "4                                      Walid S. Saba   \n",
       "\n",
       "                                               title  \\\n",
       "0  Introduction to Arabic Speech Recognition Usin...   \n",
       "1  Arabic Speech Recognition System using CMU-Sph...   \n",
       "2  On the Development of Text Input Method - Less...   \n",
       "3  Network statistics on early English Syntax: St...   \n",
       "4           A Note on Ontology and Ordinary Language   \n",
       "\n",
       "                                            comments  journal-ref  doi  \\\n",
       "0  4 pages, 3 figures and 2 tables, was in Inform...          NaN  NaN   \n",
       "1         5 pages, 3 figures and 2 tables, in French          NaN  NaN   \n",
       "2                                           10 pages          NaN  NaN   \n",
       "3  New abstract. Due to a mistake, abstract from ...          NaN  NaN   \n",
       "4                                 19 pages, 1 figure          NaN  NaN   \n",
       "\n",
       "  report-no   categories license  \\\n",
       "0       NaN  cs.CL cs.AI     NaN   \n",
       "1       NaN  cs.CL cs.AI     NaN   \n",
       "2       NaN  cs.CL cs.HC     NaN   \n",
       "3       NaN        cs.CL     NaN   \n",
       "4       NaN  cs.AI cs.CL     NaN   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    In this paper Arabic was investigated from t...   \n",
       "1    In this paper we present the creation of an ...   \n",
       "2    Intelligent Input Methods (IM) are essential...   \n",
       "3    This paper includes a reflection on the role...   \n",
       "4    We argue for a compositional semantics groun...   \n",
       "\n",
       "                                            versions update_date  \\\n",
       "0  [{'version': 'v1', 'created': 'Tue, 17 Apr 200...  2007-05-23   \n",
       "1  [{'version': 'v1', 'created': 'Tue, 17 Apr 200...  2007-05-23   \n",
       "2  [{'version': 'v1', 'created': 'Fri, 27 Apr 200...  2007-05-23   \n",
       "3  [{'version': 'v1', 'created': 'Fri, 27 Apr 200...  2007-05-23   \n",
       "4  [{'version': 'v1', 'created': 'Mon, 30 Apr 200...  2007-05-23   \n",
       "\n",
       "                                      authors_parsed  pdf_stored  xml_stored  \n",
       "0  [['Satori', 'H.', ''], ['Harti', 'M.', ''], ['...        True       False  \n",
       "1  [['Satori', 'H.', ''], ['Harti', 'M.', ''], ['...        True       False  \n",
       "2  [['Jiang', 'Mike Tian-Jian', ''], ['Liu', 'Den...        True       False  \n",
       "3               [['Corominas-Murtra', 'Bernat', '']]        True       False  \n",
       "4                         [['Saba', 'Walid S.', '']]        True       False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(unpublished_NLP.shape)\n",
    "unpublished_NLP.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Access to PDF files [TO BE COMPLETED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33817, 14)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/arxiv/arxiv-metadata-nlp-unpublished.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_and_xml_file_paths_from_df_row(row:pd.DataFrame)->List[Tuple[str, str]]:\n",
    "    \"\"\"Returns a list of tuples containing the (theoretical) names of the pdf and xml files of a paper.\n",
    "    There is a path name for each version mentionned in the metadata. The names are returned by decreasing version (latest first).\"\"\"\n",
    "    pdf_and_xml_paths = []\n",
    "\n",
    "    # get the paper id\n",
    "    full_id = row[\"id\"]\n",
    "\n",
    "    # depending on the id format, the pdf file will be named differently\n",
    "    if \".\" in full_id:\n",
    "        pdf_name = f\"{full_id}\"\n",
    "    elif \"/\" in full_id:\n",
    "        category, id = full_id.split(\"/\")[:2]\n",
    "        pdf_name = f\"{id}\"\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "    # get the different versions of the paper\n",
    "    versions = json.loads(row[\"versions\"].replace(\"\\'\", \"\\\"\"))\n",
    "\n",
    "    for v in versions[::-1]:\n",
    "        pdf_and_xml_paths.append((f\"{pdf_name}{v['version']}.pdf\", f\"{pdf_name}{v['version']}.grobid.tei.xml\"))\n",
    "\n",
    "    return pdf_and_xml_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0708.2303v2.pdf', '0708.2303v2.grobid.tei.xml'),\n",
       " ('0708.2303v1.pdf', '0708.2303v1.grobid.tei.xml')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pdf_and_xml_file_paths_from_df_row(df.iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33817it [00:09, 3702.53it/s]\n"
     ]
    }
   ],
   "source": [
    "pdf_stored = []\n",
    "xml_stored = []\n",
    "\n",
    "pdf_dir = \"../data/arxiv/pdf/\"\n",
    "xml_dir = \"../data/arxiv/tei.xml/\"\n",
    "\n",
    "xml_files = []\n",
    "\n",
    "for i, row in tqdm.tqdm(df.iterrows()):\n",
    "    pdf_xml_paths = get_pdf_and_xml_file_paths_from_df_row(row)\n",
    "    found = False\n",
    "    for pdf, xml in pdf_xml_paths:\n",
    "        # check the xml first (it is the most important)\n",
    "        if os.path.exists(f\"{xml_dir}{xml}\"):\n",
    "            xml_files.append(xml)\n",
    "            xml_stored.append(True)\n",
    "            pdf_stored.append(True)\n",
    "            found = True\n",
    "            break\n",
    "        elif os.path.exists(f\"{pdf_dir}{pdf}\"):\n",
    "            pdf_stored.append(True)\n",
    "            xml_stored.append(False)\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if not found:\n",
    "        pdf_stored.append(False)\n",
    "        xml_stored.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pdf_stored\"] = pdf_stored\n",
    "df[\"xml_stored\"] = xml_stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "831\n",
      "1621\n"
     ]
    }
   ],
   "source": [
    "print(len(df[df[\"xml_stored\"] == True]))\n",
    "print(len(df[df[\"pdf_stored\"] == True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journal-ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>report-no</th>\n",
       "      <th>categories</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>pdf_stored</th>\n",
       "      <th>xml_stored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.2083</td>\n",
       "      <td>Hassan Satori</td>\n",
       "      <td>H. Satori, M. Harti and N. Chenfour</td>\n",
       "      <td>Introduction to Arabic Speech Recognition Usin...</td>\n",
       "      <td>4 pages, 3 figures and 2 tables, was in Inform...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL cs.AI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this paper Arabic was investigated from t...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Tue, 17 Apr 200...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[['Satori', 'H.', ''], ['Harti', 'M.', ''], ['...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.2201</td>\n",
       "      <td>Hassan Satori</td>\n",
       "      <td>H. Satori, M. Harti and N. Chenfour</td>\n",
       "      <td>Arabic Speech Recognition System using CMU-Sph...</td>\n",
       "      <td>5 pages, 3 figures and 2 tables, in French</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL cs.AI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this paper we present the creation of an ...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Tue, 17 Apr 200...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[['Satori', 'H.', ''], ['Harti', 'M.', ''], ['...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.3665</td>\n",
       "      <td>Tian-Jian Jiang</td>\n",
       "      <td>Mike Tian-Jian Jiang, Deng Liu, Meng-Juei Hsie...</td>\n",
       "      <td>On the Development of Text Input Method - Less...</td>\n",
       "      <td>10 pages</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL cs.HC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Intelligent Input Methods (IM) are essential...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Fri, 27 Apr 200...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[['Jiang', 'Mike Tian-Jian', ''], ['Liu', 'Den...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.3708</td>\n",
       "      <td>Bernat Corominas-Murtra BCM</td>\n",
       "      <td>Bernat Corominas-Murtra</td>\n",
       "      <td>Network statistics on early English Syntax: St...</td>\n",
       "      <td>New abstract. Due to a mistake, abstract from ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This paper includes a reflection on the role...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Fri, 27 Apr 200...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[['Corominas-Murtra', 'Bernat', '']]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.3886</td>\n",
       "      <td>W Saba</td>\n",
       "      <td>Walid S. Saba</td>\n",
       "      <td>A Note on Ontology and Ordinary Language</td>\n",
       "      <td>19 pages, 1 figure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.AI cs.CL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We argue for a compositional semantics groun...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 30 Apr 200...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[['Saba', 'Walid S.', '']]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                    submitter  \\\n",
       "0  0704.2083                Hassan Satori   \n",
       "1  0704.2201                Hassan Satori   \n",
       "2  0704.3665              Tian-Jian Jiang   \n",
       "3  0704.3708  Bernat Corominas-Murtra BCM   \n",
       "4  0704.3886                       W Saba   \n",
       "\n",
       "                                             authors  \\\n",
       "0                H. Satori, M. Harti and N. Chenfour   \n",
       "1                H. Satori, M. Harti and N. Chenfour   \n",
       "2  Mike Tian-Jian Jiang, Deng Liu, Meng-Juei Hsie...   \n",
       "3                            Bernat Corominas-Murtra   \n",
       "4                                      Walid S. Saba   \n",
       "\n",
       "                                               title  \\\n",
       "0  Introduction to Arabic Speech Recognition Usin...   \n",
       "1  Arabic Speech Recognition System using CMU-Sph...   \n",
       "2  On the Development of Text Input Method - Less...   \n",
       "3  Network statistics on early English Syntax: St...   \n",
       "4           A Note on Ontology and Ordinary Language   \n",
       "\n",
       "                                            comments  journal-ref  doi  \\\n",
       "0  4 pages, 3 figures and 2 tables, was in Inform...          NaN  NaN   \n",
       "1         5 pages, 3 figures and 2 tables, in French          NaN  NaN   \n",
       "2                                           10 pages          NaN  NaN   \n",
       "3  New abstract. Due to a mistake, abstract from ...          NaN  NaN   \n",
       "4                                 19 pages, 1 figure          NaN  NaN   \n",
       "\n",
       "  report-no   categories license  \\\n",
       "0       NaN  cs.CL cs.AI     NaN   \n",
       "1       NaN  cs.CL cs.AI     NaN   \n",
       "2       NaN  cs.CL cs.HC     NaN   \n",
       "3       NaN        cs.CL     NaN   \n",
       "4       NaN  cs.AI cs.CL     NaN   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    In this paper Arabic was investigated from t...   \n",
       "1    In this paper we present the creation of an ...   \n",
       "2    Intelligent Input Methods (IM) are essential...   \n",
       "3    This paper includes a reflection on the role...   \n",
       "4    We argue for a compositional semantics groun...   \n",
       "\n",
       "                                            versions update_date  \\\n",
       "0  [{'version': 'v1', 'created': 'Tue, 17 Apr 200...  2007-05-23   \n",
       "1  [{'version': 'v1', 'created': 'Tue, 17 Apr 200...  2007-05-23   \n",
       "2  [{'version': 'v1', 'created': 'Fri, 27 Apr 200...  2007-05-23   \n",
       "3  [{'version': 'v1', 'created': 'Fri, 27 Apr 200...  2007-05-23   \n",
       "4  [{'version': 'v1', 'created': 'Mon, 30 Apr 200...  2007-05-23   \n",
       "\n",
       "                                      authors_parsed  pdf_stored  xml_stored  \n",
       "0  [['Satori', 'H.', ''], ['Harti', 'M.', ''], ['...        True       False  \n",
       "1  [['Satori', 'H.', ''], ['Harti', 'M.', ''], ['...        True       False  \n",
       "2  [['Jiang', 'Mike Tian-Jian', ''], ['Liu', 'Den...        True       False  \n",
       "3               [['Corominas-Murtra', 'Bernat', '']]        True       False  \n",
       "4                         [['Saba', 'Walid S.', '']]        True       False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_be_deleted = [f for f in os.listdir(xml_dir) if f not in xml_files]\n",
    "\n",
    "# # delete the files\n",
    "# for f in to_be_deleted:\n",
    "#     os.remove(f\"{xml_dir}{f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/arxiv/arxiv-metadata-nlp-unpublished.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [arxiv-papers-download.py](arxiv-papers-download.py) for the download of the arxiv papers. (not run here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. GROBID Extraction [TO BE COMPLETED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29821\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from subprocess import run\n",
    "import shutil\n",
    "\n",
    "pdf_files = [f for f in os.listdir(\"../data/arxiv/pdf\") if f.endswith(\".pdf\")]\n",
    "print(len(pdf_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = f\"..\\\\data\\\\arxiv\\\\pdf\\\\0\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = f\"..\\\\data\\\\arxiv\\\\pdf\\\\\"\n",
    "\n",
    "for i in range(30):\n",
    "    files = pdf_files[i*1000:min((i+1)*1000, len(pdf_files))]\n",
    "    destination = f\"..\\\\data\\\\arxiv\\\\pdf\\\\{i}\\\\\"\n",
    "\n",
    "    for f in files:\n",
    "        shutil.move(f\"{source}{f}\", destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "destination = f\"..\\\\data\\\\arxiv\\\\tei.xml\\\\\"\n",
    "for i in range(30):\n",
    "    xml_files = [f for f in os.listdir(f\"..\\\\data\\\\arxiv\\\\tei.xml\\\\{i}\\\\\") if f.endswith(\".xml\")]\n",
    "    for f in xml_files:\n",
    "        shutil.move(f\"..\\\\data\\\\arxiv\\\\tei.xml\\\\{i}\\\\{f}\", destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    os.mkdir(f\"..\\\\data\\\\arxiv\\\\tei.xml\\\\{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [02:53<02:53, 173.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args=['grobid_client', '--input', '..\\\\data\\\\arxiv\\\\pdf\\\\28\\\\', '--output', '..\\\\data\\\\arxiv\\\\tei.xml\\\\28\\\\', 'processFulltextDocument'], returncode=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [12:37<00:00, 378.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args=['grobid_client', '--input', '..\\\\data\\\\arxiv\\\\pdf\\\\29\\\\', '--output', '..\\\\data\\\\arxiv\\\\tei.xml\\\\29\\\\', 'processFulltextDocument'], returncode=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from subprocess import run\n",
    "for j in tqdm.tqdm(range(28,30)):\n",
    "    source = f\"..\\\\data\\\\arxiv\\\\pdf\\\\{j}\\\\\"\n",
    "    destination = f\"..\\\\data\\\\arxiv\\\\tei.xml\\\\{j}\\\\\"\n",
    "    #code = run(\"cd ..\\\\grobid_client_python\\\\\", shell = True).returncode\n",
    "    code2 = run([\"grobid_client\", \"--input\", source, \"--output\", destination, \"processFulltextDocument\"], shell = True)\n",
    "    \n",
    "    print(code2)\n",
    "    if code2.returncode != 0:\n",
    "        break\n",
    "    #os.system(f\"grobid_client --input {source} --output {destination} processFulltextDocument --verbose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grobid_client', '--input', 'path', '--output', 'path', 'processFulltextDocument', '--verbose']\n"
     ]
    }
   ],
   "source": [
    "import shlex\n",
    "command = \"grobid_client --input path --output path processFulltextDocument --verbose\"\n",
    "args = shlex.split(command)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '0001006v1.grobid.tei.xml',\n",
       " '0001020v1.grobid.tei.xml',\n",
       " '0002017v1.grobid.tei.xml',\n",
       " '0003022v1.grobid.tei.xml',\n",
       " '0003081v1.grobid.tei.xml',\n",
       " '0004016v1.grobid.tei.xml',\n",
       " '0006012v1.grobid.tei.xml',\n",
       " '0007012v1.grobid.tei.xml',\n",
       " '0007013v1.grobid.tei.xml',\n",
       " '0007016v1.grobid.tei.xml',\n",
       " '0008032v1.grobid.tei.xml',\n",
       " '0009011v1.grobid.tei.xml',\n",
       " '0009012v1.grobid.tei.xml',\n",
       " '0009014v1.grobid.tei.xml',\n",
       " '0009015v1.grobid.tei.xml',\n",
       " '0010014v1.grobid.tei.xml',\n",
       " '0010033v1.grobid.tei.xml',\n",
       " '0011011v1.grobid.tei.xml',\n",
       " '0011028v1.grobid.tei.xml',\n",
       " '0011034v1.grobid.tei.xml',\n",
       " '0011035v1.grobid.tei.xml',\n",
       " '0103007v1.grobid.tei.xml',\n",
       " '0103013v1.grobid.tei.xml',\n",
       " '0104022v1.grobid.tei.xml',\n",
       " '0105001v1.grobid.tei.xml',\n",
       " '0105005v1.grobid.tei.xml',\n",
       " '0105019v1.grobid.tei.xml',\n",
       " '0105035v1.grobid.tei.xml',\n",
       " '0106016v1.grobid.tei.xml',\n",
       " '0107005v1.grobid.tei.xml',\n",
       " '0107012v1.grobid.tei.xml',\n",
       " '0108005v1.grobid.tei.xml',\n",
       " '0109013v1.grobid.tei.xml',\n",
       " '0109039v1.grobid.tei.xml',\n",
       " '0109218v1.grobid.tei.xml',\n",
       " '0110015v1.grobid.tei.xml',\n",
       " '0110041v1.grobid.tei.xml',\n",
       " '0110057v1.grobid.tei.xml',\n",
       " '0201008v1.grobid.tei.xml',\n",
       " '0202383v1.grobid.tei.xml',\n",
       " '0204003v1.grobid.tei.xml',\n",
       " '0204008v1.grobid.tei.xml',\n",
       " '0205025v1.grobid.tei.xml',\n",
       " '0205067v1.grobid.tei.xml',\n",
       " '0205068v1.grobid.tei.xml',\n",
       " '0207058v1.grobid.tei.xml',\n",
       " '0208020v1.grobid.tei.xml',\n",
       " '0210025v3.grobid.tei.xml',\n",
       " '0212018v1.grobid.tei.xml',\n",
       " '0302014v1.grobid.tei.xml',\n",
       " '0303002v2.grobid.tei.xml',\n",
       " '0303007v1.grobid.tei.xml',\n",
       " '0304024v1.grobid.tei.xml',\n",
       " '0305041v2.grobid.tei.xml',\n",
       " '0305053v1.grobid.tei.xml',\n",
       " '0306022v1.grobid.tei.xml',\n",
       " '0306040v1.grobid.tei.xml',\n",
       " '0306099v1.grobid.tei.xml',\n",
       " '0307030v1.grobid.tei.xml',\n",
       " '0307044v1.grobid.tei.xml',\n",
       " '0307055v1.grobid.tei.xml',\n",
       " '0308008v1.grobid.tei.xml',\n",
       " '0308016v1.grobid.tei.xml',\n",
       " '0308020v1.grobid.tei.xml',\n",
       " '0310014v1.grobid.tei.xml',\n",
       " '0310018v1.grobid.tei.xml',\n",
       " '0310041v1.grobid.tei.xml',\n",
       " '0310058v1.grobid.tei.xml',\n",
       " '0311036v1.grobid.tei.xml',\n",
       " '0312058v1.grobid.tei.xml',\n",
       " '0312060v1.grobid.tei.xml',\n",
       " '0404018v1.grobid.tei.xml',\n",
       " '0404026v1.grobid.tei.xml',\n",
       " '0404041v2.grobid.tei.xml',\n",
       " '0405037v1.grobid.tei.xml',\n",
       " '0405044v1.grobid.tei.xml',\n",
       " '0406003v1.grobid.tei.xml',\n",
       " '0406015v1.grobid.tei.xml',\n",
       " '0407005v3.grobid.tei.xml',\n",
       " '0408027v1.grobid.tei.xml',\n",
       " '0408037v1.grobid.tei.xml',\n",
       " '0408041v1.grobid.tei.xml',\n",
       " '0408052v1.grobid.tei.xml',\n",
       " '0408059v1.grobid.tei.xml',\n",
       " '0408060v1.grobid.tei.xml',\n",
       " '0409042v1.grobid.tei.xml',\n",
       " '0410017v1.grobid.tei.xml',\n",
       " '0410072v1.grobid.tei.xml',\n",
       " '0411074v1.grobid.tei.xml',\n",
       " '0412015v2.grobid.tei.xml',\n",
       " '0412024v1.grobid.tei.xml',\n",
       " '0412065v1.grobid.tei.xml',\n",
       " '0412114v1.grobid.tei.xml',\n",
       " '0412117v1.grobid.tei.xml',\n",
       " '0503030v2.grobid.tei.xml',\n",
       " '0504089v2.grobid.tei.xml',\n",
       " '0506101v1.grobid.tei.xml',\n",
       " '0510054v1.grobid.tei.xml',\n",
       " '0511079v1.grobid.tei.xml',\n",
       " '0601005v1.grobid.tei.xml',\n",
       " '0601037v1.grobid.tei.xml',\n",
       " '0602018v1.grobid.tei.xml',\n",
       " '0602093v1.grobid.tei.xml',\n",
       " '0604027v1.grobid.tei.xml',\n",
       " '0604087v1.grobid.tei.xml',\n",
       " '0605076v1.grobid.tei.xml',\n",
       " '0605101v1.grobid.tei.xml',\n",
       " '0605147v1.grobid.tei.xml',\n",
       " '0610004v1.grobid.tei.xml',\n",
       " '0610010v4.grobid.tei.xml',\n",
       " '0612033v1.grobid.tei.xml',\n",
       " '0701135v1.grobid.tei.xml',\n",
       " '0701181v1.grobid.tei.xml',\n",
       " '0702081v1.grobid.tei.xml',\n",
       " '0703049v1.grobid.tei.xml',\n",
       " '0704.2083v1.grobid.tei.xml',\n",
       " '0704.2201v1.grobid.tei.xml',\n",
       " '0704.3665v1.grobid.tei.xml',\n",
       " '0704.3708v2.grobid.tei.xml',\n",
       " '0704.3886v6.grobid.tei.xml',\n",
       " '0705.0462v1.grobid.tei.xml',\n",
       " '0705.1161v1.grobid.tei.xml',\n",
       " '0707.0895v1.grobid.tei.xml',\n",
       " '0707.1913v3.grobid.tei.xml',\n",
       " '0707.3559v1.grobid.tei.xml',\n",
       " '0708.2303v2.grobid.tei.xml',\n",
       " '0710.0169v6.grobid.tei.xml',\n",
       " '0710.0225v1.grobid.tei.xml',\n",
       " '0710.0228v1.grobid.tei.xml',\n",
       " '0710.2674v1.grobid.tei.xml',\n",
       " '0710.3285v2.grobid.tei.xml',\n",
       " '0711.2023v1.grobid.tei.xml',\n",
       " '0711.2444v1.grobid.tei.xml',\n",
       " '0711.3197v1.grobid.tei.xml',\n",
       " '0712.1529v2.grobid.tei.xml',\n",
       " '0712.3298v1.grobid.tei.xml',\n",
       " '0712.3705v1.grobid.tei.xml',\n",
       " '0801.1415v1.grobid.tei.xml',\n",
       " '0801.1658v2.grobid.tei.xml',\n",
       " '0801.3864v1.grobid.tei.xml',\n",
       " '0801.4746v5.grobid.tei.xml',\n",
       " '0802.2234v1.grobid.tei.xml',\n",
       " '0802.4112v1.grobid.tei.xml',\n",
       " '0802.4326v1.grobid.tei.xml',\n",
       " '0803.2856v1.grobid.tei.xml',\n",
       " '0804.1033v1.grobid.tei.xml',\n",
       " '0804.2354v2.grobid.tei.xml',\n",
       " '0804.3269v1.grobid.tei.xml',\n",
       " '0805.3366v1.grobid.tei.xml',\n",
       " '0807.0311v1.grobid.tei.xml',\n",
       " '0807.0565v1.grobid.tei.xml',\n",
       " '0807.3845v1.grobid.tei.xml',\n",
       " '0808.0521v1.grobid.tei.xml',\n",
       " '0808.1211v1.grobid.tei.xml',\n",
       " '0808.1753v2.grobid.tei.xml',\n",
       " '0808.3563v1.grobid.tei.xml',\n",
       " '0808.3569v3.grobid.tei.xml',\n",
       " '0808.3889v1.grobid.tei.xml',\n",
       " '0808.4122v2.grobid.tei.xml',\n",
       " '0809.0103v1.grobid.tei.xml',\n",
       " '0809.4530v2.grobid.tei.xml',\n",
       " '0810.3416v1.grobid.tei.xml',\n",
       " '0811.0453v1.grobid.tei.xml',\n",
       " '0811.4717v1.grobid.tei.xml',\n",
       " '0901.2924v1.grobid.tei.xml',\n",
       " '0901.4375v1.grobid.tei.xml',\n",
       " '0902.0606v1.grobid.tei.xml',\n",
       " '0903.2792v3.grobid.tei.xml',\n",
       " '0903.5168v1.grobid.tei.xml',\n",
       " '0905.1609v1.grobid.tei.xml',\n",
       " '0905.3318v1.grobid.tei.xml',\n",
       " '0905.4039v1.grobid.tei.xml',\n",
       " '0906.2369v1.grobid.tei.xml',\n",
       " '0906.2835v1.grobid.tei.xml',\n",
       " '0908.4413v1.grobid.tei.xml',\n",
       " '0908.4431v1.grobid.tei.xml',\n",
       " '0909.1147v1.grobid.tei.xml',\n",
       " '0909.3591v1.grobid.tei.xml',\n",
       " '0910.0537v1.grobid.tei.xml',\n",
       " '0910.5682v1.grobid.tei.xml',\n",
       " '0911.1516v2.grobid.tei.xml',\n",
       " '0911.1517v2.grobid.tei.xml',\n",
       " '0911.1965v1.grobid.tei.xml',\n",
       " '0911.2284v2.grobid.tei.xml',\n",
       " '0911.3292v2.grobid.tei.xml',\n",
       " '0911.5703v1.grobid.tei.xml',\n",
       " '1',\n",
       " '10',\n",
       " '1001.4368v1.grobid.tei.xml',\n",
       " '1002.0478v1.grobid.tei.xml',\n",
       " '1002.0479v1.grobid.tei.xml',\n",
       " '1002.0481v2.grobid.tei.xml',\n",
       " '1002.0485v1.grobid.tei.xml',\n",
       " '1002.0773v1.grobid.tei.xml',\n",
       " '1002.0904v1.grobid.tei.xml',\n",
       " '1002.1095v1.grobid.tei.xml',\n",
       " '1002.4665v1.grobid.tei.xml',\n",
       " '1003.0206v1.grobid.tei.xml',\n",
       " '1003.0337v1.grobid.tei.xml',\n",
       " '1003.0628v1.grobid.tei.xml',\n",
       " '1004.3183v1.grobid.tei.xml',\n",
       " '1004.4181v1.grobid.tei.xml',\n",
       " '1005.3902v1.grobid.tei.xml',\n",
       " '1005.4697v3.grobid.tei.xml',\n",
       " '1005.5253v1.grobid.tei.xml',\n",
       " '1005.5466v1.grobid.tei.xml',\n",
       " '1006.0153v1.grobid.tei.xml',\n",
       " '1006.1343v1.grobid.tei.xml',\n",
       " '1006.3271v1.grobid.tei.xml',\n",
       " '1006.5827v1.grobid.tei.xml',\n",
       " '1007.3254v2.grobid.tei.xml',\n",
       " '1007.4748v1.grobid.tei.xml',\n",
       " '1008.0706v1.grobid.tei.xml',\n",
       " '1008.1673v2.grobid.tei.xml',\n",
       " '1008.3667v1.grobid.tei.xml',\n",
       " '1009.0108v1.grobid.tei.xml',\n",
       " '1009.2706v1.grobid.tei.xml',\n",
       " '1009.3238v1.grobid.tei.xml',\n",
       " '1010.1826v1.grobid.tei.xml',\n",
       " '1010.2384v1.grobid.tei.xml',\n",
       " '1010.6091v4.grobid.tei.xml',\n",
       " '1011.3258v1.grobid.tei.xml',\n",
       " '1011.4623v1.grobid.tei.xml',\n",
       " '1011.5209v2.grobid.tei.xml',\n",
       " '1012.2042v1.grobid.tei.xml',\n",
       " '1012.5248v1.grobid.tei.xml',\n",
       " '1012.5962v2.grobid.tei.xml',\n",
       " '11',\n",
       " '1101.5494v1.grobid.tei.xml',\n",
       " '1101.5757v1.grobid.tei.xml',\n",
       " '1102.2831v2.grobid.tei.xml',\n",
       " '1102.5185v1.grobid.tei.xml',\n",
       " '1103.0398v1.grobid.tei.xml',\n",
       " '1103.2325v1.grobid.tei.xml',\n",
       " '1104.2034v1.grobid.tei.xml',\n",
       " '1104.4321v1.grobid.tei.xml',\n",
       " '1104.4426v3.grobid.tei.xml',\n",
       " '1105.1702v2.grobid.tei.xml',\n",
       " '1105.6162v2.grobid.tei.xml',\n",
       " '1106.0107v1.grobid.tei.xml',\n",
       " '1106.0411v1.grobid.tei.xml',\n",
       " '1106.5973v1.grobid.tei.xml',\n",
       " '1107.1753v1.grobid.tei.xml',\n",
       " '1107.4687v2.grobid.tei.xml',\n",
       " '1108.0353v2.grobid.tei.xml',\n",
       " '1108.0631v3.grobid.tei.xml',\n",
       " '1108.3848v1.grobid.tei.xml',\n",
       " '1108.5016v1.grobid.tei.xml',\n",
       " '1108.5017v1.grobid.tei.xml',\n",
       " '1108.5027v1.grobid.tei.xml',\n",
       " '1108.5567v1.grobid.tei.xml',\n",
       " '1109.0069v2.grobid.tei.xml',\n",
       " '1109.4531v1.grobid.tei.xml',\n",
       " '1109.4906v1.grobid.tei.xml',\n",
       " '1109.5798v1.grobid.tei.xml',\n",
       " '1109.6018v1.grobid.tei.xml',\n",
       " '1110.1428v1.grobid.tei.xml',\n",
       " '1110.1758v2.grobid.tei.xml',\n",
       " '1110.2162v2.grobid.tei.xml',\n",
       " '1110.3094v1.grobid.tei.xml',\n",
       " '1110.4248v1.grobid.tei.xml',\n",
       " '1111.1648v1.grobid.tei.xml',\n",
       " '1111.1673v1.grobid.tei.xml',\n",
       " '1111.3152v1.grobid.tei.xml',\n",
       " '1111.3153v1.grobid.tei.xml',\n",
       " '1111.4316v1.grobid.tei.xml',\n",
       " '1111.4343v1.grobid.tei.xml',\n",
       " '1111.5293v1.grobid.tei.xml',\n",
       " '1111.6553v1.grobid.tei.xml',\n",
       " '1112.0396v1.grobid.tei.xml',\n",
       " '1112.5947v1.grobid.tei.xml',\n",
       " '1112.6286v1.grobid.tei.xml',\n",
       " '1112.6384v1.grobid.tei.xml',\n",
       " '12',\n",
       " '1201.1192v1.grobid.tei.xml',\n",
       " '1201.2073v1.grobid.tei.xml',\n",
       " '1201.6224v2.grobid.tei.xml',\n",
       " '1202.0116v1.grobid.tei.xml',\n",
       " '1202.1054v1.grobid.tei.xml',\n",
       " '1202.2518v4.grobid.tei.xml',\n",
       " '1202.3752v1.grobid.tei.xml',\n",
       " '1202.5913v1.grobid.tei.xml',\n",
       " '1202.6583v1.grobid.tei.xml',\n",
       " '1203.0145v1.grobid.tei.xml',\n",
       " '1203.1685v1.grobid.tei.xml',\n",
       " '1203.1858v1.grobid.tei.xml',\n",
       " '1203.1889v1.grobid.tei.xml',\n",
       " '1203.2299v1.grobid.tei.xml',\n",
       " '1203.2498v2.grobid.tei.xml',\n",
       " '1203.3227v1.grobid.tei.xml',\n",
       " '1203.3511v1.grobid.tei.xml',\n",
       " '1203.4238v1.grobid.tei.xml',\n",
       " '1203.4605v1.grobid.tei.xml',\n",
       " '1203.5055v1.grobid.tei.xml',\n",
       " '1203.5073v1.grobid.tei.xml',\n",
       " '1203.6136v1.grobid.tei.xml',\n",
       " '1203.6339v1.grobid.tei.xml',\n",
       " '1204.0184v1.grobid.tei.xml',\n",
       " '1204.0188v1.grobid.tei.xml',\n",
       " '1204.0191v1.grobid.tei.xml',\n",
       " '1204.0255v1.grobid.tei.xml',\n",
       " '1204.2523v1.grobid.tei.xml',\n",
       " '1204.2804v1.grobid.tei.xml',\n",
       " '1204.3458v1.grobid.tei.xml',\n",
       " '1204.3498v2.grobid.tei.xml',\n",
       " '1204.3731v1.grobid.tei.xml',\n",
       " '1204.4346v1.grobid.tei.xml',\n",
       " '1204.6362v1.grobid.tei.xml',\n",
       " '1204.6364v1.grobid.tei.xml',\n",
       " '1204.6441v1.grobid.tei.xml',\n",
       " '1205.0627v1.grobid.tei.xml',\n",
       " '1205.1603v1.grobid.tei.xml',\n",
       " '1205.1639v1.grobid.tei.xml',\n",
       " '1205.1975v1.grobid.tei.xml',\n",
       " '1205.2657v1.grobid.tei.xml',\n",
       " '1205.3183v1.grobid.tei.xml',\n",
       " '1205.3316v1.grobid.tei.xml',\n",
       " '1205.4298v1.grobid.tei.xml',\n",
       " '1205.4387v1.grobid.tei.xml',\n",
       " '1205.6396v1.grobid.tei.xml',\n",
       " '1206.0042v1.grobid.tei.xml',\n",
       " '1206.0381v1.grobid.tei.xml',\n",
       " '1206.2009v1.grobid.tei.xml',\n",
       " '1206.3254v1.grobid.tei.xml',\n",
       " '1206.3293v1.grobid.tei.xml',\n",
       " '1206.4522v1.grobid.tei.xml',\n",
       " '1206.4637v1.grobid.tei.xml',\n",
       " '1206.4958v1.grobid.tei.xml',\n",
       " '1206.5333v2.grobid.tei.xml',\n",
       " '1206.5384v1.grobid.tei.xml',\n",
       " '1206.6403v1.grobid.tei.xml',\n",
       " '1206.6423v1.grobid.tei.xml',\n",
       " '1206.6481v1.grobid.tei.xml',\n",
       " '1206.6735v1.grobid.tei.xml',\n",
       " '1207.0052v3.grobid.tei.xml',\n",
       " '1207.0245v2.grobid.tei.xml',\n",
       " '1207.0396v1.grobid.tei.xml',\n",
       " '1207.0742v1.grobid.tei.xml',\n",
       " '1207.1847v1.grobid.tei.xml',\n",
       " '1207.2265v1.grobid.tei.xml',\n",
       " '1207.4307v1.grobid.tei.xml',\n",
       " '1207.5409v1.grobid.tei.xml',\n",
       " '1208.2873v1.grobid.tei.xml',\n",
       " '1208.3001v1.grobid.tei.xml',\n",
       " '1208.3047v1.grobid.tei.xml',\n",
       " '1208.4079v1.grobid.tei.xml',\n",
       " '1208.4503v1.grobid.tei.xml',\n",
       " '1209.0249v1.grobid.tei.xml',\n",
       " '1209.1301v1.grobid.tei.xml',\n",
       " '1209.2163v1.grobid.tei.xml',\n",
       " '1209.3126v1.grobid.tei.xml',\n",
       " '1209.4471v1.grobid.tei.xml',\n",
       " '1209.6238v1.grobid.tei.xml',\n",
       " '1210.0852v1.grobid.tei.xml',\n",
       " '1210.3312v1.grobid.tei.xml',\n",
       " '1210.3634v1.grobid.tei.xml',\n",
       " '1210.3865v1.grobid.tei.xml',\n",
       " '1210.3926v2.grobid.tei.xml',\n",
       " '1210.4854v1.grobid.tei.xml',\n",
       " '1210.4871v1.grobid.tei.xml',\n",
       " '1210.5321v1.grobid.tei.xml',\n",
       " '1210.5486v2.grobid.tei.xml',\n",
       " '1210.5517v1.grobid.tei.xml',\n",
       " '1210.5581v1.grobid.tei.xml',\n",
       " '1210.5965v1.grobid.tei.xml',\n",
       " '1210.7282v1.grobid.tei.xml',\n",
       " '1210.7917v1.grobid.tei.xml',\n",
       " '1210.8436v1.grobid.tei.xml',\n",
       " '1211.0074v1.grobid.tei.xml',\n",
       " '1211.0498v1.grobid.tei.xml',\n",
       " '1211.3402v1.grobid.tei.xml',\n",
       " '1211.4488v1.grobid.tei.xml',\n",
       " '1211.4929v1.grobid.tei.xml',\n",
       " '1211.6887v1.grobid.tei.xml',\n",
       " '1212.0074v1.grobid.tei.xml',\n",
       " '1212.0229v1.grobid.tei.xml',\n",
       " '1212.0927v3.grobid.tei.xml',\n",
       " '1212.1192v2.grobid.tei.xml',\n",
       " '1212.1478v1.grobid.tei.xml',\n",
       " '1212.1918v1.grobid.tei.xml',\n",
       " '1212.2145v1.grobid.tei.xml',\n",
       " '1212.2453v1.grobid.tei.xml',\n",
       " '1212.2477v1.grobid.tei.xml',\n",
       " '1212.2676v1.grobid.tei.xml',\n",
       " '1212.3023v1.grobid.tei.xml',\n",
       " '1212.3493v2.grobid.tei.xml',\n",
       " '1212.4674v1.grobid.tei.xml',\n",
       " '1212.6527v1.grobid.tei.xml',\n",
       " '13',\n",
       " '1301.0722v2.grobid.tei.xml',\n",
       " '1301.2466v1.grobid.tei.xml',\n",
       " '1301.2811v3.grobid.tei.xml',\n",
       " '1301.3214v1.grobid.tei.xml',\n",
       " '1301.3226v4.grobid.tei.xml',\n",
       " '1301.3547v1.grobid.tei.xml',\n",
       " '1301.3605v3.grobid.tei.xml',\n",
       " '1301.3614v3.grobid.tei.xml',\n",
       " '1301.3618v2.grobid.tei.xml',\n",
       " '1301.3627v2.grobid.tei.xml',\n",
       " '1301.3781v3.grobid.tei.xml',\n",
       " '1301.4938v3.grobid.tei.xml',\n",
       " '1301.5686v2.grobid.tei.xml',\n",
       " '1301.7382v2.grobid.tei.xml',\n",
       " '1301.7738v2.grobid.tei.xml',\n",
       " '1302.1572v1.grobid.tei.xml',\n",
       " '1302.2131v1.grobid.tei.xml',\n",
       " '1302.2569v1.grobid.tei.xml',\n",
       " '1302.4619v1.grobid.tei.xml',\n",
       " '1302.4726v1.grobid.tei.xml',\n",
       " '1302.4874v1.grobid.tei.xml',\n",
       " '1302.5181v1.grobid.tei.xml',\n",
       " '1302.5645v1.grobid.tei.xml',\n",
       " '1302.6777v1.grobid.tei.xml',\n",
       " '1303.0445v1.grobid.tei.xml',\n",
       " '1303.0446v1.grobid.tei.xml',\n",
       " '1303.0489v1.grobid.tei.xml',\n",
       " '1303.2826v1.grobid.tei.xml',\n",
       " '1303.5148v1.grobid.tei.xml',\n",
       " '1303.5778v1.grobid.tei.xml',\n",
       " '1304.0715v1.grobid.tei.xml',\n",
       " '1304.1018v2.grobid.tei.xml',\n",
       " '1304.3092v1.grobid.tei.xml',\n",
       " '1304.3265v1.grobid.tei.xml',\n",
       " '1304.3432v1.grobid.tei.xml',\n",
       " '1304.7282v1.grobid.tei.xml',\n",
       " '1304.7289v1.grobid.tei.xml',\n",
       " '1304.7507v1.grobid.tei.xml',\n",
       " '1304.7728v1.grobid.tei.xml',\n",
       " '1304.8016v1.grobid.tei.xml',\n",
       " '1305.0556v2.grobid.tei.xml',\n",
       " '1305.0625v1.grobid.tei.xml',\n",
       " '1305.1319v1.grobid.tei.xml',\n",
       " '1305.1343v1.grobid.tei.xml',\n",
       " '1305.1426v1.grobid.tei.xml',\n",
       " '1305.2846v1.grobid.tei.xml',\n",
       " '1305.2847v1.grobid.tei.xml',\n",
       " '1305.2959v1.grobid.tei.xml',\n",
       " '1305.3107v1.grobid.tei.xml',\n",
       " '1305.3882v2.grobid.tei.xml',\n",
       " '1305.3981v1.grobid.tei.xml',\n",
       " '1305.5566v2.grobid.tei.xml',\n",
       " '1305.5753v3.grobid.tei.xml',\n",
       " '1305.5785v1.grobid.tei.xml',\n",
       " '1305.5918v1.grobid.tei.xml',\n",
       " '1305.6238v1.grobid.tei.xml',\n",
       " '1305.7014v1.grobid.tei.xml',\n",
       " '1306.0963v1.grobid.tei.xml',\n",
       " '1306.1343v1.grobid.tei.xml',\n",
       " '1306.1927v1.grobid.tei.xml',\n",
       " '1306.2268v1.grobid.tei.xml',\n",
       " '1306.2593v2.grobid.tei.xml',\n",
       " '1306.3692v2.grobid.tei.xml',\n",
       " '1306.4134v1.grobid.tei.xml',\n",
       " '1306.4139v1.grobid.tei.xml',\n",
       " '1306.5263v1.grobid.tei.xml',\n",
       " '1306.6944v1.grobid.tei.xml',\n",
       " '1307.0261v1.grobid.tei.xml',\n",
       " '1307.1872v1.grobid.tei.xml',\n",
       " '1307.4038v1.grobid.tei.xml',\n",
       " '1307.4879v2.grobid.tei.xml',\n",
       " '1307.5336v2.grobid.tei.xml',\n",
       " '1307.5736v1.grobid.tei.xml',\n",
       " '1307.6163v2.grobid.tei.xml',\n",
       " '1307.6235v5.grobid.tei.xml',\n",
       " '1307.6726v1.grobid.tei.xml',\n",
       " '1307.6937v1.grobid.tei.xml',\n",
       " '1307.7382v1.grobid.tei.xml',\n",
       " '1307.8057v1.grobid.tei.xml',\n",
       " '1307.8225v1.grobid.tei.xml',\n",
       " '1308.0658v1.grobid.tei.xml',\n",
       " '1308.0897v1.grobid.tei.xml',\n",
       " '1308.1004v3.grobid.tei.xml',\n",
       " '1308.1292v1.grobid.tei.xml',\n",
       " '1308.1507v1.grobid.tei.xml',\n",
       " '1308.2359v1.grobid.tei.xml',\n",
       " '1308.2696v1.grobid.tei.xml',\n",
       " '1308.3106v1.grobid.tei.xml',\n",
       " '1308.3243v1.grobid.tei.xml',\n",
       " '1308.3294v1.grobid.tei.xml',\n",
       " '1308.3839v1.grobid.tei.xml',\n",
       " '1308.4648v3.grobid.tei.xml',\n",
       " '1308.4941v3.grobid.tei.xml',\n",
       " '1308.4965v1.grobid.tei.xml',\n",
       " '1308.5499v1.grobid.tei.xml',\n",
       " '1308.6628v2.grobid.tei.xml',\n",
       " '1309.1125v1.grobid.tei.xml',\n",
       " '1309.1501v3.grobid.tei.xml',\n",
       " '1309.1508v3.grobid.tei.xml',\n",
       " '1309.1649v2.grobid.tei.xml',\n",
       " '1309.2471v1.grobid.tei.xml',\n",
       " '1309.2853v1.grobid.tei.xml',\n",
       " '1309.3946v1.grobid.tei.xml',\n",
       " '1309.3949v1.grobid.tei.xml',\n",
       " '1309.4168v1.grobid.tei.xml',\n",
       " '1309.4628v1.grobid.tei.xml',\n",
       " '1309.5174v1.grobid.tei.xml',\n",
       " '1309.5391v1.grobid.tei.xml',\n",
       " '1309.5652v1.grobid.tei.xml',\n",
       " '1309.6047v1.grobid.tei.xml',\n",
       " '1309.6176v1.grobid.tei.xml',\n",
       " '1309.6352v1.grobid.tei.xml',\n",
       " '1309.6722v1.grobid.tei.xml',\n",
       " '1309.6874v1.grobid.tei.xml',\n",
       " '1309.7312v1.grobid.tei.xml',\n",
       " '1310.0201v2.grobid.tei.xml',\n",
       " '1310.0573v1.grobid.tei.xml',\n",
       " '1310.0575v2.grobid.tei.xml',\n",
       " '1310.0578v1.grobid.tei.xml',\n",
       " '1310.0581v1.grobid.tei.xml',\n",
       " '1310.1249v1.grobid.tei.xml',\n",
       " '1310.1285v3.grobid.tei.xml',\n",
       " '1310.1425v1.grobid.tei.xml',\n",
       " '1310.1426v1.grobid.tei.xml',\n",
       " '1310.1597v1.grobid.tei.xml',\n",
       " '1310.1964v1.grobid.tei.xml',\n",
       " '1310.1975v1.grobid.tei.xml',\n",
       " '1310.2527v1.grobid.tei.xml',\n",
       " '1310.3099v2.grobid.tei.xml',\n",
       " '1310.3333v1.grobid.tei.xml',\n",
       " '1310.3499v1.grobid.tei.xml',\n",
       " '1310.4546v1.grobid.tei.xml',\n",
       " '1310.4938v1.grobid.tei.xml',\n",
       " '1310.5963v1.grobid.tei.xml',\n",
       " '1311.0833v1.grobid.tei.xml',\n",
       " '1311.1169v1.grobid.tei.xml',\n",
       " '1311.1539v1.grobid.tei.xml',\n",
       " '1311.2252v1.grobid.tei.xml',\n",
       " '1311.2702v1.grobid.tei.xml',\n",
       " '1311.2978v1.grobid.tei.xml',\n",
       " '1311.3011v2.grobid.tei.xml',\n",
       " '1311.3987v1.grobid.tei.xml',\n",
       " '1311.6063v5.grobid.tei.xml',\n",
       " '1311.6421v1.grobid.tei.xml',\n",
       " '1312.0482v1.grobid.tei.xml',\n",
       " '1312.0493v1.grobid.tei.xml',\n",
       " '1312.2087v1.grobid.tei.xml',\n",
       " '1312.2137v1.grobid.tei.xml',\n",
       " '1312.2844v1.grobid.tei.xml',\n",
       " '1312.3005v3.grobid.tei.xml',\n",
       " '1312.3251v1.grobid.tei.xml',\n",
       " '1312.3258v1.grobid.tei.xml',\n",
       " '1312.4092v1.grobid.tei.xml',\n",
       " '1312.4706v1.grobid.tei.xml',\n",
       " '1312.4824v2.grobid.tei.xml',\n",
       " '1312.5129v2.grobid.tei.xml',\n",
       " '1312.5198v4.grobid.tei.xml',\n",
       " '1312.5559v3.grobid.tei.xml',\n",
       " '1312.5985v2.grobid.tei.xml',\n",
       " '1312.6168v3.grobid.tei.xml',\n",
       " '1312.6173v4.grobid.tei.xml',\n",
       " '1312.6192v4.grobid.tei.xml',\n",
       " '1312.6802v1.grobid.tei.xml',\n",
       " '1312.6849v2.grobid.tei.xml',\n",
       " '1312.6947v1.grobid.tei.xml',\n",
       " '1312.6948v1.grobid.tei.xml',\n",
       " '1312.7223v1.grobid.tei.xml',\n",
       " '1312.7832v9.grobid.tei.xml',\n",
       " '14',\n",
       " '1401.0509v3.grobid.tei.xml',\n",
       " '1401.0794v1.grobid.tei.xml',\n",
       " '1401.1158v1.grobid.tei.xml',\n",
       " '1401.1803v1.grobid.tei.xml',\n",
       " '1401.2258v1.grobid.tei.xml',\n",
       " '1401.2618v1.grobid.tei.xml',\n",
       " '1401.2663v1.grobid.tei.xml',\n",
       " '1401.2851v1.grobid.tei.xml',\n",
       " '1401.3322v1.grobid.tei.xml',\n",
       " '1401.3372v1.grobid.tei.xml',\n",
       " '1401.3669v1.grobid.tei.xml',\n",
       " '1401.4634v1.grobid.tei.xml',\n",
       " '1401.4869v1.grobid.tei.xml',\n",
       " '1401.4994v1.grobid.tei.xml',\n",
       " '1401.6122v1.grobid.tei.xml',\n",
       " '1401.6224v1.grobid.tei.xml',\n",
       " '1401.6571v1.grobid.tei.xml',\n",
       " '1401.6984v1.grobid.tei.xml',\n",
       " '1402.0543v1.grobid.tei.xml',\n",
       " '1402.1128v1.grobid.tei.xml',\n",
       " '1402.1454v1.grobid.tei.xml',\n",
       " '1402.1668v1.grobid.tei.xml',\n",
       " '1402.2427v1.grobid.tei.xml',\n",
       " '1402.2796v1.grobid.tei.xml',\n",
       " '1402.3382v1.grobid.tei.xml',\n",
       " '1402.3722v1.grobid.tei.xml',\n",
       " '1402.3891v1.grobid.tei.xml',\n",
       " '1402.4259v1.grobid.tei.xml',\n",
       " '1402.4678v1.grobid.tei.xml',\n",
       " '1402.4802v2.grobid.tei.xml',\n",
       " '1402.6238v1.grobid.tei.xml',\n",
       " '1402.6764v1.grobid.tei.xml',\n",
       " '1402.7265v1.grobid.tei.xml',\n",
       " '1403.0052v1.grobid.tei.xml',\n",
       " '1403.0531v1.grobid.tei.xml',\n",
       " '1403.0541v1.grobid.tei.xml',\n",
       " '1403.0801v2.grobid.tei.xml',\n",
       " '1403.1194v1.grobid.tei.xml',\n",
       " '1403.1252v2.grobid.tei.xml',\n",
       " '1403.1451v1.grobid.tei.xml',\n",
       " '1403.2004v1.grobid.tei.xml',\n",
       " '1403.2152v1.grobid.tei.xml',\n",
       " '1403.2345v1.grobid.tei.xml',\n",
       " '1403.3142v3.grobid.tei.xml',\n",
       " '1403.3185v1.grobid.tei.xml',\n",
       " '1403.3668v2.grobid.tei.xml',\n",
       " '1403.4024v3.grobid.tei.xml',\n",
       " '1403.4467v2.grobid.tei.xml',\n",
       " '1403.4473v1.grobid.tei.xml',\n",
       " '1403.4887v2.grobid.tei.xml',\n",
       " '1403.4928v1.grobid.tei.xml',\n",
       " '1403.5596v1.grobid.tei.xml',\n",
       " '1403.6023v1.grobid.tei.xml',\n",
       " '1403.6381v1.grobid.tei.xml',\n",
       " '1403.6392v2.grobid.tei.xml',\n",
       " '1403.6397v1.grobid.tei.xml',\n",
       " '1403.7335v1.grobid.tei.xml',\n",
       " '1403.7455v1.grobid.tei.xml',\n",
       " '1404.1521v3.grobid.tei.xml',\n",
       " '1404.1982v1.grobid.tei.xml',\n",
       " '1404.2997v1.grobid.tei.xml',\n",
       " '1404.3233v1.grobid.tei.xml',\n",
       " '1404.3759v1.grobid.tei.xml',\n",
       " '1404.3959v1.grobid.tei.xml',\n",
       " '1404.4314v1.grobid.tei.xml',\n",
       " '1404.4326v1.grobid.tei.xml',\n",
       " '1404.4572v1.grobid.tei.xml',\n",
       " '1404.4606v3.grobid.tei.xml',\n",
       " '1404.4714v1.grobid.tei.xml',\n",
       " '1404.6491v1.grobid.tei.xml',\n",
       " '1405.0049v2.grobid.tei.xml',\n",
       " '1405.0145v1.grobid.tei.xml',\n",
       " '1405.0546v2.grobid.tei.xml',\n",
       " '1405.0603v1.grobid.tei.xml',\n",
       " '1405.0616v1.grobid.tei.xml',\n",
       " '1405.0701v1.grobid.tei.xml',\n",
       " '1405.1346v1.grobid.tei.xml',\n",
       " '1405.1379v1.grobid.tei.xml',\n",
       " '1405.1406v1.grobid.tei.xml',\n",
       " '1405.1893v2.grobid.tei.xml',\n",
       " '1405.2048v1.grobid.tei.xml',\n",
       " '1405.2386v1.grobid.tei.xml',\n",
       " '1405.2434v1.grobid.tei.xml',\n",
       " '1405.2584v1.grobid.tei.xml',\n",
       " '1405.3272v2.grobid.tei.xml',\n",
       " '1405.3282v1.grobid.tei.xml',\n",
       " '1405.3772v1.grobid.tei.xml',\n",
       " '1405.3786v1.grobid.tei.xml',\n",
       " '1405.4053v2.grobid.tei.xml',\n",
       " '1405.4248v1.grobid.tei.xml',\n",
       " '1405.4273v1.grobid.tei.xml',\n",
       " '1405.4433v1.grobid.tei.xml',\n",
       " '1405.4599v1.grobid.tei.xml',\n",
       " '1405.4918v1.grobid.tei.xml',\n",
       " '1405.5654v1.grobid.tei.xml',\n",
       " '1405.6068v1.grobid.tei.xml',\n",
       " '1405.6103v1.grobid.tei.xml',\n",
       " '1405.6667v1.grobid.tei.xml',\n",
       " '1405.6678v1.grobid.tei.xml',\n",
       " '1405.7397v1.grobid.tei.xml',\n",
       " '1405.7519v1.grobid.tei.xml',\n",
       " '1405.7908v1.grobid.tei.xml',\n",
       " '1405.7975v1.grobid.tei.xml',\n",
       " '1406.0079v1.grobid.tei.xml',\n",
       " '1406.1143v1.grobid.tei.xml',\n",
       " '1406.1203v1.grobid.tei.xml',\n",
       " '1406.1234v1.grobid.tei.xml',\n",
       " '1406.1241v1.grobid.tei.xml',\n",
       " '1406.1765v1.grobid.tei.xml',\n",
       " '1406.2022v1.grobid.tei.xml',\n",
       " '1406.2035v2.grobid.tei.xml',\n",
       " '1406.2096v1.grobid.tei.xml',\n",
       " '1406.2204v1.grobid.tei.xml',\n",
       " '1406.2298v1.grobid.tei.xml',\n",
       " '1406.2538v1.grobid.tei.xml',\n",
       " '1406.2903v2.grobid.tei.xml',\n",
       " '1406.2963v2.grobid.tei.xml',\n",
       " '1406.3287v3.grobid.tei.xml',\n",
       " '1406.3855v1.grobid.tei.xml',\n",
       " '1406.3976v1.grobid.tei.xml',\n",
       " '1406.3987v1.grobid.tei.xml',\n",
       " '1406.4057v1.grobid.tei.xml',\n",
       " '1406.4211v1.grobid.tei.xml',\n",
       " '1406.4824v1.grobid.tei.xml',\n",
       " '1406.5181v2.grobid.tei.xml',\n",
       " '1406.5598v1.grobid.tei.xml',\n",
       " '1406.5679v1.grobid.tei.xml',\n",
       " '1406.5691v1.grobid.tei.xml',\n",
       " '1406.5824v1.grobid.tei.xml',\n",
       " '1406.7314v1.grobid.tei.xml',\n",
       " '1406.7558v1.grobid.tei.xml',\n",
       " '1406.7806v2.grobid.tei.xml',\n",
       " '1407.0167v1.grobid.tei.xml',\n",
       " '1407.1165v1.grobid.tei.xml',\n",
       " '1407.1687v3.grobid.tei.xml',\n",
       " '1407.1933v1.grobid.tei.xml',\n",
       " '1407.2918v1.grobid.tei.xml',\n",
       " '1407.3636v1.grobid.tei.xml',\n",
       " '1407.3751v1.grobid.tei.xml',\n",
       " '1407.4723v1.grobid.tei.xml',\n",
       " '1407.6027v1.grobid.tei.xml',\n",
       " '1407.6099v1.grobid.tei.xml',\n",
       " '1407.6439v3.grobid.tei.xml',\n",
       " '1407.6639v3.grobid.tei.xml',\n",
       " '1407.6853v1.grobid.tei.xml',\n",
       " '1407.6872v1.grobid.tei.xml',\n",
       " '1407.7169v1.grobid.tei.xml',\n",
       " '1407.7357v1.grobid.tei.xml',\n",
       " '1407.7736v1.grobid.tei.xml',\n",
       " '1407.8215v1.grobid.tei.xml',\n",
       " '1408.0016v1.grobid.tei.xml',\n",
       " '1408.0782v1.grobid.tei.xml',\n",
       " '1408.0985v1.grobid.tei.xml',\n",
       " '1408.1031v2.grobid.tei.xml',\n",
       " '1408.1928v1.grobid.tei.xml',\n",
       " '1408.1985v1.grobid.tei.xml',\n",
       " '1408.2359v2.grobid.tei.xml',\n",
       " '1408.2466v1.grobid.tei.xml',\n",
       " '1408.2873v2.grobid.tei.xml',\n",
       " '1408.3153v2.grobid.tei.xml',\n",
       " '1408.3829v1.grobid.tei.xml',\n",
       " '1408.3934v1.grobid.tei.xml',\n",
       " '1408.4753v1.grobid.tei.xml',\n",
       " '1408.5403v1.grobid.tei.xml',\n",
       " '1408.5427v1.grobid.tei.xml',\n",
       " '1408.6418v1.grobid.tei.xml',\n",
       " '1408.6762v1.grobid.tei.xml',\n",
       " '1408.6988v1.grobid.tei.xml',\n",
       " '1409.0314v2.grobid.tei.xml',\n",
       " '1409.0473v7.grobid.tei.xml',\n",
       " '1409.1612v2.grobid.tei.xml',\n",
       " '1409.2073v1.grobid.tei.xml',\n",
       " '1409.2433v1.grobid.tei.xml',\n",
       " '1409.2944v2.grobid.tei.xml',\n",
       " '1409.2993v1.grobid.tei.xml',\n",
       " '1409.3005v1.grobid.tei.xml',\n",
       " '1409.3215v3.grobid.tei.xml',\n",
       " '1409.3512v1.grobid.tei.xml',\n",
       " '1409.3813v1.grobid.tei.xml',\n",
       " '1409.3942v1.grobid.tei.xml',\n",
       " '1409.4169v1.grobid.tei.xml',\n",
       " '1409.4504v1.grobid.tei.xml',\n",
       " '1409.4614v4.grobid.tei.xml',\n",
       " '1409.4617v1.grobid.tei.xml',\n",
       " '1409.5502v1.grobid.tei.xml',\n",
       " '1409.5623v2.grobid.tei.xml',\n",
       " '1409.7336v2.grobid.tei.xml',\n",
       " '1409.7386v1.grobid.tei.xml',\n",
       " '1409.7591v1.grobid.tei.xml',\n",
       " '1409.7612v1.grobid.tei.xml',\n",
       " '1409.7619v1.grobid.tei.xml',\n",
       " '1409.7985v5.grobid.tei.xml',\n",
       " '1409.8008v1.grobid.tei.xml',\n",
       " '1409.8152v1.grobid.tei.xml',\n",
       " '1409.8558v1.grobid.tei.xml',\n",
       " '1409.8581v1.grobid.tei.xml',\n",
       " '1410.0210v4.grobid.tei.xml',\n",
       " '1410.0291v2.grobid.tei.xml',\n",
       " '1410.0316v1.grobid.tei.xml',\n",
       " '1410.0718v2.grobid.tei.xml',\n",
       " '1410.1135v1.grobid.tei.xml',\n",
       " '1410.2045v1.grobid.tei.xml',\n",
       " '1410.2082v2.grobid.tei.xml',\n",
       " '1410.2149v1.grobid.tei.xml',\n",
       " '1410.2455v3.grobid.tei.xml',\n",
       " '1410.2686v2.grobid.tei.xml',\n",
       " '1410.3791v1.grobid.tei.xml',\n",
       " '1410.3916v9.grobid.tei.xml',\n",
       " '1410.4176v1.grobid.tei.xml',\n",
       " '1410.4281v2.grobid.tei.xml',\n",
       " '1410.4639v3.grobid.tei.xml',\n",
       " '1410.4863v1.grobid.tei.xml',\n",
       " '1410.4966v1.grobid.tei.xml',\n",
       " '1410.5078v1.grobid.tei.xml',\n",
       " '1410.6903v1.grobid.tei.xml',\n",
       " '1410.7382v1.grobid.tei.xml',\n",
       " '1410.8027v3.grobid.tei.xml',\n",
       " '1410.8326v1.grobid.tei.xml',\n",
       " '1410.8498v2.grobid.tei.xml',\n",
       " '1410.8749v1.grobid.tei.xml',\n",
       " '1410.8783v1.grobid.tei.xml',\n",
       " '1410.8808v1.grobid.tei.xml',\n",
       " '1411.0129v2.grobid.tei.xml',\n",
       " '1411.0778v1.grobid.tei.xml',\n",
       " '1411.0861v1.grobid.tei.xml',\n",
       " '1411.1006v2.grobid.tei.xml',\n",
       " '1411.1147v2.grobid.tei.xml',\n",
       " '1411.1243v1.grobid.tei.xml',\n",
       " '1411.1999v1.grobid.tei.xml',\n",
       " '1411.2328v1.grobid.tei.xml',\n",
       " '1411.2539v1.grobid.tei.xml',\n",
       " '1411.2674v3.grobid.tei.xml',\n",
       " '1411.2679v1.grobid.tei.xml',\n",
       " '1411.2738v4.grobid.tei.xml',\n",
       " '1411.3146v1.grobid.tei.xml',\n",
       " '1411.3315v1.grobid.tei.xml',\n",
       " '1411.4072v1.grobid.tei.xml',\n",
       " '1411.4109v1.grobid.tei.xml',\n",
       " '1411.4114v1.grobid.tei.xml',\n",
       " '1411.4116v1.grobid.tei.xml',\n",
       " '1411.4194v1.grobid.tei.xml',\n",
       " '1411.4455v1.grobid.tei.xml',\n",
       " '1411.4472v1.grobid.tei.xml',\n",
       " '1411.4614v1.grobid.tei.xml',\n",
       " '1411.4618v1.grobid.tei.xml',\n",
       " '1411.4952v3.grobid.tei.xml',\n",
       " '1411.5595v2.grobid.tei.xml',\n",
       " '1411.5654v1.grobid.tei.xml',\n",
       " '1411.5726v2.grobid.tei.xml',\n",
       " '1411.5732v1.grobid.tei.xml',\n",
       " '1411.6699v1.grobid.tei.xml',\n",
       " '1411.6718v2.grobid.tei.xml',\n",
       " '1411.7942v2.grobid.tei.xml',\n",
       " '1412.0751v1.grobid.tei.xml',\n",
       " '1412.0879v1.grobid.tei.xml',\n",
       " '1412.1215v1.grobid.tei.xml',\n",
       " '1412.1454v2.grobid.tei.xml',\n",
       " '1412.1632v1.grobid.tei.xml',\n",
       " '1412.1841v2.grobid.tei.xml',\n",
       " '1412.2197v2.grobid.tei.xml',\n",
       " '1412.2378v1.grobid.tei.xml',\n",
       " '1412.2442v1.grobid.tei.xml',\n",
       " '1412.2821v1.grobid.tei.xml',\n",
       " '1412.3336v1.grobid.tei.xml',\n",
       " '1412.3714v2.grobid.tei.xml',\n",
       " '1412.4314v2.grobid.tei.xml',\n",
       " '1412.4369v3.grobid.tei.xml',\n",
       " '1412.4385v3.grobid.tei.xml',\n",
       " '1412.4616v1.grobid.tei.xml',\n",
       " '1412.4682v1.grobid.tei.xml',\n",
       " '1412.4846v2.grobid.tei.xml',\n",
       " '1412.5335v7.grobid.tei.xml',\n",
       " '1412.5404v1.grobid.tei.xml',\n",
       " '1412.5448v1.grobid.tei.xml',\n",
       " '1412.5567v2.grobid.tei.xml',\n",
       " '1412.5659v1.grobid.tei.xml',\n",
       " '1412.5673v3.grobid.tei.xml',\n",
       " '1412.5836v3.grobid.tei.xml',\n",
       " '1412.6264v1.grobid.tei.xml',\n",
       " '1412.6277v2.grobid.tei.xml',\n",
       " '1412.6334v4.grobid.tei.xml',\n",
       " '1412.6418v3.grobid.tei.xml',\n",
       " '1412.6448v4.grobid.tei.xml',\n",
       " '1412.6568v3.grobid.tei.xml',\n",
       " '1412.6575v4.grobid.tei.xml',\n",
       " '1412.6577v3.grobid.tei.xml',\n",
       " '1412.6616v1.grobid.tei.xml',\n",
       " '1412.6623v4.grobid.tei.xml',\n",
       " '1412.6645v3.grobid.tei.xml',\n",
       " '1412.6815v2.grobid.tei.xml',\n",
       " '1412.6881v3.grobid.tei.xml',\n",
       " '1412.7004v2.grobid.tei.xml',\n",
       " '1412.7026v2.grobid.tei.xml',\n",
       " '1412.7028v4.grobid.tei.xml',\n",
       " '1412.7063v5.grobid.tei.xml',\n",
       " '1412.7091v3.grobid.tei.xml',\n",
       " '1412.7415v2.grobid.tei.xml',\n",
       " '1412.7449v3.grobid.tei.xml',\n",
       " '1412.7782v1.grobid.tei.xml',\n",
       " '1412.8419v3.grobid.tei.xml',\n",
       " '15',\n",
       " '1501.00311v1.grobid.tei.xml',\n",
       " '1501.01243v1.grobid.tei.xml',\n",
       " '1501.01254v1.grobid.tei.xml',\n",
       " '1501.01386v1.grobid.tei.xml',\n",
       " '1501.01866v1.grobid.tei.xml',\n",
       " '1501.01894v1.grobid.tei.xml',\n",
       " '1501.02527v1.grobid.tei.xml',\n",
       " '1501.03214v1.grobid.tei.xml',\n",
       " '1501.03302v2.grobid.tei.xml',\n",
       " '1501.04324v1.grobid.tei.xml',\n",
       " '1501.04325v1.grobid.tei.xml',\n",
       " '1501.04346v1.grobid.tei.xml',\n",
       " '1501.05203v3.grobid.tei.xml',\n",
       " '1501.05396v1.grobid.tei.xml',\n",
       " '1501.07005v1.grobid.tei.xml',\n",
       " '1501.07496v1.grobid.tei.xml',\n",
       " '1501.07676v1.grobid.tei.xml',\n",
       " '1502.00512v1.grobid.tei.xml',\n",
       " '1502.00731v4.grobid.tei.xml',\n",
       " '1502.00831v2.grobid.tei.xml',\n",
       " '1502.01446v1.grobid.tei.xml',\n",
       " '1502.02233v1.grobid.tei.xml',\n",
       " '1502.02655v1.grobid.tei.xml',\n",
       " '1502.03322v1.grobid.tei.xml',\n",
       " '1502.03671v2.grobid.tei.xml',\n",
       " '1502.03682v1.grobid.tei.xml',\n",
       " '1502.03752v1.grobid.tei.xml',\n",
       " '1502.04049v1.grobid.tei.xml',\n",
       " '1502.04081v2.grobid.tei.xml',\n",
       " '1502.04174v1.grobid.tei.xml',\n",
       " '1502.05698v9.grobid.tei.xml',\n",
       " '1502.06161v1.grobid.tei.xml',\n",
       " '1502.07038v1.grobid.tei.xml',\n",
       " '1502.07157v2.grobid.tei.xml',\n",
       " '1502.07257v2.grobid.tei.xml',\n",
       " '1502.07504v1.grobid.tei.xml',\n",
       " '1502.08029v5.grobid.tei.xml',\n",
       " '1503.00064v1.grobid.tei.xml',\n",
       " '1503.00168v1.grobid.tei.xml',\n",
       " '1503.00841v1.grobid.tei.xml',\n",
       " '1503.01129v1.grobid.tei.xml',\n",
       " '1503.01258v1.grobid.tei.xml',\n",
       " '1503.01397v3.grobid.tei.xml',\n",
       " '1503.01549v1.grobid.tei.xml',\n",
       " '1503.01655v2.grobid.tei.xml',\n",
       " '1503.02108v2.grobid.tei.xml',\n",
       " '1503.02417v1.grobid.tei.xml',\n",
       " '1503.02427v6.grobid.tei.xml',\n",
       " '1503.03244v1.grobid.tei.xml',\n",
       " '1503.03512v4.grobid.tei.xml',\n",
       " '1503.03535v2.grobid.tei.xml',\n",
       " '1503.03989v1.grobid.tei.xml',\n",
       " '1503.04723v1.grobid.tei.xml',\n",
       " '1503.04881v1.grobid.tei.xml',\n",
       " '1503.05123v1.grobid.tei.xml',\n",
       " '1503.05543v1.grobid.tei.xml',\n",
       " '1503.05615v2.grobid.tei.xml',\n",
       " '1503.05626v1.grobid.tei.xml',\n",
       " '1503.05907v1.grobid.tei.xml',\n",
       " '1503.06151v1.grobid.tei.xml',\n",
       " '1503.06733v2.grobid.tei.xml',\n",
       " '1503.07283v1.grobid.tei.xml',\n",
       " '1503.07294v1.grobid.tei.xml',\n",
       " '1503.07613v1.grobid.tei.xml',\n",
       " '1503.07921v2.grobid.tei.xml',\n",
       " '1503.08155v1.grobid.tei.xml',\n",
       " '1503.08167v2.grobid.tei.xml',\n",
       " '1503.08542v1.grobid.tei.xml',\n",
       " '1503.08581v1.grobid.tei.xml',\n",
       " '1503.08895v5.grobid.tei.xml',\n",
       " '1503.09144v1.grobid.tei.xml',\n",
       " '1504.00325v2.grobid.tei.xml',\n",
       " '1504.00657v4.grobid.tei.xml',\n",
       " '1504.00923v1.grobid.tei.xml',\n",
       " '1504.01182v1.grobid.tei.xml',\n",
       " '1504.01255v3.grobid.tei.xml',\n",
       " '1504.01383v1.grobid.tei.xml',\n",
       " '1504.01427v1.grobid.tei.xml',\n",
       " '1504.01482v1.grobid.tei.xml',\n",
       " '1504.01483v1.grobid.tei.xml',\n",
       " '1504.01684v1.grobid.tei.xml',\n",
       " '1504.02059v1.grobid.tei.xml',\n",
       " '1504.02148v1.grobid.tei.xml',\n",
       " '1504.03425v1.grobid.tei.xml',\n",
       " '1504.03608v1.grobid.tei.xml',\n",
       " '1504.03659v1.grobid.tei.xml',\n",
       " '1504.04716v1.grobid.tei.xml',\n",
       " '1504.04751v1.grobid.tei.xml',\n",
       " '1504.04802v1.grobid.tei.xml',\n",
       " '1504.04884v3.grobid.tei.xml',\n",
       " '1504.05319v2.grobid.tei.xml',\n",
       " '1504.06063v5.grobid.tei.xml',\n",
       " '1504.06077v1.grobid.tei.xml',\n",
       " '1504.06078v1.grobid.tei.xml',\n",
       " '1504.06391v1.grobid.tei.xml',\n",
       " '1504.06665v2.grobid.tei.xml',\n",
       " '1504.06692v2.grobid.tei.xml',\n",
       " '1504.06936v1.grobid.tei.xml',\n",
       " '1504.07071v1.grobid.tei.xml',\n",
       " '1504.07225v3.grobid.tei.xml',\n",
       " '1504.07324v1.grobid.tei.xml',\n",
       " '1504.07459v1.grobid.tei.xml',\n",
       " '1504.07678v1.grobid.tei.xml',\n",
       " '1504.08102v1.grobid.tei.xml',\n",
       " '1504.08183v1.grobid.tei.xml',\n",
       " '1505.00138v1.grobid.tei.xml',\n",
       " '1505.00161v1.grobid.tei.xml',\n",
       " '1505.00277v1.grobid.tei.xml',\n",
       " '1505.00468v7.grobid.tei.xml',\n",
       " '1505.00863v1.grobid.tei.xml',\n",
       " '1505.01072v1.grobid.tei.xml',\n",
       " '1505.01121v3.grobid.tei.xml',\n",
       " '1505.01393v1.grobid.tei.xml',\n",
       " '1505.01504v2.grobid.tei.xml',\n",
       " '1505.02074v4.grobid.tei.xml',\n",
       " '1505.02251v1.grobid.tei.xml',\n",
       " '1505.02425v1.grobid.tei.xml',\n",
       " '1505.02973v1.grobid.tei.xml',\n",
       " '1505.03239v1.grobid.tei.xml',\n",
       " '1505.04197v1.grobid.tei.xml',\n",
       " '1505.04313v1.grobid.tei.xml',\n",
       " '1505.04342v6.grobid.tei.xml',\n",
       " '1505.04657v2.grobid.tei.xml',\n",
       " '1505.04891v2.grobid.tei.xml',\n",
       " '1505.05253v1.grobid.tei.xml',\n",
       " '1505.05612v3.grobid.tei.xml',\n",
       " '1505.05899v1.grobid.tei.xml',\n",
       " '1505.06027v2.grobid.tei.xml',\n",
       " '1505.06256v1.grobid.tei.xml',\n",
       " '1505.06427v1.grobid.tei.xml',\n",
       " '1505.07302v4.grobid.tei.xml',\n",
       " '1505.07599v3.grobid.tei.xml',\n",
       " '1505.07712v1.grobid.tei.xml',\n",
       " '1505.07909v4.grobid.tei.xml',\n",
       " '1505.07931v1.grobid.tei.xml',\n",
       " '1505.08149v3.grobid.tei.xml',\n",
       " '1506.00037v1.grobid.tei.xml',\n",
       " '1506.00195v1.grobid.tei.xml',\n",
       " '1506.00196v3.grobid.tei.xml',\n",
       " '1506.00278v1.grobid.tei.xml',\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../data/arxiv/tei.xml/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create `Corpus` object (on toy corpus) and extract papers content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_arxiv = utils.Corpus.Corpus(metadata_path = \"../data/arxiv/arxiv-metadata-nlp-unpublished-sample-1000.csv\",\n",
    "                      xml_dir_path= \"../data/arxiv/tei.xml/\",\n",
    "                      name = \"arXiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/arxiv/tei.xml//0001006v1.grobid.tei.xml'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_arxiv.xml_dir_path + \"/\" + os.listdir(corpus_arxiv.xml_dir_path)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus 'arXiv' is being initialized...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 208/1000 [02:26<09:16,  1.42it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcorpus_arxiv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cleme\\Documents\\STAGE\\claims-in-NLP\\corpus-constitution\\..\\utils\\Corpus.py:66\u001b[0m, in \u001b[0;36mCorpus.initialize\u001b[1;34m(self, verbose)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorpus \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is being initialized...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_papers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorpus \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m papers have been loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\cleme\\Documents\\STAGE\\claims-in-NLP\\corpus-constitution\\..\\utils\\Corpus.py:54\u001b[0m, in \u001b[0;36mCorpus.load_papers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Load the papers\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(df\u001b[38;5;241m.\u001b[39miterrows(), total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df)):\n\u001b[1;32m---> 54\u001b[0m     paper \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPaper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPaper\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m paper\u001b[38;5;241m.\u001b[39minit_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpapers\u001b[38;5;241m.\u001b[39mappend(paper)\n",
      "File \u001b[1;32mc:\\Users\\cleme\\Documents\\STAGE\\claims-in-NLP\\corpus-constitution\\..\\utils\\Paper.py:117\u001b[0m, in \u001b[0;36mPaper.__init__\u001b[1;34m(self, d, c)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Other corpus       \u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msections, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnb_ref, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_content_from_xml\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxml_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabstract\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cleme\\Documents\\STAGE\\claims-in-NLP\\corpus-constitution\\..\\utils\\Paper.py:222\u001b[0m, in \u001b[0;36mPaper.load_content_from_xml\u001b[1;34m(self, xml_file, abstract)\u001b[0m\n\u001b[0;32m    219\u001b[0m     header \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munidentified-section\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;66;03m# split the content into sentences\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m sentences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msents)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, sentence \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sentences):\n\u001b[0;32m    225\u001b[0m     sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(sentence)\n",
      "File \u001b[1;32mc:\\Users\\cleme\\Documents\\STAGE\\claims-in-NLP\\.venv\\Lib\\site-packages\\spacy\\language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1049\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcomponent_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cleme\\Documents\\STAGE\\claims-in-NLP\\.venv\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:53\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\cleme\\Documents\\STAGE\\claims-in-NLP\\.venv\\Lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:343\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.set_annotations\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\cleme\\Documents\\STAGE\\claims-in-NLP\\.venv\\Lib\\site-packages\\spacy\\pipeline\\_parser_internals\\ner.pyx:275\u001b[0m, in \u001b[0;36mspacy.pipeline._parser_internals.ner.BiluoPushDown.set_annotations\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\cleme\\Documents\\STAGE\\claims-in-NLP\\.venv\\Lib\\site-packages\\spacy\\tokens\\doc.pyx:811\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.set_ents\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\cleme\\Documents\\STAGE\\claims-in-NLP\\.venv\\Lib\\site-packages\\spacy\\tokens\\doc.pyx:127\u001b[0m, in \u001b[0;36mspacy.tokens.doc.SetEntsDefault.values\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\enum.py:803\u001b[0m, in \u001b[0;36mEnumType.__members__\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;124;03m    Return the number of members (no aliases)\u001b[39;00m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_member_names_)\n\u001b[1;32m--> 803\u001b[0m \u001b[38;5;129m@bltns\u001b[39m\u001b[38;5;241m.\u001b[39mproperty\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__members__\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[0;32m    805\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;124;03m    Returns a mapping of member name->value.\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \n\u001b[0;32m    808\u001b[0m \u001b[38;5;124;03m    This mapping lists all enum members, including aliases. Note that this\u001b[39;00m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;124;03m    is a read-only view of the internal mapping.\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MappingProxyType(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_member_map_)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "corpus_arxiv.initialize(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus 'arXiv' was filled with 208 papers:\n",
      "  - 168 papers were successfully loaded\n",
      "  - 40 papers could not be loaded\n",
      "\n",
      "Errors:\n",
      "  - FileNotFoundError: XML file does not exist : 39\n",
      "  - Noisy data: wrong language (fr) : 1\n"
     ]
    }
   ],
   "source": [
    "corpus_arxiv.describe(error_verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cleme\\Documents\\STAGE\\data\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "p = corpus_ACL.papers[0]\n",
    "s_embeddings = [model.encode(s) for s in p.content[\"sentence\"].values]\n",
    "#scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We present a series of studies of affirmative cue words-a family of cue words such as \"okay\" or \"alright\" that speakers use frequently in conversation.\n",
      "---> 0.6065555810928345 : Examples of cue phrases include now, well, so, and, but, then, after all, furthermore, however, in consequence, as a matter of fact, in fact, actually, okay, alright, for example, and incidentally.\n",
      "---> 0.8207764625549316 : In this study, we focus on a subclass of cue phrases that we term affirmative cue words (hereafter, ACWs), and that include alright, mm-hm, okay, right, and uh-huh, inter alia.\n",
      "---> 0.6668821573257446 : Whereas ACWs thus form a subset of more general classes of utterances which have been studied in more general studies of cue words, cue phrases, discourse markers, feedback utterances, linguistic feedback, acknowledgments, grounding acts, our focus is on this particular subset of lexical items which may convey an affirmative response-but which may also convey many different meanings.\n",
      "---> 0.6692189574241638 : Prior work on the automatic classification of cue phrases includes a series of studies performed by Hirschberg and Litman (Hirschberg andLitman 1987, 1993;Litman and Hirschberg 1990), which focus on differentiating between the discourse and sentential senses of single-word cue phrases such as now, well, okay, say, and so in American English.\n",
      "---> 0.6344627737998962 : These include not only the computational linguists' cue phrases but also expressions such as I see or oh wow, which CA research describes in terms of attention, understanding, and acceptance by the speaker of a proposition uttered by another conversation participant (Kendon 1967;Yngve 1970;Duncan 1972;Schegloff 1982;Jefferson 1984).\n",
      "---> 0.6366628408432007 : The authors examine 1,155 conversations from the Switchboard database (Godfrey, Holliman, and McDaniel 1992), and report that the vast majority of these four dialogue acts are realized with words like yeah, okay, or uh-huh.\n",
      "---> 0.6164366006851196 : Despite their high frequency in spontaneous conversation, the set of ACWs we examine here have seldom, if ever, been an object of study in themselves, as a separate subclass of cue phrases or dialogue acts.\n",
      "---> 0.657342791557312 : Some have attempted to model other types of cue phrases (e.g., well, like) or cue phrases in general; others discuss discourse/ pragmatic functions that may be conveyed through ACWs, but which may also be conveyed through other types of expressions (e.g., agreements may be communicated by single words such as yes or longer cue phrases such as that's correct).\n",
      "---> 0.6398480534553528 : (2007) suggest that, in task-oriented American English dialogue, contextual information (e.g., duration of surrounding silence, number of surrounding words) as well as word-final intonation figure as the most salient cues to disambiguation of the function of the word okay by human listeners.\n",
      "---> 0.6946202516555786 : Also, in a study of the function of intonation in Scottish English task-oriented dialogue, Kowtko (1996) examines a corpus of 273 instances of single-word utterances, including affirmative cue words such as mmhm, okay, right, uh-huh, and yes.\n",
      "---> 0.6347091197967529 : Although broader studies focusing on the pragmatic function of cue phrases, discourse markers, linguistic feedback, and dialogue acts do shed light on the particular subset of utterances we are studying, and although there is some information on particular lexical items we include here in our study, the class of ACWs itself has received little attention.\n",
      "---> 0.7147622108459473 : In this section we present results of a series of statistical tests aimed at identifying contextual, acoustic, and prosodic differences in the production of the various discourse/ pragmatic functions of affirmative cue words.\n",
      "---> 0.6025700569152832 : Alright and okay are the only two ACWs in the corpus that are used to cue the beginning of a new discourse segment, either combined with an agreement function (PBeg) or in its pure form (CBeg).\n",
      "---> 0.6580368280410767 : In this section we present results from machine learning (ML) experiments aimed at investigating how accurately affirmative cue words may be classified automatically into their various discourse/pragmatic functions.\n",
      "---> 0.6153199076652527 : We note that previous studies have attempted to disambiguate between the sentential and discourse uses of cue phrases such as now, well, and like, in corpora containing comparable numbers of instances of each class.\n",
      "---> 0.6374293565750122 : Among the cue words tested in Litman (1996) is okay, one of the ACWs we also investigate.\n",
      "---> 0.813957154750824 : In this work we have undertaken a comprehensive study of affirmative cue words, a subset of cue phrases such as okay, yeah, or alright that may be utilized to convey as many as ten different discourse/pragmatic functions, such as indicating continued attention to the interlocutor or cueing the beginning of a new topic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> 0.7070017457008362 : In summary, in this study we have identified a number of characterizations of affirmative cue words in a large corpus of SAE task-oriented dialogue.\n",
      "\n",
      "These words pose a challenge for spoken dialogue systems because of their ambiguity: They may be used for agreeing with what the interlocutor has said, indicating continued attention, or for cueing the start of a new topic, among other meanings.\n",
      "---> 0.7507622838020325 : These words are frequent in spontaneous conversation, especially in task-oriented dialogue, and are heavily overloaded: Their possible discourse/pragmatic functions include agreeing with what the interlocutor has said, displaying interest and continued attention, and cueing the start of a new topic.\n",
      "---> 0.6897234320640564 : The disambiguation of these meanings we believe is critical to the success of spoken dialogue systems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> 0.60649174451828 : Considering the high frequency of ACWs in task-oriented dialogue, it is critical for some spoken language processing applications such as spoken dialogue systems to model the usage of these words correctly, from both an understanding and a generation perspective.\n",
      "\n",
      "We describe differences in the acoustic/prosodic realization of such functions in a corpus of spontaneous, task-oriented dialogues in Standard American English.\n",
      "---> 0.653379499912262 : Section 4 presents a statistical description of the acoustic, prosodic, and contextual characteristics of the functions of ACWs in this corpus.\n",
      "---> 0.6250091195106506 : Novick and Sutton (1994) propose an alternative categorization of linguistic feedback in task-oriented dialogue, which is based on the structural context of exchanges rather than on the characteristics of the preceding utterance.\n",
      "---> 0.6316356658935547 : Recently, Gravano and Hirschberg (2009a, 2009b, 2011) describe six distinct prosodic, acoustic, and lexical events in American English speech that tend to precede the occurrence of a backchannel by the interlocutor.\n",
      "---> 0.653546154499054 : For example, Hockey (1993) examines the prosodic variation of two ACWs, okay and uh-huh (66 and 77 data points, respectively) produced as full intonational phrases in two spontaneous task-oriented dialogues.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> 0.6159815788269043 : The comparison of these numeric acoustic features across discourse/pragmatic functions confirms that the observations made previously for categorical prosodic features also hold when considering numeric features such as pitch slope, thus making the likelihood that such observations will be of practical use in actual systems.\n",
      "---> 0.6037591695785522 : The experiments are conducted on transcripts of 1,368 utterances from 14 dialogues in English.\n",
      "---> 0.607715904712677 : In the study of automatic classification of ACWs presented in Section 5 we show that for spoken task-oriented dialogue, the simple discourse/sentential distinction is insufficient.\n",
      "\n",
      "These results are important both for interpretation and for production in spoken language applications.\n",
      "---> 0.7787131071090698 : This kind of characterization is important both for interpretation and for production in spoken language applications: If we can find reliable features that effectively distinguish the various uses of these words, we can hope to interpret them automatically and generate them appropriately.\n",
      "---> 0.6060587763786316 : Our corpus includes instances conveying each of the ten identified meanings, and this item shows the highest degree of variation along the acoustic/prosodic features we have examined.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:01,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We also assess the predictive power of computational methods for the automatic disambiguation of these words.\n",
      "---> 0.6079588532447815 : The corpus on which our experiments were conducted, rich in ACWs conveying a wide range of discourse/pragmatic functions, has allowed us to systematically investigate many dimensions of these words, including their production and automatic disambiguation.\n",
      "\n",
      "We find that contextual information and final intonation figure as the most salient cues to automatic disambiguation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "497it [00:01, 300.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, se1 in tqdm.tqdm(enumerate(s_embeddings)):\n",
    "    if p.content.loc[i][\"section\"] != \"abstract\":\n",
    "        continue\n",
    "    s1 = p.content.iloc[i][\"sentence\"]\n",
    "    print(f\"{s1}\")\n",
    "    for j, se2 in enumerate(s_embeddings):\n",
    "        if j > i and p.content.loc[j, \"candidate\"] == True:\n",
    "            s2 = p.content.iloc[j][\"sentence\"]\n",
    "            score = util.pytorch_cos_sim(se1, se2)\n",
    "            if score > 0.6:\n",
    "                print(f\"---> {score.item()} : {s2}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We present a series of studies of affirmative cue words-a family of cue words such as \"okay\" or \"alright\" that speakers use frequently in conversation.\n",
      "---> 0.41379310344827586 : In this study, we focus on a subclass of cue phrases that we term affirmative cue words (hereafter, ACWs), and that include alright, mm-hm, okay, right, and uh-huh, inter alia.\n",
      "---> 0.4242424242424242 : Also, in a study of the function of intonation in Scottish English task-oriented dialogue, Kowtko (1996) examines a corpus of 273 instances of single-word utterances, including affirmative cue words such as mmhm, okay, right, uh-huh, and yes.\n",
      "---> 0.45 : In this work we have undertaken a comprehensive study of affirmative cue words, a subset of cue phrases such as okay, yeah, or alright that may be utilized to convey as many as ten different discourse/pragmatic functions, such as indicating continued attention to the interlocutor or cueing the beginning of a new topic.\n",
      "---> 0.4313725490196078 : In summary, in this study we have identified a number of characterizations of affirmative cue words in a large corpus of SAE task-oriented dialogue.\n",
      "\n",
      "These words pose a challenge for spoken dialogue systems because of their ambiguity: They may be used for agreeing with what the interlocutor has said, indicating continued attention, or for cueing the start of a new topic, among other meanings.\n",
      "---> 0.4878048780487805 : These words are frequent in spontaneous conversation, especially in task-oriented dialogue, and are heavily overloaded: Their possible discourse/pragmatic functions include agreeing with what the interlocutor has said, displaying interest and continued attention, and cueing the start of a new topic.\n",
      "\n",
      "We describe differences in the acoustic/prosodic realization of such functions in a corpus of spontaneous, task-oriented dialogues in Standard American English.\n",
      "---> 0.4090909090909091 : Section 4 presents a statistical description of the acoustic, prosodic, and contextual characteristics of the functions of ACWs in this corpus.\n",
      "---> 0.4126984126984127 : Also, in a study of the function of intonation in Scottish English task-oriented dialogue, Kowtko (1996) examines a corpus of 273 instances of single-word utterances, including affirmative cue words such as mmhm, okay, right, uh-huh, and yes.\n",
      "---> 0.4583333333333333 : In summary, in this study we have identified a number of characterizations of affirmative cue words in a large corpus of SAE task-oriented dialogue.\n",
      "\n",
      "These results are important both for interpretation and for production in spoken language applications.\n",
      "---> 0.42857142857142855 : This kind of characterization is important both for interpretation and for production in spoken language applications: If we can find reliable features that effectively distinguish the various uses of these words, we can hope to interpret them automatically and generate them appropriately.\n",
      "\n",
      "We also assess the predictive power of computational methods for the automatic disambiguation of these words.\n",
      "---> 0.4375 : The disambiguation of these meanings we believe is critical to the success of spoken dialogue systems.\n",
      "---> 0.4210526315789473 : In the studies presented here, our goal is to extend our understanding of ACWs, in particular by finding descriptions of the acoustic/prosodic characteristics of their different functions, and by assessing the predictive power of computational methods for their automatic disambiguation.\n",
      "\n",
      "We find that contextual information and final intonation figure as the most salient cues to automatic disambiguation.\n",
      "---> 0.41935483870967744 : (2007) suggest that, in task-oriented American English dialogue, contextual information (e.g., duration of surrounding silence, number of surrounding words) as well as word-final intonation figure as the most salient cues to disambiguation of the function of the word okay by human listeners.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "for i, s1 in enumerate(p.content[\"sentence\"].values):\n",
    "    if p.content.loc[i][\"section\"] != \"abstract\":\n",
    "        continue\n",
    "    print(f\"{s1}\")\n",
    "    for j, s2 in enumerate(p.content[\"sentence\"].values):\n",
    "        if j > i and p.content.loc[j, \"candidate\"] == True:\n",
    "            r_scores = scorer.score(s1, s2)\n",
    "            if r_scores[\"rouge1\"].fmeasure > 0.4:\n",
    "                print(f\"---> {r_scores['rouge1'].fmeasure} : {s2}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 12.,  33.,  52.,  82., 117., 108., 120., 118.,  96.,  86.,  59.,\n",
       "         45.,  36.,  27.,  10.,  11.,   3.,   2.,   2.,   3.]),\n",
       " array([-0.06328004, -0.02201925,  0.01924153,  0.06050231,  0.1017631 ,\n",
       "         0.14302388,  0.18428467,  0.22554545,  0.26680624,  0.30806702,\n",
       "         0.34932781,  0.39058859,  0.43184938,  0.47311016,  0.51437094,\n",
       "         0.55563173,  0.59689251,  0.6381533 ,  0.67941408,  0.72067487,\n",
       "         0.76193565]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = sorted(scores, key = lambda x: x[2], reverse = True)\n",
    "plt.hist([s[2] for s in scores], bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Between 1.0 and 0.95\n",
      "\n",
      "---Between 0.95 and 0.8999999999999999\n",
      "\n",
      "---Between 0.8999999999999999 and 0.8499999999999999\n",
      "\n",
      "---Between 0.8499999999999999 and 0.7999999999999998\n",
      "\n",
      "---Between 0.7999999999999998 and 0.7499999999999998\n",
      "\n",
      "---Between 0.7499999999999998 and 0.6999999999999997\n",
      "The proposed LM can be expanded to new domains by adding about 2% of parameters for a first domain and 13% parameters for after second domain. \n",
      " The proposed architecture allows LMs to expand multi-domain, suppressing the increase of the number of parameters. \n",
      " 0.7619356513023376\n",
      "  We propose an adapter based multi-domain Transformer based language model (LM) for Transformer ASR. \n",
      " In this paper, we study an external LM structure for Transformer based ASR model that can be adapted for multi-domain with only 2% or 13% parameter addition per domain. \n",
      " 0.7546730637550354\n",
      "The proposed model can reuse the full fine-tuned LM which is fine-tuned using all layers of an original model. \n",
      " Finally, the proposed architecture can reuse standard full fine-tuned LMs. \n",
      " 0.7542180418968201\n",
      "\n",
      "---Between 0.6999999999999997 and 0.6499999999999997\n",
      "The proposed model can reuse the full fine-tuned LM which is fine-tuned using all layers of an original model. \n",
      " So, the full fine-tuned LMs can be easily reused (or transferred) without any changes. \n",
      " 0.7150662541389465\n",
      "\n",
      "---Between 0.6499999999999997 and 0.5999999999999996\n",
      "Using proposed adapter based approach, we observed that a general LM with adapter can outperform a dedicated music domain LM in terms of word error rate (WER). \n",
      " In the experiments, a general domain LM (G-LM), a music specialized domain LM (M-LM), and adapter added general and music LMs (G-LM-A, M-LM-A) are used. \n",
      " 0.6839401721954346\n",
      "The proposed LM can be expanded to new domains by adding about 2% of parameters for a first domain and 13% parameters for after second domain. \n",
      " 2) Multi-domain LM can be supported with fewer parameters. \n",
      " 0.6787692904472351\n",
      "  We propose an adapter based multi-domain Transformer based language model (LM) for Transformer ASR. \n",
      " To the best of our knowledge, this is a first attempt applying adapters to Transformer LM in ASR. \n",
      " 0.6717246174812317\n",
      "\n",
      "---Between 0.5999999999999996 and 0.5499999999999996\n",
      "The proposed model is also effective in reducing the model maintenance cost because it is possible to omit the costly and time-consuming common LM pre-training process. \n",
      " 3) Our approach provides cost efficient way to maintain existing models. \n",
      " 0.630357563495636\n",
      "The proposed LM can be expanded to new domains by adding about 2% of parameters for a first domain and 13% parameters for after second domain. \n",
      " Therefore, a multi-domain LM configuration with the structure shown in Figure 2 is possible. \n",
      " 0.6172383427619934\n",
      "\n",
      "---Between 0.5499999999999996 and 0.4999999999999996\n",
      "The model can perform multi-domain adaptation with only the small size adapters and its related layers. \n",
      " This means that a common G-LM with adapters can be used as a dedicated domain LM, and we can switch only adapter related layers to fit our model on each domain. \n",
      " 0.5986753106117249\n",
      "  We propose an adapter based multi-domain Transformer based language model (LM) for Transformer ASR. \n",
      " Transformer was first introduced as a model for translation [1]. \n",
      " 0.5889422297477722\n",
      "The model consists of a big size common LM and small size adapters. \n",
      " In the paper, a large common model is used as a base model. \n",
      " 0.5846380591392517\n",
      "The proposed LM can be expanded to new domains by adding about 2% of parameters for a first domain and 13% parameters for after second domain. \n",
      " Since 𝑓 𝐴 is a relatively small value, the increasing number of parameters per domain is about 2% for the first domain and about 13% for after the second domain. \n",
      " 0.5825341939926147\n",
      "  We propose an adapter based multi-domain Transformer based language model (LM) for Transformer ASR. \n",
      " Also we observed that applying adapter module on Transformer LM has an effect on WER improvement especially for proper nouns that is hard to be handled with a common base LM. \n",
      " 0.5804556608200073\n",
      "The proposed model can reuse the full fine-tuned LM which is fine-tuned using all layers of an original model. \n",
      " Table 5 compares the case of using a G-LM as a common base LM with an iterative adapter fine-tuned G-LM (E2E-G-LMiter) and the case of creating a dedicated M-LM and full fine-tune or adapter fine-tune it (E2E-M-LM, E2E-M-LM-A). \n",
      " 0.5801664590835571\n",
      "The proposed model can reuse the full fine-tuned LM which is fine-tuned using all layers of an original model. \n",
      " The proposed model is also effective in reducing the model maintenance cost because it is possible to omit the costly and time-consuming common LM pre-training process. \n",
      " 0.5724422931671143\n",
      "Using proposed adapter based approach, we observed that a general LM with adapter can outperform a dedicated music domain LM in terms of word error rate (WER). \n",
      " Intuitively, when we decode music domain TCs with the E2E model and G-LM without any adaptation (E2E-G-LM) as a baseline, it showed a higher error rates than E2E-M-LM and E2E-M-LM-A. \n",
      " 0.5709532499313354\n",
      "  We propose an adapter based multi-domain Transformer based language model (LM) for Transformer ASR. \n",
      " For multilingual ASR, a structure is introduced so that only adapter layers can be switched [20]. \n",
      " 0.5706966519355774\n",
      "The proposed model can reuse the full fine-tuned LM which is fine-tuned using all layers of an original model. \n",
      " Meanwhile, in [16], a method to fine-tune models by adding only adjustable 3.6% of parameters has been proposed. \n",
      " 0.564490795135498\n",
      "  We propose an adapter based multi-domain Transformer based language model (LM) for Transformer ASR. \n",
      " Figure 1 shows a Transformer based E2E ASR models with an external LM. \n",
      " 0.5633689165115356\n",
      "  We propose an adapter based multi-domain Transformer based language model (LM) for Transformer ASR. \n",
      " In this paper, adapter based multi-domain LM structure has been proposed. \n",
      " 0.5611745715141296\n",
      "The proposed LM can be expanded to new domains by adding about 2% of parameters for a first domain and 13% parameters for after second domain. \n",
      " For simplicity we set batch size and the number of domains to one in the followings. \n",
      " 0.5524855852127075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for score in np.arange(1.0, 0.5, -0.05):\n",
    "    print(f\"---Between {score} and {score - 0.05}\")\n",
    "    _ = [print(s[0], \"\\n\", s[1], \"\\n\", s[2]) for s in scores if s[2] > score and s[2] < score + 0.05]\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8875]])\n",
      "  The long-standing one-to-many issue of the open-domain dialogues poses significant challenges for automatic evaluation methods, i.e., there may be multiple suitable responses which differ in semantics for a given conversational context.\n",
      "In addition, we provide a detailed analysis of the effectiveness of our proposed method in solving the one-to-many issue in open-domain dialogue evaluation.\n",
      "\n",
      "tensor([[0.8517]])\n",
      "  The long-standing one-to-many issue of the open-domain dialogues poses significant challenges for automatic evaluation methods, i.e., there may be multiple suitable responses which differ in semantics for a given conversational context.\n",
      "To tackle the one-to-many issue, we design a reference-based automatic evaluation metric (CMN), which can robustly evaluate open-domain dialogues with a single gold-standard reference.\n",
      "\n",
      "tensor([[0.8243]])\n",
      "Experimental results on two open-domain dialogue datasets demonstrate the superiority of our method compared with a wide range of baselines, especially in handling responses which are distant to the golden reference responses in semantics.\n",
      "Experimental results on two open-domain dialogue datasets show the superiority of our method compared to a wide range of baseline metrics based on both Pearson and Spearman correlations with human annotations.\n",
      "\n",
      "tensor([[0.8081]])\n",
      "  The long-standing one-to-many issue of the open-domain dialogues poses significant challenges for automatic evaluation methods, i.e., there may be multiple suitable responses which differ in semantics for a given conversational context.\n",
      "Although our proposed method performs well in evaluating the open-domain dialogue systems, it also has some limitations.\n",
      "\n",
      "tensor([[0.7995]])\n",
      "Experimental results on two open-domain dialogue datasets demonstrate the superiority of our method compared with a wide range of baselines, especially in handling responses which are distant to the golden reference responses in semantics.\n",
      "Existing approaches for evaluating open-domain dialogue systems can be broadly divided into two different categories: reference-based and referencefree approaches.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cos_sim_scores = []\n",
    "for a_s in abs_sentences:\n",
    "    embedding_1= model.encode(a_s, convert_to_tensor=True)\n",
    "    for i, na_s in enumerate(non_abs_sentences):\n",
    "        embedding_2 = model.encode(na_s, convert_to_tensor=True)\n",
    "        cos_sim = util.pytorch_cos_sim(embedding_1, embedding_2)\n",
    "        cos_sim_scores.append((cos_sim, a_s, na_s))\n",
    "\n",
    "cos_sim_scores = sorted(cos_sim_scores, key = lambda x: x[0], reverse = True)\n",
    "for top_sim in cos_sim_scores[:5]:\n",
    "    print(top_sim[0])\n",
    "    print(top_sim[1])\n",
    "    print(top_sim[2])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of some papers for annotation (doccano)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 5 random papers in acl and 5 random papers in arxiv\n",
    "import random\n",
    "# random seed for reproducibility\n",
    "random.seed(23)\n",
    "random_acl = random.sample(corpus_ACL.papers, 5)\n",
    "random_arxiv = random.sample(corpus_arxiv.papers, 5)\n",
    "\n",
    "random_list = random_acl + random_arxiv\n",
    "\n",
    "# shuffle the list\n",
    "random.shuffle(random_list)\n",
    "\n",
    "data = []\n",
    "\n",
    "for rp in random_list:\n",
    "    contents = rp.content[[\"sentence\", \"section\", \"id\", \"candidate\"]].values\n",
    "    for i, row in enumerate(contents):\n",
    "        if row[3] == True:\n",
    "            # catch the previous sentence\n",
    "            if i == 0:\n",
    "                prev_sec, prev_sent = None, None\n",
    "            else:\n",
    "                prev_sec, prev_sent = contents[i-1][1], contents[i-1][0]\n",
    "\n",
    "            # current sentence (the one to annotate)\n",
    "            sec, sent = row[1], row[0]\n",
    "\n",
    "            # catch the next sentence\n",
    "            if i == len(contents) - 1:\n",
    "                next_sec, next_sent = None, None\n",
    "            else:\n",
    "                next_sec, next_sent = contents[i+1][1], contents[i+1][0]\n",
    "\n",
    "            data.append({\"article_id\": rp.id, \"source\": rp.corpus.name, \"sent_id\": row[2], \"prev_sec\": prev_sec, \"prev_sent\": prev_sent, \"sec\": sec, \"sent\": sent, \"next_sec\": next_sec, \"next_sent\": next_sent})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>source</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>prev_sec</th>\n",
       "      <th>prev_sent</th>\n",
       "      <th>sec</th>\n",
       "      <th>sent</th>\n",
       "      <th>next_sec</th>\n",
       "      <th>next_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012.08013</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The prevalence of ambiguous acronyms make sc...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>We introduce new methods for acronym identific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012.08013</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>1</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The prevalence of ambiguous acronyms make sc...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>We introduce new methods for acronym identific...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Both of our systems achieve significant perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012.08013</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>2</td>\n",
       "      <td>abstract</td>\n",
       "      <td>We introduce new methods for acronym identific...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Both of our systems achieve significant perfor...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Our models were trained in part on new distant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012.08013</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>3</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Both of our systems achieve significant perfor...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Our models were trained in part on new distant...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>We also identified a duplication conflict issu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012.08013</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>4</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Our models were trained in part on new distant...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>We also identified a duplication conflict issu...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>We publicly released all three of these datase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>2211.05414</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>228</td>\n",
       "      <td>Ethics Statement</td>\n",
       "      <td>In our paper, we discussed the usage of ADEPT ...</td>\n",
       "      <td>Ethics Statement</td>\n",
       "      <td>It is reasonable to have concerns that a binar...</td>\n",
       "      <td>Ethics Statement</td>\n",
       "      <td>Luckily, all pieces of ADEPT are directly exte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>2211.05414</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>229</td>\n",
       "      <td>Ethics Statement</td>\n",
       "      <td>It is reasonable to have concerns that a binar...</td>\n",
       "      <td>Ethics Statement</td>\n",
       "      <td>Luckily, all pieces of ADEPT are directly exte...</td>\n",
       "      <td>Ethics Statement</td>\n",
       "      <td>Unfortunately, we cannot ensure or contradict ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>2211.05414</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>230</td>\n",
       "      <td>Ethics Statement</td>\n",
       "      <td>Luckily, all pieces of ADEPT are directly exte...</td>\n",
       "      <td>Ethics Statement</td>\n",
       "      <td>Unfortunately, we cannot ensure or contradict ...</td>\n",
       "      <td>Ethics Statement</td>\n",
       "      <td>Goldfarb-Tarrant et al.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>2211.05414</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>231</td>\n",
       "      <td>Ethics Statement</td>\n",
       "      <td>Unfortunately, we cannot ensure or contradict ...</td>\n",
       "      <td>Ethics Statement</td>\n",
       "      <td>Goldfarb-Tarrant et al.</td>\n",
       "      <td>Ethics Statement</td>\n",
       "      <td>(2020) makes an effort to deny the causality b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>2211.05414</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>232</td>\n",
       "      <td>Ethics Statement</td>\n",
       "      <td>Goldfarb-Tarrant et al.</td>\n",
       "      <td>Ethics Statement</td>\n",
       "      <td>(2020) makes an effort to deny the causality b...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1154 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_id source  sent_id          prev_sec  \\\n",
       "0     2012.08013  arXiv        0              None   \n",
       "1     2012.08013  arXiv        1          abstract   \n",
       "2     2012.08013  arXiv        2          abstract   \n",
       "3     2012.08013  arXiv        3          abstract   \n",
       "4     2012.08013  arXiv        4          abstract   \n",
       "...          ...    ...      ...               ...   \n",
       "1149  2211.05414  arXiv      228  Ethics Statement   \n",
       "1150  2211.05414  arXiv      229  Ethics Statement   \n",
       "1151  2211.05414  arXiv      230  Ethics Statement   \n",
       "1152  2211.05414  arXiv      231  Ethics Statement   \n",
       "1153  2211.05414  arXiv      232  Ethics Statement   \n",
       "\n",
       "                                              prev_sent               sec  \\\n",
       "0                                                  None          abstract   \n",
       "1       The prevalence of ambiguous acronyms make sc...          abstract   \n",
       "2     We introduce new methods for acronym identific...          abstract   \n",
       "3     Both of our systems achieve significant perfor...          abstract   \n",
       "4     Our models were trained in part on new distant...          abstract   \n",
       "...                                                 ...               ...   \n",
       "1149  In our paper, we discussed the usage of ADEPT ...  Ethics Statement   \n",
       "1150  It is reasonable to have concerns that a binar...  Ethics Statement   \n",
       "1151  Luckily, all pieces of ADEPT are directly exte...  Ethics Statement   \n",
       "1152  Unfortunately, we cannot ensure or contradict ...  Ethics Statement   \n",
       "1153                            Goldfarb-Tarrant et al.  Ethics Statement   \n",
       "\n",
       "                                                   sent          next_sec  \\\n",
       "0       The prevalence of ambiguous acronyms make sc...          abstract   \n",
       "1     We introduce new methods for acronym identific...          abstract   \n",
       "2     Both of our systems achieve significant perfor...          abstract   \n",
       "3     Our models were trained in part on new distant...          abstract   \n",
       "4     We also identified a duplication conflict issu...          abstract   \n",
       "...                                                 ...               ...   \n",
       "1149  It is reasonable to have concerns that a binar...  Ethics Statement   \n",
       "1150  Luckily, all pieces of ADEPT are directly exte...  Ethics Statement   \n",
       "1151  Unfortunately, we cannot ensure or contradict ...  Ethics Statement   \n",
       "1152                            Goldfarb-Tarrant et al.  Ethics Statement   \n",
       "1153  (2020) makes an effort to deny the causality b...              None   \n",
       "\n",
       "                                              next_sent  \n",
       "0     We introduce new methods for acronym identific...  \n",
       "1     Both of our systems achieve significant perfor...  \n",
       "2     Our models were trained in part on new distant...  \n",
       "3     We also identified a duplication conflict issu...  \n",
       "4     We publicly released all three of these datase...  \n",
       "...                                                 ...  \n",
       "1149  Luckily, all pieces of ADEPT are directly exte...  \n",
       "1150  Unfortunately, we cannot ensure or contradict ...  \n",
       "1151                            Goldfarb-Tarrant et al.  \n",
       "1152  (2020) makes an effort to deny the causality b...  \n",
       "1153                                               None  \n",
       "\n",
       "[1154 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_anno = pd.DataFrame(data)\n",
    "df_anno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For arxiv papers, we'll redraw some articles to avoid them being part of the ACL Antho / being too recent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_anno.to_csv(\"claims-to-annotate-10-papers.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W17-4709' 'P18-1048' 'Y15-1047' 'N19-1358' '2020.signlang-1.20']\n"
     ]
    }
   ],
   "source": [
    "df_anno = pd.read_csv(\"claims-to-annotate-10-papers.csv\")\n",
    "df_anno = df_anno[df_anno[\"source\"] == \"ACL\"]\n",
    "random_acl = df_anno.article_id.unique()\n",
    "print(random_acl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023    8868\n",
       "2024    5198\n",
       "2022    4439\n",
       "2021    3906\n",
       "2020    3332\n",
       "2019    2480\n",
       "2018    1821\n",
       "2017    1247\n",
       "2016     922\n",
       "2015     468\n",
       "2014     291\n",
       "2008     238\n",
       "2007     190\n",
       "2013     161\n",
       "2012     124\n",
       "2011      46\n",
       "2009      46\n",
       "2010      40\n",
       "Name: update_year, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpublished_NLP = pd.read_csv(\"arxiv-metadata-nlp-unpublished.csv\")\n",
    "unpublished_NLP[\"update_year\"] = unpublished_NLP[\"update_date\"].apply(lambda x: x[:4])\n",
    "unpublished_NLP[\"update_year\"] = unpublished_NLP[\"update_year\"].astype(int)\n",
    "unpublished_NLP[\"update_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(511, 14)\n"
     ]
    }
   ],
   "source": [
    "unpublished_NLP_upto2022 = unpublished_NLP[unpublished_NLP[\"update_year\"]<2023]\n",
    "arxiv_df = pd.read_csv(\"arxiv-metadata-nlp-unpublished-sample-1000.csv\")\n",
    "arxiv_df = arxiv_df[arxiv_df[\"id\"].isin(set(unpublished_NLP_upto2022.id.values))]\n",
    "print(arxiv_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1605.05172', '2012.04584', '2103.14302', '1708.01009', '1611.08765']\n",
      "['2020.signlang-1.20', 'W17-4709', 'N19-1358', '2103.14302', 'Y15-1047', 'P18-1048', '1708.01009', '1611.08765', '1605.05172', '2012.04584']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(23)\n",
    "random_arxiv = random.sample(list(arxiv_df[\"id\"]), 5)\n",
    "print(random_arxiv)\n",
    "\n",
    "random_idx = random_arxiv + list(random_acl)\n",
    "random.shuffle(random_idx)\n",
    "print(random_idx)\n",
    "\n",
    "data = []\n",
    "for idx in random_idx:\n",
    "    if idx in random_arxiv:\n",
    "        p = corpus_arxiv.get_paper_by_id(idx)\n",
    "\n",
    "        contents = p.content[[\"sentence\", \"section\", \"id\", \"candidate\"]].values\n",
    "        for i, row in enumerate(contents):\n",
    "            if row[3] == True:\n",
    "                # catch the previous sentence\n",
    "                if i == 0:\n",
    "                    prev_sec, prev_sent = None, None\n",
    "                else:\n",
    "                    prev_sec, prev_sent = contents[i-1][1], contents[i-1][0]\n",
    "\n",
    "                # current sentence (the one to annotate)\n",
    "                sec, sent = row[1], row[0]\n",
    "\n",
    "                # catch the next sentence\n",
    "                if i == len(contents) - 1:\n",
    "                    next_sec, next_sent = None, None\n",
    "                else:\n",
    "                    next_sec, next_sent = contents[i+1][1], contents[i+1][0]\n",
    "\n",
    "                data.append({\"article-title\": p.title, \"article_id\": p.id, \"source\": p.corpus.name, \"sent_id\": row[2], \"prev_sec\": prev_sec, \"prev_sent\": prev_sent, \"sec\": sec, \"sent\": sent, \"next_sec\": next_sec, \"next_sent\": next_sent})\n",
    "\n",
    "    else:\n",
    "        rows = df_anno[df_anno[\"article_id\"] == idx]\n",
    "        for i, row in rows.iterrows():\n",
    "            data.append({\"article-title\": \"\", \"article_id\": row[\"article_id\"], \"source\": \"ACL\", \"sent_id\": row[\"sent_id\"], \"prev_sec\": row[\"prev_sec\"], \"prev_sent\": row[\"prev_sent\"], \"sec\": row[\"sec\"], \"sent\": row[\"sent\"], \"next_sec\": row[\"next_sec\"], \"next_sent\": row[\"next_sent\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article-title</th>\n",
       "      <th>article_id</th>\n",
       "      <th>source</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>prev_sec</th>\n",
       "      <th>prev_sent</th>\n",
       "      <th>sec</th>\n",
       "      <th>sent</th>\n",
       "      <th>next_sec</th>\n",
       "      <th>next_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2020.signlang-1.20</td>\n",
       "      <td>ACL</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abstract</td>\n",
       "      <td>In this paper we report on a research effort f...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Three sequential models have been developed fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2020.signlang-1.20</td>\n",
       "      <td>ACL</td>\n",
       "      <td>1</td>\n",
       "      <td>abstract</td>\n",
       "      <td>In this paper we report on a research effort f...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Three sequential models have been developed fo...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The models have been applied to a Danish and a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2020.signlang-1.20</td>\n",
       "      <td>ACL</td>\n",
       "      <td>2</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Three sequential models have been developed fo...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The models have been applied to a Danish and a...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Moreover, during the reported research, a meth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2020.signlang-1.20</td>\n",
       "      <td>ACL</td>\n",
       "      <td>3</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The models have been applied to a Danish and a...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Moreover, during the reported research, a meth...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>One of the problems relating to sign language ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2020.signlang-1.20</td>\n",
       "      <td>ACL</td>\n",
       "      <td>4</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Moreover, during the reported research, a meth...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>One of the problems relating to sign language ...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>Therefore, most data collections contain a ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>Distilling Knowledge from Reader to Retriever ...</td>\n",
       "      <td>2012.04584</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>230</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In this paper, we introduce a method to train ...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>Our approach is inspired by knowledge distilla...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In particular, we use the cross-attention scor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>Distilling Knowledge from Reader to Retriever ...</td>\n",
       "      <td>2012.04584</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>231</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>Our approach is inspired by knowledge distilla...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In particular, we use the cross-attention scor...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>We compare different ways to aggregate the sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Distilling Knowledge from Reader to Retriever ...</td>\n",
       "      <td>2012.04584</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>232</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In particular, we use the cross-attention scor...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>We compare different ways to aggregate the sco...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>We show that iteratively training the reader a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Distilling Knowledge from Reader to Retriever ...</td>\n",
       "      <td>2012.04584</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>233</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>We compare different ways to aggregate the sco...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>We show that iteratively training the reader a...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In the future, we would like to explore better...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Distilling Knowledge from Reader to Retriever ...</td>\n",
       "      <td>2012.04584</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>234</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>We show that iteratively training the reader a...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In the future, we would like to explore better...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>987 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         article-title          article_id  \\\n",
       "0                                                       2020.signlang-1.20   \n",
       "1                                                       2020.signlang-1.20   \n",
       "2                                                       2020.signlang-1.20   \n",
       "3                                                       2020.signlang-1.20   \n",
       "4                                                       2020.signlang-1.20   \n",
       "..                                                 ...                 ...   \n",
       "982  Distilling Knowledge from Reader to Retriever ...          2012.04584   \n",
       "983  Distilling Knowledge from Reader to Retriever ...          2012.04584   \n",
       "984  Distilling Knowledge from Reader to Retriever ...          2012.04584   \n",
       "985  Distilling Knowledge from Reader to Retriever ...          2012.04584   \n",
       "986  Distilling Knowledge from Reader to Retriever ...          2012.04584   \n",
       "\n",
       "    source  sent_id    prev_sec  \\\n",
       "0      ACL        0         NaN   \n",
       "1      ACL        1    abstract   \n",
       "2      ACL        2    abstract   \n",
       "3      ACL        3    abstract   \n",
       "4      ACL        4    abstract   \n",
       "..     ...      ...         ...   \n",
       "982  arXiv      230  CONCLUSION   \n",
       "983  arXiv      231  CONCLUSION   \n",
       "984  arXiv      232  CONCLUSION   \n",
       "985  arXiv      233  CONCLUSION   \n",
       "986  arXiv      234  CONCLUSION   \n",
       "\n",
       "                                             prev_sent           sec  \\\n",
       "0                                                  NaN      abstract   \n",
       "1    In this paper we report on a research effort f...      abstract   \n",
       "2    Three sequential models have been developed fo...      abstract   \n",
       "3    The models have been applied to a Danish and a...      abstract   \n",
       "4    Moreover, during the reported research, a meth...  Introduction   \n",
       "..                                                 ...           ...   \n",
       "982  In this paper, we introduce a method to train ...    CONCLUSION   \n",
       "983  Our approach is inspired by knowledge distilla...    CONCLUSION   \n",
       "984  In particular, we use the cross-attention scor...    CONCLUSION   \n",
       "985  We compare different ways to aggregate the sco...    CONCLUSION   \n",
       "986  We show that iteratively training the reader a...    CONCLUSION   \n",
       "\n",
       "                                                  sent      next_sec  \\\n",
       "0    In this paper we report on a research effort f...      abstract   \n",
       "1    Three sequential models have been developed fo...      abstract   \n",
       "2    The models have been applied to a Danish and a...      abstract   \n",
       "3    Moreover, during the reported research, a meth...  Introduction   \n",
       "4    One of the problems relating to sign language ...  Introduction   \n",
       "..                                                 ...           ...   \n",
       "982  Our approach is inspired by knowledge distilla...    CONCLUSION   \n",
       "983  In particular, we use the cross-attention scor...    CONCLUSION   \n",
       "984  We compare different ways to aggregate the sco...    CONCLUSION   \n",
       "985  We show that iteratively training the reader a...    CONCLUSION   \n",
       "986  In the future, we would like to explore better...          None   \n",
       "\n",
       "                                             next_sent  \n",
       "0    Three sequential models have been developed fo...  \n",
       "1    The models have been applied to a Danish and a...  \n",
       "2    Moreover, during the reported research, a meth...  \n",
       "3    One of the problems relating to sign language ...  \n",
       "4    Therefore, most data collections contain a ver...  \n",
       "..                                                 ...  \n",
       "982  In particular, we use the cross-attention scor...  \n",
       "983  We compare different ways to aggregate the sco...  \n",
       "984  We show that iteratively training the reader a...  \n",
       "985  In the future, we would like to explore better...  \n",
       "986                                               None  \n",
       "\n",
       "[987 rows x 10 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W17-4709': 'Tree as a Pivot: Syntactic Matching Methods in Pivot Translation',\n",
       " 'P18-1048': 'Self-regulation: Employing a Generative Adversarial Network to Improve Event Detection',\n",
       " 'Y15-1047': 'Not Voice but Case Identity in {VP} Ellipsis of {E}nglish',\n",
       " 'N19-1358': 'Playing Text-Adventure Games with Graph-Based Deep Reinforcement Learning',\n",
       " '2020.signlang-1.20': 'Recognition of Static Features in Sign Language Using Key-Points'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acl = pd.read_pickle(\"acl-metadata-sample-1000.pkl\")\n",
    "id2titles = {}\n",
    "for idx in random_acl:\n",
    "    id2titles[idx] = df_acl[df_acl[\"acl_id\"] == idx].title.values[0]\n",
    "\n",
    "id2titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article-title\n",
       "Not Voice but Case Identity in {VP} Ellipsis of {E}nglish                                     183\n",
       "Fill it up: Exploiting partial dependency annotations in a minimum\\n  spanning tree parser    141\n",
       "Self-regulation: Employing a Generative Adversarial Network to Improve Event Detection        136\n",
       "Playing Text-Adventure Games with Graph-Based Deep Reinforcement Learning                     112\n",
       "Siamese convolutional networks based on phonetic features for cognate\\n  identification       103\n",
       "Tree as a Pivot: Syntactic Matching Methods in Pivot Translation                               92\n",
       "Revisiting Activation Regularization for Language RNNs                                         76\n",
       "Distilling Knowledge from Reader to Retriever for Question Answering                           66\n",
       "Mutually-Constrained Monotonic Multihead Attention for Online ASR                              61\n",
       "Recognition of Static Features in Sign Language Using Key-Points                               17\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx in random_acl:\n",
    "    # assign the title\n",
    "    df.loc[df[\"article_id\"] == idx, \"article-title\"] = id2titles[idx]\n",
    "df.value_counts(\"article-title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article-title</th>\n",
       "      <th>article_id</th>\n",
       "      <th>source</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>prev_sec</th>\n",
       "      <th>prev_sent</th>\n",
       "      <th>sec</th>\n",
       "      <th>sent</th>\n",
       "      <th>next_sec</th>\n",
       "      <th>next_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recognition of Static Features in Sign Languag...</td>\n",
       "      <td>2020.signlang-1.20</td>\n",
       "      <td>ACL</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abstract</td>\n",
       "      <td>In this paper we report on a research effort f...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Three sequential models have been developed fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recognition of Static Features in Sign Languag...</td>\n",
       "      <td>2020.signlang-1.20</td>\n",
       "      <td>ACL</td>\n",
       "      <td>1</td>\n",
       "      <td>abstract</td>\n",
       "      <td>In this paper we report on a research effort f...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Three sequential models have been developed fo...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The models have been applied to a Danish and a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recognition of Static Features in Sign Languag...</td>\n",
       "      <td>2020.signlang-1.20</td>\n",
       "      <td>ACL</td>\n",
       "      <td>2</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Three sequential models have been developed fo...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The models have been applied to a Danish and a...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Moreover, during the reported research, a meth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recognition of Static Features in Sign Languag...</td>\n",
       "      <td>2020.signlang-1.20</td>\n",
       "      <td>ACL</td>\n",
       "      <td>3</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The models have been applied to a Danish and a...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Moreover, during the reported research, a meth...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>One of the problems relating to sign language ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Recognition of Static Features in Sign Languag...</td>\n",
       "      <td>2020.signlang-1.20</td>\n",
       "      <td>ACL</td>\n",
       "      <td>4</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Moreover, during the reported research, a meth...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>One of the problems relating to sign language ...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>Therefore, most data collections contain a ver...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       article-title          article_id  \\\n",
       "0  Recognition of Static Features in Sign Languag...  2020.signlang-1.20   \n",
       "1  Recognition of Static Features in Sign Languag...  2020.signlang-1.20   \n",
       "2  Recognition of Static Features in Sign Languag...  2020.signlang-1.20   \n",
       "3  Recognition of Static Features in Sign Languag...  2020.signlang-1.20   \n",
       "4  Recognition of Static Features in Sign Languag...  2020.signlang-1.20   \n",
       "\n",
       "  source  sent_id  prev_sec  \\\n",
       "0    ACL        0       NaN   \n",
       "1    ACL        1  abstract   \n",
       "2    ACL        2  abstract   \n",
       "3    ACL        3  abstract   \n",
       "4    ACL        4  abstract   \n",
       "\n",
       "                                           prev_sent           sec  \\\n",
       "0                                                NaN      abstract   \n",
       "1  In this paper we report on a research effort f...      abstract   \n",
       "2  Three sequential models have been developed fo...      abstract   \n",
       "3  The models have been applied to a Danish and a...      abstract   \n",
       "4  Moreover, during the reported research, a meth...  Introduction   \n",
       "\n",
       "                                                sent      next_sec  \\\n",
       "0  In this paper we report on a research effort f...      abstract   \n",
       "1  Three sequential models have been developed fo...      abstract   \n",
       "2  The models have been applied to a Danish and a...      abstract   \n",
       "3  Moreover, during the reported research, a meth...  Introduction   \n",
       "4  One of the problems relating to sign language ...  Introduction   \n",
       "\n",
       "                                           next_sent  \n",
       "0  Three sequential models have been developed fo...  \n",
       "1  The models have been applied to a Danish and a...  \n",
       "2  Moreover, during the reported research, a meth...  \n",
       "3  One of the problems relating to sign language ...  \n",
       "4  Therefore, most data collections contain a ver...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "doccano_id2article_id = {i:idx for i, idx in enumerate(random_idx)}\n",
    "article_id2doccano_id = {idx:i for i, idx in enumerate(random_idx)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article-title</th>\n",
       "      <th>article_id</th>\n",
       "      <th>source</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>prev_sec</th>\n",
       "      <th>prev_sent</th>\n",
       "      <th>sec</th>\n",
       "      <th>sent</th>\n",
       "      <th>next_sec</th>\n",
       "      <th>next_sent</th>\n",
       "      <th>article_id-d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recognition of Static Features in Sign Languag...</td>\n",
       "      <td>2020.signlang-1.20</td>\n",
       "      <td>ACL</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abstract</td>\n",
       "      <td>In this paper we report on a research effort f...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Three sequential models have been developed fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recognition of Static Features in Sign Languag...</td>\n",
       "      <td>2020.signlang-1.20</td>\n",
       "      <td>ACL</td>\n",
       "      <td>1</td>\n",
       "      <td>abstract</td>\n",
       "      <td>In this paper we report on a research effort f...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Three sequential models have been developed fo...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The models have been applied to a Danish and a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recognition of Static Features in Sign Languag...</td>\n",
       "      <td>2020.signlang-1.20</td>\n",
       "      <td>ACL</td>\n",
       "      <td>2</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Three sequential models have been developed fo...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The models have been applied to a Danish and a...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Moreover, during the reported research, a meth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recognition of Static Features in Sign Languag...</td>\n",
       "      <td>2020.signlang-1.20</td>\n",
       "      <td>ACL</td>\n",
       "      <td>3</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The models have been applied to a Danish and a...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Moreover, during the reported research, a meth...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>One of the problems relating to sign language ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Recognition of Static Features in Sign Languag...</td>\n",
       "      <td>2020.signlang-1.20</td>\n",
       "      <td>ACL</td>\n",
       "      <td>4</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Moreover, during the reported research, a meth...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>One of the problems relating to sign language ...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>Therefore, most data collections contain a ver...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>Distilling Knowledge from Reader to Retriever ...</td>\n",
       "      <td>2012.04584</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>230</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In this paper, we introduce a method to train ...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>Our approach is inspired by knowledge distilla...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In particular, we use the cross-attention scor...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>Distilling Knowledge from Reader to Retriever ...</td>\n",
       "      <td>2012.04584</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>231</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>Our approach is inspired by knowledge distilla...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In particular, we use the cross-attention scor...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>We compare different ways to aggregate the sco...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Distilling Knowledge from Reader to Retriever ...</td>\n",
       "      <td>2012.04584</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>232</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In particular, we use the cross-attention scor...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>We compare different ways to aggregate the sco...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>We show that iteratively training the reader a...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Distilling Knowledge from Reader to Retriever ...</td>\n",
       "      <td>2012.04584</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>233</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>We compare different ways to aggregate the sco...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>We show that iteratively training the reader a...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In the future, we would like to explore better...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Distilling Knowledge from Reader to Retriever ...</td>\n",
       "      <td>2012.04584</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>234</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>We show that iteratively training the reader a...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In the future, we would like to explore better...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>987 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         article-title          article_id  \\\n",
       "0    Recognition of Static Features in Sign Languag...  2020.signlang-1.20   \n",
       "1    Recognition of Static Features in Sign Languag...  2020.signlang-1.20   \n",
       "2    Recognition of Static Features in Sign Languag...  2020.signlang-1.20   \n",
       "3    Recognition of Static Features in Sign Languag...  2020.signlang-1.20   \n",
       "4    Recognition of Static Features in Sign Languag...  2020.signlang-1.20   \n",
       "..                                                 ...                 ...   \n",
       "982  Distilling Knowledge from Reader to Retriever ...          2012.04584   \n",
       "983  Distilling Knowledge from Reader to Retriever ...          2012.04584   \n",
       "984  Distilling Knowledge from Reader to Retriever ...          2012.04584   \n",
       "985  Distilling Knowledge from Reader to Retriever ...          2012.04584   \n",
       "986  Distilling Knowledge from Reader to Retriever ...          2012.04584   \n",
       "\n",
       "    source  sent_id    prev_sec  \\\n",
       "0      ACL        0         NaN   \n",
       "1      ACL        1    abstract   \n",
       "2      ACL        2    abstract   \n",
       "3      ACL        3    abstract   \n",
       "4      ACL        4    abstract   \n",
       "..     ...      ...         ...   \n",
       "982  arXiv      230  CONCLUSION   \n",
       "983  arXiv      231  CONCLUSION   \n",
       "984  arXiv      232  CONCLUSION   \n",
       "985  arXiv      233  CONCLUSION   \n",
       "986  arXiv      234  CONCLUSION   \n",
       "\n",
       "                                             prev_sent           sec  \\\n",
       "0                                                  NaN      abstract   \n",
       "1    In this paper we report on a research effort f...      abstract   \n",
       "2    Three sequential models have been developed fo...      abstract   \n",
       "3    The models have been applied to a Danish and a...      abstract   \n",
       "4    Moreover, during the reported research, a meth...  Introduction   \n",
       "..                                                 ...           ...   \n",
       "982  In this paper, we introduce a method to train ...    CONCLUSION   \n",
       "983  Our approach is inspired by knowledge distilla...    CONCLUSION   \n",
       "984  In particular, we use the cross-attention scor...    CONCLUSION   \n",
       "985  We compare different ways to aggregate the sco...    CONCLUSION   \n",
       "986  We show that iteratively training the reader a...    CONCLUSION   \n",
       "\n",
       "                                                  sent      next_sec  \\\n",
       "0    In this paper we report on a research effort f...      abstract   \n",
       "1    Three sequential models have been developed fo...      abstract   \n",
       "2    The models have been applied to a Danish and a...      abstract   \n",
       "3    Moreover, during the reported research, a meth...  Introduction   \n",
       "4    One of the problems relating to sign language ...  Introduction   \n",
       "..                                                 ...           ...   \n",
       "982  Our approach is inspired by knowledge distilla...    CONCLUSION   \n",
       "983  In particular, we use the cross-attention scor...    CONCLUSION   \n",
       "984  We compare different ways to aggregate the sco...    CONCLUSION   \n",
       "985  We show that iteratively training the reader a...    CONCLUSION   \n",
       "986  In the future, we would like to explore better...           NaN   \n",
       "\n",
       "                                             next_sent  article_id-d  \n",
       "0    Three sequential models have been developed fo...             0  \n",
       "1    The models have been applied to a Danish and a...             0  \n",
       "2    Moreover, during the reported research, a meth...             0  \n",
       "3    One of the problems relating to sign language ...             0  \n",
       "4    Therefore, most data collections contain a ver...             0  \n",
       "..                                                 ...           ...  \n",
       "982  In particular, we use the cross-attention scor...             9  \n",
       "983  We compare different ways to aggregate the sco...             9  \n",
       "984  We show that iteratively training the reader a...             9  \n",
       "985  In the future, we would like to explore better...             9  \n",
       "986                                                NaN             9  \n",
       "\n",
       "[987 rows x 11 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"article_id-d\"] = df[\"article_id\"].apply(lambda x: article_id2doccano_id[x])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"claims-to-annotate-10-papers-fulldoc.csv\", index = False)\n",
    "df = pd.read_csv(\"claims-to-annotate-10-papers-fulldoc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save doccano_id2article_id as a json file\n",
    "import json\n",
    "with open(\"doccano_id2article_id-10-article.json\", \"w\") as f:\n",
    "    json.dump(doccano_id2article_id, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cleme\\AppData\\Local\\Temp\\ipykernel_11684\\2342835808.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_anno[\"label\"] = [\"\"] * df_anno.shape[0]\n"
     ]
    }
   ],
   "source": [
    "df_anno = df[[\"article_id-d\", \"sent_id\", \"sent\", \"sec\", \"prev_sec\", \"prev_sent\", \"next_sec\", \"next_sent\"]]\n",
    "df_anno[\"label\"] = [\"\"] * df_anno.shape[0]\n",
    "df_anno = df_anno.rename(columns = {\"article_id-d\": \"doccano_art_id\", \"sent_id\": \"sentence_id\", \"sent\": \"sentence\", \"sec\": \"current_sentence_section\", \"prev_sec\": \"previous_sentence_section\", \"prev_sent\": \"previous_sentence\", \"next_sec\": \"next_sentence_section\", \"next_sent\": \"next_sentence\"})\n",
    "df_anno.to_csv(\"claims-to-annotate-10-papers-partialdoc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doccano_art_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>current_sentence_section</th>\n",
       "      <th>previous_sentence_section</th>\n",
       "      <th>previous_sentence</th>\n",
       "      <th>next_sentence_section</th>\n",
       "      <th>next_sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>In this paper we report on a research effort f...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Three sequential models have been developed fo...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Three sequential models have been developed fo...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>abstract</td>\n",
       "      <td>In this paper we report on a research effort f...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The models have been applied to a Danish and a...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>The models have been applied to a Danish and a...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Three sequential models have been developed fo...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Moreover, during the reported research, a meth...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moreover, during the reported research, a meth...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The models have been applied to a Danish and a...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>One of the problems relating to sign language ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>One of the problems relating to sign language ...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Moreover, during the reported research, a meth...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>Therefore, most data collections contain a ver...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>9</td>\n",
       "      <td>230</td>\n",
       "      <td>Our approach is inspired by knowledge distilla...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In this paper, we introduce a method to train ...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In particular, we use the cross-attention scor...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>9</td>\n",
       "      <td>231</td>\n",
       "      <td>In particular, we use the cross-attention scor...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>Our approach is inspired by knowledge distilla...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>We compare different ways to aggregate the sco...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>9</td>\n",
       "      <td>232</td>\n",
       "      <td>We compare different ways to aggregate the sco...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In particular, we use the cross-attention scor...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>We show that iteratively training the reader a...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>9</td>\n",
       "      <td>233</td>\n",
       "      <td>We show that iteratively training the reader a...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>We compare different ways to aggregate the sco...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In the future, we would like to explore better...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>9</td>\n",
       "      <td>234</td>\n",
       "      <td>In the future, we would like to explore better...</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>We show that iteratively training the reader a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>987 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doccano_art_id  sentence_id  \\\n",
       "0                 0            0   \n",
       "1                 0            1   \n",
       "2                 0            2   \n",
       "3                 0            3   \n",
       "4                 0            4   \n",
       "..              ...          ...   \n",
       "982               9          230   \n",
       "983               9          231   \n",
       "984               9          232   \n",
       "985               9          233   \n",
       "986               9          234   \n",
       "\n",
       "                                              sentence  \\\n",
       "0    In this paper we report on a research effort f...   \n",
       "1    Three sequential models have been developed fo...   \n",
       "2    The models have been applied to a Danish and a...   \n",
       "3    Moreover, during the reported research, a meth...   \n",
       "4    One of the problems relating to sign language ...   \n",
       "..                                                 ...   \n",
       "982  Our approach is inspired by knowledge distilla...   \n",
       "983  In particular, we use the cross-attention scor...   \n",
       "984  We compare different ways to aggregate the sco...   \n",
       "985  We show that iteratively training the reader a...   \n",
       "986  In the future, we would like to explore better...   \n",
       "\n",
       "    current_sentence_section previous_sentence_section  \\\n",
       "0                   abstract                       NaN   \n",
       "1                   abstract                  abstract   \n",
       "2                   abstract                  abstract   \n",
       "3                   abstract                  abstract   \n",
       "4               Introduction                  abstract   \n",
       "..                       ...                       ...   \n",
       "982               CONCLUSION                CONCLUSION   \n",
       "983               CONCLUSION                CONCLUSION   \n",
       "984               CONCLUSION                CONCLUSION   \n",
       "985               CONCLUSION                CONCLUSION   \n",
       "986               CONCLUSION                CONCLUSION   \n",
       "\n",
       "                                     previous_sentence next_sentence_section  \\\n",
       "0                                                  NaN              abstract   \n",
       "1    In this paper we report on a research effort f...              abstract   \n",
       "2    Three sequential models have been developed fo...              abstract   \n",
       "3    The models have been applied to a Danish and a...          Introduction   \n",
       "4    Moreover, during the reported research, a meth...          Introduction   \n",
       "..                                                 ...                   ...   \n",
       "982  In this paper, we introduce a method to train ...            CONCLUSION   \n",
       "983  Our approach is inspired by knowledge distilla...            CONCLUSION   \n",
       "984  In particular, we use the cross-attention scor...            CONCLUSION   \n",
       "985  We compare different ways to aggregate the sco...            CONCLUSION   \n",
       "986  We show that iteratively training the reader a...                   NaN   \n",
       "\n",
       "                                         next_sentence label  \n",
       "0    Three sequential models have been developed fo...        \n",
       "1    The models have been applied to a Danish and a...        \n",
       "2    Moreover, during the reported research, a meth...        \n",
       "3    One of the problems relating to sign language ...        \n",
       "4    Therefore, most data collections contain a ver...        \n",
       "..                                                 ...   ...  \n",
       "982  In particular, we use the cross-attention scor...        \n",
       "983  We compare different ways to aggregate the sco...        \n",
       "984  We show that iteratively training the reader a...        \n",
       "985  In the future, we would like to explore better...        \n",
       "986                                                NaN        \n",
       "\n",
       "[987 rows x 9 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020.signlang-1.20',\n",
       " 'W17-4709',\n",
       " 'N19-1358',\n",
       " '2103.14302',\n",
       " 'Y15-1047',\n",
       " 'P18-1048',\n",
       " '1708.01009',\n",
       " '1611.08765',\n",
       " '1605.05172',\n",
       " '2012.04584']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020.signlang-1.20 ACL\n",
      "W17-4709 ACL\n",
      "N19-1358 ACL\n",
      "2103.14302 arXiv\n",
      "Y15-1047 ACL\n",
      "P18-1048 ACL\n",
      "1708.01009 arXiv\n",
      "1611.08765 arXiv\n",
      "1605.05172 arXiv\n",
      "2012.04584 arXiv\n"
     ]
    }
   ],
   "source": [
    "for idx in random_idx:\n",
    "    source = \"arXiv\" if idx in random_arxiv else \"ACL\"\n",
    "    print(idx, source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 3, 6]\n"
     ]
    }
   ],
   "source": [
    "reduced_list = [\"2020.signlang-1.20\", \"W17-4709\", \"2103.14302\", \"1708.01009\"]\n",
    "red_doccano = [article_id2doccano_id[idx] for idx in reduced_list]\n",
    "print(red_doccano)\n",
    "\n",
    "red_df = df[df[\"article_id\"].isin(reduced_list)]\n",
    "red_df.to_csv(\"claims-to-annotate-4-papers-fulldoc.csv\", index = False)\n",
    "\n",
    "red_df_anno = df_anno[df_anno[\"doccano_art_id\"].isin(red_doccano)]\n",
    "red_df_anno.to_csv(\"claims-to-annotate-4-papers-partialdoc.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 6], dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_df_anno.doccano_art_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Text inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.7.4-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy)\n",
      "  Downloading thinc-8.2.3-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1 (from spacy)\n",
      "  Using cached smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\cleme\\documents\\stage\\claims-in-nlp\\.venv\\lib\\site-packages (from spacy) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\cleme\\documents\\stage\\claims-in-nlp\\.venv\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Downloading pydantic-2.7.0-py3-none-any.whl.metadata (103 kB)\n",
      "     ---------------------------------------- 0.0/103.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 103.4/103.4 kB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cleme\\documents\\stage\\claims-in-nlp\\.venv\\lib\\site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cleme\\documents\\stage\\claims-in-nlp\\.venv\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cleme\\documents\\stage\\claims-in-nlp\\.venv\\lib\\site-packages (from spacy) (24.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\cleme\\documents\\stage\\claims-in-nlp\\.venv\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.1 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading pydantic_core-2.18.1-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\cleme\\documents\\stage\\claims-in-nlp\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cleme\\documents\\stage\\claims-in-nlp\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cleme\\documents\\stage\\claims-in-nlp\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cleme\\documents\\stage\\claims-in-nlp\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cleme\\documents\\stage\\claims-in-nlp\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Downloading blis-0.7.11-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\cleme\\documents\\stage\\claims-in-nlp\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\cleme\\documents\\stage\\claims-in-nlp\\.venv\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cleme\\documents\\stage\\claims-in-nlp\\.venv\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n",
      "Downloading spacy-3.7.4-cp311-cp311-win_amd64.whl (12.1 MB)\n",
      "   ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/12.1 MB 5.3 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.5/12.1 MB 5.5 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.7/12.1 MB 5.7 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.1/12.1 MB 5.7 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.2/12.1 MB 6.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.5/12.1 MB 6.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.7/12.1 MB 5.4 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.9/12.1 MB 5.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.0/12.1 MB 5.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.3/12.1 MB 5.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.4/12.1 MB 5.0 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.6/12.1 MB 4.9 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.7/12.1 MB 4.9 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.9/12.1 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.1/12.1 MB 4.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.3/12.1 MB 4.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.5/12.1 MB 4.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.6/12.1 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.8/12.1 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.9/12.1 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.2/12.1 MB 4.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.4/12.1 MB 4.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.5/12.1 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.7/12.1 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.8/12.1 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.1/12.1 MB 4.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.2/12.1 MB 4.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.3/12.1 MB 4.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.4/12.1 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.4/12.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.6/12.1 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.7/12.1 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.7/12.1 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.8/12.1 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.9/12.1 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.0/12.1 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.1/12.1 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.2/12.1 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.4/12.1 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.5/12.1 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.6/12.1 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.7/12.1 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.9/12.1 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.0/12.1 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.1/12.1 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.2/12.1 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.3/12.1 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.5/12.1 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.6/12.1 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.7/12.1 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.8/12.1 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.9/12.1 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.0/12.1 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.1/12.1 MB 3.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.2/12.1 MB 3.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.3/12.1 MB 3.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.3/12.1 MB 3.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.4/12.1 MB 3.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.4/12.1 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.6/12.1 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.6/12.1 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.7/12.1 MB 3.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.8/12.1 MB 3.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.8/12.1 MB 3.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.9/12.1 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.0/12.1 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.1/12.1 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.1/12.1 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.2/12.1 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.3/12.1 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.3/12.1 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.4/12.1 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.5/12.1 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.6/12.1 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/12.1 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/12.1 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.8/12.1 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.9/12.1 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.9/12.1 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.0/12.1 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.0/12.1 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.1/12.1 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.1/12.1 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.2/12.1 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.3/12.1 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.3/12.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.3/12.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.4/12.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.5/12.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.5/12.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.6/12.1 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.8/12.1 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.8/12.1 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.0/12.1 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.0/12.1 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.2/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.3/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.4/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.6/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.7/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.9/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.0/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.1/12.1 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/181.6 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 122.9/181.6 kB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 181.6/181.6 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 122.3/122.3 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.7.0-py3-none-any.whl (407 kB)\n",
      "   ---------------------------------------- 0.0/407.9 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 143.4/407.9 kB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 307.2/407.9 kB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 407.9/407.9 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.18.1-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.9 MB 3.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.2/1.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.3/1.9 MB 2.7 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/1.9 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.6/1.9 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.6/1.9 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.7/1.9 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.7/1.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.9/1.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.9/1.9 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/1.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.1/1.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.2/1.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.2/1.9 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.3/1.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.4/1.9 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.5/1.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.7/1.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/1.9 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.9/1.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 1.8 MB/s eta 0:00:00\n",
      "Using cached smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl (479 kB)\n",
      "   ---------------------------------------- 0.0/479.7 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 71.7/479.7 kB 2.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 174.1/479.7 kB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 276.5/479.7 kB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 358.4/479.7 kB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 419.8/479.7 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 479.7/479.7 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading thinc-8.2.3-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.5 MB 991.0 kB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.1/1.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.2/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.3/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.4/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.7/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.7/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.8/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.9/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.1/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.2/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.4/1.5 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.4/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 1.7 MB/s eta 0:00:00\n",
      "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.0/46.0 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB 1.2 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading blis-0.7.11-cp311-cp311-win_amd64.whl (6.6 MB)\n",
      "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/6.6 MB 1.3 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.2/6.6 MB 1.7 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.2/6.6 MB 1.7 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.3/6.6 MB 1.8 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.4/6.6 MB 1.9 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.5/6.6 MB 1.8 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.6/6.6 MB 1.8 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.6/6.6 MB 1.8 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.7/6.6 MB 1.8 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.8/6.6 MB 1.8 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.0/6.6 MB 1.8 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.1/6.6 MB 1.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.2/6.6 MB 1.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.2/6.6 MB 1.9 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.3/6.6 MB 1.9 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.4/6.6 MB 1.9 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.5/6.6 MB 1.8 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 1.5/6.6 MB 1.8 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 1.6/6.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 1.7/6.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 1.8/6.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 1.9/6.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 1.9/6.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.0/6.6 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.0/6.6 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.1/6.6 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.1/6.6 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.2/6.6 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.3/6.6 MB 1.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 2.3/6.6 MB 1.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 2.4/6.6 MB 1.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.5/6.6 MB 1.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.6/6.6 MB 1.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.6/6.6 MB 1.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 2.7/6.6 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 2.8/6.6 MB 1.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 2.8/6.6 MB 1.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 2.9/6.6 MB 1.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 3.0/6.6 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 3.0/6.6 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 3.1/6.6 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 3.2/6.6 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 3.3/6.6 MB 1.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 3.3/6.6 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.4/6.6 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.4/6.6 MB 1.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 3.5/6.6 MB 1.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 3.5/6.6 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.7/6.6 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.8/6.6 MB 1.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.9/6.6 MB 1.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.9/6.6 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 4.1/6.6 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 4.2/6.6 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 4.3/6.6 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 4.4/6.6 MB 1.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 4.5/6.6 MB 1.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 4.5/6.6 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.7/6.6 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.7/6.6 MB 1.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.9/6.6 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 5.0/6.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.1/6.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.2/6.6 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.3/6.6 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.4/6.6 MB 1.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.5/6.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.7/6.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.8/6.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.9/6.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.0/6.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.1/6.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.1/6.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.2/6.6 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.3/6.6 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.3/6.6 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.4/6.6 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.4/6.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.5/6.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.5/6.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.5/6.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.6/6.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.6/6.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.6/6.6 MB 1.7 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 30.7/45.0 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.0/45.0 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, pydantic-core, murmurhash, langcodes, cloudpathlib, catalogue, blis, annotated-types, typer, srsly, pydantic, preshed, confection, weasel, thinc, spacy\n",
      "Successfully installed annotated-types-0.6.0 blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 pydantic-2.7.0 pydantic-core-2.18.1 smart-open-6.4.0 spacy-3.7.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.3 typer-0.9.4 wasabi-1.1.2 weasel-0.3.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\cleme\\documents\\stage\\claims-in-nlp\\.venv\\lib\\site-packages\\grobid_client_python-0.0.8-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"\"\"2 Related Works\n",
    "2.1 OOS detection\n",
    "Different natural language processing (NLP) tasks\n",
    "employ OOS detection. Examples include text classification (Fumera et al., 2003; Tan et al., 2019)\n",
    "and question answering (Rajpurkar et al., 2018;\n",
    "Kamath et al., 2020). Various methods have been\n",
    "proposed to detect OOS such as extrapolating to\n",
    "OOS samples (Daumé III, 2007; Yogatama et al.,\n",
    "2019), deciding whether to predict or abstain on\n",
    "test examples (Dong et al., 2018; Feng et al., 2019),\n",
    "etc. Below, three methods, which are the building\n",
    "blocks of both GOLD and SILVER, are reviewed.\n",
    "(1) MaxProb (Hendrycks and Gimpel, 2017). A\n",
    "supporting model for a classification task (e.g., intent classification) is trained in advance. If the\n",
    "maximum value of the output probability distribution is below a predetermined threshold, then the\n",
    "input is classified as OOS.\n",
    "(2) BertEmbed (Podolskiy et al., 2021). For\n",
    "each category, embeddings of all its samples are calculated by fine-tuned BERT (Devlin et al., 2019). If\n",
    "an input’s embedding is sufficiently far (measured\n",
    "by cosine distance), then the input is classified as\n",
    "OOS.\n",
    "(3) Dropout (Gal and Ghahramani, 2016). If the\n",
    "predictions of models whose nodes are dropped out\n",
    "randomly agree with each other, then the input is\n",
    "classified as INS.\n",
    "SILVER builds a strong classifier by combining\n",
    "these methods to accurately detect OOS dialogues.\"\"\"\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Related Works\n",
      "2.1 OOS detection\n",
      "Different natural language processing (NLP) tasks\n",
      "employ OOS detection.\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "2 Related Works\n",
      "2.1 OOS detection\n",
      "Different natural language processing (NLP) tasks\n",
      "employ OOS detection.\n",
      "Examples include text classification (Fumera et al., 2003; Tan et al., 2019)\n",
      "and question answering (Rajpurkar et al., 2018;\n",
      "Kamath et al., 2020).\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "Examples include text classification (Fumera et al., 2003; Tan et al., 2019)\n",
      "and question answering (Rajpurkar et al., 2018;\n",
      "Kamath et al., 2020).\n",
      "Various methods have been\n",
      "proposed to detect OOS such as extrapolating to\n",
      "OOS samples (Daumé III, 2007; Yogatama et al.,\n",
      "2019), deciding whether to predict or abstain on\n",
      "test examples (Dong et al., 2018; Feng et al., 2019),\n",
      "etc.\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "Various methods have been\n",
      "proposed to detect OOS such as extrapolating to\n",
      "OOS samples (Daumé III, 2007; Yogatama et al.,\n",
      "2019), deciding whether to predict or abstain on\n",
      "test examples (Dong et al., 2018; Feng et al., 2019),\n",
      "etc.\n",
      "Below, three methods, which are the building\n",
      "blocks of both GOLD and SILVER, are reviewed.\n",
      "\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "Below, three methods, which are the building\n",
      "blocks of both GOLD and SILVER, are reviewed.\n",
      "\n",
      "(1) MaxProb (Hendrycks and Gimpel, 2017).\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "(1) MaxProb (Hendrycks and Gimpel, 2017).\n",
      "A\n",
      "supporting model for a classification task (e.g., intent classification) is trained in advance.\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "A\n",
      "supporting model for a classification task (e.g., intent classification) is trained in advance.\n",
      "If the\n",
      "maximum value of the output probability distribution is below a predetermined threshold, then the\n",
      "input is classified as OOS.\n",
      "\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "If the\n",
      "maximum value of the output probability distribution is below a predetermined threshold, then the\n",
      "input is classified as OOS.\n",
      "\n",
      "(2) BertEmbed (Podolskiy et al., 2021).\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "(2) BertEmbed (Podolskiy et al., 2021).\n",
      "For\n",
      "each category, embeddings of all its samples are calculated by fine-tuned BERT (Devlin et al., 2019).\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "For\n",
      "each category, embeddings of all its samples are calculated by fine-tuned BERT (Devlin et al., 2019).\n",
      "If\n",
      "an input’s embedding is sufficiently far (measured\n",
      "by cosine distance), then the input is classified as\n",
      "OOS.\n",
      "\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "If\n",
      "an input’s embedding is sufficiently far (measured\n",
      "by cosine distance), then the input is classified as\n",
      "OOS.\n",
      "\n",
      "(3) Dropout (Gal and Ghahramani, 2016).\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "(3) Dropout (Gal and Ghahramani, 2016).\n",
      "If the\n",
      "predictions of models whose nodes are dropped out\n",
      "randomly agree with each other, then the input is\n",
      "classified as INS.\n",
      "\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "If the\n",
      "predictions of models whose nodes are dropped out\n",
      "randomly agree with each other, then the input is\n",
      "classified as INS.\n",
      "\n",
      "SILVER builds a strong classifier by combining\n",
      "these methods to accurately detect OOS dialogues.\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "SILVER builds a strong classifier by combining\n",
      "these methods to accurately detect OOS dialogues.\n"
     ]
    }
   ],
   "source": [
    "for s in doc.sents:\n",
    "    print(s)\n",
    "    print(type(s))\n",
    "    print(str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixes = list(nlp.Defaults.suffixes)\n",
    "suffixes.remove(\"\\]\")\n",
    "suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n",
    "nlp.tokenizer.suffix_search = suffix_regex.search\n",
    "\n",
    "prefixes = list(nlp.Defaults.prefixes)\n",
    "prefixes.remove(\"\\[\")\n",
    "prefix_regex = spacy.util.compile_prefix_regex(prefixes)\n",
    "nlp.tokenizer.prefix_search = prefix_regex.search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task\n",
      "\n",
      "-\n",
      "\n",
      "oriented\n",
      "\n",
      "dialogue\n",
      "\n",
      "systems\n",
      "\n",
      "are\n",
      "\n",
      "ubiquitous\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "Budzianowski\n",
      "\n",
      "et\n",
      "\n",
      "al\n",
      "\n",
      ".\n",
      "\n",
      ",\n",
      "\n",
      "2018\n",
      "\n",
      ";\n",
      "\n",
      "Chiu\n",
      "\n",
      "et\n",
      "\n",
      "al\n",
      "\n",
      ".\n",
      "\n",
      ",\n",
      "\n",
      "2022\n",
      "\n",
      ")\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "However\n",
      "\n",
      ",\n",
      "\n",
      "they\n",
      "\n",
      "require\n",
      "\n",
      "human\n",
      "\n",
      "operators\n",
      "\n",
      "to\n",
      "\n",
      "deal\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "with\n",
      "\n",
      "complicated\n",
      "\n",
      "intentions\n",
      "\n",
      "that\n",
      "\n",
      "are\n",
      "\n",
      "beyond\n",
      "\n",
      "their\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "capacities\n",
      "\n",
      ".\n",
      "\n",
      "Thus\n",
      "\n",
      ",\n",
      "\n",
      "out\n",
      "\n",
      "-\n",
      "\n",
      "of\n",
      "\n",
      "-\n",
      "\n",
      "scope\n",
      "\n",
      "(\n",
      "\n",
      "OOS\n",
      "\n",
      ")\n",
      "\n",
      "detection\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "remains\n",
      "\n",
      "a\n",
      "\n",
      "serious\n",
      "\n",
      "issue\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Due\n",
      "\n",
      "to\n",
      "\n",
      "the\n",
      "\n",
      "lack\n",
      "\n",
      "of\n",
      "\n",
      "OOS\n",
      "\n",
      "annotations\n",
      "\n",
      "in\n",
      "\n",
      "openworld\n",
      "\n",
      "settings\n",
      "\n",
      ",\n",
      "\n",
      "previous\n",
      "\n",
      "research\n",
      "\n",
      "usually\n",
      "\n",
      "detects\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "OOS\n",
      "\n",
      "samples\n",
      "\n",
      "indirectly\n",
      "\n",
      "such\n",
      "\n",
      "as\n",
      "\n",
      "resorting\n",
      "\n",
      "to\n",
      "\n",
      "inscope\n",
      "\n",
      "(\n",
      "\n",
      "INS\n",
      "\n",
      ")\n",
      "\n",
      "samples\n",
      "\n",
      ".\n",
      "\n",
      "Recently\n",
      "\n",
      ",\n",
      "\n",
      "data\n",
      "\n",
      "augmentation\n",
      "\n",
      "methods\n",
      "\n",
      "(\n",
      "\n",
      "Ng\n",
      "\n",
      "et\n",
      "\n",
      "al\n",
      "\n",
      ".\n",
      "\n",
      ",\n",
      "\n",
      "2020\n",
      "\n",
      ";\n",
      "\n",
      "Razumovskaia\n",
      "\n",
      "et\n",
      "\n",
      "al\n",
      "\n",
      ".\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2022\n",
      "\n",
      ")\n",
      "\n",
      "have\n",
      "\n",
      "made\n",
      "\n",
      "it\n",
      "\n",
      "possible\n",
      "\n",
      "to\n",
      "\n",
      "detect\n",
      "\n",
      "OOS\n",
      "\n",
      "directly\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "using\n",
      "\n",
      "a\n",
      "\n",
      "binary\n",
      "\n",
      "classifier\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "One\n",
      "\n",
      "such\n",
      "\n",
      "method\n",
      "\n",
      "is\n",
      "\n",
      "GOLD\n",
      "\n",
      "(\n",
      "\n",
      "Chen\n",
      "\n",
      "and\n",
      "\n",
      "Yu\n",
      "\n",
      ",\n",
      "\n",
      "2021\n",
      "\n",
      ")\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GOLD\n",
      "\n",
      "uses\n",
      "\n",
      "simple\n",
      "\n",
      "rules\n",
      "\n",
      "to\n",
      "\n",
      "replace\n",
      "\n",
      "utterances\n",
      "\n",
      "in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "known\n",
      "\n",
      "OOS\n",
      "\n",
      "dialogues\n",
      "\n",
      "with\n",
      "\n",
      "sentences\n",
      "\n",
      "selected\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "from\n",
      "\n",
      "a\n",
      "\n",
      "large\n",
      "\n",
      "pool\n",
      "\n",
      ",\n",
      "\n",
      "making\n",
      "\n",
      "it\n",
      "\n",
      "possible\n",
      "\n",
      "to\n",
      "\n",
      "train\n",
      "\n",
      "a\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "binary\n",
      "\n",
      "classifier\n",
      "\n",
      "to\n",
      "\n",
      "decide\n",
      "\n",
      "OOS\n",
      "\n",
      "dialogues\n",
      "\n",
      "directly\n",
      "\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in doc:\n",
    "    print(t)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Recurrent neural networks (RNNs) serve as a fundamental building block for many sequence tasks across natural language processing.\n",
      "\n",
      "Recent research has focused on recurrent dropout techniques or custom RNN cells in order to improve performance.\n",
      "\n",
      "Both of these can require substantial modifications to the machine learning model or to the underlying RNN configurations.\n",
      "\n",
      "We revisit traditional regularization techniques, specifically L2 regularization on RNN activations and slowness regularization over successive hidden states, to improve the performance of RNNs on the task of language modeling.\n",
      "\n",
      "Both of these techniques require minimal modification to existing RNN architectures and result in performance improvements comparable or superior to more complicated regularization techniques or custom cell architectures.\n",
      "\n",
      "These regularization techniques can be used without any modification on optimized LSTM implementations such as the NVIDIA cuDNN LSTM.\n",
      "\n",
      "The need for effective regularization methods for RNNs has seen extensive focus in recent years.\n",
      "\n",
      "While application of dropout (Srivastava et al., 2014) to the input and output of an RNN has been shown to be effective (Zaremba et al., 2014), dropout is destructive when naively applied to the recurrent connections of an RNN.\n",
      "\n",
      "When naive dropout is applied to the recurrent connections, it is almost impossible to retain information over long periods of time.\n",
      "\n",
      "Given this fundamental issue, substantial work has gone into understanding and improving dropout when applied to recurrent connections.\n",
      "\n",
      "Of these techniques, which we shall broadly refer to as recurrent dropout, some specific variations have gained popular usage.\n",
      "\n",
      "Part of 34 th International Conference on Machine Learning's Workshop on Learning to Generate Natural Language, Sydney, Australia, 2017.\n",
      "\n",
      "Copyright 2017 by the author(s).\n",
      "\n",
      "Variational RNNs (Gal & Ghahramani, 2016) drop the same network units at each timestep, as opposed to dropping different network units at each timestep.\n",
      "\n",
      "By performing dropout on the same units at each timestep, destructive loss of the RNN hidden state is avoided and the same information is masked at each timestep.\n",
      "\n",
      "Rather than dropping units, another tactic is to drop updates to given network units.\n",
      "\n",
      "Semeniuta et al.\n",
      "\n",
      "(2016) perform dropout on the input gate of the LSTM (Hochreiter & Schmidhuber, 1997) but allow the forget gate to discard portions of the existing hidden state.\n",
      "\n",
      "Zoneout (Krueger et al., 2016) prevents hidden state updates from occurring by setting a randomly selected subset of network unit activations in h t+1 to be equal to the previous activations from h t .\n",
      "\n",
      "Both of these act to prevent updates to the hidden state while preserving existing content.\n",
      "\n",
      "On an extreme end, work has also been done to restrict the recurrent matrices in an RNN in order to limit their computational capacity.\n",
      "\n",
      "Some RNN architectures only allow element-wise interactions (Balduzzi & Ghifary, 2016;Bradbury et al., 2016;Seo et al., 2016), removing the recurrent matrix entirely, while others act to restrict the capacity by parameterizing the recurrent matrix (Arjovsky et al., 2016;Wisdom et al., 2016;Jing et al., 2016).\n",
      "\n",
      "Other forms of regularization explicitly act upon activations such as such as batch normalization (Ioffe & Szegedy, 2015), recurrent batch normalization (Cooijmans et al., 2016), and layer normalization (Ba et al., 2016).\n",
      "\n",
      "These all introduce additional training parameters and can complicate the training process while increasing the sensitivity of the model.\n",
      "\n",
      "Norm stabilization (Krueger & Memisevic, 2015) penalizes the model when the norm of an RNN's hidden state changes substantially between timesteps, achieving strong results in character language modeling on and phoneme recognition.\n",
      "\n",
      "In this work, we revisit L 2 regularization in the form of activation regularization (AR) and temporal activation regularization (TAR).\n",
      "\n",
      "When applied to modern baselines that do not contain recurrent dropout or normalization techniques, AR and TAR achieve comparable or superior results.\n",
      "\n",
      "which may require modifications to the RNN cell itself or complex model changes, both AR and TAR require no substantial modifications to the RNN or model.\n",
      "\n",
      "This enables AR and TAR to be applied to optimized RNN implementations such as the cuDNN LSTM which can be many times faster than naïve but flexible LSTM implementations.\n",
      "\n",
      "L 2 activation regularization (AR) While L 2 regularization is traditionally used on the weights of machine learning models (L 2 weight decay), it could also be used on the activations.\n",
      "\n",
      "We define AR as α L 2 (m ⊙ h t ) where m is the dropout mask used by later parts of the model, L 2 (•) = • 2 (L 2 norm), h t is the output of the RNN at timestep t, and α is a scaling coefficient.\n",
      "\n",
      "When applied to the output of a dense layer, AR penalizes activations that are substantially away from 0, encouraging the activations to remain small.\n",
      "\n",
      "While acting implicitly rather than explicitly, this has similarities to the various batch or layer normalization techniques.\n",
      "\n",
      "The L 2 penalty on the RNN activations can be applied to h t or to m ⊙ h t (the dropped output used in the rest of the model).\n",
      "\n",
      "In our experiments, we found that applying AR to m ⊙ h t was more effective than applying it to neurons not updated during the current optimization step.\n",
      "\n",
      "Adding a prior that minimizes differences between states has been explored in the past.\n",
      "\n",
      "This broad concept falls under the broad concept of slowness regularization (Hinton, 1989;Földiák, 1991;Luciw & Schmidhuber, 2012;Jonschkowski & Brock, 2015;Wen et al., 2015) which attempts to minimize L(f (x t ), f (x t+1 )) where L is a loss function describing the distance between f (x t ) and f (x t+1 ) and f is an arbitrary mapping function.\n",
      "\n",
      "Temporal activation regularization (TAR) is a direct descendant of this slowness regularization, minimizing β L 2 (h t -h t+1 ) where L 2 (•) = • 2 (L 2 norm), h t is the output of the RNN at timestep t, and β is a scaling coefficient.\n",
      "\n",
      "TAR penalizes any large changes in hidden state between timesteps, encouraging the model to keep the output as consistent as possible.\n",
      "\n",
      "For the LSTM, the hidden state which is regularized is only h t , not the long term memory c t , though this could optionally be regularized in a similar manner.\n",
      "\n",
      "To understand the potential of AR and TAR, we investigate their impact on language model perplexity when used independently in Table 1 (AR) and Table 2 (TAR).\n",
      "\n",
      "While both result in a substantial reduction in perplexity, AR results in the strongest improvement of 5.3, while TAR only achieves 4.3.\n",
      "\n",
      "The drops achieved by this are equivalent to using an LSTM model with twice as many parameters -a substantial improvement given the simplicity of AR and TAR.\n",
      "\n",
      "Evaluating AR and TAR jointly on PTB: When both AR and TAR are used together, we found the best result was achieved by decreasing α and β, likely as the model was over-regularized otherwise.\n",
      "\n",
      "In Table 3 we present PTB results for three different model sizes comparing models without AR/TAR to those which use both.\n",
      "\n",
      "The model sizes h ∈ [650, 950, 1500] were chosen to be comparable in size to other published results.\n",
      "\n",
      "With both AR and TAR, the smallest model has an improvement of 6.2 over the baseline model.\n",
      "\n",
      "The improvements continue for the two larger size models, h = 950 and h = 1500, though the gains fall off as the model size is increased.\n",
      "\n",
      "Comparing to state-of-the-art PTB: In Table 5 we summarize the current state of the art models in language modeling over the Penn Treebank.\n",
      "\n",
      "The largest LSTM we train (h = 1500) achieves comparable results to the Recurrent Highway Network (RHN) (Zilly et al., 2016), a human developed custom RNN architecture, but with approximately double the number of parameters.\n",
      "\n",
      "Although the LSTM uses twice as many parameters, the RHN runs a cell 10 times per timestep (referred to as recurrence depth), resulting in far more computation.\n",
      "\n",
      "This would likely result in the RHN being slower than the larger LSTM model during both training and prediction, especially when factoring in optimized LSTM implementations such as NVIDIA's cuDNN LSTM.\n",
      "\n",
      "We also compare to the Neural Architecture Search (NAS) cell (Zoph & Le, 2016).\n",
      "\n",
      "While Zoph & Le (2016) do not report any of the hyperparameters or what type of dropout they used for their Penn Treebank result, they do note that they performed an extensive hyperparameter search over learning rate, weight initialization, dropout rates, and decay epoch in order to produce their best performing model.\n",
      "\n",
      "It is possible that a large contributor to their improved result was in these tuned hyperparameters as they did not compare their NAS cell results to a standard or variational LSTM cell that was subjected to the same extensive hyperparameter search.\n",
      "\n",
      "Our largest LSTM results are 3 perplexity higher in comparison but have not undergone extensive hyperparameter search, do not use additional regularization techniques such as recurrent or embedding dropout, and do not use a custom RNN cell.\n",
      "\n",
      "In this work, we revisit L 2 regularization in the form of activation regularization (AR) and temporal activation regularization (TAR).\n",
      "\n",
      "While simple to implement, activity regularization and temporal activity regularization are com-\n",
      "\n",
      "For generating text samples, words were sampled using the standard generation script contained in the PyTorch word level language modeling example.\n",
      "\n",
      "WikiText-2 was used given the larger vocabulary and more realistic looking text.\n",
      "\n",
      "Neither the eos token nor the unk were allowed to be selected.\n",
      "\n",
      "Each paragraph is a separate sample of text with the tokens following Moses (Koehn et al., 2007), joining words with @-@ and dot-decimal split to a @.\n",
      "\n",
      "Something Borrowed \" is the second episode of the fourth season of the American comedy television series The X @-@ Files .\n",
      "\n",
      "The episode was written by David McCarthy and directed by Mark Sacks .\n",
      "\n",
      "It aired in the United States on November 30 , 2011 , as a two @-@ episode episode, watched by 4 @.\n",
      "\n",
      "@ 9 million viewers and was the highest rated show on the Fox network .\n",
      "\n",
      "The work of Olivier 's , a large 1950s table with the center of a vinyl beam , was used for bony motifs from the upper @-@ production model via the Club van X .\n",
      "\n",
      "The modified works were released in the museum , which gave its namesake to the visual designers in Hong Kong .\n",
      "\n",
      "The first prototype was released for the PlayStation 4 , containing the 2 @.\n",
      "\n",
      "@ 5 part series , with 3 @.\n",
      "\n",
      "@ 5 million copies sold .\n",
      "\n",
      "In October 2010 , Activision announced that both the game and the main gameplay was \" downloadable \" .\n",
      "\n",
      "The first game , titled Snow : The Game of the Battlefield 2 : The Ultimate Warrior , was the third anime game , and was released in August 2016 .\n",
      "\n",
      "The German Land Forces had been reversed in the early 1990s , although the Soviet Union continued to deter NDH forces in the nation .\n",
      "\n",
      "The area was moved to Sarajevo , and the troops were despatched to the National Register of Historic Places in the summer of 1918 for the establishment of full political and social parties .\n",
      "\n",
      "The Polish language was protected by the Soviet Union , which was the first Polish continental conflict of the newly formed Union in North America , and the Polish Front with the last of the Polish Communist Party .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cand_sents = p.content[p.content[\"candidate\"] == True][\"sentence\"]\n",
    "\n",
    "for s in cand_sents:\n",
    "    print(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "with open(\"../data/arxiv/tei.xml/1708.01009v1.grobid.tei.xml\", encoding = \"utf-8\") as f:\n",
    "    root = ET.fromstring(f.read())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element '{http://www.tei-c.org/ns/1.0}note' at 0x0000021A393472E0> {http://www.tei-c.org/ns/1.0}note {'place': 'foot', 'n': '1', '{http://www.w3.org/XML/1998/namespace}id': 'foot_0'}\n",
      "<Element '{http://www.tei-c.org/ns/1.0}note' at 0x0000021A39347600> {http://www.tei-c.org/ns/1.0}note {'place': 'foot', 'n': '1', '{http://www.w3.org/XML/1998/namespace}id': 'foot_1'}\n"
     ]
    }
   ],
   "source": [
    "for child in root[1][0]:\n",
    "    if \"note\" in child.tag:\n",
    "        print(child, child.tag, child.attrib)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
