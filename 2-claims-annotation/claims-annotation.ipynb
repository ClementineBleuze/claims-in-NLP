{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\") \n",
    "from utils.ClaimDB import ClaimDB\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialization of `ClaimDB` : load papers from ACL and ArXiv `Corpus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the ACL and arXiv corpora\n",
    "# with open(\"../data/acl/corpus_ACL.pkl\", \"rb\") as f:\n",
    "#     corpus_ACL = pickle.load(f)\n",
    "\n",
    "# with open(\"../data/arxiv/corpus_arxiv.pkl\", \"rb\") as f:\n",
    "#     corpus_arxiv = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus 'arXiv' was filled with 33982 papers:\n",
      "  - 28624 papers were successfully loaded\n",
      "  - 5358 papers could not be loaded\n",
      "\n",
      "Errors:\n",
      "  - FileNotFoundError: XML file does not exist : 3471\n",
      "  - Noisy data: wrong language (fr) : 48\n",
      "  - Noisy data: wrong language (uk) : 5\n",
      "  - Noisy data: wrong language (ru) : 9\n",
      "  - Noisy data: wrong language (da) : 4\n",
      "  - parsing error: not enough paper content found (<2 distinct sections) : 14\n",
      "  - Noisy data: wrong language (hi) : 1\n",
      "  - Noisy data: wrong language (de) : 8\n",
      "  - Noisy data: wrong language (tr) : 12\n",
      "  - Noisy data: wrong language (id) : 4\n",
      "  - Noisy data: wrong language (pt) : 8\n",
      "  - Noisy data: wrong language (pl) : 2\n",
      "  - Noisy data: wrong language (es) : 12\n",
      "  - Noisy data: wrong language (it) : 8\n",
      "  - Noisy data: wrong language (zh-cn) : 1\n",
      "  - Noisy data: wrong language (et) : 3\n",
      "  - Noisy data: wrong language (tl) : 1\n",
      "  - Noisy data: wrong language (hu) : 1\n",
      "  - Noisy data: wrong language (ko) : 1\n",
      "  - Noisy data: wrong language (no) : 1\n",
      "  - Noisy data: wrong language (ja) : 1\n",
      "  - Noisy data: wrong language (mk) : 1\n",
      "  - Noisy data: wrong language (sl) : 2\n",
      "  - Noisy data: wrong language (so) : 2\n",
      "  - Duplicate error: also found in ACL corpus : 1\n",
      "  - Too many candidate sentences (> Q3+1.5*IQR = 314.0)  : 1627\n",
      "  - Not enough candidate sentences (<20) : 110\n"
     ]
    }
   ],
   "source": [
    "# corpus_arxiv.describe(error_verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in corpus_ACL.papers:\n",
    "#     p.content[\"candidate\"] = [True] * len(p.content)\n",
    "\n",
    "# for p in corpus_arxiv.papers:\n",
    "#     p.content[\"candidate\"] = [True] * len(p.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58180/58180 [01:58<00:00, 489.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# for p in tqdm(corpus_ACL.papers):\n",
    "#     p.preprocess_content_sections()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58180/58180 [04:56<00:00, 196.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# removed = set()\n",
    "\n",
    "# for p in tqdm(corpus_ACL.papers):\n",
    "#     for i, row in p.content.iterrows():\n",
    "#         if row[\"candidate\"] == False:\n",
    "#             removed.add(row[\"section\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# # draw 100 random papers\n",
    "# random.seed(0)\n",
    "# random_ids = random.sample(range(0, len(corpus_ACL.papers)), 100)\n",
    "\n",
    "# removed_sections = []\n",
    "# removed_sentences = []\n",
    "\n",
    "# for r_id in random_ids:\n",
    "#     p = corpus_ACL.papers[r_id]\n",
    "\n",
    "#     removed = p.content[p.content[\"candidate\"] == False]\n",
    "\n",
    "#     removed_sections.append(len(list(removed[\"section\"].unique())))\n",
    "#     removed_sentences.append(len(removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.42\n",
      "28.14\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# print(np.mean(removed_sections))\n",
    "# print(np.mean(removed_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242, 3)\n"
     ]
    }
   ],
   "source": [
    "# data = []\n",
    "\n",
    "# for r_id in random_ids:\n",
    "#     p = corpus_ACL.papers[r_id]\n",
    "\n",
    "#     removed = p.content[p.content[\"candidate\"] == False]\n",
    "    \n",
    "#     if len(removed) > 0:\n",
    "#         sections = list(removed[\"section\"].unique())\n",
    "#         for s in sections:\n",
    "#             n = \"? - \"\n",
    "            \n",
    "#             for i, sec_d in p.sections.items():\n",
    "#                 if sec_d[\"header\"] == s:\n",
    "#                     if sec_d[\"n\"] != None:\n",
    "#                         n = sec_d[\"n\"] + \" -\"\n",
    "#                         break\n",
    "\n",
    "#             data.append({\n",
    "#                 \"paper_id\": p.id,\n",
    "#                 \"title\" : p.title,\n",
    "#                 \"section\": n + s,\n",
    "#             })\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "# print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11,001 New Features for Statistical Machine Translation</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Framework to Generate Sets of Terms from Large Scale Medical Vocabularies for Natural Language Processing</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Semi-Supervised Approach for Gender Identification</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Text Classifier Based on Sentence Category {VSM}</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A picture is worth a thousand words: Using {O}pen{C}lip{A}rt library for enriching {I}ndo{W}ord{N}et</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{OCR} Processing of {S}wedish Historical Newspapers Using Deep Hybrid {CNN}{--}{LSTM} Networks</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{P}rague {D}ependency {T}reebank 2.5 {--} a Revisited Version of {PDT} 2.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{Q}i{N}i{A}n at {S}em{E}val-2022 Task 5: Multi-Modal Misogyny Detection and Classification</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{USFD}{'}s Phrase-level Quality Estimation Systems</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{W}iki{R}eading: A Novel Large-scale Language Understanding Task over {W}ikipedia</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    paper_id  section\n",
       "title                                                                \n",
       "11,001 New Features for Statistical Machine Tra...         1        1\n",
       "A Framework to Generate Sets of Terms from Larg...         3        3\n",
       "A Semi-Supervised Approach for Gender Identific...         4        4\n",
       "A Text Classifier Based on Sentence Category {VSM}         1        1\n",
       "A picture is worth a thousand words: Using {O}p...         4        4\n",
       "...                                                      ...      ...\n",
       "{OCR} Processing of {S}wedish Historical Newspa...         4        4\n",
       "{P}rague {D}ependency {T}reebank 2.5 {--} a Rev...         2        2\n",
       "{Q}i{N}i{A}n at {S}em{E}val-2022 Task 5: Multi-...         4        4\n",
       "{USFD}{'}s Phrase-level Quality Estimation Systems         1        1\n",
       "{W}iki{R}eading: A Novel Large-scale Language U...        14       14\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.groupby(\"title\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\cleme\\documents\\stage\\claims-in-nlp\\.venv\\lib\\site-packages\\grobid_client_python-0.0.8-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.2-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install openpyxl\n",
    "# df.to_excel(\"removed-sections-to-check.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the corpora\n",
    "# with open(\"../data/acl/corpus_ACL.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(corpus_ACL, f)\n",
    "\n",
    "# with open(\"../data/arxiv/corpus_arxiv.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(corpus_arxiv, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58180/58180 [04:58<00:00, 195.21it/s]\n",
      "100%|██████████| 28624/28624 [03:43<00:00, 128.35it/s]\n",
      "100%|██████████| 2/2 [08:41<00:00, 260.52s/it]\n"
     ]
    }
   ],
   "source": [
    "# # initialize a claim database\n",
    "# cdb = ClaimDB(corpora = [corpus_ACL, corpus_arxiv], annotated_idx_path=\"../data/annotated_articles.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../data/cdb.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(cdb, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v2: idx encoding article id + sentence id  \n",
    "v3: after cleaning the corpora (removing very long and very short papers)  \n",
    "v4: after turning all sentences into candidates  \n",
    "v5: after reducing clues for non-cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../data/cdb-idxmap_v5.json\", \"w\") as f:\n",
    "#     json.dump(cdb.idx_map, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/cdb.pkl\", \"rb\") as f:\n",
    "    cdb = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13511562, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdb.candidates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>corpus</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>year</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ACL</td>\n",
       "      <td>O02-2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>There is a need to measure word similarity whe...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ACL</td>\n",
       "      <td>O02-2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>Usually, measures of similarity between two wo...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ACL</td>\n",
       "      <td>O02-2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>The taxonomy approaches are more or less seman...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ACL</td>\n",
       "      <td>O02-2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>3</td>\n",
       "      <td>However, in real applications, both semantic a...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ACL</td>\n",
       "      <td>O02-2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>4</td>\n",
       "      <td>Word similarity based on context vectors is a ...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx corpus  paper_id  year  sentence_id  \\\n",
       "0    0    ACL  O02-2002  2002            0   \n",
       "1    1    ACL  O02-2002  2002            1   \n",
       "2    2    ACL  O02-2002  2002            2   \n",
       "3    3    ACL  O02-2002  2002            3   \n",
       "4    4    ACL  O02-2002  2002            4   \n",
       "\n",
       "                                            sentence   section  \n",
       "0  There is a need to measure word similarity whe...  abstract  \n",
       "1  Usually, measures of similarity between two wo...  abstract  \n",
       "2  The taxonomy approaches are more or less seman...  abstract  \n",
       "3  However, in real applications, both semantic a...  abstract  \n",
       "4  Word similarity based on context vectors is a ...  abstract  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdb.candidates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx                                                      3075789\n",
       "corpus                                                       ACL\n",
       "paper_id                                                D19-6126\n",
       "year                                                        2019\n",
       "sentence_id                                                   29\n",
       "sentence       If the information is sufficient to answer the...\n",
       "section                                             Introduction\n",
       "Name: 3075789, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdb.get_candidate_by_id(3075789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>corpus</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>year</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3938559</th>\n",
       "      <td>3938559</td>\n",
       "      <td>ACL</td>\n",
       "      <td>C12-1078</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>Recently, methods for mining graph sequences h...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938560</th>\n",
       "      <td>3938560</td>\n",
       "      <td>ACL</td>\n",
       "      <td>C12-1078</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>A graph sequence is a data structure used to r...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938561</th>\n",
       "      <td>3938561</td>\n",
       "      <td>ACL</td>\n",
       "      <td>C12-1078</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>The aim of graph sequence mining is to enumera...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938562</th>\n",
       "      <td>3938562</td>\n",
       "      <td>ACL</td>\n",
       "      <td>C12-1078</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>Dependency analysis is recognized as a basic p...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938563</th>\n",
       "      <td>3938563</td>\n",
       "      <td>ACL</td>\n",
       "      <td>C12-1078</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>In transition-based parsers for dependency ana...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938818</th>\n",
       "      <td>3938818</td>\n",
       "      <td>ACL</td>\n",
       "      <td>C12-1078</td>\n",
       "      <td>2012</td>\n",
       "      <td>259</td>\n",
       "      <td>In addition, rewriting rules are more humanrea...</td>\n",
       "      <td>Conclusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938819</th>\n",
       "      <td>3938819</td>\n",
       "      <td>ACL</td>\n",
       "      <td>C12-1078</td>\n",
       "      <td>2012</td>\n",
       "      <td>260</td>\n",
       "      <td>Kudo et al.</td>\n",
       "      <td>Conclusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938820</th>\n",
       "      <td>3938820</td>\n",
       "      <td>ACL</td>\n",
       "      <td>C12-1078</td>\n",
       "      <td>2012</td>\n",
       "      <td>261</td>\n",
       "      <td>(2005) proposed a method for extracting featur...</td>\n",
       "      <td>Conclusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938821</th>\n",
       "      <td>3938821</td>\n",
       "      <td>ACL</td>\n",
       "      <td>C12-1078</td>\n",
       "      <td>2012</td>\n",
       "      <td>262</td>\n",
       "      <td>Using the features, the transition-based parse...</td>\n",
       "      <td>Conclusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938822</th>\n",
       "      <td>3938822</td>\n",
       "      <td>ACL</td>\n",
       "      <td>C12-1078</td>\n",
       "      <td>2012</td>\n",
       "      <td>263</td>\n",
       "      <td>Compared with that method, using our method pr...</td>\n",
       "      <td>Conclusion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             idx corpus  paper_id  year  sentence_id  \\\n",
       "3938559  3938559    ACL  C12-1078  2012            0   \n",
       "3938560  3938560    ACL  C12-1078  2012            1   \n",
       "3938561  3938561    ACL  C12-1078  2012            2   \n",
       "3938562  3938562    ACL  C12-1078  2012            3   \n",
       "3938563  3938563    ACL  C12-1078  2012            4   \n",
       "...          ...    ...       ...   ...          ...   \n",
       "3938818  3938818    ACL  C12-1078  2012          259   \n",
       "3938819  3938819    ACL  C12-1078  2012          260   \n",
       "3938820  3938820    ACL  C12-1078  2012          261   \n",
       "3938821  3938821    ACL  C12-1078  2012          262   \n",
       "3938822  3938822    ACL  C12-1078  2012          263   \n",
       "\n",
       "                                                  sentence     section  \n",
       "3938559  Recently, methods for mining graph sequences h...    abstract  \n",
       "3938560  A graph sequence is a data structure used to r...    abstract  \n",
       "3938561  The aim of graph sequence mining is to enumera...    abstract  \n",
       "3938562  Dependency analysis is recognized as a basic p...    abstract  \n",
       "3938563  In transition-based parsers for dependency ana...    abstract  \n",
       "...                                                    ...         ...  \n",
       "3938818  In addition, rewriting rules are more humanrea...  Conclusion  \n",
       "3938819                                        Kudo et al.  Conclusion  \n",
       "3938820  (2005) proposed a method for extracting featur...  Conclusion  \n",
       "3938821  Using the features, the transition-based parse...  Conclusion  \n",
       "3938822  Compared with that method, using our method pr...  Conclusion  \n",
       "\n",
       "[264 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdb.get_candidates_by_paper_id(\"C12-1078\", \"ACL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(912, 7)\n"
     ]
    }
   ],
   "source": [
    "test_df = cdb.candidates[cdb.candidates[\"paper_id\"] == \"cs/9911011\"]\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>year</th>\n",
       "      <th>section</th>\n",
       "      <th>prev_text</th>\n",
       "      <th>prev_section</th>\n",
       "      <th>next_text</th>\n",
       "      <th>next_section</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recent developments in theoretical linguisti...</td>\n",
       "      <td>13510650</td>\n",
       "      <td>One-Level Prosodic Morphology</td>\n",
       "      <td>1999</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Of these, reduplication is particularly challe...</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Of these, reduplication is particularly challe...</td>\n",
       "      <td>13510651</td>\n",
       "      <td>One-Level Prosodic Morphology</td>\n",
       "      <td>1999</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Recent developments in theoretical linguisti...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>In this paper I argue for certain extensions t...</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In this paper I argue for certain extensions t...</td>\n",
       "      <td>13510652</td>\n",
       "      <td>One-Level Prosodic Morphology</td>\n",
       "      <td>1999</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Of these, reduplication is particularly challe...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>In a nutshell, enriched lexical representation...</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In a nutshell, enriched lexical representation...</td>\n",
       "      <td>13510653</td>\n",
       "      <td>One-Level Prosodic Morphology</td>\n",
       "      <td>1999</td>\n",
       "      <td>abstract</td>\n",
       "      <td>In this paper I argue for certain extensions t...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>A kind of resource consciousness is introduced...</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A kind of resource consciousness is introduced...</td>\n",
       "      <td>13510654</td>\n",
       "      <td>One-Level Prosodic Morphology</td>\n",
       "      <td>1999</td>\n",
       "      <td>abstract</td>\n",
       "      <td>In a nutshell, enriched lexical representation...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The non-finite-state copying aspect of redupli...</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>This approach then promises to adress the stor...</td>\n",
       "      <td>13511557</td>\n",
       "      <td>One-Level Prosodic Morphology</td>\n",
       "      <td>1999</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>The second phase consists of ordinary FSA/FST ...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>Finally, annotations could simply be output st...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>Finally, annotations could simply be output st...</td>\n",
       "      <td>13511558</td>\n",
       "      <td>One-Level Prosodic Morphology</td>\n",
       "      <td>1999</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>This approach then promises to adress the stor...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>Mohri (1994) has described an algorithm to mak...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>Mohri (1994) has described an algorithm to mak...</td>\n",
       "      <td>13511559</td>\n",
       "      <td>One-Level Prosodic Morphology</td>\n",
       "      <td>1999</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>Finally, annotations could simply be output st...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>Advantages and disadvantages of this approach ...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>Advantages and disadvantages of this approach ...</td>\n",
       "      <td>13511560</td>\n",
       "      <td>One-Level Prosodic Morphology</td>\n",
       "      <td>1999</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>Mohri (1994) has described an algorithm to mak...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>Of course, application of underlying and surfa...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>Of course, application of underlying and surfa...</td>\n",
       "      <td>13511561</td>\n",
       "      <td>One-Level Prosodic Morphology</td>\n",
       "      <td>1999</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>Advantages and disadvantages of this approach ...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>912 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text    doc_id  \\\n",
       "0      Recent developments in theoretical linguisti...  13510650   \n",
       "1    Of these, reduplication is particularly challe...  13510651   \n",
       "2    In this paper I argue for certain extensions t...  13510652   \n",
       "3    In a nutshell, enriched lexical representation...  13510653   \n",
       "4    A kind of resource consciousness is introduced...  13510654   \n",
       "..                                                 ...       ...   \n",
       "907  This approach then promises to adress the stor...  13511557   \n",
       "908  Finally, annotations could simply be output st...  13511558   \n",
       "909  Mohri (1994) has described an algorithm to mak...  13511559   \n",
       "910  Advantages and disadvantages of this approach ...  13511560   \n",
       "911  Of course, application of underlying and surfa...  13511561   \n",
       "\n",
       "                       paper_title  year     section  \\\n",
       "0    One-Level Prosodic Morphology  1999    abstract   \n",
       "1    One-Level Prosodic Morphology  1999    abstract   \n",
       "2    One-Level Prosodic Morphology  1999    abstract   \n",
       "3    One-Level Prosodic Morphology  1999    abstract   \n",
       "4    One-Level Prosodic Morphology  1999    abstract   \n",
       "..                             ...   ...         ...   \n",
       "907  One-Level Prosodic Morphology  1999  Discussion   \n",
       "908  One-Level Prosodic Morphology  1999  Discussion   \n",
       "909  One-Level Prosodic Morphology  1999  Discussion   \n",
       "910  One-Level Prosodic Morphology  1999  Discussion   \n",
       "911  One-Level Prosodic Morphology  1999  Discussion   \n",
       "\n",
       "                                             prev_text prev_section  \\\n",
       "0                                                                     \n",
       "1      Recent developments in theoretical linguisti...     abstract   \n",
       "2    Of these, reduplication is particularly challe...     abstract   \n",
       "3    In this paper I argue for certain extensions t...     abstract   \n",
       "4    In a nutshell, enriched lexical representation...     abstract   \n",
       "..                                                 ...          ...   \n",
       "907  The second phase consists of ordinary FSA/FST ...   Discussion   \n",
       "908  This approach then promises to adress the stor...   Discussion   \n",
       "909  Finally, annotations could simply be output st...   Discussion   \n",
       "910  Mohri (1994) has described an algorithm to mak...   Discussion   \n",
       "911  Advantages and disadvantages of this approach ...   Discussion   \n",
       "\n",
       "                                             next_text next_section label  \n",
       "0    Of these, reduplication is particularly challe...     abstract        \n",
       "1    In this paper I argue for certain extensions t...     abstract        \n",
       "2    In a nutshell, enriched lexical representation...     abstract        \n",
       "3    A kind of resource consciousness is introduced...     abstract        \n",
       "4    The non-finite-state copying aspect of redupli...     abstract        \n",
       "..                                                 ...          ...   ...  \n",
       "907  Finally, annotations could simply be output st...   Discussion        \n",
       "908  Mohri (1994) has described an algorithm to mak...   Discussion        \n",
       "909  Advantages and disadvantages of this approach ...   Discussion        \n",
       "910  Of course, application of underlying and surfa...   Discussion        \n",
       "911                                                                        \n",
       "\n",
       "[912 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdb.prepare_for_doccano_format(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2008.eamt-1.21', 'W15-1816']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acl_idx = cdb.draw_random_idx_from_corpus(\"ACL\", 2)\n",
    "acl_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1802.00382', '1810.09536']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arx_idx = cdb.draw_random_idx_from_corpus(\"arXiv\", 2)\n",
    "arx_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1802.00382', '1810.09536', '2008.eamt-1.21', 'W15-1816']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_idx = arx_idx + acl_idx\n",
    "all_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(622, 7)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "acl_idx = ['2008.eamt-1.21', 'W15-1816']\n",
    "arx_idx = ['1802.00382', '1810.09536']\n",
    "all_idx = ['1802.00382', '1810.09536', '2008.eamt-1.21', 'W15-1816']\n",
    "\n",
    "for idx in acl_idx:\n",
    "    df = pd.concat([df, cdb.get_candidates_by_paper_id(idx, \"ACL\")], ignore_index=True)\n",
    "\n",
    "for idx in arx_idx:\n",
    "    df = pd.concat([df, cdb.get_candidates_by_paper_id(idx, \"arXiv\")], ignore_index=True)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>year</th>\n",
       "      <th>section</th>\n",
       "      <th>prev_text</th>\n",
       "      <th>prev_section</th>\n",
       "      <th>next_text</th>\n",
       "      <th>next_section</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This paper focuses on domain specific use of M...</td>\n",
       "      <td>1763760</td>\n",
       "      <td>Domain specific {MT} in use</td>\n",
       "      <td>2008</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>We report on the feedback of post-editors usin...</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We report on the feedback of post-editors usin...</td>\n",
       "      <td>1763761</td>\n",
       "      <td>Domain specific {MT} in use</td>\n",
       "      <td>2008</td>\n",
       "      <td>abstract</td>\n",
       "      <td>This paper focuses on domain specific use of M...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The post-editor profile defined by the LSP is ...</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The post-editor profile defined by the LSP is ...</td>\n",
       "      <td>1763762</td>\n",
       "      <td>Domain specific {MT} in use</td>\n",
       "      <td>2008</td>\n",
       "      <td>abstract</td>\n",
       "      <td>We report on the feedback of post-editors usin...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The relation between the Translation Edit Rate...</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The relation between the Translation Edit Rate...</td>\n",
       "      <td>1763763</td>\n",
       "      <td>Domain specific {MT} in use</td>\n",
       "      <td>2008</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The post-editor profile defined by the LSP is ...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>We find TER a candidate for an automatic metri...</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We find TER a candidate for an automatic metri...</td>\n",
       "      <td>1763764</td>\n",
       "      <td>Domain specific {MT} in use</td>\n",
       "      <td>2008</td>\n",
       "      <td>abstract</td>\n",
       "      <td>The relation between the Translation Edit Rate...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>LSP tests show 67% saved time in post-editing ...</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   doc_id  \\\n",
       "0  This paper focuses on domain specific use of M...  1763760   \n",
       "1  We report on the feedback of post-editors usin...  1763761   \n",
       "2  The post-editor profile defined by the LSP is ...  1763762   \n",
       "3  The relation between the Translation Edit Rate...  1763763   \n",
       "4  We find TER a candidate for an automatic metri...  1763764   \n",
       "\n",
       "                   paper_title  year   section  \\\n",
       "0  Domain specific {MT} in use  2008  abstract   \n",
       "1  Domain specific {MT} in use  2008  abstract   \n",
       "2  Domain specific {MT} in use  2008  abstract   \n",
       "3  Domain specific {MT} in use  2008  abstract   \n",
       "4  Domain specific {MT} in use  2008  abstract   \n",
       "\n",
       "                                           prev_text prev_section  \\\n",
       "0                                                                   \n",
       "1  This paper focuses on domain specific use of M...     abstract   \n",
       "2  We report on the feedback of post-editors usin...     abstract   \n",
       "3  The post-editor profile defined by the LSP is ...     abstract   \n",
       "4  The relation between the Translation Edit Rate...     abstract   \n",
       "\n",
       "                                           next_text next_section label  \n",
       "0  We report on the feedback of post-editors usin...     abstract        \n",
       "1  The post-editor profile defined by the LSP is ...     abstract        \n",
       "2  The relation between the Translation Edit Rate...     abstract        \n",
       "3  We find TER a candidate for an automatic metri...     abstract        \n",
       "4  LSP tests show 67% saved time in post-editing ...     abstract        "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doccano = cdb.prepare_for_doccano_format(df)\n",
    "df_doccano[\"label\"] = \"\" * df_doccano.shape[0]\n",
    "df_doccano.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doccano.to_csv(\"to-annotate-4.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_ACL = cdb.corpora[0]\n",
    "p = corpus_ACL.get_paper_by_id(\"W15-1816\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'n': '1', 'header': 'Introduction', 'head_n': None},\n",
       " 1: {'n': '2', 'header': 'Related work', 'head_n': None},\n",
       " 2: {'n': '3', 'header': 'Data sets', 'head_n': None},\n",
       " 3: {'n': '4', 'header': 'Experimental set-up', 'head_n': None},\n",
       " 4: {'n': '4.1',\n",
       "  'header': 'K-means word clustering with dependency features',\n",
       "  'head_n': '4'},\n",
       " 5: {'n': '4.2', 'header': 'Parser set-up', 'head_n': '4'},\n",
       " 6: {'n': '4.2.1', 'header': 'Parser features', 'head_n': '4.2'},\n",
       " 7: {'n': '4.2.2', 'header': 'Gold vs. predicted PoS tags', 'head_n': '4.2'},\n",
       " 8: {'n': '5', 'header': 'Experiments and results', 'head_n': None},\n",
       " 9: {'n': '5.1', 'header': 'Reuters clusters', 'head_n': '5'},\n",
       " 10: {'n': '5.2', 'header': 'Per-domain SANCL clusters', 'head_n': '5'},\n",
       " 11: {'n': '5.3', 'header': 'All-in-one SANCL clusters', 'head_n': '5'},\n",
       " 12: {'n': '5.4',\n",
       "  'header': 'Comparison to using Brown clusters',\n",
       "  'head_n': '5'},\n",
       " 13: {'n': '6', 'header': 'Summary and future work', 'head_n': None}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58180/58180 [00:00<00:00, 128993.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53258\n",
      "47930\n",
      "28947\n",
      "24473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "has_intro = []\n",
    "has_concl = []\n",
    "has_results = []\n",
    "last_sections = set()\n",
    "\n",
    "for p in tqdm(corpus_ACL.papers):\n",
    "    sections = [v[\"header\"].lower() for k, v in p.sections.items()]\n",
    "\n",
    "    if \"introduction\" in sections:\n",
    "        has_intro.append(p.id)\n",
    "\n",
    "    if \"conclusion\" in sections:\n",
    "        has_concl.append(p.id)\n",
    "    else:\n",
    "        for s in sections:\n",
    "            if \"conclusion\" in s:\n",
    "                has_concl.append(p.id)\n",
    "                break\n",
    "    if \"results\" in sections:\n",
    "        has_results.append(p.id)\n",
    "\n",
    "    else:\n",
    "        for s in sections:\n",
    "            if \"result\" in s:\n",
    "                has_results.append(p.id)\n",
    "                break\n",
    "\n",
    "print(len(has_intro))\n",
    "print(len(has_concl))\n",
    "print(len(has_results))\n",
    "print(len(list(set(has_intro).intersection(set(has_concl)).intersection(set(has_results)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28624/28624 [00:02<00:00, 13600.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24988\n",
      "24446\n",
      "16297\n",
      "12871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "has_intro = []\n",
    "has_concl = []\n",
    "has_results = []\n",
    "last_sections = set()\n",
    "\n",
    "for p in tqdm(corpus_arxiv.papers):\n",
    "    sections = [v[\"header\"].lower() for k, v in p.sections.items()]\n",
    "\n",
    "    if \"introduction\" in sections:\n",
    "        has_intro.append(p.id)\n",
    "\n",
    "    if \"conclusion\" in sections:\n",
    "        has_concl.append(p.id)\n",
    "    else:\n",
    "        for s in sections:\n",
    "            if \"conclusion\" in s:\n",
    "                has_concl.append(p.id)\n",
    "                break\n",
    "    if \"results\" in sections:\n",
    "        has_results.append(p.id)\n",
    "\n",
    "    else:\n",
    "        for s in sections:\n",
    "            if \"result\" in s:\n",
    "                has_results.append(p.id)\n",
    "                break\n",
    "\n",
    "print(len(has_intro))\n",
    "print(len(has_concl))\n",
    "print(len(has_results))\n",
    "print(len(list(set(has_intro).intersection(set(has_concl)).intersection(set(has_results)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'n': '1', 'header': 'Introduction', 'head_n': None},\n",
       " 1: {'n': '2', 'header': 'Background', 'head_n': None},\n",
       " 2: {'n': '3', 'header': 'The Problem', 'head_n': None},\n",
       " 3: {'n': '3.1', 'header': 'Reduplication', 'head_n': '3'},\n",
       " 4: {'n': None, 'header': 'unidentified-section', 'head_n': None},\n",
       " 5: {'n': None, 'header': 'unidentified-section', 'head_n': None},\n",
       " 6: {'n': '3.2', 'header': 'Discontiguity', 'head_n': '3'},\n",
       " 7: {'n': '3.3', 'header': 'Partiality', 'head_n': '3'},\n",
       " 8: {'n': '3.4',\n",
       "  'header': 'Floating Morphemes and Directionality',\n",
       "  'head_n': '3'},\n",
       " 9: {'n': '4',\n",
       "  'header': 'Extending Finite-State Methods to One-Level Prosodic Morphology',\n",
       "  'head_n': None},\n",
       " 10: {'n': '4.1', 'header': 'Technical Preliminaries', 'head_n': '4'},\n",
       " 11: {'n': '4.2', 'header': 'Enriched Representations', 'head_n': '4'},\n",
       " 12: {'n': '4.3', 'header': 'Resource Consciousness', 'head_n': '4'},\n",
       " 13: {'n': '4.4', 'header': 'Copying as Intersection', 'head_n': '4'},\n",
       " 14: {'n': '4.5', 'header': 'Bounded Local Optimization', 'head_n': '4'},\n",
       " 15: {'n': '4.6',\n",
       "  'header': 'Flat representation of prosodic constituency',\n",
       "  'head_n': '4'},\n",
       " 16: {'n': '4.7', 'header': 'Parsing', 'head_n': '4'},\n",
       " 17: {'n': '5', 'header': 'Implemented Case Studies', 'head_n': None},\n",
       " 18: {'n': '5.1', 'header': 'Ulwa construct state infixation', 'head_n': '5'},\n",
       " 19: {'n': '5.2', 'header': 'German hypocoristic truncation', 'head_n': '5'},\n",
       " 20: {'n': '5.3',\n",
       "  'header': 'Tagalog overapplying reduplication',\n",
       "  'head_n': '5'},\n",
       " 21: {'n': '6', 'header': 'Discussion', 'head_n': None}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. abstract\n",
      "2. Introduction\n",
      "3. Background\n",
      "4. The Problem\n",
      "\t1. Reduplication\n",
      "\t2. unidentified-section\n",
      "\t3. unidentified-section\n",
      "\t4. Discontiguity\n",
      "\t5. Partiality\n",
      "\t6. Floating Morphemes and Directionality\n",
      "5. Extending Finite-State Methods to One-Level Prosodic Morphology\n",
      "\t1. Technical Preliminaries\n",
      "\t2. Enriched Representations\n",
      "\t3. Resource Consciousness\n",
      "\t4. Copying as Intersection\n",
      "\t5. Bounded Local Optimization\n",
      "\t6. Flat representation of prosodic constituency\n",
      "\t7. Parsing\n",
      "6. Implemented Case Studies\n",
      "\t1. Ulwa construct state infixation\n",
      "\t2. German hypocoristic truncation\n",
      "\t3. Tagalog overapplying reduplication\n",
      "7. Discussion\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def reorder_section_hierarchy(sections):\n",
    "\n",
    "    # initialize section hierarchy with abstract\n",
    "    d = {0: {\"header\" : \"abstract\"}}\n",
    "    i = 1\n",
    "\n",
    "    # add the other sections\n",
    "    for _, s in sections.items():\n",
    "        \n",
    "        if s[\"head_n\"] == None:\n",
    "\n",
    "            if s[\"n\"] != None or s[\"header\"] != \"unidentified-section\":\n",
    "                d[i] = {\"header\" : s[\"header\"],\n",
    "                        \"subsections\": {}}\n",
    "                i += 1\n",
    "            \n",
    "            else:\n",
    "                j = len(d[i-1][\"subsections\"])\n",
    "                k = len(d[i-1][\"subsections\"][j-1][\"subsections\"])\n",
    "                if k > 0:\n",
    "                    d[i-1][\"subsections\"][j-1][\"subsections\"][k] = {\"header\" : s[\"header\"], \"subsections\" : {}}\n",
    "                else:\n",
    "                    d[i-1][\"subsections\"][j] = {\"header\" : s[\"header\"], \"subsections\" : {}}\n",
    "        \n",
    "        else:\n",
    "            j = len(d[i-1][\"subsections\"])\n",
    "            d[i-1][\"subsections\"][j] = {\"header\" : s[\"header\"], \"subsections\" : {}}\n",
    "\n",
    "    return d\n",
    "\n",
    "def pretty_print_sections_dict(d, indent = 0):\n",
    "    s = \"\"\n",
    "    for i, (k, v) in enumerate(d.items()):\n",
    "        if v[\"header\"] != \"abstract\":\n",
    "            i = i + 1\n",
    "        s += \"\\t\"*indent + f\"{i}. \" + v[\"header\"] + \"\\n\"\n",
    "        if \"subsections\" in v:\n",
    "            s += pretty_print_sections_dict(v[\"subsections\"], indent + 1)\n",
    "\n",
    "    return s\n",
    "\n",
    "d = reorder_section_hierarchy(p.sections)\n",
    "print(pretty_print_sections_dict(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_head(d, section, direct = False):\n",
    "    heads = []\n",
    "    for i, sec in list(d.items())[1:]:\n",
    "\n",
    "        while sec[\"subsections\"] != {}:\n",
    "            ss = list(sec[\"subsections\"].keys())\n",
    "\n",
    "            if section in ss:\n",
    "                heads.append(sec[\"header\"])\n",
    "\n",
    "            else:\n",
    "                for s in ss:\n",
    "                    heads.extend(find_head(sec[\"subsections\"][s], section))\n",
    "            break\n",
    "        \n",
    "    return heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'subsections'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfind_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReduplication\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[71], line 11\u001b[0m, in \u001b[0;36mfind_head\u001b[1;34m(d, section, direct)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m ss:\n\u001b[1;32m---> 11\u001b[0m                 heads\u001b[38;5;241m.\u001b[39mextend(\u001b[43mfind_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43msec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubsections\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msection\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m heads\n",
      "Cell \u001b[1;32mIn[71], line 5\u001b[0m, in \u001b[0;36mfind_head\u001b[1;34m(d, section, direct)\u001b[0m\n\u001b[0;32m      2\u001b[0m heads \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, sec \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(d\u001b[38;5;241m.\u001b[39mitems())[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43msec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubsections\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m {}:\n\u001b[0;32m      6\u001b[0m         ss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(sec[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubsections\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m section \u001b[38;5;129;01min\u001b[39;00m ss:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'subsections'"
     ]
    }
   ],
   "source": [
    "find_head(d, \"Reduplication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "introduction\n",
      "data resources\n",
      "sinica corpus\n",
      "cilin-a chinese thesaurus\n",
      "sense disambiguation\n",
      "the extraction of co-occurrence data\n",
      "context vector model\n",
      "role vector of word\n",
      "similarities between two context vectors\n",
      "similarity clustering\n",
      "clustering algorithm\n",
      "clustering results vs cilin classification\n",
      "cilin classifications re -examined\n",
      "word set\n",
      "conclusions\n",
      "\n",
      "introduction\n",
      "data\n",
      "gold standard thread extraction from the enron email corpus\n",
      "text similarity features\n",
      "evaluation\n",
      "data sampling\n",
      "results\n",
      "inherent limitations\n",
      "error analysis\n",
      "conclusion\n",
      "\n",
      "introduction\n",
      "training data\n",
      "word alignment\n",
      "named entities and cognates\n",
      "transliteration similarity\n",
      "local word grouping\n",
      "dictionary lookup\n",
      "expected english words\n",
      "nearest aligned neighbors\n",
      "test data results\n",
      "\n",
      "introduction\n",
      "related work\n",
      "recognized semantic relation types\n",
      "semantic relation recognition rule-based algorithm\n",
      "recognizing word pairs and triples\n",
      "'aircraft made by pzl in (year) 1938 in łódź (city)'\n",
      "applying wccl operators\n",
      "results and conclusions\n",
      "\n",
      "unidentified-section\n",
      "goals\n",
      "promote work on european language pairs:\n",
      "rules of engagement\n",
      "results\n",
      "team\n",
      "survey\n",
      "outlook\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in has_results[:5]:\n",
    "    p = corpus_ACL.get_paper_by_id(i)\n",
    "    sections = [v[\"header\"].lower() for k, v in p.sections.items()]\n",
    "    for s in sections:\n",
    "        print(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vl evaluation programs',\n",
       " 'issues',\n",
       " 'generation speech recognition',\n",
       " 'the experiment',\n",
       " 'evaluation on coreference resolution',\n",
       " 'eclat : language and technology programme',\n",
       " 'presenter details',\n",
       " 'automatic speech recognition',\n",
       " 'results and analysis',\n",
       " 'f.4 model-based algorithms',\n",
       " 'increasing parallelism',\n",
       " 'presentation outlook',\n",
       " '95',\n",
       " 'k. mckeown from columbia university gave a multimedia presentation',\n",
       " 'subjnum (plural→singular)',\n",
       " 'a.6 reproducibility statement',\n",
       " 'extended combinators',\n",
       " 'a.5 annotation interfaces',\n",
       " 'grammar evaluation',\n",
       " 'trading off content versus attribute',\n",
       " 'experiences and future plans',\n",
       " 'general discussion & conclusion',\n",
       " 'bcu-dlist-ehu-best',\n",
       " 'f.2 full table of results',\n",
       " 'conclusion and futur e wor k',\n",
       " 'evaluation and outlook',\n",
       " 'd uncertainty estimates and calibration performance',\n",
       " 'computational resource comparison',\n",
       " 'conclusion and limitations',\n",
       " 'what was learned about evaluatio n',\n",
       " 'a.3 joint distribution',\n",
       " 'deployment',\n",
       " 'w ork finished and in progress',\n",
       " 'results',\n",
       " 'lexlcal prediction',\n",
       " 'new results',\n",
       " 'c.2 softmax with bias term',\n",
       " 'context',\n",
       " 'description',\n",
       " 'b experimental choices',\n",
       " 'comparison with previous studies',\n",
       " 'effect of training data size',\n",
       " 'future works',\n",
       " 'discourse processin g',\n",
       " 'parsing and otiier enllancements',\n",
       " 'conci usion',\n",
       " 'tions using gsl',\n",
       " 'a event types',\n",
       " 'c further details on npmi vs. nll as stopping criteria',\n",
       " 'states mf',\n",
       " 'fig. 1 using olisa function in ideakeeper',\n",
       " 'experiments and evaluation',\n",
       " 'search flow',\n",
       " 'motivation & background',\n",
       " 'human evaluation and analysis',\n",
       " 'the cofi interface',\n",
       " 'b hyperparameters',\n",
       " 'developing an intranet mt system',\n",
       " 'coordination and centrality',\n",
       " 'edge annotation',\n",
       " 'd.1 accuracy by antecedent distance',\n",
       " 'document-level and segment-level evaluation',\n",
       " 'contributions and limitations',\n",
       " 'll%',\n",
       " 'treelet vs. template systems',\n",
       " 'conclusions and further works',\n",
       " 'modules',\n",
       " 'shared task results',\n",
       " 'possible future additions:',\n",
       " 'licensing',\n",
       " 'user manipulations',\n",
       " 'c more example topics',\n",
       " 'msa',\n",
       " 'd example reframes',\n",
       " 'automatic adjustments of the structure of hmm models',\n",
       " 'a.1 training hyperparameters',\n",
       " 'f o o t n o t e s',\n",
       " 'discusion and conclusions',\n",
       " 'status of work',\n",
       " 'state of development',\n",
       " 'results of feature selection',\n",
       " 'validation on a mwe extraction task',\n",
       " 'a.4 attention analysis',\n",
       " 'icat l g: ei',\n",
       " 'a.6 technical implementation of data search',\n",
       " 'a.3 state-of-the-art baselines',\n",
       " 'e.3 on using regularization',\n",
       " 'advertisement slogan generator',\n",
       " 'analysis and examples',\n",
       " 'verb word analysis',\n",
       " 'c human evaluation system',\n",
       " 'conclusion and further directions',\n",
       " 'b screen layout of the editor',\n",
       " 'detailed results for additional positional information',\n",
       " 'proposed lexical stegosystem',\n",
       " 'd explanation of adjustments for specific languages on ud',\n",
       " 'findings and future work',\n",
       " '25',\n",
       " 'a.4 somewhat related work',\n",
       " 'results and future work',\n",
       " 'viii. cunclusion',\n",
       " 'indexing',\n",
       " \"evaluator's workbench for translation tools?\",\n",
       " 'a.8 potential risks',\n",
       " \"'men/para': 'adhikarana kaaraka'\",\n",
       " 'ablation study of constrains',\n",
       " 'some remarks on the complexity of di-recognition',\n",
       " 'corpora',\n",
       " 'new data format',\n",
       " 'word alignment annotation interface',\n",
       " 'contrastive topic -pero/aber vs. contrastive focus -sino/sondern',\n",
       " 'official evaluation results',\n",
       " 'hill-climb',\n",
       " 'conclusion and further steps',\n",
       " 'evaluation metric',\n",
       " 'c full wiki setting details',\n",
       " 'no analysis found',\n",
       " 'terminology of a unified dependency parser',\n",
       " 'cross-corpus experiments',\n",
       " 'conclusions & further research',\n",
       " 'appendix b: carllani example data from redacted source',\n",
       " 'observations on running the task and the evaluation',\n",
       " 'conclusion and related work',\n",
       " 'future remarks',\n",
       " 'extensions to the model and areas for further work',\n",
       " 'content of the demonstration',\n",
       " 'generalization',\n",
       " 'the formal evaluatio n',\n",
       " 'a sample derivation 8',\n",
       " 'project conclusion and possible evolutions',\n",
       " 'new directions',\n",
       " 'a.1 original spanish debate',\n",
       " 'conclusions and decisions',\n",
       " 'analysis dialogue',\n",
       " 'current status of the ldc system',\n",
       " 'discourse structure',\n",
       " 'd license information',\n",
       " 'general conclusion',\n",
       " 'b.2 training details',\n",
       " 'conclusion and discussion',\n",
       " 'completing the example',\n",
       " 'p361',\n",
       " 'a detailed experimental setup',\n",
       " 'error category example',\n",
       " 'conclusion & perspectives',\n",
       " 'ethical consideration',\n",
       " 'conclusions and future work',\n",
       " 'genre variation',\n",
       " 'adding annotators',\n",
       " 'further works',\n",
       " 'analytics and visualizations',\n",
       " '(v x)tree(x) d cylindrical(x) (vx)cylindr ea(x) hon(x)',\n",
       " 'underuse phenomenon',\n",
       " 'conclusions & perspectives',\n",
       " 'minimally supervised learning',\n",
       " 'societal impact',\n",
       " 'motivation and theoretical implications',\n",
       " 'c details on post-rating interviews',\n",
       " 'j[d ccr',\n",
       " 'b dip features',\n",
       " 'results, comments and conclusion',\n",
       " 'c hyperparameters for fine-tuning',\n",
       " 'a.2 hyper-parameters of the nre model',\n",
       " 'anagramma',\n",
       " 'd.2 hyperparameters for fine-tuning',\n",
       " 'd additional experiments',\n",
       " 'statistical machine translation.',\n",
       " 'maximum entropy modeling',\n",
       " 'final comments',\n",
       " 'b segmentations with increasing number of training epochs',\n",
       " 'post-level classifiers with attribution',\n",
       " 'concusion',\n",
       " 'proceedings of icslp 98 fifth international',\n",
       " 'b intermediate checkpoints',\n",
       " 'why use a logical framework',\n",
       " 'a computational treatment: typed-feature structure approach',\n",
       " 'c details of experiments',\n",
       " 'd annotation interfaces and guidelines',\n",
       " 'overall procedure and results',\n",
       " 'industrial parsing of software manuals',\n",
       " 'verifying the extended search system',\n",
       " 'b.5 english monolingual data size influence',\n",
       " '[coffee break] (20 mins)',\n",
       " 'evaluation, baselines and scheduling',\n",
       " 'integer ld, sac',\n",
       " 'concluding statement',\n",
       " 'output to press',\n",
       " 'english reference',\n",
       " 'lessons',\n",
       " 'sentences correctly flagged',\n",
       " 'contiguity',\n",
       " 'my analysis',\n",
       " 'future work and conclusions',\n",
       " 'f-score = 2* (precision * recall) / precision + recall',\n",
       " 'b evaluation datasets',\n",
       " 'e.2 implementation',\n",
       " 'roberta',\n",
       " 'b implementation details',\n",
       " 'phrase lists tools',\n",
       " 'abner:',\n",
       " 'linear mixed model analysis',\n",
       " \"what does it mean for a human or machine to 'know' a language?\",\n",
       " \"what's next?\",\n",
       " 'collocation syllable adaptor grammar',\n",
       " 'b.2 extended versions of previous figures',\n",
       " 'b.4 flickr30k entities',\n",
       " 'working with industry data',\n",
       " 'domain dependent substrings',\n",
       " '.amalia functionality',\n",
       " 'empirical work and discussion',\n",
       " 'application potential',\n",
       " 'a.2 english→russian experiments',\n",
       " 'b.3 quality of influence estimations',\n",
       " 'contrast and coarticulatory propensity in vowel harmony systems',\n",
       " 'perceiving evidence',\n",
       " '7.recognition performance',\n",
       " '5.2',\n",
       " 'suggested improvements in the logic',\n",
       " 'department.',\n",
       " 'opportunities for low-code development in interface modification',\n",
       " 'g tokenization examples',\n",
       " 'observations and ongoing work',\n",
       " 'training toolkit',\n",
       " 'version 2: as a transparent edit layer',\n",
       " 'conclusion and future shared tasks',\n",
       " 'analysis of srl',\n",
       " 'f qualitative analysis of t-vis',\n",
       " 'conclusion and ongoing work',\n",
       " 'problematic words and tags',\n",
       " 'prototype implementation',\n",
       " 'f statistics of datasets',\n",
       " 'conclusion and future',\n",
       " 'c qualitative analysis',\n",
       " 'a.4 other uses of context similarity',\n",
       " 'future works and conclusion',\n",
       " 'd elasticsearch query construction',\n",
       " 'conclusions: why is this efficient ?',\n",
       " 'g examples from imagecode for all phenomena',\n",
       " 'system name',\n",
       " 'trans verbatim',\n",
       " 'information gain based pruning (igbp):',\n",
       " 'b ordering and relationship of attributes',\n",
       " 'abstract entities and adjectives',\n",
       " 'mary-nom',\n",
       " 'if at same intermediate level it is',\n",
       " 'edge combination',\n",
       " 'parametric models',\n",
       " 'ix. conclusion \"',\n",
       " 'extralink: integrating information extraction and automatic hyperlinking',\n",
       " '\"da 3 \"+artifactual types',\n",
       " 'duration',\n",
       " 'towards an alignment of wordnet and framenet',\n",
       " 'speed of the analysis',\n",
       " 'abstract syntax',\n",
       " 'multi-segment constructions of causality',\n",
       " 'presenter information',\n",
       " 'discussion and concluding remarks',\n",
       " 'a.2 automatic detection',\n",
       " 'hindi vs. telugu',\n",
       " 'failed attempts',\n",
       " 'rl oi# r~',\n",
       " 'machine translation sergei nirenburg, (colgate university)',\n",
       " 'visualization of model',\n",
       " 'analysis and future work',\n",
       " 'system training',\n",
       " 'the reconstruction of deletions in',\n",
       " 'error analysis-2',\n",
       " 'e evaluation details',\n",
       " 'a.5 em scores on mrqa shared task datasets',\n",
       " 'adaptation of the understanding system',\n",
       " 'conclusions and ongoing research',\n",
       " 'estimating the gold standard',\n",
       " 'future research directions',\n",
       " 'benefits of on-line collaboration using the xtrf-tm platform.',\n",
       " 'a comparison with ask',\n",
       " 'a.2 evaluation metric discussion',\n",
       " 'interaction',\n",
       " 'b snowclone reference detector:',\n",
       " 'identification constraints',\n",
       " 'computational linguistics',\n",
       " 'c_star test result',\n",
       " 'note.* estibaliz amorrortu and magdalena',\n",
       " 'b system diagram for corpus analyses',\n",
       " 'hpsg markers',\n",
       " 'data-driven historical linguistics',\n",
       " 'linguistic correlates of neuro-degenerative disorders',\n",
       " 'unification and parsing times',\n",
       " 'avenues for future research',\n",
       " 'general remarks',\n",
       " 'computing n p,δ via sampling',\n",
       " 't5 + t-ph (marriage and civil law)',\n",
       " '• making the right investment',\n",
       " 'evaluation procedure',\n",
       " \"7' discussion\",\n",
       " 'approaches to achieving full specilication',\n",
       " 'a rose is a roze is a roz is a woz',\n",
       " 'checking systemic descriptions',\n",
       " 'evaluation on english social media content',\n",
       " 'the server side',\n",
       " 'wikipedia data',\n",
       " 'evaluation methodology',\n",
       " 'error characteristics',\n",
       " 'proposed applications',\n",
       " 'neural machine translation',\n",
       " 'design and implementation',\n",
       " 'open code and data',\n",
       " 'evaluation on the iscslp2006-sre database',\n",
       " 'the new picture',\n",
       " 'summary conclusions',\n",
       " 'part vi references',\n",
       " 'wizard-of-oz data collection websites',\n",
       " 'b.2 dataset details',\n",
       " 'additional tables and figures',\n",
       " 'resolving the scope of hedge keywords',\n",
       " 'the semantic web for nlg tasks',\n",
       " 'f additional interpretability example',\n",
       " 'a.3.1 user study parameters',\n",
       " 'current functionalities of mirto and perspectives',\n",
       " 'speaker grouping',\n",
       " 'visualizing model attention',\n",
       " 'submission',\n",
       " 'observations about events',\n",
       " '~-~ j pragmte i semte i s-stfitc-',\n",
       " 'e releases & codes',\n",
       " 'reference resolution in the linguistic',\n",
       " 'discussion-conclusion',\n",
       " 'experimental result and evaluation',\n",
       " 'e additional results',\n",
       " 'the semantic knowledge base',\n",
       " 'e fine-grained categorization results',\n",
       " 'supported languages',\n",
       " 'choosing the best translation',\n",
       " 'linker',\n",
       " 'discussions 6 conclusion',\n",
       " 'evaluation methods and technology',\n",
       " 'scenarios of use for mt systems',\n",
       " 'summary and present status',\n",
       " 'or end of the study and the fact that the end imposes constraints on the choice of means.',\n",
       " 'statistical methods',\n",
       " 'how many bootstrap samples are needed?',\n",
       " 'corpus processing',\n",
       " 'the limitations of contextual features',\n",
       " 'use of semantic information',\n",
       " 'dependency on threshold value τ',\n",
       " 'b details on expert evaluation of correctness',\n",
       " 'conclusion: lexicalized grammars the other way round',\n",
       " 'automatically generated declination',\n",
       " 'anti-c-command and beyond',\n",
       " 'v.1',\n",
       " 'g hyperparameters',\n",
       " 'auxiliary information',\n",
       " 'broader impact statement',\n",
       " 'current andfuture work',\n",
       " 'action',\n",
       " 'd limitations and potential risks',\n",
       " 'e few-shot and zero-shot event extraction',\n",
       " '6.conclusion and future works',\n",
       " 'c variations on structured hinge loss',\n",
       " 'conclusions and future outlook',\n",
       " 'evaluating existing spell checker',\n",
       " 'boundedness',\n",
       " 'a. post-study survey',\n",
       " 'retrieval experiments',\n",
       " 'development status',\n",
       " 'conclusion: value for nlp and future work',\n",
       " 'complains of fornication in the lower limbs.',\n",
       " 'finkler, w. and neumann, g.',\n",
       " 'plans for future work',\n",
       " 'lm perplexity',\n",
       " 'topic alignment difficulties',\n",
       " 'a.3 significance estimates',\n",
       " 'the source of the mnc1',\n",
       " 'system walkthroug h',\n",
       " 'closing comments',\n",
       " 'so,',\n",
       " 'limitations:',\n",
       " \"matador's online output\",\n",
       " 'resolving nominal coreference:',\n",
       " 'discussion of the experimental results',\n",
       " 'phraseological nature of binary conjunctions',\n",
       " 'conclusion & further work',\n",
       " 'the semantic work bench',\n",
       " 'alternative summaries',\n",
       " \"bill's legacy\",\n",
       " 'dropped pronoun translation',\n",
       " 'related work and conclusions',\n",
       " 'b equations for squashing experiments',\n",
       " 'e annotation guidelines',\n",
       " 'development history',\n",
       " '304103008:local_advancement_flap_(procedure)',\n",
       " 'computers naming',\n",
       " 'd exhibition of more causal chains',\n",
       " 'pluto web application',\n",
       " 'b full results',\n",
       " 'human evaluation settings',\n",
       " 'knight decoding complexity',\n",
       " 'quantificational structures in situation semantics',\n",
       " 'tonal patterns of two kana and hangeul',\n",
       " 'd hard prompts',\n",
       " 'progress and next steps',\n",
       " 'segmentation and evaluation',\n",
       " 'does company x take more risks than company y?',\n",
       " 'evaluating the impact of unsupervised models',\n",
       " 'format and detailed schedule',\n",
       " 'expert',\n",
       " 'd case study',\n",
       " 'summary and outlook: extending zap',\n",
       " 'antelogue api and demo',\n",
       " 'c details of espada creation',\n",
       " 'processing',\n",
       " 'conclusion: future of supervised parsing',\n",
       " 'interrob',\n",
       " 'contextual resolution primitives.',\n",
       " 'distribution',\n",
       " 'collc|usiol~',\n",
       " 'future research direction',\n",
       " 'c o n clu sio n',\n",
       " 'v. experiments',\n",
       " 'generalization in ale',\n",
       " 'b iterated information gain filtration',\n",
       " 'transdisciplinary aspects',\n",
       " 'submitted data',\n",
       " 'conclusions-future work',\n",
       " 'preliminary conclusion -outlook',\n",
       " 'per-entity analysis in',\n",
       " 'corpus size and syntactic behavior',\n",
       " 'i postpone ]',\n",
       " 'evaluation packages',\n",
       " 'conclusion and general notes on the give challenge',\n",
       " 'results and discussions',\n",
       " 'toward communicative agent',\n",
       " 'e drop error analysis',\n",
       " 'sink eventstr =',\n",
       " 'a.4 correlation analysis',\n",
       " 'c multi-encoder',\n",
       " 'auditory neurophysiology',\n",
       " 'measure meaning discrepancies',\n",
       " '3, the supervisor',\n",
       " 'computing time',\n",
       " 'acl membership application',\n",
       " 'de (ref)',\n",
       " 'tipster in eu projects',\n",
       " 'open access',\n",
       " 'c hyperparameters and training',\n",
       " 'task organization',\n",
       " 'c.1 runtime',\n",
       " 'the consensus summary as an evaluation tool',\n",
       " 'conclusions and future developments',\n",
       " 'recommendations for future research',\n",
       " '69.38',\n",
       " 'd.5 evaluation metric',\n",
       " 'question: what makes a good domain for mdl?',\n",
       " 'any new updates or fixes to the excel application would always be installed in the',\n",
       " 'seq2drnn',\n",
       " 'applhp dp participant',\n",
       " 'conclusions and outlook',\n",
       " 'd computational complexity',\n",
       " 'automatic term extraction',\n",
       " 'evaluations and discussion',\n",
       " '4~3 combining the results: monte carlo simulation',\n",
       " 'limitations and fu rther work',\n",
       " 'recognizing action vs. stative adjectives',\n",
       " 'event extraction evaluation',\n",
       " 'e means and standard deviations of final results on nli/rc datasets',\n",
       " 'open research challenges',\n",
       " 'b feedback questions',\n",
       " 'related work and remarks',\n",
       " 'results of sentence recall study',\n",
       " 'b.2 implementation details',\n",
       " 'conclusions and feature work',\n",
       " 'example 11',\n",
       " 'constituent reordering and syntax model combined',\n",
       " 'preliminary analysis',\n",
       " 'statistics',\n",
       " 'final recommendations',\n",
       " 'appendix: parsing algorithm',\n",
       " 'entry ( editore )',\n",
       " 'c isotropy scores on glue',\n",
       " 'distribution of the corpus',\n",
       " 'these are two examples of queries:',\n",
       " 'the weakly deterministic boundary',\n",
       " 'a probing classifiers',\n",
       " 'teacher mode',\n",
       " 'some closing thoughts',\n",
       " 'lm prior',\n",
       " 'conclusions and future scope',\n",
       " 'applied research',\n",
       " 'scope model based on the bioscope corpus',\n",
       " 'reflections and further work',\n",
       " 'concluding thanks and a bit of personal history',\n",
       " 'classifier',\n",
       " 'open questions',\n",
       " 'limitations of system performance and data collection',\n",
       " 'comparison to related work',\n",
       " 'experimental study',\n",
       " 'selecting text in the dictionary entry',\n",
       " 'intersection component',\n",
       " 'evaluation as hegemony',\n",
       " 'an analysis of',\n",
       " 'first results',\n",
       " 'a grammar and lexicon of the corpus',\n",
       " 'training',\n",
       " 'almost monotonic translation (ie)',\n",
       " 'd.4 related work general algorithm',\n",
       " 'c fine-tuning settings',\n",
       " 'oun',\n",
       " 'direct versus complex rules',\n",
       " 'desiderata for a dialogue model',\n",
       " 'b analysis on using the normalization of pmi scores',\n",
       " '--the full catastrophe',\n",
       " 'possible services & further enhancements',\n",
       " 'h related work',\n",
       " 'experience in the field',\n",
       " 'c additional reconstructed graphs',\n",
       " 'd dataset maps & acquisitions',\n",
       " 'status and conclusions',\n",
       " 'extraction of questions from interaction data',\n",
       " 'conslusions',\n",
       " 'current < rightmost',\n",
       " 'd notes on reproducibility',\n",
       " 'evaluation on the weighting scheme',\n",
       " 'research in progress',\n",
       " 'f implementation details',\n",
       " 'window span',\n",
       " 'experimentation',\n",
       " 'conclusion and feature work',\n",
       " 'a.1 results for different settings',\n",
       " 'between construction and truth',\n",
       " 'dan roth',\n",
       " 'the project structure',\n",
       " 'conclusion and proposals',\n",
       " 'lewis',\n",
       " 'm negligible effect of random ordering',\n",
       " 'topic',\n",
       " 'i',\n",
       " 'a supplementary materials',\n",
       " 'remarks and future work',\n",
       " 'previous editions and related tutorials',\n",
       " 'frame assignment',\n",
       " 'conclusions and current research',\n",
       " 'towards the future',\n",
       " 'conclude and future work',\n",
       " 'acklowledgments',\n",
       " 'joining terms',\n",
       " 'is it a real advance or just a hollywood term?',\n",
       " 'summary and future implementations',\n",
       " 'conclusions and further directions of research',\n",
       " 'summary and contributions',\n",
       " 'extended abstract',\n",
       " 'can constraint relations be compiled out of rules?',\n",
       " 'other applications of the multi-level classifier',\n",
       " 'references:',\n",
       " \"st'\",\n",
       " 'analysis of results',\n",
       " 'ongoing work',\n",
       " 'conclusion and lessons learned',\n",
       " 'experiment on finnish treebank data',\n",
       " 'that lets us generate -e (string 1)',\n",
       " 'using glosser',\n",
       " 'discussion/future work',\n",
       " 'practical issues and conclusions',\n",
       " 'b coreference annotations',\n",
       " 'presenters',\n",
       " 'b session details and raw similarities',\n",
       " 'eli e',\n",
       " 'a.3 action-graphs from real annotated graphs',\n",
       " 'conclusion 7',\n",
       " 'facebook case',\n",
       " 'a.1.2 results',\n",
       " 'possible applications',\n",
       " 'adjunct resolution',\n",
       " 'c example captions for different models',\n",
       " '5.conclusion',\n",
       " 'effect of the parameters j',\n",
       " 'finding all applicable rules',\n",
       " 'experimental evaluation and results',\n",
       " 'summary and conclusion',\n",
       " 'domain adaptation',\n",
       " 'applications and outlook',\n",
       " '7: condemnatory',\n",
       " 'conservatives liberals',\n",
       " 'discussions and concluding remarks',\n",
       " '7ol',\n",
       " 'further perspectives',\n",
       " 'pa_vincent',\n",
       " 'a hyperparameter tuning details',\n",
       " 'winiwarter ~ i(ambayashi',\n",
       " 'right node raising',\n",
       " 'ordered list of lexical items conclusion',\n",
       " 'controlled language generation',\n",
       " 'result of pos tagging',\n",
       " 'experiment 3: disambiguation',\n",
       " 'd.1 evaluation metrics',\n",
       " 'a additional analysis',\n",
       " 'future direction s',\n",
       " 'c statistics of the drafts',\n",
       " 'acquisition of transfer knowledge: techniques',\n",
       " '• syntactic validation of split compound recognition',\n",
       " 'implications for automated scoring',\n",
       " 'b.3 query: chronic headache and depression review',\n",
       " 'd.2 the case of the anthem/cigna merger',\n",
       " 'facts & figures of sap',\n",
       " 'dialogue game',\n",
       " 'algorithm 1. membership in .l(arg)',\n",
       " 'conclusions:',\n",
       " 'conclusion and directions for future research',\n",
       " 'zapirain et al. (',\n",
       " 'miscellaneous points',\n",
       " 'future enhancement: xbrl',\n",
       " 'a.2 additional introspection',\n",
       " 'example representations',\n",
       " 'turkers vs experts',\n",
       " 'fax-a-query: the ultimate in wysiwyg',\n",
       " 'd continued pre-training details',\n",
       " \"a.2 plots with metrics' performance\",\n",
       " '1989, 343 pages computer science university microfilms international adg89-10833',\n",
       " 'c on clu sion and future w ork',\n",
       " 'f hyper-parameters selection',\n",
       " 'threats to validity',\n",
       " 'analysis of the identification results',\n",
       " 'dnn-based ensemble classifier',\n",
       " 'extrinsic evaluation',\n",
       " 'speech act type analysis by simple plan recognition inference',\n",
       " 'a.2.2 implementation of the word-averaging baseline',\n",
       " 'conclusion and perspectives',\n",
       " 'two use scenarios',\n",
       " 'concluding remarks and future work',\n",
       " \"fv's and functors\",\n",
       " 'future research.',\n",
       " 'a proof of proposition 1',\n",
       " '1486',\n",
       " 'conclusions and applications',\n",
       " 'ukrainian manual study',\n",
       " 'the dispatcher',\n",
       " 'database and interface design',\n",
       " 'wikipedia evaluation',\n",
       " 'statistics of event mention pairs',\n",
       " 'initial dialogue:',\n",
       " 'c statistics on the metrics data',\n",
       " 'activities for user and agent',\n",
       " 'd results of the proposed algorithms in the chatworks dataset',\n",
       " 'allowing more elaborate improvisation',\n",
       " \"vendors' feedback\",\n",
       " '5507',\n",
       " 'classified documents',\n",
       " 'semantic analyis:',\n",
       " 'references.',\n",
       " 'results and reflections',\n",
       " 'rule factorization',\n",
       " 'interface and implementatien notes',\n",
       " 'experiments on semi-supervised learning approach',\n",
       " 'related and future work',\n",
       " 'documents',\n",
       " 'p arsin g f ea tu re-b a sed t a g s',\n",
       " 'convergence',\n",
       " 'recognition for context-sensitive grammar abcgram',\n",
       " 'a additional experiments and results',\n",
       " 'integrated system performance',\n",
       " 'extent experiment',\n",
       " 'ways of scope taking anna szabolcsi (editor)',\n",
       " 'i co ch( m) l',\n",
       " 'obtaining alignments from derivations',\n",
       " 'discussions and further work',\n",
       " 'and future plans',\n",
       " 'accepting the responsibility themself',\n",
       " 'why even small things do matter',\n",
       " 'modelling the status checking loop',\n",
       " 'background context',\n",
       " 'irregular inflection',\n",
       " 'quality of text embedding:',\n",
       " 'short numerical overview of the test pattern instances',\n",
       " 'some pointers',\n",
       " 'summary and recommendation',\n",
       " 'implications for treebanking',\n",
       " 'c hyperparameters',\n",
       " 'v. conclusion:',\n",
       " 'd',\n",
       " 'cross-validation. possible explanations of the results',\n",
       " 'a runtime complexity analysis',\n",
       " 'f generated samples of debiased dataset',\n",
       " 'perspective:',\n",
       " '15)',\n",
       " 'team collaboration',\n",
       " 'c.1 right context for link prediction',\n",
       " 'human perception of quality',\n",
       " 'seq2seq',\n",
       " 'other syntactic elements',\n",
       " 'linear discriminant features',\n",
       " 'final comments and conclusion',\n",
       " 'conclusion and open questions',\n",
       " 'a.2 detailed responses to reviewer questions',\n",
       " '6, conclusions',\n",
       " 'marking',\n",
       " 'translation algorithm',\n",
       " 'method',\n",
       " 'example: exploitation of layout annotation for the study of loanwords',\n",
       " 'connotative dependency structure',\n",
       " 'conclusion and further development',\n",
       " 'current status and future enhancements',\n",
       " 'simpática. friendly',\n",
       " 'sandhi',\n",
       " 'effectiveness of syntactic and semantic cues for semantic classification',\n",
       " 'conclusions and future wor k',\n",
       " 'event generated precondition batted',\n",
       " 'evaluation procedure and results',\n",
       " 't h e c om puter databaise',\n",
       " 'related work and concluding remarks',\n",
       " 'd supplemental material: improved inference d.1 inference process',\n",
       " 'test results',\n",
       " 'multilingual components needed',\n",
       " 'the metaphor magnet web app',\n",
       " 'label antecedent succedent',\n",
       " 'further differences',\n",
       " 'timetable',\n",
       " 'appendix a submissions',\n",
       " 'population of informants: do we get even',\n",
       " '[ [relh pdss ible-erpect] [obje [ [relg ta-perfecti ve] [obje [ [il~3..~ wakara-1]]]]]]] ]',\n",
       " 'a.4 dimensions of human evaluation',\n",
       " 'use case',\n",
       " 'results in task c',\n",
       " 'towards language standards',\n",
       " \"conclusion and further 'york\",\n",
       " 'the morphology system. the main',\n",
       " 'longer-term plans',\n",
       " 'd.1 analysis on few-shot learning design',\n",
       " 'future work and discussion',\n",
       " 'zero fertility',\n",
       " 'generation:',\n",
       " 'b additional generation examples',\n",
       " '• translation solutions for service providers (translation of web pages and e-mail)',\n",
       " 'comparing human-generated paraphrases',\n",
       " 'results and discussion',\n",
       " 'expert evaluation',\n",
       " 'conclusion and plans',\n",
       " 'evaluation of the disambiguation module',\n",
       " 'application: improving ner performance on twitter',\n",
       " 'c appendix: extracting content from url documents',\n",
       " 'a.1 entity candidate generator details',\n",
       " 'combining mt systems with different',\n",
       " '${title}',\n",
       " 'c.3 network structure of models',\n",
       " 'c.5 baselines',\n",
       " 'reproducibility and continuing development',\n",
       " 'b.3 do phrasal annotations bias nmt?',\n",
       " 'schedule',\n",
       " 'application and results',\n",
       " 'an example',\n",
       " 'c.2 more analyses results',\n",
       " 'acoustic modelling',\n",
       " 'conclusion.',\n",
       " 'evaluation of unknown-word boundary identification',\n",
       " 'incorrect word order 73',\n",
       " 'refined experiment',\n",
       " 'discussions & conclusions',\n",
       " 'conclusions and recommendations',\n",
       " 'literature',\n",
       " 'expected results',\n",
       " '105',\n",
       " 'a.3 model performance',\n",
       " 'biographies of presenters',\n",
       " 'our method versus the classic one',\n",
       " \"• `watashi ga piza' is formalised as ]uopiza[u watashi]\",\n",
       " 'annotation process and agreement',\n",
       " 'status and future work',\n",
       " 'discussion, conclusion, and future work',\n",
       " 'a.7 fnet code',\n",
       " 'b.3 data statistics for benchmarks',\n",
       " '. indirect questions',\n",
       " 'chinese kinship terms',\n",
       " 'c onclusions and f uture w ork',\n",
       " 'conclusions work and future',\n",
       " 'l l m',\n",
       " 'deliberation',\n",
       " 'proceedings of the 2nd',\n",
       " 'conclusions and future potential',\n",
       " 'questioner',\n",
       " 'h hyperparameter tuning',\n",
       " 'software and data',\n",
       " 'conclusions and further problems',\n",
       " 'models',\n",
       " 'summary and system performance',\n",
       " 'c rationale perturbation for adapted models',\n",
       " 'result, discussion, and future works',\n",
       " 'the implementation of writing tools in educational settings',\n",
       " 'generating applications',\n",
       " '6.conclusion',\n",
       " 'room for improvement',\n",
       " 'knowing when enough is enough',\n",
       " 'simple type theory',\n",
       " 'reviewed by john roach virginia polytechnic institute and state university',\n",
       " 'psa:',\n",
       " 'pollack',\n",
       " 'analysis & discussion',\n",
       " 'conclusion and additional questions',\n",
       " 'compound clustering experiment',\n",
       " 'description of tutorial content',\n",
       " 'ethics statement',\n",
       " 'deriving a word data base',\n",
       " 'e implementation details',\n",
       " 'a.3 analogy',\n",
       " 'submitted runs',\n",
       " 'significance',\n",
       " 'namesake',\n",
       " 'annotation schemes & validation',\n",
       " '6-7 november 1986, waterloo, canada',\n",
       " 'contributions of other components',\n",
       " 'conclusions',\n",
       " 'lessons learnt and further work',\n",
       " 'qualitative inspection of extractors',\n",
       " 'plurals',\n",
       " 'e ample',\n",
       " 'd proof of thm. 2.1, necessity',\n",
       " 'conclusions and future research',\n",
       " 'summary and further studies',\n",
       " 'resolved feature structures',\n",
       " '•deriving plans for warning instructions',\n",
       " 'h details on automatic evaluation for model revisions',\n",
       " 'references',\n",
       " 'putting the pieces together',\n",
       " 'an experiment to produce sentences from valency patterns',\n",
       " 'insights and future directions',\n",
       " 'conclusion and continuation',\n",
       " 'c model details',\n",
       " 'the results and conclusions',\n",
       " 'summary and future work',\n",
       " 'b regression analysis on held-out test data',\n",
       " 'iterative evolution of estwn',\n",
       " 'error-rate-per-word',\n",
       " 'the ud treebanks',\n",
       " 'jo abilistic',\n",
       " 'c robustness to out-of-domain data',\n",
       " 'o rd erin g gen eration altern atives',\n",
       " 'a note on expressiveness: scope vs. scrambling',\n",
       " 'the topic/focus articulation',\n",
       " 'parsing results',\n",
       " 'before feedback',\n",
       " 'so the following example',\n",
       " 'post-processing',\n",
       " '8.implementation',\n",
       " 'the experiment and evaluation',\n",
       " 'model validation',\n",
       " 'a semi-supervised extension',\n",
       " \". h e h a d n 't h eard irom\",\n",
       " 'formulas for computation',\n",
       " 'increasing coverage',\n",
       " 'members for use in laboratories or libraries must be paid for at the \"others\" rate.',\n",
       " 'b hyperparameter',\n",
       " 'summary of formulae **',\n",
       " 'parameter estimation',\n",
       " 'conclusions and further desiderata',\n",
       " 'unsolvable examples',\n",
       " 'a.3 development set performance',\n",
       " 'conclusion � future work',\n",
       " 'contemporary limitations and challenges',\n",
       " 'stem',\n",
       " 'speech recognition system',\n",
       " 'concluding points',\n",
       " 'research contributions & a look into the future',\n",
       " 'mention-level evaluation',\n",
       " 'tuning the mt system on w4p texts',\n",
       " 'polycategoriality across verbal nouns and no-type adjectival nouns and adnominals',\n",
       " 'next steps and conclusion',\n",
       " 'd performance test result for gender',\n",
       " 'it i s c l e a r t h a t t h e \"depth\" of t h e search, as measured by',\n",
       " 'feature analysis',\n",
       " 'sublanguage engineering issues',\n",
       " 'd.2 activation tensors for different architectures',\n",
       " 'c automatic evaluation results',\n",
       " \"pbt translation this one and what 's the difference between ? hybrid translation\",\n",
       " 'conclusion and discussions',\n",
       " 'impact',\n",
       " 'n-gram utilities',\n",
       " 'markow analysis of large corpora and wordclass systems',\n",
       " 'integration of a focus module into speech synthesis systems',\n",
       " 'challenges and future work',\n",
       " 'integration',\n",
       " 'performance on the assessor example set',\n",
       " 'd implementation details',\n",
       " '&rqfoxvlrq',\n",
       " 'results and further work',\n",
       " 'future work',\n",
       " 'linguistic properties',\n",
       " 'b.3 dependency parser',\n",
       " 'baseline model',\n",
       " 'improving accuracy',\n",
       " 'a replication details',\n",
       " 'c mt system configuration',\n",
       " 'a review of possible enhancements',\n",
       " 'conclusion and prospects',\n",
       " 'early use of the corpus and future work',\n",
       " 'a.5 additional plots',\n",
       " 'what this tells us about metaphor-in-language',\n",
       " 'c bleu scores',\n",
       " 'a.4 related work',\n",
       " 'd annotation guidelines',\n",
       " 'd. human evaluation details',\n",
       " 'cluster summarisation',\n",
       " 'c.7 human evaluation',\n",
       " 'dictionary',\n",
       " 'experiment and result',\n",
       " 'of the work and',\n",
       " 'conclusions -future work',\n",
       " 'les lois linguistiques',\n",
       " 'punctuation and speech transcription practice',\n",
       " 'a.2 signature of paths',\n",
       " 'fiyure 5. illustrative definitioil of idiosyncratic gap',\n",
       " 'd discussion of instances',\n",
       " 'sentence 1 baseline +utdp rules reference',\n",
       " 'a.2 clarification question generation models',\n",
       " '514',\n",
       " 'b.1 report organization',\n",
       " 'multimodal adaptation',\n",
       " 'axioms in action',\n",
       " 'frequency',\n",
       " 'sources and resources -towards a new paradigm of collaboration',\n",
       " 'appendix: subject instructions',\n",
       " 'c validation performance',\n",
       " 'social network analysis',\n",
       " 'd ablation study on contrastive learning and knowledge distillation',\n",
       " 'asr output',\n",
       " 'conclusion and criticism',\n",
       " 'evaluation of effectiveness',\n",
       " 'las uas ls',\n",
       " 'proof',\n",
       " 'a.5 visualization of the parses',\n",
       " 'b.2 preprocessing details',\n",
       " 'f data generation example',\n",
       " 'c.1 data specifications',\n",
       " 'applications',\n",
       " 'effectiveness of robust mt training',\n",
       " 'performance tests',\n",
       " 'c adding entity annotations to squad dataset',\n",
       " 'b example utterances at various generations',\n",
       " 'experiments and discussion',\n",
       " 'conclusions and further research',\n",
       " 'outlook: connecting the dots',\n",
       " 'concluding remarks and discussions',\n",
       " 'experimental results and conclusion',\n",
       " 'conclusion : for the new great age of translation',\n",
       " 'with coverage penalty',\n",
       " 'b.3 mlp v.s. cnn',\n",
       " 'a.2.1 phrases for crises',\n",
       " 'conclusion and future perspectives',\n",
       " 'test',\n",
       " 'vi. conclusions',\n",
       " 'd training and platform details',\n",
       " 'changing user perception of mt',\n",
       " 'general results',\n",
       " 'main focus points',\n",
       " 'persons',\n",
       " 'influence of embedding granularities and dimensions',\n",
       " 'grammatical coverage',\n",
       " 'barry friedson, of martin',\n",
       " 'evaluation of projected parses',\n",
       " 'fl~ xp+r',\n",
       " 'mt toolkits',\n",
       " 'additional features',\n",
       " 'risk and impact of mistakes',\n",
       " 'conclusion and comments',\n",
       " 'c.2 adversarial words and masking',\n",
       " 'practical results',\n",
       " 'alternatives to collocation for recognition applications',\n",
       " 'b.4 error analysis',\n",
       " 'languages utterances',\n",
       " 'joint training',\n",
       " 'a.2 results for style classifiers/regressor',\n",
       " 'a.3.1 adaptation to chinese inputs',\n",
       " 'a.4 topics extracted by topic mining',\n",
       " 'compute the complete containing degree rel 2 of the sememes of def',\n",
       " 'summary and future studies',\n",
       " 'current status and conclusion',\n",
       " 'flexibility',\n",
       " 'd examples of template generation',\n",
       " 'negative − → postive',\n",
       " 'std_scores',\n",
       " 'how many americans suffer from food allergies?',\n",
       " 'not~',\n",
       " 'system scope',\n",
       " 'further analysis',\n",
       " 'prospects',\n",
       " 'al (19as)',\n",
       " 'e transferbility',\n",
       " 'experiments results',\n",
       " 'genre',\n",
       " 'next, dr. ristad returns to my criticism of his incompletely specified reduction arguments:',\n",
       " 'final results and conclusion',\n",
       " 'overall errors',\n",
       " 'conclusion and future expectations',\n",
       " '5) an experimental approach to work out rules of analysis',\n",
       " 'the structure of cs',\n",
       " 'implications',\n",
       " 'implementation status',\n",
       " 'appendix: query for vorfeld',\n",
       " 'summary and directions',\n",
       " 'b annotation guidelines',\n",
       " 'b qualitative examples',\n",
       " 'evaluation of syntactic analysis',\n",
       " 'conclusion and future extensions',\n",
       " 'evaluation methods',\n",
       " 'c additional figures',\n",
       " ...}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Introduction\n",
      "2 - Background\n",
      "5 - Conclusions and outlook\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_main_sections_rpz_from_paper(p):\n",
    "    main_sections = \"\"\n",
    "    for k, v in p.sections.items():\n",
    "        if v[\"n\"] != None:\n",
    "            n = str(v['n'])\n",
    "            if len(n.split(\".\")) == 1:\n",
    "                main_sections += n + \" - \" +v[\"header\"] + \"\\n\"\n",
    "\n",
    "    return main_sections\n",
    "\n",
    "print(get_main_sections_rpz_from_paper(p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cdb.annotated_idx_path, \"r\") as f:\n",
    "    anno = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v1': [['ACL', '2020.signlang-1.20'],\n",
       "  ['ACL', 'W17-4709'],\n",
       "  ['ACL', 'N19-1358'],\n",
       "  ['arXiv', '2103.14302'],\n",
       "  ['ACL', 'Y15-1047'],\n",
       "  ['ACL', 'P18-1048'],\n",
       "  ['arXiv', '1708.01009'],\n",
       "  ['arXiv', '1611.08765'],\n",
       "  ['arXiv', '1605.05172'],\n",
       "  ['arXiv', '2012.04584']]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v1': [['ACL', '2020.signlang-1.20'],\n",
       "  ['ACL', 'W17-4709'],\n",
       "  ['ACL', 'N19-1358'],\n",
       "  ['arXiv', '2103.14302'],\n",
       "  ['ACL', 'Y15-1047'],\n",
       "  ['ACL', 'P18-1048'],\n",
       "  ['arXiv', '1708.01009'],\n",
       "  ['arXiv', '1611.08765'],\n",
       "  ['arXiv', '1605.05172'],\n",
       "  ['arXiv', '2012.04584']],\n",
       " 'v2': [['ACL', 'W17-5513'], ['arXiv', '2108.06957']]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno['v2'] = [[c, id] for c,id in idx]\n",
    "anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cdb.annotated_idx_path, \"w\") as f:\n",
    "    json.dump(anno, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_ACL, corpus_arxiv = cdb.corpora\n",
    "\n",
    "p1 = corpus_ACL.get_paper_by_id(\"W17-5513\")\n",
    "p2 = corpus_arxiv.get_paper_by_id(\"2108.06957\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 4)\n",
      "(34, 4)\n",
      "(180, 4)\n",
      "(142, 4)\n"
     ]
    }
   ],
   "source": [
    "print(p1.content.shape)\n",
    "print(p1.content[p1.content[\"candidate\"] == True].shape)\n",
    "\n",
    "print(p2.content.shape)\n",
    "print(p2.content[p2.content[\"candidate\"] == True].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Related Work', 'Architecture Description', 'Preprocessing',\n",
       "       'Dialogue Model', 'Postprocessing', 'Operation modes',\n",
       "       'Data Collection Mode', 'Execution Mode', 'Feature Highlights',\n",
       "       'Case Studies', 'Building a simple agent',\n",
       "       'Building a goal oriented system',\n",
       "       'Building a neural response generation agent',\n",
       "       'HRED in execution mode'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.content[p1.content[\"candidate\"] == False].section.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Model Enhancement Techniques'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2.content[p2.content[\"candidate\"] == False].section.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abstract', 'Introduction', 'Relation Extraction',\n",
       "       'Sentence-level Event Extraction',\n",
       "       'Document-level Event Extraction', 'Loss function', 'Main Results',\n",
       "       'Conclusions'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2.content[p2.content[\"candidate\"] == True].section.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
