id,text,,doccano_art_id,sentence_id,current_sentence_section,previous_sentence_section,previous_sentence,next_sentence_section,next_sentence,label,Comments
2143,In this paper we report on a research effort focusing on recognition of static features of sign formation in single sign videos.,0,0,0,abstract,,,abstract,"Three sequential models have been developed for handshape, palm orientation and location of sign formation respectively, which make use of key-points extracted via OpenPose software.",FACT,
2144,"Three sequential models have been developed for handshape, palm orientation and location of sign formation respectively, which make use of key-points extracted via OpenPose software.",1,0,1,abstract,abstract,In this paper we report on a research effort focusing on recognition of static features of sign formation in single sign videos.,abstract,"The models have been applied to a Danish and a Greek Sign Language dataset, providing results around 96%.",FACT,
2145,"The models have been applied to a Danish and a Greek Sign Language dataset, providing results around 96%.",2,0,2,abstract,abstract,"Three sequential models have been developed for handshape, palm orientation and location of sign formation respectively, which make use of key-points extracted via OpenPose software.",abstract,"Moreover, during the reported research, a method has been developed for identifying the time-frame of real signing in the video, which allows to ignore transition frames during sign recognition processing.",POS,
2146,"Moreover, during the reported research, a method has been developed for identifying the time-frame of real signing in the video, which allows to ignore transition frames during sign recognition processing.",3,0,3,abstract,abstract,"The models have been applied to a Danish and a Greek Sign Language dataset, providing results around 96%.",Introduction,"One of the problems relating to sign language recognition is the lack of appropriate datasets for algorithm training, since most datasets are recorded for academic purposes and as such, they concentrate in human learning rather than machine learning.",FACT,
2147,"One of the problems relating to sign language recognition is the lack of appropriate datasets for algorithm training, since most datasets are recorded for academic purposes and as such, they concentrate in human learning rather than machine learning.",4,0,4,Introduction,abstract,"Moreover, during the reported research, a method has been developed for identifying the time-frame of real signing in the video, which allows to ignore transition frames during sign recognition processing.",Introduction,"Therefore, most data collections contain a very large number of different glosses with very few repetitions of each.",NC,
2148,"Therefore, most data collections contain a very large number of different glosses with very few repetitions of each.",5,0,5,Introduction,Introduction,"One of the problems relating to sign language recognition is the lack of appropriate datasets for algorithm training, since most datasets are recorded for academic purposes and as such, they concentrate in human learning rather than machine learning.",Introduction,This characteristic makes it very unlikely for these datasets to be used as training sets for classification algorithms in sign recognition level.,NC,
2149,This characteristic makes it very unlikely for these datasets to be used as training sets for classification algorithms in sign recognition level.,6,0,6,Introduction,Introduction,"Therefore, most data collections contain a very large number of different glosses with very few repetitions of each.",Introduction,"Thus, we developed a system in the direction of ""phonological"" features recognition.",NC,
2150,"Thus, we developed a system in the direction of ""phonological"" features recognition.",7,0,7,Introduction,Introduction,This characteristic makes it very unlikely for these datasets to be used as training sets for classification algorithms in sign recognition level.,Introduction,"This way we can extract a dataset with a lot of examples for every handshape, palm orientation and hand location out of the video collections.",FACT,
2151,"This way we can extract a dataset with a lot of examples for every handshape, palm orientation and hand location out of the video collections.",8,0,8,Introduction,Introduction,"Thus, we developed a system in the direction of ""phonological"" features recognition.",Datasets,For the purposes of the project two collections of single gloss videos were used as datasets.,NC,
2152,"OpenPose is a software freely distributed by Carnegie Melon University, Perceptual Computing Lab (Cao et al., 2018).",9,0,22,Openpose,Datasets,This feature is making the whole process easier when trying to split the dictionary into handshape classes.,Openpose,It is used as a tool of human body keypoints extraction from a single image or video frame.,NC,
2153,It is used as a tool of human body keypoints extraction from a single image or video frame.,10,0,23,Openpose,Openpose,"OpenPose is a software freely distributed by Carnegie Melon University, Perceptual Computing Lab (Cao et al., 2018).",Openpose,"It offers an estimation of 25 body/foot keypoints, 2x21 hand keypoints and 70 face keypoints.",NC,
2154,"It offers an estimation of 25 body/foot keypoints, 2x21 hand keypoints and 70 face keypoints.",11,0,24,Openpose,Openpose,It is used as a tool of human body keypoints extraction from a single image or video frame.,Openpose,"In the case of a 2D video input, for each keypoint it returns a vector containing 3 elements.",NC,
2155,"In the case of a 2D video input, for each keypoint it returns a vector containing 3 elements.",12,0,25,Openpose,Openpose,"It offers an estimation of 25 body/foot keypoints, 2x21 hand keypoints and 70 face keypoints.",Openpose,"The first 2 correspond to the (x,y) coordinates with reference to the upper left corner of the image.",NC,
2156,"The first 2 correspond to the (x,y) coordinates with reference to the upper left corner of the image.",13,0,26,Openpose,Openpose,"In the case of a 2D video input, for each keypoint it returns a vector containing 3 elements.",Openpose,"The third is a value in the range [0,1] which is quantification of the confidence given by the program that the specific keypoint is correctly located in the frame.",NC,
2157,"The third is a value in the range [0,1] which is quantification of the confidence given by the program that the specific keypoint is correctly located in the frame.",14,0,27,Openpose,Openpose,"The first 2 correspond to the (x,y) coordinates with reference to the upper left corner of the image.",Openpose,The novelty behind OpenPose relies on the fact that it works for more than one person per image but more importantly the keypoint analysis is not affected when part of the individual's body is out of frame.,NC,
2158,The novelty behind OpenPose relies on the fact that it works for more than one person per image but more importantly the keypoint analysis is not affected when part of the individual's body is out of frame.,15,0,28,Openpose,Openpose,"The third is a value in the range [0,1] which is quantification of the confidence given by the program that the specific keypoint is correctly located in the frame.",Openpose,This last feature is crucial for applications on sign language videos where the signer appears above the waist level (Figure 1).,NC,
2159,This last feature is crucial for applications on sign language videos where the signer appears above the waist level (Figure 1).,16,0,29,Openpose,Openpose,The novelty behind OpenPose relies on the fact that it works for more than one person per image but more importantly the keypoint analysis is not affected when part of the individual's body is out of frame.,Our Method,The first step in our method is transforming each video frame into keypoints using the OpenPose software.,NC,
2160,Pivot translation is a useful method for translating between languages with little or no parallel data by utilizing parallel data in an intermediate language such as English.,17,1,0,abstract,,,abstract,"A popular approach for pivot translation used in phrase-based or tree-based translation models combines source-pivot and pivot-target translation models into a source-target model, as known as triangulation.",NC,
2161,"A popular approach for pivot translation used in phrase-based or tree-based translation models combines source-pivot and pivot-target translation models into a source-target model, as known as triangulation.",18,1,1,abstract,abstract,Pivot translation is a useful method for translating between languages with little or no parallel data by utilizing parallel data in an intermediate language such as English.,abstract,"However, this combination is based on the constituent words' surface forms and often produces incorrect source-target phrase pairs due to semantic ambiguity in the pivot language, and interlingual differences.",NC,
2162,"However, this combination is based on the constituent words' surface forms and often produces incorrect source-target phrase pairs due to semantic ambiguity in the pivot language, and interlingual differences.",19,1,2,abstract,abstract,"A popular approach for pivot translation used in phrase-based or tree-based translation models combines source-pivot and pivot-target translation models into a source-target model, as known as triangulation.",abstract,This degrades translation accuracy.,NC,
2163,This degrades translation accuracy.,20,1,3,abstract,abstract,"However, this combination is based on the constituent words' surface forms and often produces incorrect source-target phrase pairs due to semantic ambiguity in the pivot language, and interlingual differences.",abstract,"In this paper, we propose a approach for the triangulation using syntactic subtrees in the pivot language to distinguish pivot language words by their syntactic roles to avoid incorrect phrase combinations.",NC,
2164,"In this paper, we propose a approach for the triangulation using syntactic subtrees in the pivot language to distinguish pivot language words by their syntactic roles to avoid incorrect phrase combinations.",21,1,4,abstract,abstract,This degrades translation accuracy.,abstract,"Experimental results on the United Nations Parallel Corpus show the proposed method gains in all tested combinations of language, up to 2.3 BLEU points.",FACT,
2165,"Experimental results on the United Nations Parallel Corpus show the proposed method gains in all tested combinations of language, up to 2.3 BLEU points.",22,1,5,abstract,abstract,"In this paper, we propose a approach for the triangulation using syntactic subtrees in the pivot language to distinguish pivot language words by their syntactic roles to avoid incorrect phrase combinations.",abstract,1,POS,
2166,1,23,1,6,abstract,abstract,"Experimental results on the United Nations Parallel Corpus show the proposed method gains in all tested combinations of language, up to 2.3 BLEU points.",Introduction,"In statistical machine translation (SMT) (Brown et al., 1993), it is known that translation with models trained on larger parallel corpora can achieve greater accuracy (Dyer et al., 2008).",NC,
2167,"In statistical machine translation (SMT) (Brown et al., 1993), it is known that translation with models trained on larger parallel corpora can achieve greater accuracy (Dyer et al., 2008).",24,1,7,Introduction,abstract,1,Introduction,"Unfortunately, large bilingual corpora are not readily available for many language pairs, particularly those that do not include English.",NC,
2168,"Unfortunately, large bilingual corpora are not readily available for many language pairs, particularly those that do not include English.",25,1,8,Introduction,Introduction,"In statistical machine translation (SMT) (Brown et al., 1993), it is known that translation with models trained on larger parallel corpora can achieve greater accuracy (Dyer et al., 2008).",Introduction,"One effective solution to overcome the scarceness of bilingual data is to introduce a pivot language for which paral-1 Code to replicate the experiments can be found at https://github.com/akivajp/wmt2017 lel data with the source and target languages exists (de Gispert and Mariño, 2006).",NC,
2169,"One effective solution to overcome the scarceness of bilingual data is to introduce a pivot language for which paral-1 Code to replicate the experiments can be found at https://github.com/akivajp/wmt2017 lel data with the source and target languages exists (de Gispert and Mariño, 2006).",26,1,9,Introduction,Introduction,"Unfortunately, large bilingual corpora are not readily available for many language pairs, particularly those that do not include English.",Introduction,"Among various methods using pivot languages, one popular and effective method is the triangulation method (Utiyama and Isahara, 2007;Cohn and Lapata, 2007), which first combines sourcepivot and pivot-target translation models (TMs) into a source-target model, then translates using this combined model.",NC,
2170,"Among various methods using pivot languages, one popular and effective method is the triangulation method (Utiyama and Isahara, 2007;Cohn and Lapata, 2007), which first combines sourcepivot and pivot-target translation models (TMs) into a source-target model, then translates using this combined model.",27,1,10,Introduction,Introduction,"One effective solution to overcome the scarceness of bilingual data is to introduce a pivot language for which paral-1 Code to replicate the experiments can be found at https://github.com/akivajp/wmt2017 lel data with the source and target languages exists (de Gispert and Mariño, 2006).",Introduction,"The procedure of triangulating two TMs into one has been examined for different frameworks of SMT and its effectiveness has been confirmed both in Phrase-Based SMT (PBMT) (Koehn et al., 2003;Utiyama and Isahara, 2007) and in Hierarchical Phrase-Based SMT (Hiero) (Chiang, 2007;Miura et al., 2015).",NC,
2171,"The procedure of triangulating two TMs into one has been examined for different frameworks of SMT and its effectiveness has been confirmed both in Phrase-Based SMT (PBMT) (Koehn et al., 2003;Utiyama and Isahara, 2007) and in Hierarchical Phrase-Based SMT (Hiero) (Chiang, 2007;Miura et al., 2015).",28,1,11,Introduction,Introduction,"Among various methods using pivot languages, one popular and effective method is the triangulation method (Utiyama and Isahara, 2007;Cohn and Lapata, 2007), which first combines sourcepivot and pivot-target translation models (TMs) into a source-target model, then translates using this combined model.",Introduction,"However, word sense ambiguity and interlingual differences of word usage cause difficulty in accurately learning correspondences between source and target phrases, and thus the accuracy obtained by triangulated models lags behind that of models trained on direct parallel corpora.",NC,
2172,"However, word sense ambiguity and interlingual differences of word usage cause difficulty in accurately learning correspondences between source and target phrases, and thus the accuracy obtained by triangulated models lags behind that of models trained on direct parallel corpora.",29,1,12,Introduction,Introduction,"The procedure of triangulating two TMs into one has been examined for different frameworks of SMT and its effectiveness has been confirmed both in Phrase-Based SMT (PBMT) (Koehn et al., 2003;Utiyama and Isahara, 2007) and in Hierarchical Phrase-Based SMT (Hiero) (Chiang, 2007;Miura et al., 2015).",Introduction,"In the triangulation method, source-pivot and pivot-target phrase pairs are connected as a sourcetarget phrase pair when a common pivot-side phrase exists.",NC,
2173,"In the triangulation method, source-pivot and pivot-target phrase pairs are connected as a sourcetarget phrase pair when a common pivot-side phrase exists.",30,1,13,Introduction,Introduction,"However, word sense ambiguity and interlingual differences of word usage cause difficulty in accurately learning correspondences between source and target phrases, and thus the accuracy obtained by triangulated models lags behind that of models trained on direct parallel corpora.",Introduction,"In Figure 1 (a), we show an example of standard triangulation on Hiero TMs that combines hierarchical rules of phrase pairs by matching pivot phrases with equivalent surface forms.",NC,
2174,"In Figure 1 (a), we show an example of standard triangulation on Hiero TMs that combines hierarchical rules of phrase pairs by matching pivot phrases with equivalent surface forms.",31,1,14,Introduction,Introduction,"In the triangulation method, source-pivot and pivot-target phrase pairs are connected as a sourcetarget phrase pair when a common pivot-side phrase exists.",Introduction,"This example also demonstrates problems of ambiguity: the English word ""record"" can correspond to several different parts-of-speech according to the context.",NC,
2175,"This example also demonstrates problems of ambiguity: the English word ""record"" can correspond to several different parts-of-speech according to the context.",32,1,15,Introduction,Introduction,"In Figure 1 (a), we show an example of standard triangulation on Hiero TMs that combines hierarchical rules of phrase pairs by matching pivot phrases with equivalent surface forms.",Introduction,"More broadly, phrases including this word also have different possible grammatical structures, but it is impossible to uniquely identify this structure unless information about the surrounding context is given.",NC,
2176,"More broadly, phrases including this word also have different possible grammatical structures, but it is impossible to uniquely identify this structure unless information about the surrounding context is given.",33,1,16,Introduction,Introduction,"This example also demonstrates problems of ambiguity: the English word ""record"" can correspond to several different parts-of-speech according to the context.",Introduction,This varying syntactic structure will affect translation.,NC,
2177,This varying syntactic structure will affect translation.,34,1,17,Introduction,Introduction,"More broadly, phrases including this word also have different possible grammatical structures, but it is impossible to uniquely identify this structure unless information about the surrounding context is given.",Introduction,"For example, the French verb ""enregistrer"" corresponds to the English verb ""record"", but the French noun ""dossier"" also corresponds to ""record"" -as a noun.",NC,
2178,"For example, the French verb ""enregistrer"" corresponds to the English verb ""record"", but the French noun ""dossier"" also corresponds to ""record"" -as a noun.",35,1,18,Introduction,Introduction,This varying syntactic structure will affect translation.,Introduction,"As a more extreme example, Chinese is a languages that does not have inflections according to the part-of-speech of the word.",NC,
2179,"As a more extreme example, Chinese is a languages that does not have inflections according to the part-of-speech of the word.",36,1,19,Introduction,Introduction,"For example, the French verb ""enregistrer"" corresponds to the English verb ""record"", but the French noun ""dossier"" also corresponds to ""record"" -as a noun.",Introduction,"As a result, even in the contexts where ""record"" is used with different parts-of-speech, the Chinese word ""记录"" will be used, although the word order will change.",NC,
2180,"As a result, even in the contexts where ""record"" is used with different parts-of-speech, the Chinese word ""记录"" will be used, although the word order will change.",37,1,20,Introduction,Introduction,"As a more extreme example, Chinese is a languages that does not have inflections according to the part-of-speech of the word.",Introduction,"These facts might result in an incorrect connection of ""[X1] enregistrer [X2]"" and ""[X2] [X1] 记录"" even though proper correspondence of ""[X1] enregistrer [X2]"" and ""[X1] dossier [X2]"" would be ""[X1] 记 录 [X2]"" and ""[X2] [X1] 记 录"".",NC,
2181,"These facts might result in an incorrect connection of ""[X1] enregistrer [X2]"" and ""[X2] [X1] 记录"" even though proper correspondence of ""[X1] enregistrer [X2]"" and ""[X1] dossier [X2]"" would be ""[X1] 记 录 [X2]"" and ""[X2] [X1] 记 录"".",38,1,21,Introduction,Introduction,"As a result, even in the contexts where ""record"" is used with different parts-of-speech, the Chinese word ""记录"" will be used, although the word order will change.",Introduction,"Hence a superficial phrase matching method based solely on the surface form of the pivot will often combine incorrect phrase pairs, causing translation errors if their translation scores are estimated to be higher than the proper correspondences.",NC,
2182,"Hence a superficial phrase matching method based solely on the surface form of the pivot will often combine incorrect phrase pairs, causing translation errors if their translation scores are estimated to be higher than the proper correspondences.",39,1,22,Introduction,Introduction,"These facts might result in an incorrect connection of ""[X1] enregistrer [X2]"" and ""[X2] [X1] 记录"" even though proper correspondence of ""[X1] enregistrer [X2]"" and ""[X1] dossier [X2]"" would be ""[X1] 记 录 [X2]"" and ""[X2] [X1] 记 录"".",Introduction,"Given this background, we hypothesize that disambiguation of these cases would be easier if the necessary syntactic information such as phrase structures are considered during pivoting.",NC,"analyse tirée d'un exemple (example = not a claim), mais servant de base à une hypothèse de travail"
2183,"Given this background, we hypothesize that disambiguation of these cases would be easier if the necessary syntactic information such as phrase structures are considered during pivoting.",40,1,23,Introduction,Introduction,"Hence a superficial phrase matching method based solely on the surface form of the pivot will often combine incorrect phrase pairs, causing translation errors if their translation scores are estimated to be higher than the proper correspondences.",Introduction,"To incorporate this intuition into our models, we propose a method that considers syntactic information of the pivot phrase, as shown in Figure 1  (b).",POS,
2184,"To incorporate this intuition into our models, we propose a method that considers syntactic information of the pivot phrase, as shown in Figure 1  (b).",41,1,24,Introduction,Introduction,"Given this background, we hypothesize that disambiguation of these cases would be easier if the necessary syntactic information such as phrase structures are considered during pivoting.",Introduction,"In this way, the model will distinguish translation rules extracted in contexts in which the English symbol string ""[X1] record [X2]"" behaves as a verbal phrase, from contexts in which the same string acts as nominal phrase.",FACT,
2185,"In this way, the model will distinguish translation rules extracted in contexts in which the English symbol string ""[X1] record [X2]"" behaves as a verbal phrase, from contexts in which the same string acts as nominal phrase.",42,1,25,Introduction,Introduction,"To incorporate this intuition into our models, we propose a method that considers syntactic information of the pivot phrase, as shown in Figure 1  (b).",Introduction,"Specifically, we propose a method based on Synchronous Context-Free Grammars (SCFGs) (Aho and Ullman, 1969;Chiang, 2007), which are widely used in tree-based machine translation frameworks ( §2).",POS,
2186,"Specifically, we propose a method based on Synchronous Context-Free Grammars (SCFGs) (Aho and Ullman, 1969;Chiang, 2007), which are widely used in tree-based machine translation frameworks ( §2).",43,1,26,Introduction,Introduction,"In this way, the model will distinguish translation rules extracted in contexts in which the English symbol string ""[X1] record [X2]"" behaves as a verbal phrase, from contexts in which the same string acts as nominal phrase.",Introduction,"After describing the baseline triangulation method ( §3), which uses only the surface forms for performing triangulation, we propose two methods for triangulation based on syntactic matching ( §4).",NC,"précisions sur la méthode développée, déjà introduite précédemment, mais on reste dans l'introduction ..."
2187,"After describing the baseline triangulation method ( §3), which uses only the surface forms for performing triangulation, we propose two methods for triangulation based on syntactic matching ( §4).",44,1,27,Introduction,Introduction,"Specifically, we propose a method based on Synchronous Context-Free Grammars (SCFGs) (Aho and Ullman, 1969;Chiang, 2007), which are widely used in tree-based machine translation frameworks ( §2).",Introduction,"The first places a hard restriction on exact matching of parse trees ( §4.1) included in translation rules, while the second places a softer restriction allowing partial matches ( §4.2).",NC,
2188,"The first places a hard restriction on exact matching of parse trees ( §4.1) included in translation rules, while the second places a softer restriction allowing partial matches ( §4.2).",45,1,28,Introduction,Introduction,"After describing the baseline triangulation method ( §3), which uses only the surface forms for performing triangulation, we propose two methods for triangulation based on syntactic matching ( §4).",Introduction,"To investigate the effect of our proposed method on pivot translation quality, we perform experiments of pivot translation on the United Nations Parallel Corpus (Ziemski et al., 2016), which shows that our method indeed provide significant gains in accuracy (of up to 2.3 BLEU points), in almost all combinations of 5 languages with English as a pivot language ( §5).",NC,
2189,"To investigate the effect of our proposed method on pivot translation quality, we perform experiments of pivot translation on the United Nations Parallel Corpus (Ziemski et al., 2016), which shows that our method indeed provide significant gains in accuracy (of up to 2.3 BLEU points), in almost all combinations of 5 languages with English as a pivot language ( §5).",46,1,29,Introduction,Introduction,"The first places a hard restriction on exact matching of parse trees ( §4.1) included in translation rules, while the second places a softer restriction allowing partial matches ( §4.2).",Introduction,"In addition, as an auxiliary result, we compare pivot translation using the proposed method with zero-shot neural machine translation, and find that triangulation of symbolic translation models still significantly outperforms neural MT in the zero-resource scenario.",FACT#POS,
2190,"In addition, as an auxiliary result, we compare pivot translation using the proposed method with zero-shot neural machine translation, and find that triangulation of symbolic translation models still significantly outperforms neural MT in the zero-resource scenario.",47,1,30,Introduction,Introduction,"To investigate the effect of our proposed method on pivot translation quality, we perform experiments of pivot translation on the United Nations Parallel Corpus (Ziemski et al., 2016), which shows that our method indeed provide significant gains in accuracy (of up to 2.3 BLEU points), in almost all combinations of 5 languages with English as a pivot language ( §5).",Synchronous Context-Free Grammars,"In this section, first we cover SCFGs, which are widely used in machine translation, particularly hierarchical phrase-based translation (Hiero) (Chiang, 2007).",FACT#POS,
2191,"In this section, first we cover SCFGs, which are widely used in machine translation, particularly hierarchical phrase-based translation (Hiero) (Chiang, 2007).",48,1,31,Synchronous Context-Free Grammars,Introduction,"In addition, as an auxiliary result, we compare pivot translation using the proposed method with zero-shot neural machine translation, and find that triangulation of symbolic translation models still significantly outperforms neural MT in the zero-resource scenario.",Synchronous Context-Free Grammars,"In SCFGs, the elementary structures used in translation are synchronous rewrite rules with aligned pairs of source and target symbols on the right-hand side: X → ⟨ s, t ⟩ (1) where X is the head symbol of the rewrite rule, and s and t are both strings of terminals and nonterminals on the source and target side respectively.",NC,
2192,"In SCFGs, the elementary structures used in translation are synchronous rewrite rules with aligned pairs of source and target symbols on the right-hand side: X → ⟨ s, t ⟩ (1) where X is the head symbol of the rewrite rule, and s and t are both strings of terminals and nonterminals on the source and target side respectively.",49,1,32,Synchronous Context-Free Grammars,Synchronous Context-Free Grammars,"In this section, first we cover SCFGs, which are widely used in machine translation, particularly hierarchical phrase-based translation (Hiero) (Chiang, 2007).",Synchronous Context-Free Grammars,"Each string in the right side pair has the same number of indexed non-terminals, and identically indexed non-terminals correspond to eachother.",NC,
2193,"Each string in the right side pair has the same number of indexed non-terminals, and identically indexed non-terminals correspond to eachother.",50,1,33,Synchronous Context-Free Grammars,Synchronous Context-Free Grammars,"In SCFGs, the elementary structures used in translation are synchronous rewrite rules with aligned pairs of source and target symbols on the right-hand side: X → ⟨ s, t ⟩ (1) where X is the head symbol of the rewrite rule, and s and t are both strings of terminals and nonterminals on the source and target side respectively.",Synchronous Context-Free Grammars,"For example, a synchronous rule could take the form of: X → ⟨X 0 of X 1 , X 1 的 X 0 ⟩ .",NC,
2194,"For example, a synchronous rule could take the form of: X → ⟨X 0 of X 1 , X 1 的 X 0 ⟩ .",51,1,34,Synchronous Context-Free Grammars,Synchronous Context-Free Grammars,"Each string in the right side pair has the same number of indexed non-terminals, and identically indexed non-terminals correspond to eachother.",Synchronous Context-Free Grammars,Synchronous rules can be extracted based on parallel sentences and automatically obtained word alignments.,NC,
2195,Synchronous rules can be extracted based on parallel sentences and automatically obtained word alignments.,52,1,35,Synchronous Context-Free Grammars,Synchronous Context-Free Grammars,"For example, a synchronous rule could take the form of: X → ⟨X 0 of X 1 , X 1 的 X 0 ⟩ .",Synchronous Context-Free Grammars,"Each extracted rule is scored with phrase translation probabilities in both directions ϕ(s|t) and ϕ(t|s), lexical translation probabilities in both directions ϕ lex (s|t) and ϕ lex (t|s), a word penalty counting the terminals in t, and a constant phrase penalty of 1.",NC,
2196,"Each extracted rule is scored with phrase translation probabilities in both directions ϕ(s|t) and ϕ(t|s), lexical translation probabilities in both directions ϕ lex (s|t) and ϕ lex (t|s), a word penalty counting the terminals in t, and a constant phrase penalty of 1.",53,1,36,Synchronous Context-Free Grammars,Synchronous Context-Free Grammars,Synchronous rules can be extracted based on parallel sentences and automatically obtained word alignments.,Synchronous Context-Free Grammars,"At translation time, the decoder searches for the target sentence that maximizes the derivation probability, which is defined as the sum of the scores of the rules used in the derivation, and the log of the language model (LM) probability over the target strings.",NC,
2197,"At translation time, the decoder searches for the target sentence that maximizes the derivation probability, which is defined as the sum of the scores of the rules used in the derivation, and the log of the language model (LM) probability over the target strings.",54,1,37,Synchronous Context-Free Grammars,Synchronous Context-Free Grammars,"Each extracted rule is scored with phrase translation probabilities in both directions ϕ(s|t) and ϕ(t|s), lexical translation probabilities in both directions ϕ lex (s|t) and ϕ lex (t|s), a word penalty counting the terminals in t, and a constant phrase penalty of 1.",Synchronous Context-Free Grammars,"When not considering an LM, it is possible to efficiently find the best translation for an input sentence using the CKY+ algorithm (Chappelier et al., 1998).",NC,
2198,"When not considering an LM, it is possible to efficiently find the best translation for an input sentence using the CKY+ algorithm (Chappelier et al., 1998).",55,1,38,Synchronous Context-Free Grammars,Synchronous Context-Free Grammars,"At translation time, the decoder searches for the target sentence that maximizes the derivation probability, which is defined as the sum of the scores of the rules used in the derivation, and the log of the language model (LM) probability over the target strings.",Synchronous Context-Free Grammars,"When using an LM, the expanded search space is further reduced based on a limit on expanded edges, or total states per span, through a procedure such as cube pruning (Chiang, 2007).",NC,
2199,"When using an LM, the expanded search space is further reduced based on a limit on expanded edges, or total states per span, through a procedure such as cube pruning (Chiang, 2007).",56,1,39,Synchronous Context-Free Grammars,Synchronous Context-Free Grammars,"When not considering an LM, it is possible to efficiently find the best translation for an input sentence using the CKY+ algorithm (Chappelier et al., 1998).",Hierarchical Rules,"In this section, we specifically cover the rules used in Hiero.",NC,
2200,"In this section, we specifically cover the rules used in Hiero.",57,1,40,Hierarchical Rules,Synchronous Context-Free Grammars,"When using an LM, the expanded search space is further reduced based on a limit on expanded edges, or total states per span, through a procedure such as cube pruning (Chiang, 2007).",Hierarchical Rules,"Hierarchical rules are composed of initial head symbol S, and synchronous rules containing terminals and single kind of non-terminals X.",NC,
2201,"Hierarchical rules are composed of initial head symbol S, and synchronous rules containing terminals and single kind of non-terminals X.",58,1,41,Hierarchical Rules,Hierarchical Rules,"In this section, we specifically cover the rules used in Hiero.",Hierarchical Rules,"2 Hierarchical rules are extracted using the same phrase extraction procedure used in phrase-based translation (Koehn et al., 2003) based on word alignments, followed by a step that performs recursive extraction of hierarchical phrases (Chiang, 2007).",NC,
2202,"2 Hierarchical rules are extracted using the same phrase extraction procedure used in phrase-based translation (Koehn et al., 2003) based on word alignments, followed by a step that performs recursive extraction of hierarchical phrases (Chiang, 2007).",59,1,42,Hierarchical Rules,Hierarchical Rules,"Hierarchical rules are composed of initial head symbol S, and synchronous rules containing terminals and single kind of non-terminals X.",Hierarchical Rules,"For example, hierarchical rules could take the form of: X → ⟨Officers, 主席团 成員⟩ (3) X → ⟨the Committee, 委员会⟩ (4) X → ⟨X 0 of X 1 , X 1 的 X 0 ⟩ .",NC,
2203,"For example, hierarchical rules could take the form of: X → ⟨Officers, 主席团 成員⟩ (3) X → ⟨the Committee, 委员会⟩ (4) X → ⟨X 0 of X 1 , X 1 的 X 0 ⟩ .",60,1,43,Hierarchical Rules,Hierarchical Rules,"2 Hierarchical rules are extracted using the same phrase extraction procedure used in phrase-based translation (Koehn et al., 2003) based on word alignments, followed by a step that performs recursive extraction of hierarchical phrases (Chiang, 2007).",Hierarchical Rules,"( ) From these rules, we can translate the input sentence by derivation: S → ⟨X 0 , X 0 ⟩ ⇒ ⟨X 1 of X 2 , X 2 的 X 1 ⟩ ⇒ ⟨Officers of X 2 , X 2 主席团 成員⟩ ⇒ ⟨Officers of the Committee, 委员会 的 主席团 成員⟩ The advantage of Hiero is that it is able to achieve relatively high word re-ordering accuracy (compared to other symbolic SMT alternatives such as standard phrase-based MT) without language-dependent processing.",NC,
2204,"( ) From these rules, we can translate the input sentence by derivation: S → ⟨X 0 , X 0 ⟩ ⇒ ⟨X 1 of X 2 , X 2 的 X 1 ⟩ ⇒ ⟨Officers of X 2 , X 2 主席团 成員⟩ ⇒ ⟨Officers of the Committee, 委员会 的 主席团 成員⟩ The advantage of Hiero is that it is able to achieve relatively high word re-ordering accuracy (compared to other symbolic SMT alternatives such as standard phrase-based MT) without language-dependent processing.",61,1,44,Hierarchical Rules,Hierarchical Rules,"For example, hierarchical rules could take the form of: X → ⟨Officers, 主席团 成員⟩ (3) X → ⟨the Committee, 委员会⟩ (4) X → ⟨X 0 of X 1 , X 1 的 X 0 ⟩ .",Hierarchical Rules,"On the other hand, since it does not use syntactic information and tries to extract all possible combinations of rules, it has the tendency to extract very large translation rule tables and also tends to be less syntactically faithful in its derivations.",NC,
2205,"On the other hand, since it does not use syntactic information and tries to extract all possible combinations of rules, it has the tendency to extract very large translation rule tables and also tends to be less syntactically faithful in its derivations.",62,1,45,Hierarchical Rules,Hierarchical Rules,"( ) From these rules, we can translate the input sentence by derivation: S → ⟨X 0 , X 0 ⟩ ⇒ ⟨X 1 of X 2 , X 2 的 X 1 ⟩ ⇒ ⟨Officers of X 2 , X 2 主席团 成員⟩ ⇒ ⟨Officers of the Committee, 委员会 的 主席团 成員⟩ The advantage of Hiero is that it is able to achieve relatively high word re-ordering accuracy (compared to other symbolic SMT alternatives such as standard phrase-based MT) without language-dependent processing.",Explicitly Syntactic Rules,"An alternative to Hiero rules is the use of synchronous context-free grammar or synchronous tree-substitution grammar (Graehl and Knight, 2004) rules that explicitly take into account the syntax of the source side (tree-to-string rules), target side (string-to-tree rules), or both (tree-to-tree rules).",NC,
2206,"An alternative to Hiero rules is the use of synchronous context-free grammar or synchronous tree-substitution grammar (Graehl and Knight, 2004) rules that explicitly take into account the syntax of the source side (tree-to-string rules), target side (string-to-tree rules), or both (tree-to-tree rules).",63,1,46,Explicitly Syntactic Rules,Hierarchical Rules,"On the other hand, since it does not use syntactic information and tries to extract all possible combinations of rules, it has the tendency to extract very large translation rule tables and also tends to be less syntactically faithful in its derivations.",Explicitly Syntactic Rules,"Taking the example of tree-to-string (T2S) rules, these use parse trees on the source language side, and the head symbols of the synchronous rules are not limited to S or X, but instead use non-terminal symbols corresponding to the phrase structure tags of a given parse tree.",NC,
2207,"Taking the example of tree-to-string (T2S) rules, these use parse trees on the source language side, and the head symbols of the synchronous rules are not limited to S or X, but instead use non-terminal symbols corresponding to the phrase structure tags of a given parse tree.",64,1,47,Explicitly Syntactic Rules,Explicitly Syntactic Rules,"An alternative to Hiero rules is the use of synchronous context-free grammar or synchronous tree-substitution grammar (Graehl and Knight, 2004) rules that explicitly take into account the syntax of the source side (tree-to-string rules), target side (string-to-tree rules), or both (tree-to-tree rules).",Explicitly Syntactic Rules,"For example, T2S rules could take the form of: X NP → ⟨(NP (NNS Officers)), 主席团 成員⟩ (6) X NP → ⟨(NP (DT the) (NNP Committee)), 委员会⟩ (7) X PP → ⟨ (PP (IN of) X NP,0 ), X0 的 ⟩ (8) X NP → ⟨ (NP X NP,0 X PP,1 ), X1 X0 ⟩ .",NC,
2208,"For example, T2S rules could take the form of: X NP → ⟨(NP (NNS Officers)), 主席团 成員⟩ (6) X NP → ⟨(NP (DT the) (NNP Committee)), 委员会⟩ (7) X PP → ⟨ (PP (IN of) X NP,0 ), X0 的 ⟩ (8) X NP → ⟨ (NP X NP,0 X PP,1 ), X1 X0 ⟩ .",65,1,48,Explicitly Syntactic Rules,Explicitly Syntactic Rules,"Taking the example of tree-to-string (T2S) rules, these use parse trees on the source language side, and the head symbols of the synchronous rules are not limited to S or X, but instead use non-terminal symbols corresponding to the phrase structure tags of a given parse tree.",Explicitly Syntactic Rules,"Here, parse subtrees of the source language rules are given in the form of S-expressions.",NC,
2209,"Here, parse subtrees of the source language rules are given in the form of S-expressions.",66,1,49,Explicitly Syntactic Rules,Explicitly Syntactic Rules,"For example, T2S rules could take the form of: X NP → ⟨(NP (NNS Officers)), 主席团 成員⟩ (6) X NP → ⟨(NP (DT the) (NNP Committee)), 委员会⟩ (7) X PP → ⟨ (PP (IN of) X NP,0 ), X0 的 ⟩ (8) X NP → ⟨ (NP X NP,0 X PP,1 ), X1 X0 ⟩ .",Explicitly Syntactic Rules,"From these rules, we can translate from the parse tree of the input sentence by derivation: X ROOT → ⟨ X NP,0 , X0 ⟩ ⇒ ⟨ (NP X NP,1 X PP,2 ), X2 X1 ⟩ ⇒ ⟨ (NP (NP (NNS Officers) X PP,2 )), X2 主席团 成員 ⟩ * ⇒ ⟨ (NP (NP (NNS Officers)) (PP (IN of) (NP (DT the) (NNP Committee)))) , 委员会 的 主席团 成員 ⟩ In this way, it is possible in T2S translation to obtain a result conforming to the source language's grammar.",NC,
2210,"From these rules, we can translate from the parse tree of the input sentence by derivation: X ROOT → ⟨ X NP,0 , X0 ⟩ ⇒ ⟨ (NP X NP,1 X PP,2 ), X2 X1 ⟩ ⇒ ⟨ (NP (NP (NNS Officers) X PP,2 )), X2 主席团 成員 ⟩ * ⇒ ⟨ (NP (NP (NNS Officers)) (PP (IN of) (NP (DT the) (NNP Committee)))) , 委员会 的 主席团 成員 ⟩ In this way, it is possible in T2S translation to obtain a result conforming to the source language's grammar.",67,1,50,Explicitly Syntactic Rules,Explicitly Syntactic Rules,"Here, parse subtrees of the source language rules are given in the form of S-expressions.",Explicitly Syntactic Rules,"This method also has the advantage the number of less-useful synchronous rules extracted by syntax-agnostic methods such as Hiero are reduced, making it possible to learn more compact rule tables and allowing for faster translation.",NC,
2211,"This method also has the advantage the number of less-useful synchronous rules extracted by syntax-agnostic methods such as Hiero are reduced, making it possible to learn more compact rule tables and allowing for faster translation.",68,1,51,Explicitly Syntactic Rules,Explicitly Syntactic Rules,"From these rules, we can translate from the parse tree of the input sentence by derivation: X ROOT → ⟨ X NP,0 , X0 ⟩ ⇒ ⟨ (NP X NP,1 X PP,2 ), X2 X1 ⟩ ⇒ ⟨ (NP (NP (NNS Officers) X PP,2 )), X2 主席团 成員 ⟩ * ⇒ ⟨ (NP (NP (NNS Officers)) (PP (IN of) (NP (DT the) (NNP Committee)))) , 委员会 的 主席团 成員 ⟩ In this way, it is possible in T2S translation to obtain a result conforming to the source language's grammar.",Standard Triangulation Method,"In the triangulation method by Cohn and Lapata (2007), we first train source-pivot and pivot-target rule tables as T SP and T P T respectively.",NC,
2212,"In the previous section, we explained about the standard triangulation method and mentioned that the pivot-side ambiguity causes incorrect estimation of translation probability and the translation accuracy might decrease.",69,1,59,Triangulation with Syntactic Matching,Standard Triangulation Method,"Specifically, if there are multiple interpretations of the pivot phrase as shown in the example of Figure 1, source and target phrases that do not correspond to each other semantically might be connected, and over-estimation by summing products of the translation probabilities is likely to cause failed translations.",Triangulation with Syntactic Matching,"To address this problem, it is desirable to be able to distinguish pivotside phrases that have different syntactic roles or meanings, even if the symbol strings are exactly equivalent.",NC,
2213,"To address this problem, it is desirable to be able to distinguish pivotside phrases that have different syntactic roles or meanings, even if the symbol strings are exactly equivalent.",70,1,60,Triangulation with Syntactic Matching,Triangulation with Syntactic Matching,"In the previous section, we explained about the standard triangulation method and mentioned that the pivot-side ambiguity causes incorrect estimation of translation probability and the translation accuracy might decrease.",Triangulation with Syntactic Matching,"In the following two sections, we describe two methods to distinguish pivot phrases that have syntactically different roles, one based on exact matching of parse trees, and one based on soft matching.",POS,claim implicite ?
2214,"In the following two sections, we describe two methods to distinguish pivot phrases that have syntactically different roles, one based on exact matching of parse trees, and one based on soft matching.",71,1,61,Triangulation with Syntactic Matching,Triangulation with Syntactic Matching,"To address this problem, it is desirable to be able to distinguish pivotside phrases that have different syntactic roles or meanings, even if the symbol strings are exactly equivalent.",Exact Matching of Parse Subtrees,"In the exact matching method, we first train pivotsource and pivot-target T2S TMs by parsing the pivot side of parallel corpora, and store them into rule tables as T P S and T P T respectively.",NC,
2215,"In the exact matching method, we first train pivotsource and pivot-target T2S TMs by parsing the pivot side of parallel corpora, and store them into rule tables as T P S and T P T respectively.",72,1,62,Exact Matching of Parse Subtrees,Triangulation with Syntactic Matching,"In the following two sections, we describe two methods to distinguish pivot phrases that have syntactically different roles, one based on exact matching of parse trees, and one based on soft matching.",Exact Matching of Parse Subtrees,"Synchronous rules of T P S and T P T take the form of X → ⟨p, s⟩ and X → ⟨ p, t ⟩ respectively, where p is a symbol string that expresses pivot-side parse subtree (S-expression), s and t express source and target symbol strings.",NC,
2216,"Synchronous rules of T P S and T P T take the form of X → ⟨p, s⟩ and X → ⟨ p, t ⟩ respectively, where p is a symbol string that expresses pivot-side parse subtree (S-expression), s and t express source and target symbol strings.",73,1,63,Exact Matching of Parse Subtrees,Exact Matching of Parse Subtrees,"In the exact matching method, we first train pivotsource and pivot-target T2S TMs by parsing the pivot side of parallel corpora, and store them into rule tables as T P S and T P T respectively.",Exact Matching of Parse Subtrees,"The procedure of synthesizing source-target synchronous rules essentially follows equations ( 11)-( 14), except using T P S instead of T SP (direction of probability features is reversed) and pivot subtree p instead of pivot phrase p. Here s and t do not have syntactic information, therefore the synthesized synchronous rules should be hierarchical rules explained in §2.2.",NC,
2217,"The procedure of synthesizing source-target synchronous rules essentially follows equations ( 11)-( 14), except using T P S instead of T SP (direction of probability features is reversed) and pivot subtree p instead of pivot phrase p. Here s and t do not have syntactic information, therefore the synthesized synchronous rules should be hierarchical rules explained in §2.2.",74,1,64,Exact Matching of Parse Subtrees,Exact Matching of Parse Subtrees,"Synchronous rules of T P S and T P T take the form of X → ⟨p, s⟩ and X → ⟨ p, t ⟩ respectively, where p is a symbol string that expresses pivot-side parse subtree (S-expression), s and t express source and target symbol strings.",Exact Matching of Parse Subtrees,"The matching condition of this method has harder constraints than matching of superficial symbols in standard triangulation, and has the potential to reduce incorrect connections of phrase pairs, resulting in a more reliable triangulated TM.",NC,
2218,"The matching condition of this method has harder constraints than matching of superficial symbols in standard triangulation, and has the potential to reduce incorrect connections of phrase pairs, resulting in a more reliable triangulated TM.",75,1,65,Exact Matching of Parse Subtrees,Exact Matching of Parse Subtrees,"The procedure of synthesizing source-target synchronous rules essentially follows equations ( 11)-( 14), except using T P S instead of T SP (direction of probability features is reversed) and pivot subtree p instead of pivot phrase p. Here s and t do not have syntactic information, therefore the synthesized synchronous rules should be hierarchical rules explained in §2.2.",Exact Matching of Parse Subtrees,"On the other hand, the number of connected rules decreases as well in this restricted triangulation, and the coverage of the triangulated model might be reduced.",NC,
2219,"On the other hand, the number of connected rules decreases as well in this restricted triangulation, and the coverage of the triangulated model might be reduced.",76,1,66,Exact Matching of Parse Subtrees,Exact Matching of Parse Subtrees,"The matching condition of this method has harder constraints than matching of superficial symbols in standard triangulation, and has the potential to reduce incorrect connections of phrase pairs, resulting in a more reliable triangulated TM.",Exact Matching of Parse Subtrees,Therefore it is important to create TMs that are both reliabile and have high coverage.,NC,
2220,Therefore it is important to create TMs that are both reliabile and have high coverage.,77,1,67,Exact Matching of Parse Subtrees,Exact Matching of Parse Subtrees,"On the other hand, the number of connected rules decreases as well in this restricted triangulation, and the coverage of the triangulated model might be reduced.",Partial Matching of Parse Subtrees,"To prevent the problem of the reduction of coverage in the exact matching method, we also propose a partial matching method that keeps coverage just like standard triangulation by allowing connection of incompletely equivalent pivot subtrees.",NC,
2221,"To prevent the problem of the reduction of coverage in the exact matching method, we also propose a partial matching method that keeps coverage just like standard triangulation by allowing connection of incompletely equivalent pivot subtrees.",78,1,68,Partial Matching of Parse Subtrees,Exact Matching of Parse Subtrees,Therefore it is important to create TMs that are both reliabile and have high coverage.,Partial Matching of Parse Subtrees,"To estimate translation probabilities in partial matching, we first define weighted triangulation generalizing the equations ( 11)-( 14) of standard triangulation with weight function ψ(•): ϕ ( t|s ) = ∑ pT ∑ pS ϕ ( t| pT ) ψ ( pT | pS ) ϕ ( pS |s) , ϕ ( s|t ) = ∑ pS ∑ pT ϕ (s| pS ) ψ ( pS | pT ) ϕ ( pT |t ) , ϕ lex ( t|s ) = ∑ pT ∑ pS ϕ lex ( t| pT ) ψ ( pT | pS ) ϕ lex ( pS |s) , (19) ϕ lex ( s|t ) = ∑ pS ∑ pT ϕ lex (s| pS ) ψ ( pS | pT ) ϕ lex ( pT |t ) where pS ∈ T SP and pT ∈ P P T are pivot parse subtrees of source-pivot and pivot-target synchronous rules respectively.",FACT,
2222,"To estimate translation probabilities in partial matching, we first define weighted triangulation generalizing the equations ( 11)-( 14) of standard triangulation with weight function ψ(•): ϕ ( t|s ) = ∑ pT ∑ pS ϕ ( t| pT ) ψ ( pT | pS ) ϕ ( pS |s) , ϕ ( s|t ) = ∑ pS ∑ pT ϕ (s| pS ) ψ ( pS | pT ) ϕ ( pT |t ) , ϕ lex ( t|s ) = ∑ pT ∑ pS ϕ lex ( t| pT ) ψ ( pT | pS ) ϕ lex ( pS |s) , (19) ϕ lex ( s|t ) = ∑ pS ∑ pT ϕ lex (s| pS ) ψ ( pS | pT ) ϕ lex ( pT |t ) where pS ∈ T SP and pT ∈ P P T are pivot parse subtrees of source-pivot and pivot-target synchronous rules respectively.",79,1,69,Partial Matching of Parse Subtrees,Partial Matching of Parse Subtrees,"To prevent the problem of the reduction of coverage in the exact matching method, we also propose a partial matching method that keeps coverage just like standard triangulation by allowing connection of incompletely equivalent pivot subtrees.",Partial Matching of Parse Subtrees,"By adjusting ψ(•), we can control the magnitude of the penalty for the case of incompletely matched connections.",NC,
2223,"By adjusting ψ(•), we can control the magnitude of the penalty for the case of incompletely matched connections.",80,1,70,Partial Matching of Parse Subtrees,Partial Matching of Parse Subtrees,"To estimate translation probabilities in partial matching, we first define weighted triangulation generalizing the equations ( 11)-( 14) of standard triangulation with weight function ψ(•): ϕ ( t|s ) = ∑ pT ∑ pS ϕ ( t| pT ) ψ ( pT | pS ) ϕ ( pS |s) , ϕ ( s|t ) = ∑ pS ∑ pT ϕ (s| pS ) ψ ( pS | pT ) ϕ ( pT |t ) , ϕ lex ( t|s ) = ∑ pT ∑ pS ϕ lex ( t| pT ) ψ ( pT | pS ) ϕ lex ( pS |s) , (19) ϕ lex ( s|t ) = ∑ pS ∑ pT ϕ lex (s| pS ) ψ ( pS | pT ) ϕ lex ( pT |t ) where pS ∈ T SP and pT ∈ P P T are pivot parse subtrees of source-pivot and pivot-target synchronous rules respectively.",Partial Matching of Parse Subtrees,"If we define ψ( pT | pS ) = 1 when pT is equal to pS and ψ( pT | pS ) = 0 otherwise, equations ( 17)-( 20) are equivalent with equations ( 11)-( 14).",NC,
2224,"If we define ψ( pT | pS ) = 1 when pT is equal to pS and ψ( pT | pS ) = 0 otherwise, equations ( 17)-( 20) are equivalent with equations ( 11)-( 14).",81,1,71,Partial Matching of Parse Subtrees,Partial Matching of Parse Subtrees,"By adjusting ψ(•), we can control the magnitude of the penalty for the case of incompletely matched connections.",Partial Matching of Parse Subtrees,"Better estimating ψ(•) is not trivial, and cooccurrence counts of pS and pT are not available.",NC,
2225,"Better estimating ψ(•) is not trivial, and cooccurrence counts of pS and pT are not available.",82,1,72,Partial Matching of Parse Subtrees,Partial Matching of Parse Subtrees,"If we define ψ( pT | pS ) = 1 when pT is equal to pS and ψ( pT | pS ) = 0 otherwise, equations ( 17)-( 20) are equivalent with equations ( 11)-( 14).",Partial Matching of Parse Subtrees,"Therefore we introduce a heuristic estimation method as follows: ψ( pT | pS) = w( pS, pT ) ∑ p∈T P T w( pS, p) • max p∈T P T w( pS, p) (21) ψ( pS| pT ) w( pS, pT ) ∑ p∈T SP w(p, pT ) • max p∈T SP w(p, pT ) (22) w( pS, pT ) =    0 (f lat( pS) ̸ = f lat( pT )) exp (−d ( pS, pT )) (otherwise) (23) d( pS, pT ) = T reeEditDistance( pS, pT ) where f lat(p) returns the symbol string of p keeping non-terminals, and T reeEditDistance( pS , pT ) is minimum cost of a sequence of operations (contract an edge, uncontract an edge, modify the label of an edge) needed to transform pS into pT (Klein, 1998).",NC,
2226,"Therefore we introduce a heuristic estimation method as follows: ψ( pT | pS) = w( pS, pT ) ∑ p∈T P T w( pS, p) • max p∈T P T w( pS, p) (21) ψ( pS| pT ) w( pS, pT ) ∑ p∈T SP w(p, pT ) • max p∈T SP w(p, pT ) (22) w( pS, pT ) =    0 (f lat( pS) ̸ = f lat( pT )) exp (−d ( pS, pT )) (otherwise) (23) d( pS, pT ) = T reeEditDistance( pS, pT ) where f lat(p) returns the symbol string of p keeping non-terminals, and T reeEditDistance( pS , pT ) is minimum cost of a sequence of operations (contract an edge, uncontract an edge, modify the label of an edge) needed to transform pS into pT (Klein, 1998).",83,1,73,Partial Matching of Parse Subtrees,Partial Matching of Parse Subtrees,"Better estimating ψ(•) is not trivial, and cooccurrence counts of pS and pT are not available.",Partial Matching of Parse Subtrees,"According to equations ( 21)-( 24), we can assure that incomplete match of pivot subtrees leads d(•) ≥ 1 and penalizes such that ψ(•) ≤ 1/e d ≤ 1/e, while exact match of subtrees leads to a value of ψ(•) at least e ≈ 2.718 times larger than when using partially matched subtrees.",NC,
2227,"According to equations ( 21)-( 24), we can assure that incomplete match of pivot subtrees leads d(•) ≥ 1 and penalizes such that ψ(•) ≤ 1/e d ≤ 1/e, while exact match of subtrees leads to a value of ψ(•) at least e ≈ 2.718 times larger than when using partially matched subtrees.",84,1,74,Partial Matching of Parse Subtrees,Partial Matching of Parse Subtrees,"Therefore we introduce a heuristic estimation method as follows: ψ( pT | pS) = w( pS, pT ) ∑ p∈T P T w( pS, p) • max p∈T P T w( pS, p) (21) ψ( pS| pT ) w( pS, pT ) ∑ p∈T SP w(p, pT ) • max p∈T SP w(p, pT ) (22) w( pS, pT ) =    0 (f lat( pS) ̸ = f lat( pT )) exp (−d ( pS, pT )) (otherwise) (23) d( pS, pT ) = T reeEditDistance( pS, pT ) where f lat(p) returns the symbol string of p keeping non-terminals, and T reeEditDistance( pS , pT ) is minimum cost of a sequence of operations (contract an edge, uncontract an edge, modify the label of an edge) needed to transform pS into pT (Klein, 1998).",Experimental Set-Up,"To investigate the effect of our proposed approach, we evaluate the translation accuracy through pivot translation experiments on the United Nations Parallel Corpus (UN6Way) (Ziemski et al., 2016).",NC,
2228,Translating with a Hiero TM directly trained on the source-target parallel corpus without using pivot language (as an oracle).,85,1,92,Direct:,Experimental Set-Up,We evaluate 6 translation methods:,Tri. Hiero:,"Triangulating source-pivot and pivot-target Hiero TMs into a source-target Hiero TM using the traditional method (baseline, §3).",NC,
2229,"Triangulating source-pivot and pivot-target Hiero TMs into a source-target Hiero TM using the traditional method (baseline, §3).",86,1,93,Tri. Hiero:,Direct:,Translating with a Hiero TM directly trained on the source-target parallel corpus without using pivot language (as an oracle).,Tri. TreeExact,"Triangulating pivot-source and pivot-target T2S TMs into a source-target Hiero TM using the proposed exact matching of pivot subtrees (proposed 1, §4.1).",NC,
2230,"Triangulating pivot-source and pivot-target T2S TMs into a source-target Hiero TM using the proposed exact matching of pivot subtrees (proposed 1, §4.1).",87,1,94,Tri. TreeExact,Tri. Hiero:,"Triangulating source-pivot and pivot-target Hiero TMs into a source-target Hiero TM using the traditional method (baseline, §3).",Tri. TreePartial,"Triangulating pivot-source and pivot-target T2S TMs into a source-target Hiero TM using the proposed partial matching of pivot subtrees (proposed 2, §4.2).",NC,
2231,"Triangulating pivot-source and pivot-target T2S TMs into a source-target Hiero TM using the proposed partial matching of pivot subtrees (proposed 2, §4.2).",88,1,95,Tri. TreePartial,Tri. TreeExact,"Triangulating pivot-source and pivot-target T2S TMs into a source-target Hiero TM using the proposed exact matching of pivot subtrees (proposed 1, §4.1).",Experimental Results,The result of experiments using all combinations of pivot translation tasks for 5 languages via English is shown in Table 1.,NC,
2232,The result of experiments using all combinations of pivot translation tasks for 5 languages via English is shown in Table 1.,89,1,96,Experimental Results,Tri. TreePartial,"Triangulating pivot-source and pivot-target T2S TMs into a source-target Hiero TM using the proposed partial matching of pivot subtrees (proposed 2, §4.2).",Experimental Results,"From the results, we can see that the proposed partial matching method of pivot subtrees in triangulation outperforms the standard triangulation method for all language pairs and achieves higher or almost equal scores than proposed exact matching method.",NC,
2233,"From the results, we can see that the proposed partial matching method of pivot subtrees in triangulation outperforms the standard triangulation method for all language pairs and achieves higher or almost equal scores than proposed exact matching method.",90,1,97,Experimental Results,Experimental Results,The result of experiments using all combinations of pivot translation tasks for 5 languages via English is shown in Table 1.,Experimental Results,"The exact matching method also outperforms the standard triangulation method in the majority of the language pairs, but has a lesser improvement than partial matching method.",POS,
2234,"The exact matching method also outperforms the standard triangulation method in the majority of the language pairs, but has a lesser improvement than partial matching method.",91,1,98,Experimental Results,Experimental Results,"From the results, we can see that the proposed partial matching method of pivot subtrees in triangulation outperforms the standard triangulation method for all language pairs and achieves higher or almost equal scores than proposed exact matching method.",Experimental Results,In Table 2 we show the comparison of coverage of each proposed triangulated method.,POS,
2235,In Table 2 we show the comparison of coverage of each proposed triangulated method.,92,1,99,Experimental Results,Experimental Results,"The exact matching method also outperforms the standard triangulation method in the majority of the language pairs, but has a lesser improvement than partial matching method.",Experimental Results,"From this table, we can see that the exact matching method reduces several percent in number of unique phrases while the partial matching method keeps the same coverage with surfaceform matching.",NC,
2236,"From this table, we can see that the exact matching method reduces several percent in number of unique phrases while the partial matching method keeps the same coverage with surfaceform matching.",93,1,100,Experimental Results,Experimental Results,In Table 2 we show the comparison of coverage of each proposed triangulated method.,Experimental Results,We can consider that it is one of the reasons of the difference in improvement stability between the partial and exact matching methods.,POS,
2237,We can consider that it is one of the reasons of the difference in improvement stability between the partial and exact matching methods.,94,1,101,Experimental Results,Experimental Results,"From this table, we can see that the exact matching method reduces several percent in number of unique phrases while the partial matching method keeps the same coverage with surfaceform matching.",Experimental Results,We show an example of a translated sentences for which pivot-side ambiguity is resolved in the the syntactic matching methods:,POS,
2238,We show an example of a translated sentences for which pivot-side ambiguity is resolved in the the syntactic matching methods:,95,1,102,Experimental Results,Experimental Results,We can consider that it is one of the reasons of the difference in improvement stability between the partial and exact matching methods.,Reference in Spanish:,Suiza alienta a todos los Estados partes : a ::: que ::::::: apoyen ::: la :::::: actual ::::: labor :::::::::: conceptual ::: de :: la ::::::::: Secretaría .,NC,
2239,"Recent results (Firat et al., 2016;Johnson et al., 2016) have found that neural machine translation systems can gain the ability to perform translation with zero parallel resources by training on multiple sets of bilingual data.",96,1,107,Comparison with Neural MT:,Reference in Spanish:,We can confirm that the derivation improves word-selection and word-reordering by using this rule.,Comparison with Neural MT:,"However, previous work has not examined the competitiveness of these methods with pivot-based symbolic SMT frameworks such as PBMT or Hiero.",NC,
2240,"However, previous work has not examined the competitiveness of these methods with pivot-based symbolic SMT frameworks such as PBMT or Hiero.",97,1,108,Comparison with Neural MT:,Comparison with Neural MT:,"Recent results (Firat et al., 2016;Johnson et al., 2016) have found that neural machine translation systems can gain the ability to perform translation with zero parallel resources by training on multiple sets of bilingual data.",Comparison with Neural MT:,"In this section, we compare a zero-shot NMT model (detailed parameters in  Johnson et al.",NC,
2241,"In this section, we compare a zero-shot NMT model (detailed parameters in  Johnson et al.",98,1,109,Comparison with Neural MT:,Comparison with Neural MT:,"However, previous work has not examined the competitiveness of these methods with pivot-based symbolic SMT frameworks such as PBMT or Hiero.",Comparison with Neural MT:,"To train and evaluate NMT models, we adopt NMTKit.",NC,
2242,"To train and evaluate NMT models, we adopt NMTKit.",99,1,110,Comparison with Neural MT:,Comparison with Neural MT:,"In this section, we compare a zero-shot NMT model (detailed parameters in  Johnson et al.",Comparison with Neural MT:,"7 From the results we see the tendency of NMT that directly trained model achieves high translation accuracy even for translation between languages of different families, on the other hand, the accuracy is drastically reduced in the situation when there is no sourcetarget parallel corpora for training.",NC,
2243,"7 From the results we see the tendency of NMT that directly trained model achieves high translation accuracy even for translation between languages of different families, on the other hand, the accuracy is drastically reduced in the situation when there is no sourcetarget parallel corpora for training.",100,1,111,Comparison with Neural MT:,Comparison with Neural MT:,"To train and evaluate NMT models, we adopt NMTKit.",Comparison with Neural MT:,"Cascade is one immediate method connecting two TMs, and NMT cascade translation shows the medium performance in this experiment.",POS,
2244,"Cascade is one immediate method connecting two TMs, and NMT cascade translation shows the medium performance in this experiment.",101,1,112,Comparison with Neural MT:,Comparison with Neural MT:,"7 From the results we see the tendency of NMT that directly trained model achieves high translation accuracy even for translation between languages of different families, on the other hand, the accuracy is drastically reduced in the situation when there is no sourcetarget parallel corpora for training.",Comparison with Neural MT:,"In our setting, while bilingually trained NMT systems were competitive or outperformed Hiero-based models, zeroshot translation is uniformly weaker.",NC,
2245,"In our setting, while bilingually trained NMT systems were competitive or outperformed Hiero-based models, zeroshot translation is uniformly weaker.",102,1,113,Comparison with Neural MT:,Comparison with Neural MT:,"Cascade is one immediate method connecting two TMs, and NMT cascade translation shows the medium performance in this experiment.",Comparison with Neural MT:,"This may be because we used only 1 LSTM layer for encoder/decoder, or because the amount of parallel corpora or language pairs were not sufficient.",POS,
2246,"This may be because we used only 1 LSTM layer for encoder/decoder, or because the amount of parallel corpora or language pairs were not sufficient.",103,1,114,Comparison with Neural MT:,Comparison with Neural MT:,"In our setting, while bilingually trained NMT systems were competitive or outperformed Hiero-based models, zeroshot translation is uniformly weaker.",Comparison with Neural MT:,"Thus, we can posit that while zero-shot translation has demonstrated reasonable results in some settings, successful zero-shot translation systems are far from trivial to build, and pivot-based symbolic MT systems such as PBMT or Hiero may still be a competitive alternative.",POS,"cause d'un résultat, et non sa conséquence (conséquence directe d'un résultat = claim), quand même considéré comme une analyse directe de résultat ?"
2247,"Thus, we can posit that while zero-shot translation has demonstrated reasonable results in some settings, successful zero-shot translation systems are far from trivial to build, and pivot-based symbolic MT systems such as PBMT or Hiero may still be a competitive alternative.",104,1,115,Comparison with Neural MT:,Comparison with Neural MT:,"This may be because we used only 1 LSTM layer for encoder/decoder, or because the amount of parallel corpora or language pairs were not sufficient.",Conclusion,"In this paper, we have proposed a method of pivot translation using triangulation with exact or partial matching method of pivot-side parse subtrees.",POS,
2248,"In this paper, we have proposed a method of pivot translation using triangulation with exact or partial matching method of pivot-side parse subtrees.",105,1,116,Conclusion,Comparison with Neural MT:,"Thus, we can posit that while zero-shot translation has demonstrated reasonable results in some settings, successful zero-shot translation systems are far from trivial to build, and pivot-based symbolic MT systems such as PBMT or Hiero may still be a competitive alternative.",Conclusion,"In experiments, we found that these triangulated models are effective in particular when allowing partial matching.",FACT,
2249,"In experiments, we found that these triangulated models are effective in particular when allowing partial matching.",106,1,117,Conclusion,Conclusion,"In this paper, we have proposed a method of pivot translation using triangulation with exact or partial matching method of pivot-side parse subtrees.",Conclusion,"To estimate translation probabilities, we introduced heuristic that has no guarantee to be optimal.",POS,
2250,"To estimate translation probabilities, we introduced heuristic that has no guarantee to be optimal.",107,1,118,Conclusion,Conclusion,"In experiments, we found that these triangulated models are effective in particular when allowing partial matching.",Conclusion,"Therefore in the future, we plan to explore more refined estimation methods that utilize machine learning.",FACT#NEG,
2251,"Therefore in the future, we plan to explore more refined estimation methods that utilize machine learning.",108,1,119,Conclusion,Conclusion,"To estimate translation probabilities, we introduced heuristic that has no guarantee to be optimal.",,,PROSP,
2252,"Text-based adventure games provide a platform on which to explore reinforcement learning in the context of a combinatorial action space, such as natural language.",109,2,0,abstract,,,abstract,We present a deep reinforcement learning architecture that represents the game state as a knowledge graph which is learned during exploration.,NC,
2253,We present a deep reinforcement learning architecture that represents the game state as a knowledge graph which is learned during exploration.,110,2,1,abstract,abstract,"Text-based adventure games provide a platform on which to explore reinforcement learning in the context of a combinatorial action space, such as natural language.",abstract,"This graph is used to prune the action space, enabling more efficient exploration.",FACT,
2254,"This graph is used to prune the action space, enabling more efficient exploration.",111,2,2,abstract,abstract,We present a deep reinforcement learning architecture that represents the game state as a knowledge graph which is learned during exploration.,abstract,"The question of which action to take can be reduced to a question-answering task, a form of transfer learning that pre-trains certain parts of our architecture.",POS,
2255,"The question of which action to take can be reduced to a question-answering task, a form of transfer learning that pre-trains certain parts of our architecture.",112,2,3,abstract,abstract,"This graph is used to prune the action space, enabling more efficient exploration.",abstract,"In experiments using the TextWorld framework, we show that our proposed technique can learn a control policy faster than baseline alternatives.",POS,working hypothesis
2256,"In experiments using the TextWorld framework, we show that our proposed technique can learn a control policy faster than baseline alternatives.",113,2,4,abstract,abstract,"The question of which action to take can be reduced to a question-answering task, a form of transfer learning that pre-trains certain parts of our architecture.",abstract,We have also open-sourced our code at https://github.com/rajammanabrolu/KG-DQN.,POS,
2257,We have also open-sourced our code at https://github.com/rajammanabrolu/KG-DQN.,114,2,5,abstract,abstract,"In experiments using the TextWorld framework, we show that our proposed technique can learn a control policy faster than baseline alternatives.",Introduction,Natural language communication can be used to affect change in the real world.,FACT,link to code/data -> to keep in FACT ? could be useful for an overview of the contributions
2258,Natural language communication can be used to affect change in the real world.,115,2,6,Introduction,abstract,We have also open-sourced our code at https://github.com/rajammanabrolu/KG-DQN.,Introduction,"Text adventure games, in which players must make sense of the world through text descriptions and declare actions through natural language, can provide a stepping stone toward more real-world environments where agents must communicate to understand the state of the world and indirectly affect change in the world.",NC,
2259,"Text adventure games, in which players must make sense of the world through text descriptions and declare actions through natural language, can provide a stepping stone toward more real-world environments where agents must communicate to understand the state of the world and indirectly affect change in the world.",116,2,7,Introduction,Introduction,Natural language communication can be used to affect change in the real world.,Introduction,"Text adventure games are also useful for developing and testing reinforcement learning algorithms that must deal with the partial observability of the world (Narasimhan et al., 2015;He et al., 2016).",NC,
2260,"Text adventure games are also useful for developing and testing reinforcement learning algorithms that must deal with the partial observability of the world (Narasimhan et al., 2015;He et al., 2016).",117,2,8,Introduction,Introduction,"Text adventure games, in which players must make sense of the world through text descriptions and declare actions through natural language, can provide a stepping stone toward more real-world environments where agents must communicate to understand the state of the world and indirectly affect change in the world.",Introduction,"In text adventure games, the agent receives an incomplete textual description of the current state of the world.",NC,
2261,"In text adventure games, the agent receives an incomplete textual description of the current state of the world.",118,2,9,Introduction,Introduction,"Text adventure games are also useful for developing and testing reinforcement learning algorithms that must deal with the partial observability of the world (Narasimhan et al., 2015;He et al., 2016).",Introduction,"From this information, and previous interactions with the world, a player must determine the next best action to take to achieve some quest or goal.",NC,
2262,"From this information, and previous interactions with the world, a player must determine the next best action to take to achieve some quest or goal.",119,2,10,Introduction,Introduction,"In text adventure games, the agent receives an incomplete textual description of the current state of the world.",Introduction,The player must then com-pose a textual description of the action they intend to make and receive textual feedback of the effects of the action.,NC,
2263,The player must then com-pose a textual description of the action they intend to make and receive textual feedback of the effects of the action.,120,2,11,Introduction,Introduction,"From this information, and previous interactions with the world, a player must determine the next best action to take to achieve some quest or goal.",Introduction,"Formally, a text-based game is a partially observable Markov decision process (POMDP), represented as a 7-tuple of S, T, A, Ω, O, R, γ representing the set of environment states, conditional transition probabilities between states, words used to compose text commands, observations, observation conditional probabilities, reward function, and the discount factor respectively (Côté et al., 2018).",NC,
2264,"Formally, a text-based game is a partially observable Markov decision process (POMDP), represented as a 7-tuple of S, T, A, Ω, O, R, γ representing the set of environment states, conditional transition probabilities between states, words used to compose text commands, observations, observation conditional probabilities, reward function, and the discount factor respectively (Côté et al., 2018).",121,2,12,Introduction,Introduction,The player must then com-pose a textual description of the action they intend to make and receive textual feedback of the effects of the action.,Introduction,"In text-based games, the agent never has access to the true underlying world state and has to reason about how to act in the world based only on the textual observations.",NC,
2265,"In text-based games, the agent never has access to the true underlying world state and has to reason about how to act in the world based only on the textual observations.",122,2,13,Introduction,Introduction,"Formally, a text-based game is a partially observable Markov decision process (POMDP), represented as a 7-tuple of S, T, A, Ω, O, R, γ representing the set of environment states, conditional transition probabilities between states, words used to compose text commands, observations, observation conditional probabilities, reward function, and the discount factor respectively (Côté et al., 2018).",Introduction,"Additionally, the agent's actions must be expressed through natural language commands, ensuring that the action space is combinatorially large.",NC,
2266,"Additionally, the agent's actions must be expressed through natural language commands, ensuring that the action space is combinatorially large.",123,2,14,Introduction,Introduction,"In text-based games, the agent never has access to the true underlying world state and has to reason about how to act in the world based only on the textual observations.",Introduction,"Thus, text-based games pose a different set of challenges than traditional video games.",NC,
2267,"Thus, text-based games pose a different set of challenges than traditional video games.",124,2,15,Introduction,Introduction,"Additionally, the agent's actions must be expressed through natural language commands, ensuring that the action space is combinatorially large.",Introduction,Text-based games require a greater understanding of previous context to be able to explore the state-action space more effectively.,NC,
2268,Text-based games require a greater understanding of previous context to be able to explore the state-action space more effectively.,125,2,16,Introduction,Introduction,"Thus, text-based games pose a different set of challenges than traditional video games.",Introduction,"Such games have historically proven to be difficult to play for AI agents, and the more complex variants such as Zork still remain firmly out of the reach of existing approaches.",NC,
2269,"Such games have historically proven to be difficult to play for AI agents, and the more complex variants such as Zork still remain firmly out of the reach of existing approaches.",126,2,17,Introduction,Introduction,Text-based games require a greater understanding of previous context to be able to explore the state-action space more effectively.,Introduction,We introduce three contributions to text-based game playing to deal with the combinatorially large state and action spaces.,NC,
2270,We introduce three contributions to text-based game playing to deal with the combinatorially large state and action spaces.,127,2,18,Introduction,Introduction,"Such games have historically proven to be difficult to play for AI agents, and the more complex variants such as Zork still remain firmly out of the reach of existing approaches.",Introduction,"First, we show that a state representation in the form of a knowledge graph gives us the ability to effectively prune an action space.",FACT,
2271,"First, we show that a state representation in the form of a knowledge graph gives us the ability to effectively prune an action space.",128,2,19,Introduction,Introduction,We introduce three contributions to text-based game playing to deal with the combinatorially large state and action spaces.,Introduction,A knowledge graph captures the relationships between entities as a directed graph.,POS,
2272,A knowledge graph captures the relationships between entities as a directed graph.,129,2,20,Introduction,Introduction,"First, we show that a state representation in the form of a knowledge graph gives us the ability to effectively prune an action space.",Introduction,The knowledge graph provides a persistent memory of the world over time and enables the agent to have a prior notion of what actions it should not take at a particular stage of the game.,NC,
2273,The knowledge graph provides a persistent memory of the world over time and enables the agent to have a prior notion of what actions it should not take at a particular stage of the game.,130,2,21,Introduction,Introduction,A knowledge graph captures the relationships between entities as a directed graph.,Introduction,"Our second contribution is a deep reinforcement learning architecture, Knowledge Graph DQN (KG-DQN), that effectively uses this state rep-resentation to estimate the Q-value for a stateaction pair.",POS,
2274,"Our second contribution is a deep reinforcement learning architecture, Knowledge Graph DQN (KG-DQN), that effectively uses this state rep-resentation to estimate the Q-value for a stateaction pair.",131,2,22,Introduction,Introduction,The knowledge graph provides a persistent memory of the world over time and enables the agent to have a prior notion of what actions it should not take at a particular stage of the game.,Introduction,"This architecture leverages recent advances in graph embedding and attention techniques (Guan et al., 2018;Veličković et al., 2018) to learn which portions of the graph to pay attention to given an input state description in addition to having a mechanism that allows for natural language action inputs.",FACT#POS,
2275,"This architecture leverages recent advances in graph embedding and attention techniques (Guan et al., 2018;Veličković et al., 2018) to learn which portions of the graph to pay attention to given an input state description in addition to having a mechanism that allows for natural language action inputs.",132,2,23,Introduction,Introduction,"Our second contribution is a deep reinforcement learning architecture, Knowledge Graph DQN (KG-DQN), that effectively uses this state rep-resentation to estimate the Q-value for a stateaction pair.",Introduction,"Finally, we take initial steps toward framing the POMDP as a questionanswering (QA) problem wherein a knowledgegraph can be used to not only prune actions but to answer the question of what action is most appropriate.",POS,
2276,"Finally, we take initial steps toward framing the POMDP as a questionanswering (QA) problem wherein a knowledgegraph can be used to not only prune actions but to answer the question of what action is most appropriate.",133,2,24,Introduction,Introduction,"This architecture leverages recent advances in graph embedding and attention techniques (Guan et al., 2018;Veličković et al., 2018) to learn which portions of the graph to pay attention to given an input state description in addition to having a mechanism that allows for natural language action inputs.",Introduction,"Previous work has shown that many NLP tasks can be framed as instances of questionanswering and that we can transfer knowledge between these tasks (McCann et al., 2017).",FACT,
2277,"Previous work has shown that many NLP tasks can be framed as instances of questionanswering and that we can transfer knowledge between these tasks (McCann et al., 2017).",134,2,25,Introduction,Introduction,"Finally, we take initial steps toward framing the POMDP as a questionanswering (QA) problem wherein a knowledgegraph can be used to not only prune actions but to answer the question of what action is most appropriate.",Introduction,We show how pre-training certain parts of our KG-DQN network using existing QA methods improves performance and allows knowledge to be transferred from different games.,NC,
2278,We show how pre-training certain parts of our KG-DQN network using existing QA methods improves performance and allows knowledge to be transferred from different games.,135,2,26,Introduction,Introduction,"Previous work has shown that many NLP tasks can be framed as instances of questionanswering and that we can transfer knowledge between these tasks (McCann et al., 2017).",Introduction,We provide results on ablative experiments comparing our knowledge-graph based approach approaches to strong baselines.,POS,
2279,We provide results on ablative experiments comparing our knowledge-graph based approach approaches to strong baselines.,136,2,27,Introduction,Introduction,We show how pre-training certain parts of our KG-DQN network using existing QA methods improves performance and allows knowledge to be transferred from different games.,Introduction,Results show that incorporating a knowledge-graph into a reinforcement learning agent results in converges to the highest reward more than 40% faster than the best baseline.,FACT,
2280,Results show that incorporating a knowledge-graph into a reinforcement learning agent results in converges to the highest reward more than 40% faster than the best baseline.,137,2,28,Introduction,Introduction,We provide results on ablative experiments comparing our knowledge-graph based approach approaches to strong baselines.,Introduction,"With pre-training using a questionanswering paradigm, we achieve this fast convergence rate while also achieving high quality quest solutions as measured by the number of steps required to complete the quests.",POS,
2281,"With pre-training using a questionanswering paradigm, we achieve this fast convergence rate while also achieving high quality quest solutions as measured by the number of steps required to complete the quests.",138,2,29,Introduction,Introduction,Results show that incorporating a knowledge-graph into a reinforcement learning agent results in converges to the highest reward more than 40% faster than the best baseline.,Related Work,"A growing body of research has explored the challenges associated with text-based games (Bordes et al., 2010;Narasimhan et al., 2015;He et al., 2016;Fulda et al., 2017;Haroush et al., 2018;Côté et al., 2018;Tao et al., 2018).",POS,
2282,"In this section we introduce our knowledge graph representation, action pruning and deep Qnetwork architecture.",139,2,49,Knowledge Graph DQN,Related Work,The state representation that we have chosen as well as our method of action pruning builds on the strengths of existing approaches while simultaneously avoiding the shortcomings of ineffective exploration and lack of long-term context.,Knowledge Graph Representation,"In our approach, our agent learns a knowledge graph, stored as a set of RDF triples, i.e.",NC,
2283,"In our approach, our agent learns a knowledge graph, stored as a set of RDF triples, i.e.",140,2,50,Knowledge Graph Representation,Knowledge Graph DQN,"In this section we introduce our knowledge graph representation, action pruning and deep Qnetwork architecture.",Knowledge Graph Representation,"3-tuples of subject, relation, object .",NC,
2284,"3-tuples of subject, relation, object .",141,2,51,Knowledge Graph Representation,Knowledge Graph Representation,"In our approach, our agent learns a knowledge graph, stored as a set of RDF triples, i.e.",Knowledge Graph Representation,"These triples are extracted from the observations using Stanford's Open Information Extraction (OpenIE) (Angeli et al., 2015).",NC,
2285,"These triples are extracted from the observations using Stanford's Open Information Extraction (OpenIE) (Angeli et al., 2015).",142,2,52,Knowledge Graph Representation,Knowledge Graph Representation,"3-tuples of subject, relation, object .",Knowledge Graph Representation,OpenIE is not optimized to the regularities of text adventure games and there are a lot of relations that can be inferred from the typical structure of descriptive texts.,NC,
2286,OpenIE is not optimized to the regularities of text adventure games and there are a lot of relations that can be inferred from the typical structure of descriptive texts.,143,2,53,Knowledge Graph Representation,Knowledge Graph Representation,"These triples are extracted from the observations using Stanford's Open Information Extraction (OpenIE) (Angeli et al., 2015).",Knowledge Graph Representation,"For example, from a phrase such as ""There is an exit to the north"" one can infer a has relation between the current The knowledge graph is updated after every agent action (see Figure 1).",NC,
2287,"For example, from a phrase such as ""There is an exit to the north"" one can infer a has relation between the current The knowledge graph is updated after every agent action (see Figure 1).",144,2,54,Knowledge Graph Representation,Knowledge Graph Representation,OpenIE is not optimized to the regularities of text adventure games and there are a lot of relations that can be inferred from the typical structure of descriptive texts.,Knowledge Graph Representation,The update rules are defined such that there are portions of the graph offering short and long-term context.,NC,
2288,The update rules are defined such that there are portions of the graph offering short and long-term context.,145,2,55,Knowledge Graph Representation,Knowledge Graph Representation,"For example, from a phrase such as ""There is an exit to the north"" one can infer a has relation between the current The knowledge graph is updated after every agent action (see Figure 1).",Knowledge Graph Representation,"A special node-designated ""you""-represents the agent and relations out of this node are updated after every action with the exception of relations denoting the agent's inventory.",NC,
2289,"A special node-designated ""you""-represents the agent and relations out of this node are updated after every action with the exception of relations denoting the agent's inventory.",146,2,56,Knowledge Graph Representation,Knowledge Graph Representation,The update rules are defined such that there are portions of the graph offering short and long-term context.,Knowledge Graph Representation,Other relations persist after each action.,NC,
2290,Other relations persist after each action.,147,2,57,Knowledge Graph Representation,Knowledge Graph Representation,"A special node-designated ""you""-represents the agent and relations out of this node are updated after every action with the exception of relations denoting the agent's inventory.",Knowledge Graph Representation,We intend for the update rules to be applied to text-based games in different domains and so only hand-craft a minimal set of rules that we believe apply generally.,NC,
2291,We intend for the update rules to be applied to text-based games in different domains and so only hand-craft a minimal set of rules that we believe apply generally.,148,2,58,Knowledge Graph Representation,Knowledge Graph Representation,Other relations persist after each action.,Knowledge Graph Representation,They are: • Linking the current room type (e.g.,PROSP,
2292,They are: • Linking the current room type (e.g.,149,2,59,Knowledge Graph Representation,Knowledge Graph Representation,We intend for the update rules to be applied to text-based games in different domains and so only hand-craft a minimal set of rules that we believe apply generally.,Knowledge Graph Representation,"""basement"", ""chamber') to the items found in the room with the relation ""has"", e.g.",NC,
2293,"""basement"", ""chamber') to the items found in the room with the relation ""has"", e.g.",150,2,60,Knowledge Graph Representation,Knowledge Graph Representation,They are: • Linking the current room type (e.g.,Knowledge Graph Representation,"chamber, has, bed stand • Extracting information regarding entrances and exits and linking them to the current room, e.g.",NC,
2294,"chamber, has, bed stand • Extracting information regarding entrances and exits and linking them to the current room, e.g.",151,2,61,Knowledge Graph Representation,Knowledge Graph Representation,"""basement"", ""chamber') to the items found in the room with the relation ""has"", e.g.",Knowledge Graph Representation,"basement, has, exit to north • Removing all relations relating to the ""you"" node with the exception of inventory every action, e.g.",NC,
2295,"basement, has, exit to north • Removing all relations relating to the ""you"" node with the exception of inventory every action, e.g.",152,2,62,Knowledge Graph Representation,Knowledge Graph Representation,"chamber, has, bed stand • Extracting information regarding entrances and exits and linking them to the current room, e.g.",Knowledge Graph Representation,"you, have, cubical key • Linking rooms with directions based on the action taken to move between the rooms, e.g.",NC,
2296,"you, have, cubical key • Linking rooms with directions based on the action taken to move between the rooms, e.g.",153,2,63,Knowledge Graph Representation,Knowledge Graph Representation,"basement, has, exit to north • Removing all relations relating to the ""you"" node with the exception of inventory every action, e.g.",Knowledge Graph Representation,"chamber, east of, basement after the action ""go east"" is taken to go from the basement to the chamber All other RDF triples generated are taken from OpenIE.",NC,
2297,"chamber, east of, basement after the action ""go east"" is taken to go from the basement to the chamber All other RDF triples generated are taken from OpenIE.",154,2,64,Knowledge Graph Representation,Knowledge Graph Representation,"you, have, cubical key • Linking rooms with directions based on the action taken to move between the rooms, e.g.",Action Pruning,"The number of actions available to an agent in a text adventure game can be quite large: A = O(|V | × |O| 2 ) where V is the number of action verbs, and O is the number of distinct objects in the world that the agent can interact with, assuming that verbs can take two arguments.",NC,
2298,"The number of actions available to an agent in a text adventure game can be quite large: A = O(|V | × |O| 2 ) where V is the number of action verbs, and O is the number of distinct objects in the world that the agent can interact with, assuming that verbs can take two arguments.",155,2,65,Action Pruning,Knowledge Graph Representation,"chamber, east of, basement after the action ""go east"" is taken to go from the basement to the chamber All other RDF triples generated are taken from OpenIE.",Action Pruning,"Some actions, such as movement, inspecting inventory, or observing the room, do not have arguments.",NC,
2299,"Some actions, such as movement, inspecting inventory, or observing the room, do not have arguments.",156,2,66,Action Pruning,Action Pruning,"The number of actions available to an agent in a text adventure game can be quite large: A = O(|V | × |O| 2 ) where V is the number of action verbs, and O is the number of distinct objects in the world that the agent can interact with, assuming that verbs can take two arguments.",Action Pruning,The knowledge graph is used to prune the combinatorially large space of possible actions available to the agent as follows.,NC,
2300,The knowledge graph is used to prune the combinatorially large space of possible actions available to the agent as follows.,157,2,67,Action Pruning,Action Pruning,"Some actions, such as movement, inspecting inventory, or observing the room, do not have arguments.",Action Pruning,"Given the current state graph representation G t , the action space is pruned by ranking the full set of actions and selecting the top-k. Our action scoring function is: • +1 for each object in the action that is present in the graph; and • +1 if there exists a valid directed path between the two objects in the graph.",NC,
2301,"Given the current state graph representation G t , the action space is pruned by ranking the full set of actions and selecting the top-k. Our action scoring function is: • +1 for each object in the action that is present in the graph; and • +1 if there exists a valid directed path between the two objects in the graph.",158,2,68,Action Pruning,Action Pruning,The knowledge graph is used to prune the combinatorially large space of possible actions available to the agent as follows.,Action Pruning,We assume that each action has at most two objects (for example inserting a key in a lock).,NC,
2302,We assume that each action has at most two objects (for example inserting a key in a lock).,159,2,69,Action Pruning,Action Pruning,"Given the current state graph representation G t , the action space is pruned by ranking the full set of actions and selecting the top-k. Our action scoring function is: • +1 for each object in the action that is present in the graph; and • +1 if there exists a valid directed path between the two objects in the graph.",Model Architecture and Training,Following Narasimhan et al.,NC,
2303,"Previous work has shown that many NLP tasks can be framed as instances of question-answering and that in doing so, one can transfer knowledge between these tasks (McCann et al., 2017).",160,2,103,Game Play as Question Answering,Model Architecture and Training,The exact training mechanism is described in Algorithm 1.,Game Play as Question Answering,"In the abstract, an agent playing a text adventure game can be thought of as continuously asking the question ""What is the right action to perform in this situation?""",NC,
2304,"In the abstract, an agent playing a text adventure game can be thought of as continuously asking the question ""What is the right action to perform in this situation?""",161,2,104,Game Play as Question Answering,Game Play as Question Answering,"Previous work has shown that many NLP tasks can be framed as instances of question-answering and that in doing so, one can transfer knowledge between these tasks (McCann et al., 2017).",Game Play as Question Answering,"When appropriately trained, the agent may be able to answer the question for itself and select a good next move to execute.",NC,
2305,"When appropriately trained, the agent may be able to answer the question for itself and select a good next move to execute.",162,2,105,Game Play as Question Answering,Game Play as Question Answering,"In the abstract, an agent playing a text adventure game can be thought of as continuously asking the question ""What is the right action to perform in this situation?""",Game Play as Question Answering,Treating the problem as question-answering will not replace the need for exploration in text-adventure games.,NC,
2306,Treating the problem as question-answering will not replace the need for exploration in text-adventure games.,163,2,106,Game Play as Question Answering,Game Play as Question Answering,"When appropriately trained, the agent may be able to answer the question for itself and select a good next move to execute.",Game Play as Question Answering,"However, we hypothesize that it will cut down on the amount of exploration needed during testing time, theoretically allowing it to complete quests faster; one of the challenges of text adventure games is that the quests are puzzles and even after training, execution of the policy requires a significant amount of exploration.",NEG,
2307,"However, we hypothesize that it will cut down on the amount of exploration needed during testing time, theoretically allowing it to complete quests faster; one of the challenges of text adventure games is that the quests are puzzles and even after training, execution of the policy requires a significant amount of exploration.",164,2,107,Game Play as Question Answering,Game Play as Question Answering,Treating the problem as question-answering will not replace the need for exploration in text-adventure games.,Game Play as Question Answering,"To teach the agent to answer the question of what action is best to take given an observation, we use an offline, pre-training approach.",PROSP,
2308,"To teach the agent to answer the question of what action is best to take given an observation, we use an offline, pre-training approach.",165,2,108,Game Play as Question Answering,Game Play as Question Answering,"However, we hypothesize that it will cut down on the amount of exploration needed during testing time, theoretically allowing it to complete quests faster; one of the challenges of text adventure games is that the quests are puzzles and even after training, execution of the policy requires a significant amount of exploration.",Game Play as Question Answering,"The data for the pre-training approach is generated using an oracle, an agent capable of finishing a game perfectly in the least number of steps possible.",FACT,
2309,"The data for the pre-training approach is generated using an oracle, an agent capable of finishing a game perfectly in the least number of steps possible.",166,2,109,Game Play as Question Answering,Game Play as Question Answering,"To teach the agent to answer the question of what action is best to take given an observation, we use an offline, pre-training approach.",Game Play as Question Answering,"Specifically, the agent knows exactly what action to take given the state observation in order to advance the game in the most optimal manner possible.",NC,
2310,"Specifically, the agent knows exactly what action to take given the state observation in order to advance the game in the most optimal manner possible.",167,2,110,Game Play as Question Answering,Game Play as Question Answering,"The data for the pre-training approach is generated using an oracle, an agent capable of finishing a game perfectly in the least number of steps possible.",Game Play as Question Answering,"Through this process, we generate a set of traces consisting of state observations and actions such that the state observation provides the context for the implicit question of ""What action should be taken?""",NC,
2311,"Through this process, we generate a set of traces consisting of state observations and actions such that the state observation provides the context for the implicit question of ""What action should be taken?""",168,2,111,Game Play as Question Answering,Game Play as Question Answering,"Specifically, the agent knows exactly what action to take given the state observation in order to advance the game in the most optimal manner possible.",Game Play as Question Answering,and the oracle's correct action is the answer.,NC,
2312,and the oracle's correct action is the answer.,169,2,112,Game Play as Question Answering,Game Play as Question Answering,"Through this process, we generate a set of traces consisting of state observations and actions such that the state observation provides the context for the implicit question of ""What action should be taken?""",Game Play as Question Answering,"We then use the DrQA (Chen et al., 2017) question-answering technique to train a paired question encoder and an answer encoder that together predict the answer (action) from the question (text observation).",NC,
2313,"We then use the DrQA (Chen et al., 2017) question-answering technique to train a paired question encoder and an answer encoder that together predict the answer (action) from the question (text observation).",170,2,113,Game Play as Question Answering,Game Play as Question Answering,and the oracle's correct action is the answer.,Game Play as Question Answering,The weights from the SB-LSTM in the document encoder in the DrQA system are then used to initialize the weights of the SB-LSTM.,FACT,
2314,The weights from the SB-LSTM in the document encoder in the DrQA system are then used to initialize the weights of the SB-LSTM.,171,2,114,Game Play as Question Answering,Game Play as Question Answering,"We then use the DrQA (Chen et al., 2017) question-answering technique to train a paired question encoder and an answer encoder that together predict the answer (action) from the question (text observation).",Game Play as Question Answering,"Similarly, embedding layers of both the graph and the LSTM action encoder are initialized with the weights from the embedding layer of same document encoder.",NC,
2315,"Similarly, embedding layers of both the graph and the LSTM action encoder are initialized with the weights from the embedding layer of same document encoder.",172,2,115,Game Play as Question Answering,Game Play as Question Answering,The weights from the SB-LSTM in the document encoder in the DrQA system are then used to initialize the weights of the SB-LSTM.,Game Play as Question Answering,"Since the DrQA embedding layers are initialized with GloVe, we are transferring word embeddings that are tuned during the training of the QA architecture.",NC,
2316,"Since the DrQA embedding layers are initialized with GloVe, we are transferring word embeddings that are tuned during the training of the QA architecture.",173,2,116,Game Play as Question Answering,Game Play as Question Answering,"Similarly, embedding layers of both the graph and the LSTM action encoder are initialized with the weights from the embedding layer of same document encoder.",Game Play as Question Answering,The game traces used to train the questionanswering come from a set of games of the same domain but have different specific configurations of the environment and different quests.,NC,
2317,The game traces used to train the questionanswering come from a set of games of the same domain but have different specific configurations of the environment and different quests.,174,2,117,Game Play as Question Answering,Game Play as Question Answering,"Since the DrQA embedding layers are initialized with GloVe, we are transferring word embeddings that are tuned during the training of the QA architecture.",Game Play as Question Answering,"We use the TextWorld framework (Côté et al., 2018), which uses a grammar to generate random worlds and quests.",NC,
2318,"We use the TextWorld framework (Côté et al., 2018), which uses a grammar to generate random worlds and quests.",175,2,118,Game Play as Question Answering,Game Play as Question Answering,The game traces used to train the questionanswering come from a set of games of the same domain but have different specific configurations of the environment and different quests.,Game Play as Question Answering,"The types of rooms are the same, but their relative spatial configuration, the types of objects, and the specific sequence of actions needed to complete the quest are different each time.",NC,
2319,"The types of rooms are the same, but their relative spatial configuration, the types of objects, and the specific sequence of actions needed to complete the quest are different each time.",176,2,119,Game Play as Question Answering,Game Play as Question Answering,"We use the TextWorld framework (Côté et al., 2018), which uses a grammar to generate random worlds and quests.",Game Play as Question Answering,This means that the agent cannot simply memorize quests.,NC,
2320,This means that the agent cannot simply memorize quests.,177,2,120,Game Play as Question Answering,Game Play as Question Answering,"The types of rooms are the same, but their relative spatial configuration, the types of objects, and the specific sequence of actions needed to complete the quest are different each time.",Game Play as Question Answering,"For pre-training to work, the agent must develop a general question-answering competence that can transfer to new quests.",NC,
2321,"For pre-training to work, the agent must develop a general question-answering competence that can transfer to new quests.",178,2,121,Game Play as Question Answering,Game Play as Question Answering,This means that the agent cannot simply memorize quests.,Game Play as Question Answering,Our approach to question-answering in the context of text adventure game playing thus represents a form of transfer learning.,NC,
2322,Our approach to question-answering in the context of text adventure game playing thus represents a form of transfer learning.,179,2,122,Game Play as Question Answering,Game Play as Question Answering,"For pre-training to work, the agent must develop a general question-answering competence that can transfer to new quests.",Experiments,"We conducted experiments in the TextWorld framework (Côté et al., 2018) using their ""home"" theme.",FACT,
2323,"G1 ← updateGraph(G0, o1); A1 ← pruneActions(A, G0) Section 3.2 6: for step t=1 to T do 7: if random() < 1 then 3.",180,2,151,unidentified-section,Experiments,"Un-pruned actions with pre-training Algorithm 1 1 , 2 -greedy learning algorithm for KG-DQN 1: for episode=1 to M do 2: Initialize action dictionary A and graph G0",unidentified-section,"Pruned actions with pre-training (full) Our models use 50-dimensional word embeddings, 2 heads on the graph attention layers, minibatch size of 16, and perform a gradient descent update every 5 steps taken by the agent.",NC,
2324,"Pruned actions with pre-training (full) Our models use 50-dimensional word embeddings, 2 heads on the graph attention layers, minibatch size of 16, and perform a gradient descent update every 5 steps taken by the agent.",181,2,152,unidentified-section,unidentified-section,"G1 ← updateGraph(G0, o1); A1 ← pruneActions(A, G0) Section 3.2 6: for step t=1 to T do 7: if random() < 1 then 3.",unidentified-section,"All models are evaluated by observing the (a) time to reward convergence, and (b) the average number of steps required for the agent to finish the game with = 0.1 over 5 episodes after training has completed.",NC,
2325,"All models are evaluated by observing the (a) time to reward convergence, and (b) the average number of steps required for the agent to finish the game with = 0.1 over 5 episodes after training has completed.",182,2,153,unidentified-section,unidentified-section,"Pruned actions with pre-training (full) Our models use 50-dimensional word embeddings, 2 heads on the graph attention layers, minibatch size of 16, and perform a gradient descent update every 5 steps taken by the agent.",unidentified-section,Following Narasimhan et al.,NC,
2326,Following Narasimhan et al.,183,2,154,unidentified-section,unidentified-section,"All models are evaluated by observing the (a) time to reward convergence, and (b) the average number of steps required for the agent to finish the game with = 0.1 over 5 episodes after training has completed.",unidentified-section,"(2015) we set to a non-zero value because text adventure games, by nature, require exploration to complete the quests.",NC,
2327,"(2015) we set to a non-zero value because text adventure games, by nature, require exploration to complete the quests.",184,2,155,unidentified-section,unidentified-section,Following Narasimhan et al.,unidentified-section,All results are reported based on multiple independent trials.,NC,
2328,All results are reported based on multiple independent trials.,185,2,156,unidentified-section,unidentified-section,"(2015) we set to a non-zero value because text adventure games, by nature, require exploration to complete the quests.",unidentified-section,"For the large set of games, we only perform experiments on the best performing models found in the small set of games.",NC,
2329,"For the large set of games, we only perform experiments on the best performing models found in the small set of games.",186,2,157,unidentified-section,unidentified-section,All results are reported based on multiple independent trials.,unidentified-section,"Also note that for experiments on large games, we do not display the entire learning curve for the LSTM-DQN baseline, as it converges significantly more slowly than KG-DQN.",NC,
2330,"Also note that for experiments on large games, we do not display the entire learning curve for the LSTM-DQN baseline, as it converges significantly more slowly than KG-DQN.",187,2,158,unidentified-section,unidentified-section,"For the large set of games, we only perform experiments on the best performing models found in the small set of games.",unidentified-section,We run each experiment 5 times and average the results.,NC,
2331,We run each experiment 5 times and average the results.,188,2,159,unidentified-section,unidentified-section,"Also note that for experiments on large games, we do not display the entire learning curve for the LSTM-DQN baseline, as it converges significantly more slowly than KG-DQN.",unidentified-section,"Additionally, human performance on the both the games was measured by counting the number of steps taken to finish the game, with and without instructions on the exact quest.",NC,
2332,"Additionally, human performance on the both the games was measured by counting the number of steps taken to finish the game, with and without instructions on the exact quest.",189,2,160,unidentified-section,unidentified-section,We run each experiment 5 times and average the results.,unidentified-section,"We modified Textworld to give the human players reward feedback in the form of a score, the reward function itself is identical to that received by the deep reinforcement learning agents.",NC,
2333,"We modified Textworld to give the human players reward feedback in the form of a score, the reward function itself is identical to that received by the deep reinforcement learning agents.",190,2,161,unidentified-section,unidentified-section,"Additionally, human performance on the both the games was measured by counting the number of steps taken to finish the game, with and without instructions on the exact quest.",unidentified-section,"In one variation of this experiment, the human was given instructions on the potential sequence of steps that are required to finish the game in addition to the reward in the form of a score and in the other variation, the human received no instructions.",NC,
2334,"In one variation of this experiment, the human was given instructions on the potential sequence of steps that are required to finish the game in addition to the reward in the form of a score and in the other variation, the human received no instructions.",191,2,162,unidentified-section,unidentified-section,"We modified Textworld to give the human players reward feedback in the form of a score, the reward function itself is identical to that received by the deep reinforcement learning agents.",Results and Discussion,Recall that the number of steps required to finish the game for the oracle agent is 5 and 10 for the small and large maps respectively.,NC,
2335,Recall that the number of steps required to finish the game for the oracle agent is 5 and 10 for the small and large maps respectively.,192,2,163,Results and Discussion,unidentified-section,"In one variation of this experiment, the human was given instructions on the potential sequence of steps that are required to finish the game in addition to the reward in the form of a score and in the other variation, the human received no instructions.",Results and Discussion,It is impossible to achieve this ideal performance due to the structure of the quest.,NC,
2336,It is impossible to achieve this ideal performance due to the structure of the quest.,193,2,164,Results and Discussion,Results and Discussion,Recall that the number of steps required to finish the game for the oracle agent is 5 and 10 for the small and large maps respectively.,Results and Discussion,The player needs to interact with objects and explore the environment in order to figure out the exact sequence of actions required to finish the quest.,NC,
2337,The player needs to interact with objects and explore the environment in order to figure out the exact sequence of actions required to finish the quest.,194,2,165,Results and Discussion,Results and Discussion,It is impossible to achieve this ideal performance due to the structure of the quest.,Results and Discussion,"To help benchmark our agent's performance, we observed people unaffiliated with the research playing through the same TextWorld ""home"" quests as the other models.",NC,
2338,"To help benchmark our agent's performance, we observed people unaffiliated with the research playing through the same TextWorld ""home"" quests as the other models.",195,2,166,Results and Discussion,Results and Discussion,The player needs to interact with objects and explore the environment in order to figure out the exact sequence of actions required to finish the quest.,Results and Discussion,Those who did not receive instructions on how to finish the quest never finished a single quest and gave up after an average of 184 steps on the small map and an average of 190 steps on the large map.,NC,
2339,Those who did not receive instructions on how to finish the quest never finished a single quest and gave up after an average of 184 steps on the small map and an average of 190 steps on the large map.,196,2,167,Results and Discussion,Results and Discussion,"To help benchmark our agent's performance, we observed people unaffiliated with the research playing through the same TextWorld ""home"" quests as the other models.",Results and Discussion,"When given instructions, human players completed the quest on the large map in an average of 23 steps, finishing the game with the maximum reward possible.",POS,
2340,"When given instructions, human players completed the quest on the large map in an average of 23 steps, finishing the game with the maximum reward possible.",197,2,168,Results and Discussion,Results and Discussion,Those who did not receive instructions on how to finish the quest never finished a single quest and gave up after an average of 184 steps on the small map and an average of 190 steps on the large map.,Results and Discussion,Also note that none of the deep reinforcement learning agents received instructions.,POS,
2341,Also note that none of the deep reinforcement learning agents received instructions.,198,2,169,Results and Discussion,Results and Discussion,"When given instructions, human players completed the quest on the large map in an average of 23 steps, finishing the game with the maximum reward possible.",Results and Discussion,"On both small and large maps, all versions of KG-DQN tested converge faster than baselines (see Figure 3 for the small game and Figure 4 for the large game).",NC,
2342,"On both small and large maps, all versions of KG-DQN tested converge faster than baselines (see Figure 3 for the small game and Figure 4 for the large game).",199,2,170,Results and Discussion,Results and Discussion,Also note that none of the deep reinforcement learning agents received instructions.,Results and Discussion,We don't show BOW-DQN because it is strictly inferior to LSTM-DQN in all situations).,POS,
2343,We don't show BOW-DQN because it is strictly inferior to LSTM-DQN in all situations).,200,2,171,Results and Discussion,Results and Discussion,"On both small and large maps, all versions of KG-DQN tested converge faster than baselines (see Figure 3 for the small game and Figure 4 for the large game).",Results and Discussion,KG-DQN converges 40% faster than baseline on the small game; both KG-DQN and the LSTM-DQN baseline reaches the maximum reward of five.,NC,
2344,KG-DQN converges 40% faster than baseline on the small game; both KG-DQN and the LSTM-DQN baseline reaches the maximum reward of five.,201,2,172,Results and Discussion,Results and Discussion,We don't show BOW-DQN because it is strictly inferior to LSTM-DQN in all situations).,Results and Discussion,"On the large game, no Table 3: Average number of steps (and standard deviation) taken to complete the small game.",POS,
2345,"On the large game, no Table 3: Average number of steps (and standard deviation) taken to complete the small game.",202,2,173,Results and Discussion,Results and Discussion,KG-DQN converges 40% faster than baseline on the small game; both KG-DQN and the LSTM-DQN baseline reaches the maximum reward of five.,Results and Discussion,"agents achieve the maximum reward of 10, and the LSTM-DQN requires more than 300 episodes to converge at the same level as KG-DQN.",NC,
2346,"agents achieve the maximum reward of 10, and the LSTM-DQN requires more than 300 episodes to converge at the same level as KG-DQN.",203,2,174,Results and Discussion,Results and Discussion,"On the large game, no Table 3: Average number of steps (and standard deviation) taken to complete the small game.",Results and Discussion,"Since all versions of KG-DQN converge at approximately the same rate, we conclude that the knowledge graph-i.e., persistent memory-is the main factor helping convergence time since it is the common element across all experiments.",POS,
2347,"Since all versions of KG-DQN converge at approximately the same rate, we conclude that the knowledge graph-i.e., persistent memory-is the main factor helping convergence time since it is the common element across all experiments.",204,2,175,Results and Discussion,Results and Discussion,"agents achieve the maximum reward of 10, and the LSTM-DQN requires more than 300 episodes to converge at the same level as KG-DQN.",Results and Discussion,"After training is complete, we measure the number of steps each agent needs to complete each quest.",POS,
2348,"After training is complete, we measure the number of steps each agent needs to complete each quest.",205,2,176,Results and Discussion,Results and Discussion,"Since all versions of KG-DQN converge at approximately the same rate, we conclude that the knowledge graph-i.e., persistent memory-is the main factor helping convergence time since it is the common element across all experiments.",Results and Discussion,Full KG-DQN requires an equivalent number of steps in the small game (Table 3) and in the large game (Table 4).,NC,
2349,Full KG-DQN requires an equivalent number of steps in the small game (Table 3) and in the large game (Table 4).,206,2,177,Results and Discussion,Results and Discussion,"After training is complete, we measure the number of steps each agent needs to complete each quest.",Results and Discussion,"Differences between LSTM-DQN and full KG-DQN are not statistically significant, p = 0.199 on an independent Ttest.",POS,
2350,"Differences between LSTM-DQN and full KG-DQN are not statistically significant, p = 0.199 on an independent Ttest.",207,2,178,Results and Discussion,Results and Discussion,Full KG-DQN requires an equivalent number of steps in the small game (Table 3) and in the large game (Table 4).,Results and Discussion,The ablated versions of KG-DQN-unpruned KG-DQN and non-pre-trained KG-DQN-require many more steps to complete quests.,NEG#POS,
2351,The ablated versions of KG-DQN-unpruned KG-DQN and non-pre-trained KG-DQN-require many more steps to complete quests.,208,2,179,Results and Discussion,Results and Discussion,"Differences between LSTM-DQN and full KG-DQN are not statistically significant, p = 0.199 on an independent Ttest.",Results and Discussion,TextWorld's reward function allows for a lot of exploration of the environment without penalty so it is possible for a model that has converged on reward to complete quests in as few as five steps or in many hundreds of steps.,POS,
2352,TextWorld's reward function allows for a lot of exploration of the environment without penalty so it is possible for a model that has converged on reward to complete quests in as few as five steps or in many hundreds of steps.,209,2,180,Results and Discussion,Results and Discussion,The ablated versions of KG-DQN-unpruned KG-DQN and non-pre-trained KG-DQN-require many more steps to complete quests.,Results and Discussion,"From these results, we conclude that the pre-training using our questionanswering paradigm is allowing the agent to find a general understanding of how to pick good actions even when the agent has never seen the final",POS,
2353,"From these results, we conclude that the pre-training using our questionanswering paradigm is allowing the agent to find a general understanding of how to pick good actions even when the agent has never seen the final",210,2,181,Results and Discussion,Results and Discussion,TextWorld's reward function allows for a lot of exploration of the environment without penalty so it is possible for a model that has converged on reward to complete quests in as few as five steps or in many hundreds of steps.,Conclusions,We have shown that incorporating knowledge graphs into an deep Q-network can reduce training time for agents playing text-adventure games of various lengths.,POS,
2354,We have shown that incorporating knowledge graphs into an deep Q-network can reduce training time for agents playing text-adventure games of various lengths.,211,2,182,Conclusions,Results and Discussion,"From these results, we conclude that the pre-training using our questionanswering paradigm is allowing the agent to find a general understanding of how to pick good actions even when the agent has never seen the final",Conclusions,We speculate that this is because the knowledge graph provides a persistent memory of the world as it is being explored.,POS,
2355,We speculate that this is because the knowledge graph provides a persistent memory of the world as it is being explored.,212,2,183,Conclusions,Conclusions,We have shown that incorporating knowledge graphs into an deep Q-network can reduce training time for agents playing text-adventure games of various lengths.,Conclusions,"While the knowledge graph allows the agent to reach optimal reward more quickly, it doesn't ensure a high quality solution to quests.",POS,
2356,"While the knowledge graph allows the agent to reach optimal reward more quickly, it doesn't ensure a high quality solution to quests.",213,2,184,Conclusions,Conclusions,We speculate that this is because the knowledge graph provides a persistent memory of the world as it is being explored.,Conclusions,Action pruning using the knowledge graph and pre-training of the embeddings used in the deep Q-network result in shorter action sequences needed to complete quests.,NEG,
2357,Action pruning using the knowledge graph and pre-training of the embeddings used in the deep Q-network result in shorter action sequences needed to complete quests.,214,2,185,Conclusions,Conclusions,"While the knowledge graph allows the agent to reach optimal reward more quickly, it doesn't ensure a high quality solution to quests.",Conclusions,The insight into pre-training portions of the agent's architecture is based on converting textadventure game playing into a question-answering activity.,POS,
2358,The insight into pre-training portions of the agent's architecture is based on converting textadventure game playing into a question-answering activity.,215,2,186,Conclusions,Conclusions,Action pruning using the knowledge graph and pre-training of the embeddings used in the deep Q-network result in shorter action sequences needed to complete quests.,Conclusions,"That is, at every step, the agent is asking-and trying to answer-what is the most important thing to try.",POS,
2359,"That is, at every step, the agent is asking-and trying to answer-what is the most important thing to try.",216,2,187,Conclusions,Conclusions,The insight into pre-training portions of the agent's architecture is based on converting textadventure game playing into a question-answering activity.,Conclusions,"The pre-training acts as a form of transfer learning from different, but re-lated games.",NC,
2360,"The pre-training acts as a form of transfer learning from different, but re-lated games.",217,2,188,Conclusions,Conclusions,"That is, at every step, the agent is asking-and trying to answer-what is the most important thing to try.",Conclusions,"However, question-answering alone cannot solve the text-adventure playing problem because there will always be some trial and error required.",POS,
2361,"However, question-answering alone cannot solve the text-adventure playing problem because there will always be some trial and error required.",218,2,189,Conclusions,Conclusions,"The pre-training acts as a form of transfer learning from different, but re-lated games.",Conclusions,"By addressing the challenges of partial observability and combinatorially large action, spaces through persistent memory, our work on playing text-adventure games addresses a critical need for reinforcement learning for language.",NEG,
2362,"By addressing the challenges of partial observability and combinatorially large action, spaces through persistent memory, our work on playing text-adventure games addresses a critical need for reinforcement learning for language.",219,2,190,Conclusions,Conclusions,"However, question-answering alone cannot solve the text-adventure playing problem because there will always be some trial and error required.",Conclusions,"Textadventure games can be seen as a stepping stone toward more complex, real-world tasks; the human world is one of partial understanding through communication and acting on the world using language.",PROSP,
2363,"Textadventure games can be seen as a stepping stone toward more complex, real-world tasks; the human world is one of partial understanding through communication and acting on the world using language.",220,2,191,Conclusions,Conclusions,"By addressing the challenges of partial observability and combinatorially large action, spaces through persistent memory, our work on playing text-adventure games addresses a critical need for reinforcement learning for language.",,,PROSP,
2364,"  Despite the feature of real-time decoding, Monotonic Multihead Attention (MMA) shows comparable performance to the state-of-the-art offline methods in machine translation and automatic speech recognition (ASR) tasks.",221,3,0,abstract,,,abstract,"However, the latency of MMA is still a major issue in ASR and should be combined with a technique that can reduce the test latency at inference time, such as head-synchronous beam search decoding, which forces all non-activated heads to activate after a small fixed delay from the first head activation.",NC,
2365,"However, the latency of MMA is still a major issue in ASR and should be combined with a technique that can reduce the test latency at inference time, such as head-synchronous beam search decoding, which forces all non-activated heads to activate after a small fixed delay from the first head activation.",222,3,1,abstract,abstract,"  Despite the feature of real-time decoding, Monotonic Multihead Attention (MMA) shows comparable performance to the state-of-the-art offline methods in machine translation and automatic speech recognition (ASR) tasks.",abstract,"In this paper, we remove the discrepancy between training and test phases by considering, in the training of MMA, the interactions across multiple heads that will occur in the test time.",NC,
2366,"In this paper, we remove the discrepancy between training and test phases by considering, in the training of MMA, the interactions across multiple heads that will occur in the test time.",223,3,2,abstract,abstract,"However, the latency of MMA is still a major issue in ASR and should be combined with a technique that can reduce the test latency at inference time, such as head-synchronous beam search decoding, which forces all non-activated heads to activate after a small fixed delay from the first head activation.",abstract,"Specifically, we derive the expected alignments from monotonic attention by considering the boundaries of other heads and reflect them in the learning process.",FACT,
2367,"Specifically, we derive the expected alignments from monotonic attention by considering the boundaries of other heads and reflect them in the learning process.",224,3,3,abstract,abstract,"In this paper, we remove the discrepancy between training and test phases by considering, in the training of MMA, the interactions across multiple heads that will occur in the test time.",abstract,"We validate our proposed method on the two standard benchmark datasets for ASR and show that our approach, MMA with the mutually-constrained heads from the training stage, provides better performance than baselines.",FACT,
2368,"We validate our proposed method on the two standard benchmark datasets for ASR and show that our approach, MMA with the mutually-constrained heads from the training stage, provides better performance than baselines.",225,3,4,abstract,abstract,"Specifically, we derive the expected alignments from monotonic attention by considering the boundaries of other heads and reflect them in the learning process.",INTRODUCTION,"Online automatic speech recognition (ASR), which immediately recognizes incomplete speeches as humans do, is emerging as a core element of diverse ASR-based services such as teleconferences, AI secretaries, or AI booking services.",POS,
2369,"Online automatic speech recognition (ASR), which immediately recognizes incomplete speeches as humans do, is emerging as a core element of diverse ASR-based services such as teleconferences, AI secretaries, or AI booking services.",226,3,5,INTRODUCTION,abstract,"We validate our proposed method on the two standard benchmark datasets for ASR and show that our approach, MMA with the mutually-constrained heads from the training stage, provides better performance than baselines.",INTRODUCTION,"In particular, in these days, where the untact service market is rapidly growing due to the recent global outbreak of COVID-19, the importance of providing more realistic services by reducing latency is also growing.",NC,
2370,"In particular, in these days, where the untact service market is rapidly growing due to the recent global outbreak of COVID-19, the importance of providing more realistic services by reducing latency is also growing.",227,3,6,INTRODUCTION,INTRODUCTION,"Online automatic speech recognition (ASR), which immediately recognizes incomplete speeches as humans do, is emerging as a core element of diverse ASR-based services such as teleconferences, AI secretaries, or AI booking services.",INTRODUCTION,"However, of course, online ASR models [1,2] targeting real-time inference have concerns about performance degradation compared to traditional Copyright 2021 IEEE.",NC,
2371,"However, of course, online ASR models [1,2] targeting real-time inference have concerns about performance degradation compared to traditional Copyright 2021 IEEE.",228,3,7,INTRODUCTION,INTRODUCTION,"In particular, in these days, where the untact service market is rapidly growing due to the recent global outbreak of COVID-19, the importance of providing more realistic services by reducing latency is also growing.",INTRODUCTION,"Published in ICASSP 2021 -2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), scheduled for 6-11 June 2021 in Toronto, Ontario, Canada.",NC,
2372,"Published in ICASSP 2021 -2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), scheduled for 6-11 June 2021 in Toronto, Ontario, Canada.",229,3,8,INTRODUCTION,INTRODUCTION,"However, of course, online ASR models [1,2] targeting real-time inference have concerns about performance degradation compared to traditional Copyright 2021 IEEE.",INTRODUCTION,Personal use of this material is permitted.,NC,
2373,Personal use of this material is permitted.,230,3,9,INTRODUCTION,INTRODUCTION,"Published in ICASSP 2021 -2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), scheduled for 6-11 June 2021 in Toronto, Ontario, Canada.",INTRODUCTION,"However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works, must be obtained from the IEEE.",NC,
2374,"However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works, must be obtained from the IEEE.",231,3,10,INTRODUCTION,INTRODUCTION,Personal use of this material is permitted.,INTRODUCTION,"Contact: Manager, Copyrights and Permissions / IEEE Service Center / 445 Hoes Lane / P.O.",NC,
2375,"Contact: Manager, Copyrights and Permissions / IEEE Service Center / 445 Hoes Lane / P.O.",232,3,11,INTRODUCTION,INTRODUCTION,"However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works, must be obtained from the IEEE.",INTRODUCTION,"Box 1331 / Piscataway, NJ 08855-1331, USA.",NC,
2376,"Box 1331 / Piscataway, NJ 08855-1331, USA.",233,3,12,INTRODUCTION,INTRODUCTION,"Contact: Manager, Copyrights and Permissions / IEEE Service Center / 445 Hoes Lane / P.O.",INTRODUCTION,Telephone: + Intl.,NC,
2377,Telephone: + Intl.,234,3,13,INTRODUCTION,INTRODUCTION,"Box 1331 / Piscataway, NJ 08855-1331, USA.",INTRODUCTION,908-562-3966.,NC,
2378,908-562-3966.,235,3,14,INTRODUCTION,INTRODUCTION,Telephone: + Intl.,INTRODUCTION,"DNN-HMM hybrid models with pre-segmented alignments or offline models based on Transformer [3,4], which is the state-of-the-art in many sequence-sequence tasks nowadays.",NC,
2379,"DNN-HMM hybrid models with pre-segmented alignments or offline models based on Transformer [3,4], which is the state-of-the-art in many sequence-sequence tasks nowadays.",236,3,15,INTRODUCTION,INTRODUCTION,908-562-3966.,INTRODUCTION,"In order to overcome this performance-delay trade-off, several attempts have been made to learn or find monotonic alignments between source and target via attention mechanism [5,6,7,8,9].",NC,
2380,"In order to overcome this performance-delay trade-off, several attempts have been made to learn or find monotonic alignments between source and target via attention mechanism [5,6,7,8,9].",237,3,16,INTRODUCTION,INTRODUCTION,"DNN-HMM hybrid models with pre-segmented alignments or offline models based on Transformer [3,4], which is the state-of-the-art in many sequence-sequence tasks nowadays.",INTRODUCTION,"Especially, Monotonic Attention (MA), and Monotonic Chunkwise Attention (MoChA) [8,9] learn alignments in an end-to-end manner by calculating differentiable expected alignments in training phase and shows comparable performance to models using an offline attention.",NC,
2381,"Especially, Monotonic Attention (MA), and Monotonic Chunkwise Attention (MoChA) [8,9] learn alignments in an end-to-end manner by calculating differentiable expected alignments in training phase and shows comparable performance to models using an offline attention.",238,3,17,INTRODUCTION,INTRODUCTION,"In order to overcome this performance-delay trade-off, several attempts have been made to learn or find monotonic alignments between source and target via attention mechanism [5,6,7,8,9].",INTRODUCTION,"Very recently, motivated by the success of Transformer architecture even in ASR [4], direct attempts to make it online by applying these learning alignment strategies to Transformer, not on the traditional RNN based models, are emerging [10,11,12,13].",NC,
2382,"Very recently, motivated by the success of Transformer architecture even in ASR [4], direct attempts to make it online by applying these learning alignment strategies to Transformer, not on the traditional RNN based models, are emerging [10,11,12,13].",239,3,18,INTRODUCTION,INTRODUCTION,"Especially, Monotonic Attention (MA), and Monotonic Chunkwise Attention (MoChA) [8,9] learn alignments in an end-to-end manner by calculating differentiable expected alignments in training phase and shows comparable performance to models using an offline attention.",INTRODUCTION,"Among others, Monotonic Multihead Attention (MMA) [14] converts each of multi-heads in Transformer to MA and exploits the diversity of alignments from multiple heads.",NC,
2383,"Among others, Monotonic Multihead Attention (MMA) [14] converts each of multi-heads in Transformer to MA and exploits the diversity of alignments from multiple heads.",240,3,19,INTRODUCTION,INTRODUCTION,"Very recently, motivated by the success of Transformer architecture even in ASR [4], direct attempts to make it online by applying these learning alignment strategies to Transformer, not on the traditional RNN based models, are emerging [10,11,12,13].",INTRODUCTION,"In order to resolve the issue of MMA that has to wait for all multi-heads to decode, HeadDrop [15] drops heads stochastically in the training stage.",NC,
2384,"In order to resolve the issue of MMA that has to wait for all multi-heads to decode, HeadDrop [15] drops heads stochastically in the training stage.",241,3,20,INTRODUCTION,INTRODUCTION,"Among others, Monotonic Multihead Attention (MMA) [14] converts each of multi-heads in Transformer to MA and exploits the diversity of alignments from multiple heads.",INTRODUCTION,"[15] also proposed to use head-synchronous beam search decoding (HSD) which limits the difference in selection time between the heads in the same layer only in the inference phase, but resulting in the discrepancy between training and inference.",NC,
2385,"[15] also proposed to use head-synchronous beam search decoding (HSD) which limits the difference in selection time between the heads in the same layer only in the inference phase, but resulting in the discrepancy between training and inference.",242,3,21,INTRODUCTION,INTRODUCTION,"In order to resolve the issue of MMA that has to wait for all multi-heads to decode, HeadDrop [15] drops heads stochastically in the training stage.",INTRODUCTION,"In this paper, we propose an algorithm, called ""Mutually-Constrained Monotonic Multihead Attention"" (MCMMA), that enables the model to learns alignments along with other heads by modifying expected alignments to consistently bring constrained alignments of the test time to the training time.",NC,
2386,"In this paper, we propose an algorithm, called ""Mutually-Constrained Monotonic Multihead Attention"" (MCMMA), that enables the model to learns alignments along with other heads by modifying expected alignments to consistently bring constrained alignments of the test time to the training time.",243,3,22,INTRODUCTION,INTRODUCTION,"[15] also proposed to use head-synchronous beam search decoding (HSD) which limits the difference in selection time between the heads in the same layer only in the inference phase, but resulting in the discrepancy between training and inference.",INTRODUCTION,"By bridging the gap between the training and the test stages, MCMMA effectively improves performance.",FACT,
2387,"By bridging the gap between the training and the test stages, MCMMA effectively improves performance.",244,3,23,INTRODUCTION,INTRODUCTION,"In this paper, we propose an algorithm, called ""Mutually-Constrained Monotonic Multihead Attention"" (MCMMA), that enables the model to learns alignments along with other heads by modifying expected alignments to consistently bring constrained alignments of the test time to the training time.",PRELIMINARY,"We first review the main components which our model is based on, including monotonic attention, monotonic multihead attention, and HeadDrop with head-synchronous beam search decoding in Subsection 2.1, 2.2, and 2.3, respectively.",POS,
2388,"We first review the main components which our model is based on, including monotonic attention, monotonic multihead attention, and HeadDrop with head-synchronous beam search decoding in Subsection 2.1, 2.2, and 2.3, respectively.",245,3,24,PRELIMINARY,INTRODUCTION,"By bridging the gap between the training and the test stages, MCMMA effectively improves performance.",Monotonic Attention,MA [8] is the attention-based encoder-decoder RNN model which is able to learn monotonic alignments in an end-toend manner.,NC,
2389,MA [8] is the attention-based encoder-decoder RNN model which is able to learn monotonic alignments in an end-toend manner.,246,3,25,Monotonic Attention,PRELIMINARY,"We first review the main components which our model is based on, including monotonic attention, monotonic multihead attention, and HeadDrop with head-synchronous beam search decoding in Subsection 2.1, 2.2, and 2.3, respectively.",Monotonic Attention,"The encoder processes input sequence x = (x 1 , .",NC,
2390,"The encoder processes input sequence x = (x 1 , .",247,3,26,Monotonic Attention,Monotonic Attention,MA [8] is the attention-based encoder-decoder RNN model which is able to learn monotonic alignments in an end-toend manner.,Monotonic Attention,", x T ) to encoder states h = (h 1 , .",NC,
2391,", x T ) to encoder states h = (h 1 , .",248,3,27,Monotonic Attention,Monotonic Attention,"The encoder processes input sequence x = (x 1 , .",Monotonic Attention,"At i-th arXiv:2103.14302v1 [cs.CL] 26 Mar 2021 output step, the decoder sequentially inspects encoder states from the last selected one in the previous step and decide whether to take it or not to produce current output.",NC,
2392,"At i-th arXiv:2103.14302v1 [cs.CL] 26 Mar 2021 output step, the decoder sequentially inspects encoder states from the last selected one in the previous step and decide whether to take it or not to produce current output.",249,3,28,Monotonic Attention,Monotonic Attention,", x T ) to encoder states h = (h 1 , .",Monotonic Attention,"The probability p i,j to select h j for i-th output is computed as e i,j = MonotonicEnergy (s i-1 , h j ) and p i,j = σ (e i,j ) where s i-1 is a decoder state of (i -1)-th output step.",NC,
2393,"The probability p i,j to select h j for i-th output is computed as e i,j = MonotonicEnergy (s i-1 , h j ) and p i,j = σ (e i,j ) where s i-1 is a decoder state of (i -1)-th output step.",250,3,29,Monotonic Attention,Monotonic Attention,"At i-th arXiv:2103.14302v1 [cs.CL] 26 Mar 2021 output step, the decoder sequentially inspects encoder states from the last selected one in the previous step and decide whether to take it or not to produce current output.",Monotonic Attention,"If h j is selected, the RNN decoder takes it as context c i = h j with the previous decoder state s i-1 and output y i-1 to compute current state.",NC,
2394,"If h j is selected, the RNN decoder takes it as context c i = h j with the previous decoder state s i-1 and output y i-1 to compute current state.",251,3,30,Monotonic Attention,Monotonic Attention,"The probability p i,j to select h j for i-th output is computed as e i,j = MonotonicEnergy (s i-1 , h j ) and p i,j = σ (e i,j ) where s i-1 is a decoder state of (i -1)-th output step.",Monotonic Attention,"To make alignment learnable in the training phase, a hard selected context above is replaced by a expected context c i = L j=1 α i,j h j , the weighted sum of h with the expected alignment α computed as α i,j = p i,j j k=1 α i-1,k j-1 l=k (1 -p i,l ) .",NC,
2395,"To make alignment learnable in the training phase, a hard selected context above is replaced by a expected context c i = L j=1 α i,j h j , the weighted sum of h with the expected alignment α computed as α i,j = p i,j j k=1 α i-1,k j-1 l=k (1 -p i,l ) .",252,3,31,Monotonic Attention,Monotonic Attention,"If h j is selected, the RNN decoder takes it as context c i = h j with the previous decoder state s i-1 and output y i-1 to compute current state.",Monotonic Attention,(1) MoChA [9] extends MA by performing soft attention over fixed-length chunks of encoder states preceding the position chosen by a MA mechanism.,NC,
2396,(1) MoChA [9] extends MA by performing soft attention over fixed-length chunks of encoder states preceding the position chosen by a MA mechanism.,253,3,32,Monotonic Attention,Monotonic Attention,"To make alignment learnable in the training phase, a hard selected context above is replaced by a expected context c i = L j=1 α i,j h j , the weighted sum of h with the expected alignment α computed as α i,j = p i,j j k=1 α i-1,k j-1 l=k (1 -p i,l ) .",Monotonic Multihead Attention,MMA [14] applies MA mechanism to Transformer [3] by making each of the multiple heads of decoder-encoder attention learn monotonic alignments as MA.,NC,
2397,MMA [14] applies MA mechanism to Transformer [3] by making each of the multiple heads of decoder-encoder attention learn monotonic alignments as MA.,254,3,33,Monotonic Multihead Attention,Monotonic Attention,(1) MoChA [9] extends MA by performing soft attention over fixed-length chunks of encoder states preceding the position chosen by a MA mechanism.,Monotonic Multihead Attention,MMA borrows scaled dot-product operation of Transformer.,NC,
2398,MMA borrows scaled dot-product operation of Transformer.,255,3,34,Monotonic Multihead Attention,Monotonic Multihead Attention,MMA [14] applies MA mechanism to Transformer [3] by making each of the multiple heads of decoder-encoder attention learn monotonic alignments as MA.,Monotonic Multihead Attention,"Although MMA leads to considerable improvement in online machine translation, the latency is still high since the model should wait until all heads to select their contexts for every decoding step.",NC,
2399,"Although MMA leads to considerable improvement in online machine translation, the latency is still high since the model should wait until all heads to select their contexts for every decoding step.",256,3,35,Monotonic Multihead Attention,Monotonic Multihead Attention,MMA borrows scaled dot-product operation of Transformer.,Monotonic Multihead Attention,"Thus, the authors of [14] proposed to use additional regularization to minimize the variance of expected alignments of all heads to reduce the latency.",NC,
2400,"Thus, the authors of [14] proposed to use additional regularization to minimize the variance of expected alignments of all heads to reduce the latency.",257,3,36,Monotonic Multihead Attention,Monotonic Multihead Attention,"Although MMA leads to considerable improvement in online machine translation, the latency is still high since the model should wait until all heads to select their contexts for every decoding step.",Monotonic Multihead Attention,"Nevertheless, this approach does not model the dependency between heads explicitly.",NC,
2401,"Nevertheless, this approach does not model the dependency between heads explicitly.",258,3,37,Monotonic Multihead Attention,Monotonic Multihead Attention,"Thus, the authors of [14] proposed to use additional regularization to minimize the variance of expected alignments of all heads to reduce the latency.",HeadDrop and Head-Synchronous Decoding,HeadDrop [15] is the method that drops each head stochastically for each individual to learn alignments correctly.,NC,
2402,HeadDrop [15] is the method that drops each head stochastically for each individual to learn alignments correctly.,259,3,38,HeadDrop and Head-Synchronous Decoding,Monotonic Multihead Attention,"Nevertheless, this approach does not model the dependency between heads explicitly.",HeadDrop and Head-Synchronous Decoding,This approach improves boundary coverage and streamability of MMA [15].,NC,
2403,This approach improves boundary coverage and streamability of MMA [15].,260,3,39,HeadDrop and Head-Synchronous Decoding,HeadDrop and Head-Synchronous Decoding,HeadDrop [15] is the method that drops each head stochastically for each individual to learn alignments correctly.,HeadDrop and Head-Synchronous Decoding,"Head-synchronous decoding (HSD) [15] is the inference algorithm, where the leftmost head forces slow heads, which fail to choose any frames within waiting time threshold , to choose the rightmost of selected frames.",NC,
2404,"Head-synchronous decoding (HSD) [15] is the inference algorithm, where the leftmost head forces slow heads, which fail to choose any frames within waiting time threshold , to choose the rightmost of selected frames.",261,3,40,HeadDrop and Head-Synchronous Decoding,HeadDrop and Head-Synchronous Decoding,This approach improves boundary coverage and streamability of MMA [15].,HeadDrop and Head-Synchronous Decoding,"However, HSD considers alignments of other heads and only at the test phase.",NC,
2405,"However, HSD considers alignments of other heads and only at the test phase.",262,3,41,HeadDrop and Head-Synchronous Decoding,HeadDrop and Head-Synchronous Decoding,"Head-synchronous decoding (HSD) [15] is the inference algorithm, where the leftmost head forces slow heads, which fail to choose any frames within waiting time threshold , to choose the rightmost of selected frames.",METHOD,"In this section, we propose the algorithm to learn alignments of MA heads under a constraint of the difference of heads' alignments within each decoder layer.",NC,
2406,Boundary coverage and streamability [15] is the metric to evaluate whether the model is streamable.,263,3,82,Relative Latency,Experiment setup,"We utilize 2 CNN blocks for encoder and apply max-pooling with 2-stride after the second CNN block, the fourth, and the eighth layer in AISHELL-1.",Relative Latency,"However, it does not well suit with the MMA mechanism since predicting each output is done when the last head completes the selection.",NC,
2407,"However, it does not well suit with the MMA mechanism since predicting each output is done when the last head completes the selection.",264,3,83,Relative Latency,Relative Latency,Boundary coverage and streamability [15] is the metric to evaluate whether the model is streamable.,Relative Latency,"Instead of the above, we utilize the relative latency (ReL) by  We note that ReL is the natural extension of the existing latency metric.",NC,
2408,"Instead of the above, we utilize the relative latency (ReL) by  We note that ReL is the natural extension of the existing latency metric.",265,3,84,Relative Latency,Relative Latency,"However, it does not well suit with the MMA mechanism since predicting each output is done when the last head completes the selection.",Relative Latency,[23] provides the utterance-level latency which is the same with ReL when replacing the boundaries produced by the reference model with the gold boundaries in the definition of relative latency.,NC,
2409,[23] provides the utterance-level latency which is the same with ReL when replacing the boundaries produced by the reference model with the gold boundaries in the definition of relative latency.,266,3,85,Relative Latency,Relative Latency,"Instead of the above, we utilize the relative latency (ReL) by  We note that ReL is the natural extension of the existing latency metric.",Relative Latency,"However, acquiring the gold boundaries is complicated, so we utilize the boundaries of MMA without HSD as the reference boundaries.",NC,
2410,"However, acquiring the gold boundaries is complicated, so we utilize the boundaries of MMA without HSD as the reference boundaries.",267,3,86,Relative Latency,Relative Latency,[23] provides the utterance-level latency which is the same with ReL when replacing the boundaries produced by the reference model with the gold boundaries in the definition of relative latency.,Online ASR Results,We present the results of our approach with baselines in table 1.,NC,
2411,We present the results of our approach with baselines in table 1.,268,3,87,Online ASR Results,Relative Latency,"However, acquiring the gold boundaries is complicated, so we utilize the boundaries of MMA without HSD as the reference boundaries.",Online ASR Results,"We train our model with = 10 and = 12 on Librispeech and AISHELL-1, respectively and evaluate it with = 8 to make the setting same with [15].",NC,
2412,"We train our model with = 10 and = 12 on Librispeech and AISHELL-1, respectively and evaluate it with = 8 to make the setting same with [15].",269,3,88,Online ASR Results,Online ASR Results,We present the results of our approach with baselines in table 1.,Online ASR Results,Our model shows better performance than the baselines including HeadDrop [15].,NC,
2413,Our model shows better performance than the baselines including HeadDrop [15].,270,3,89,Online ASR Results,Online ASR Results,"We train our model with = 10 and = 12 on Librispeech and AISHELL-1, respectively and evaluate it with = 8 to make the setting same with [15].",Online ASR Results,"Especially, we reduce 2.2% of WER than HeadDrop [15] on testother in Librispeech.",POS,
2414,"Especially, we reduce 2.2% of WER than HeadDrop [15] on testother in Librispeech.",271,3,90,Online ASR Results,Online ASR Results,Our model shows better performance than the baselines including HeadDrop [15].,Online ASR Results,These results show that training alignments together with other heads' selection time improves the performance.,POS,
2415,These results show that training alignments together with other heads' selection time improves the performance.,272,3,91,Online ASR Results,Online ASR Results,"Especially, we reduce 2.2% of WER than HeadDrop [15] on testother in Librispeech.",Online ASR Results,One very interesting and unexpected point we observed in table 1 is that the WER of Transformer is higher than online models (except for MMA) in test-clean experiments.,POS,
2416,One very interesting and unexpected point we observed in table 1 is that the WER of Transformer is higher than online models (except for MMA) in test-clean experiments.,273,3,92,Online ASR Results,Online ASR Results,These results show that training alignments together with other heads' selection time improves the performance.,Online ASR Results,We con- jecture that online attention mechanisms are beneficial to exploit locality since they strongly force models to attend small chunks of an input sequence from the training phase.,POS,
2417,We con- jecture that online attention mechanisms are beneficial to exploit locality since they strongly force models to attend small chunks of an input sequence from the training phase.,274,3,93,Online ASR Results,Online ASR Results,One very interesting and unexpected point we observed in table 1 is that the WER of Transformer is higher than online models (except for MMA) in test-clean experiments.,Trade-off between Performance and Latency,"We provide trade-off graphs between quality and relative latency in fig 2 through adjusting ∈ {6, 8, 10, 12}, and ∈ {4, 8, 12} in inference time for Librispeech, and AISHELL-1, respectively.",POS,
2418,"We provide trade-off graphs between quality and relative latency in fig 2 through adjusting ∈ {6, 8, 10, 12}, and ∈ {4, 8, 12} in inference time for Librispeech, and AISHELL-1, respectively.",275,3,94,Trade-off between Performance and Latency,Online ASR Results,We con- jecture that online attention mechanisms are beneficial to exploit locality since they strongly force models to attend small chunks of an input sequence from the training phase.,Trade-off between Performance and Latency,"To calculate relative latency with time units, we multiply frame-level relative latency by 80ms since the reducing factor of frames is 8 and the shifting size is 10ms.",NC,
2419,"To calculate relative latency with time units, we multiply frame-level relative latency by 80ms since the reducing factor of frames is 8 and the shifting size is 10ms.",276,3,95,Trade-off between Performance and Latency,Trade-off between Performance and Latency,"We provide trade-off graphs between quality and relative latency in fig 2 through adjusting ∈ {6, 8, 10, 12}, and ∈ {4, 8, 12} in inference time for Librispeech, and AISHELL-1, respectively.",Trade-off between Performance and Latency,Our model outperforms baselines and is still faster than MMA without HSD even though there are small increases in relative latency compared to HeadDrop except for the case with extremely small text .,NC,
2420,Our model outperforms baselines and is still faster than MMA without HSD even though there are small increases in relative latency compared to HeadDrop except for the case with extremely small text .,277,3,96,Trade-off between Performance and Latency,Trade-off between Performance and Latency,"To calculate relative latency with time units, we multiply frame-level relative latency by 80ms since the reducing factor of frames is 8 and the shifting size is 10ms.",Trade-off between Performance and Latency,The performance degradation with small occurs since accessible input information is very limited and training models with small restricts head diversity severely.,POS,
2421,The performance degradation with small occurs since accessible input information is very limited and training models with small restricts head diversity severely.,278,3,97,Trade-off between Performance and Latency,Trade-off between Performance and Latency,Our model outperforms baselines and is still faster than MMA without HSD even though there are small increases in relative latency compared to HeadDrop except for the case with extremely small text .,Trade-off between Performance and Latency,"Thus, this result suggests that the practitioners should avoid choosing small .",NC,explication d'un résultat
2422,"Thus, this result suggests that the practitioners should avoid choosing small .",279,3,98,Trade-off between Performance and Latency,Trade-off between Performance and Latency,The performance degradation with small occurs since accessible input information is very limited and training models with small restricts head diversity severely.,CONCLUSION,We suggest the method to learn alignments with considering other heads' alignments by modifying expected alignments for all the heads of each layer to select an input frame within a fixed size window.,POS,
2423,We suggest the method to learn alignments with considering other heads' alignments by modifying expected alignments for all the heads of each layer to select an input frame within a fixed size window.,280,3,99,CONCLUSION,Trade-off between Performance and Latency,"Thus, this result suggests that the practitioners should avoid choosing small .",CONCLUSION,Our approach improves performance with only a small increase in latency by regularizing the intra-layer difference of boundaries effectively from the training phase.,FACT,
2424,Our approach improves performance with only a small increase in latency by regularizing the intra-layer difference of boundaries effectively from the training phase.,281,3,100,CONCLUSION,CONCLUSION,We suggest the method to learn alignments with considering other heads' alignments by modifying expected alignments for all the heads of each layer to select an input frame within a fixed size window.,,,POS,
2425,This paper develops a Case/case-theoretic acco unt for what Merchant (2008) calls voice mism atch in ellipsis constructions of English.,282,4,0,abstract,,,abstract,Merch ant (ibid.),FACT,
2426,Merch ant (ibid.),283,4,1,abstract,abstract,This paper develops a Case/case-theoretic acco unt for what Merchant (2008) calls voice mism atch in ellipsis constructions of English.,abstract,"reports that VP ellipsis as an elision o f smaller size VP allows voice mismatch, but Ps eudogapping and Sluicing as an elision of bigge r size vP/TP do not.",NC,
2427,"reports that VP ellipsis as an elision o f smaller size VP allows voice mismatch, but Ps eudogapping and Sluicing as an elision of bigge r size vP/TP do not.",284,4,2,abstract,abstract,Merch ant (ibid.),abstract,"However, Tanaka (2011) ar gues against Merchant's dichotomy in voice mis match between VP ellipsis and Pseudogapping, reporting that voice mismatch in both types of e llipsis is permissible or not while interacting wi th what Kehler (2000) calls discourse coherence relations between ellipsis and antecedent clause s. Departing from Kehler's (2000) insight, we s uggest that vP undergoes ellipsis in a resemblan ce discourse relation, but VP does so in a cause/ effect discourse relation.",NC,
2428,"However, Tanaka (2011) ar gues against Merchant's dichotomy in voice mis match between VP ellipsis and Pseudogapping, reporting that voice mismatch in both types of e llipsis is permissible or not while interacting wi th what Kehler (2000) calls discourse coherence relations between ellipsis and antecedent clause s. Departing from Kehler's (2000) insight, we s uggest that vP undergoes ellipsis in a resemblan ce discourse relation, but VP does so in a cause/ effect discourse relation.",285,4,3,abstract,abstract,"reports that VP ellipsis as an elision o f smaller size VP allows voice mismatch, but Ps eudogapping and Sluicing as an elision of bigge r size vP/TP do not.",abstract,"Given the asymmetry i n the size of ellipsis in tandem with discourse re lations, we argue that since Accusative as well as Nominative Case is checked outside VP, the VP to be elided can meet the identity condition on ellipsis with its antecedent VP as the object element in the former and the subject one in the latter or vice versus have not been Case-checke d yet, thus being identical in terms of Case-feat ure at the point of derivation building a VP.",POS,caractères espace --> pb au niveau du XML ?
2429,"Given the asymmetry i n the size of ellipsis in tandem with discourse re lations, we argue that since Accusative as well as Nominative Case is checked outside VP, the VP to be elided can meet the identity condition on ellipsis with its antecedent VP as the object element in the former and the subject one in the latter or vice versus have not been Case-checke d yet, thus being identical in terms of Case-feat ure at the point of derivation building a VP.",286,4,4,abstract,abstract,"However, Tanaka (2011) ar gues against Merchant's dichotomy in voice mis match between VP ellipsis and Pseudogapping, reporting that voice mismatch in both types of e llipsis is permissible or not while interacting wi th what Kehler (2000) calls discourse coherence relations between ellipsis and antecedent clause s. Departing from Kehler's (2000) insight, we s uggest that vP undergoes ellipsis in a resemblan ce discourse relation, but VP does so in a cause/ effect discourse relation.",Introduction,"According to Merchant (2008), VP ellipsis (VPE) in English allows mismatch between the voice of an elided constituent and that of its antecedent, whereas Sluicing and Pseudogapping do not.",POS,
2430,"According to Merchant (2008), VP ellipsis (VPE) in English allows mismatch between the voice of an elided constituent and that of its antecedent, whereas Sluicing and Pseudogapping do not.",287,4,5,Introduction,abstract,"Given the asymmetry i n the size of ellipsis in tandem with discourse re lations, we argue that since Accusative as well as Nominative Case is checked outside VP, the VP to be elided can meet the identity condition on ellipsis with its antecedent VP as the object element in the former and the subject one in the latter or vice versus have not been Case-checke d yet, thus being identical in terms of Case-feat ure at the point of derivation building a VP.",Introduction,This holds for either direction of voice alternation between an elided constituent and its antecedent.,NC,
2431,This holds for either direction of voice alternation between an elided constituent and its antecedent.,288,4,6,Introduction,Introduction,"According to Merchant (2008), VP ellipsis (VPE) in English allows mismatch between the voice of an elided constituent and that of its antecedent, whereas Sluicing and Pseudogapping do not.",Introduction,"This is illustrated in (1) through (3) (( 1) and (3), taken from Merchant (2008: 169-170); (2), taken from Merchant (2013: 81)).",NC,
2432,"This is illustrated in (1) through (3) (( 1) and (3), taken from Merchant (2008: 169-170); (2), taken from Merchant (2013: 81)).",289,4,7,Introduction,Introduction,This holds for either direction of voice alternation between an elided constituent and its antecedent.,Introduction,"(1) Active antecedent, passive ellipsis (VPE) a.",NC,
2433,"(1) Active antecedent, passive ellipsis (VPE) a.",290,4,8,Introduction,Introduction,"This is illustrated in (1) through (3) (( 1) and (3), taken from Merchant (2008: 169-170); (2), taken from Merchant (2013: 81)).",Introduction,The janitor must <remove the trash 1 > whenever it is apparent that [it] 1 should be [ VP removed t 1 ].,NC,
2434,The janitor must <remove the trash 1 > whenever it is apparent that [it] 1 should be [ VP removed t 1 ].,291,4,9,Introduction,Introduction,"(1) Active antecedent, passive ellipsis (VPE) a.",Introduction,"Passive antecedent, active ellipsis (VPE) b.",NC,
2435,"Passive antecedent, active ellipsis (VPE) b.",292,4,10,Introduction,Introduction,The janitor must <remove the trash 1 > whenever it is apparent that [it] 1 should be [ VP removed t 1 ].,Introduction,[The system] 1 can be <used t 1 > by anyone who wants to [ VP use it 1 ].,NC,
2436,[The system] 1 can be <used t 1 > by anyone who wants to [ VP use it 1 ].,293,4,11,Introduction,Introduction,"Passive antecedent, active ellipsis (VPE) b.",Introduction,"(2) Sluicing (TPE) *<Joe was murdered t>, but we don't know [who] 1 [ TP t 1 murdered Joe].",NC,
2437,"(2) Sluicing (TPE) *<Joe was murdered t>, but we don't know [who] 1 [ TP t 1 murdered Joe].",294,4,12,Introduction,Introduction,[The system] 1 can be <used t 1 > by anyone who wants to [ VP use it 1 ].,Introduction,"(3) Pseudogapping *Roses were brought by some, and others did bring lilies.",NC,
2438,"(3) Pseudogapping *Roses were brought by some, and others did bring lilies.",295,4,13,Introduction,Introduction,"(2) Sluicing (TPE) *<Joe was murdered t>, but we don't know [who] 1 [ TP t 1 murdered Joe].",Introduction,This paper examines the very issue of voice mismatch in the above three types of ellipsis in English.,NC,
2439,This paper examines the very issue of voice mismatch in the above three types of ellipsis in English.,296,4,14,Introduction,Introduction,"(3) Pseudogapping *Roses were brought by some, and others did bring lilies.",Introduction,"The next section reviews Merchant's (2007Merchant's ( , 2008) ) analysis of voice mismatch in ellipsis by postulating the functional category of Voice in the syntactic structure of a clause, and the subsequent rebuttal of Merchant's analysis by Tanaka (2011).",FACT,
2440,"The next section reviews Merchant's (2007Merchant's ( , 2008) ) analysis of voice mismatch in ellipsis by postulating the functional category of Voice in the syntactic structure of a clause, and the subsequent rebuttal of Merchant's analysis by Tanaka (2011).",297,4,15,Introduction,Introduction,This paper examines the very issue of voice mismatch in the above three types of ellipsis in English.,Introduction,"Departing from the empirical generalization made by Tanaka, section 3 proposes a not Voice-but Case/case-theoretic account for apparent voice mismatch in VP ellipsis and Pseudogapping.",NC,
2441,"Departing from the empirical generalization made by Tanaka, section 3 proposes a not Voice-but Case/case-theoretic account for apparent voice mismatch in VP ellipsis and Pseudogapping.",298,4,16,Introduction,Introduction,"The next section reviews Merchant's (2007Merchant's ( , 2008) ) analysis of voice mismatch in ellipsis by postulating the functional category of Voice in the syntactic structure of a clause, and the subsequent rebuttal of Merchant's analysis by Tanaka (2011).",Introduction,Section 4 investigates argument structure mismatch and its interaction with Pseudogapping.,NC,
2442,Section 4 investigates argument structure mismatch and its interaction with Pseudogapping.,299,4,17,Introduction,Introduction,"Departing from the empirical generalization made by Tanaka, section 3 proposes a not Voice-but Case/case-theoretic account for apparent voice mismatch in VP ellipsis and Pseudogapping.",Introduction,Section 5 explores a Case/casetheoretic account for voice mismatch in Sluicing.,NC,
2443,Section 5 explores a Case/casetheoretic account for voice mismatch in Sluicing.,300,4,18,Introduction,Introduction,Section 4 investigates argument structure mismatch and its interaction with Pseudogapping.,Introduction,Section 6 wraps up with a conclusion.,NC,
2444,Section 6 wraps up with a conclusion.,301,4,19,Introduction,Introduction,Section 5 explores a Case/casetheoretic account for voice mismatch in Sluicing.,No asymmetry in voice match between VP ellipsis and Pseudogapping,Consider the examples in (4) and (5).,NC,
2445,Consider the examples in (4) and (5).,302,4,20,No asymmetry in voice match between VP ellipsis and Pseudogapping,Introduction,Section 6 wraps up with a conclusion.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"It seems clear that voice mismatch is disallowed only in some of elliptical structures like VP ellipsis, Pseudogapping and Sluicing.",NC,
2446,"It seems clear that voice mismatch is disallowed only in some of elliptical structures like VP ellipsis, Pseudogapping and Sluicing.",303,4,21,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,Consider the examples in (4) and (5).,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Unlike in the ellipsis structure of (4), voice mismatch is permissible in the non-elliptical structure of ( 5).",POS,claim tiré d'un exemple mais servant de point de départ aux auteurs
2447,"Unlike in the ellipsis structure of (4), voice mismatch is permissible in the non-elliptical structure of ( 5).",304,4,22,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"It seems clear that voice mismatch is disallowed only in some of elliptical structures like VP ellipsis, Pseudogapping and Sluicing.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"(4) *Roses were brought by some, and others did bring roses, too.",NC,
2448,"(4) *Roses were brought by some, and others did bring roses, too.",305,4,23,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Unlike in the ellipsis structure of (4), voice mismatch is permissible in the non-elliptical structure of ( 5).",No asymmetry in voice match between VP ellipsis and Pseudogapping,"(5) Roses were brought by some, and others brought roses, too.",NC,
2449,"(5) Roses were brought by some, and others brought roses, too.",306,4,24,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(4) *Roses were brought by some, and others did bring roses, too.",No asymmetry in voice match between VP ellipsis and Pseudogapping,Merchant's (2008) explanation for the contrast in voice mismatch between VP ellipsis and Pseudogapping in (1) and (2) hinges on the following assumptions: (6) Syntactic isomorphism is required for ellipsis.,NC,
2450,Merchant's (2008) explanation for the contrast in voice mismatch between VP ellipsis and Pseudogapping in (1) and (2) hinges on the following assumptions: (6) Syntactic isomorphism is required for ellipsis.,307,4,25,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(5) Roses were brought by some, and others brought roses, too.",No asymmetry in voice match between VP ellipsis and Pseudogapping,(7) The v head hosts the feature [voi(ce)] responsible for active versus passive voice.,NC,
2451,(7) The v head hosts the feature [voi(ce)] responsible for active versus passive voice.,308,4,26,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,Merchant's (2008) explanation for the contrast in voice mismatch between VP ellipsis and Pseudogapping in (1) and (2) hinges on the following assumptions: (6) Syntactic isomorphism is required for ellipsis.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(8) VP ellipsis deletes a VP, but Pseudogapping deletes a vP.",NC,
2452,"(8) VP ellipsis deletes a VP, but Pseudogapping deletes a vP.",309,4,27,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,(7) The v head hosts the feature [voi(ce)] responsible for active versus passive voice.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Like most previous studies on ellipsis, Merchant first takes ellipsis to be subject to a syntactic identity condition demanding that an elided constituent be identical syntactically to its antecedent.",NC,
2453,"Like most previous studies on ellipsis, Merchant first takes ellipsis to be subject to a syntactic identity condition demanding that an elided constituent be identical syntactically to its antecedent.",310,4,28,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(8) VP ellipsis deletes a VP, but Pseudogapping deletes a vP.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"Given syntactic isomorphism for ellipsis, the uneven distribution in voice mismatch between VP ellipsis and Pseudogapping in (1) and (2) follows from the two specific components in ( 7) and (8).",NC,
2454,"Given syntactic isomorphism for ellipsis, the uneven distribution in voice mismatch between VP ellipsis and Pseudogapping in (1) and (2) follows from the two specific components in ( 7) and (8).",311,4,29,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Like most previous studies on ellipsis, Merchant first takes ellipsis to be subject to a syntactic identity condition demanding that an elided constituent be identical syntactically to its antecedent.",No asymmetry in voice match between VP ellipsis and Pseudogapping,Merchant (2008) argues that Pseudogapping elides a vP rather than a VP.,NC,
2455,Merchant (2008) argues that Pseudogapping elides a vP rather than a VP.,312,4,30,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Given syntactic isomorphism for ellipsis, the uneven distribution in voice mismatch between VP ellipsis and Pseudogapping in (1) and (2) follows from the two specific components in ( 7) and (8).",No asymmetry in voice match between VP ellipsis and Pseudogapping,The elided constituent in Pseudogapping then includes the little v that has the value of the feature [voi] determined either as active or passive.,NC,
2456,The elided constituent in Pseudogapping then includes the little v that has the value of the feature [voi] determined either as active or passive.,313,4,31,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,Merchant (2008) argues that Pseudogapping elides a vP rather than a VP.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"When the ellipsis and the antecedent clauses are not identical in voice, Pseudogapping won't meet identity in ellipsis, hence being ruled out.",NC,
2457,"When the ellipsis and the antecedent clauses are not identical in voice, Pseudogapping won't meet identity in ellipsis, hence being ruled out.",314,4,32,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,The elided constituent in Pseudogapping then includes the little v that has the value of the feature [voi] determined either as active or passive.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"In VPE, however, the little v hosting the feature [voi] is not included in the VPE site.",NC,
2458,"In VPE, however, the little v hosting the feature [voi] is not included in the VPE site.",315,4,33,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"When the ellipsis and the antecedent clauses are not identical in voice, Pseudogapping won't meet identity in ellipsis, hence being ruled out.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"In other words, the head v is external to the VPE site.",NC,
2459,"In other words, the head v is external to the VPE site.",316,4,34,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"In VPE, however, the little v hosting the feature [voi] is not included in the VPE site.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"Thus, voice mismatch does not matter for VP ellipsis, not being able to exert its effects on identity in ellipsis.",NC,
2460,"Thus, voice mismatch does not matter for VP ellipsis, not being able to exert its effects on identity in ellipsis.",317,4,35,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"In other words, the head v is external to the VPE site.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"Though Merchant (2008) provides an effective account for the distributional generalization in voice mismatch between VP ellipsis and Pseudogapping, his account confronts several problems.",NC,
2461,"Though Merchant (2008) provides an effective account for the distributional generalization in voice mismatch between VP ellipsis and Pseudogapping, his account confronts several problems.",318,4,36,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Thus, voice mismatch does not matter for VP ellipsis, not being able to exert its effects on identity in ellipsis.",No asymmetry in voice match between VP ellipsis and Pseudogapping,The first problem concerns the size of ellipsis for Pseudogapping.,NC,
2462,The first problem concerns the size of ellipsis for Pseudogapping.,319,4,37,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Though Merchant (2008) provides an effective account for the distributional generalization in voice mismatch between VP ellipsis and Pseudogapping, his account confronts several problems.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"The previous works on Pseudogapping such as Jayaseelan (1990), Lansnik (1999: chap 3), Levin (1978), andTakahashi (2004) argue that Pseudogapping is an operation of VP ellipsis rather than vP ellipsis, as typical examples of Pseudogapping in ( 9) and (10) show.",NC,
2463,"The previous works on Pseudogapping such as Jayaseelan (1990), Lansnik (1999: chap 3), Levin (1978), andTakahashi (2004) argue that Pseudogapping is an operation of VP ellipsis rather than vP ellipsis, as typical examples of Pseudogapping in ( 9) and (10) show.",320,4,38,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,The first problem concerns the size of ellipsis for Pseudogapping.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(9) *Roses were brought by some, and others did bring lilies.",NC,
2464,"(9) *Roses were brought by some, and others did bring lilies.",321,4,39,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"The previous works on Pseudogapping such as Jayaseelan (1990), Lansnik (1999: chap 3), Levin (1978), andTakahashi (2004) argue that Pseudogapping is an operation of VP ellipsis rather than vP ellipsis, as typical examples of Pseudogapping in ( 9) and (10) show.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"(10) *Some brought roses, and lilies were brought by others.",NC,
2465,"(10) *Some brought roses, and lilies were brought by others.",322,4,40,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(9) *Roses were brought by some, and others did bring lilies.",No asymmetry in voice match between VP ellipsis and Pseudogapping,Merchant (2008) in fact brings forth the examples in ( 11) and ( 12) to support his thesis that Pseudogapping applies to a larger category than VP ellipsis.,NC,
2466,Merchant (2008) in fact brings forth the examples in ( 11) and ( 12) to support his thesis that Pseudogapping applies to a larger category than VP ellipsis.,323,4,41,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(10) *Some brought roses, and lilies were brought by others.",No asymmetry in voice match between VP ellipsis and Pseudogapping,The judgements reported in ( 11) and ( 12) are Merchant's.,NC,
2467,The judgements reported in ( 11) and ( 12) are Merchant's.,324,4,42,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,Merchant (2008) in fact brings forth the examples in ( 11) and ( 12) to support his thesis that Pseudogapping applies to a larger category than VP ellipsis.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(11) Many of them have turned in their assignment already, but they haven't yet all.",NC,
2468,"(11) Many of them have turned in their assignment already, but they haven't yet all.",325,4,43,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,The judgements reported in ( 11) and ( 12) are Merchant's.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(12) Many of them have turned in their assignment already, but they haven't yet (*all) their paper (*all).",NC,
2469,"(12) Many of them have turned in their assignment already, but they haven't yet (*all) their paper (*all).",326,4,44,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(11) Many of them have turned in their assignment already, but they haven't yet all.",No asymmetry in voice match between VP ellipsis and Pseudogapping,Merchant assumes with Sportiche (1988) that a floating quantifier like all can be dropped off in the specifier position of any functional category it has moved through.,NC,
2470,Merchant assumes with Sportiche (1988) that a floating quantifier like all can be dropped off in the specifier position of any functional category it has moved through.,327,4,45,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(12) Many of them have turned in their assignment already, but they haven't yet (*all) their paper (*all).",No asymmetry in voice match between VP ellipsis and Pseudogapping,"All in (11) presumably moves through [spec, vP].",NC,
2471,"All in (11) presumably moves through [spec, vP].",328,4,46,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,Merchant assumes with Sportiche (1988) that a floating quantifier like all can be dropped off in the specifier position of any functional category it has moved through.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Since the constituent elided in VP ellipsis, by assumption, is smaller than vP and all is external to ellipsis site, the sentence in ( 11) is received as acceptable.",NC,
2472,"Since the constituent elided in VP ellipsis, by assumption, is smaller than vP and all is external to ellipsis site, the sentence in ( 11) is received as acceptable.",329,4,47,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"All in (11) presumably moves through [spec, vP].",No asymmetry in voice match between VP ellipsis and Pseudogapping,"By contrast, the sentence in (12) involving Pseudogapping, according to Merchant, is ruled out because Pseudogapping elides a vP that includes the position all moves through; thus, the floating quantifier all should have been included in the portion elided by Pseudogapping.",NC,
2473,"By contrast, the sentence in (12) involving Pseudogapping, according to Merchant, is ruled out because Pseudogapping elides a vP that includes the position all moves through; thus, the floating quantifier all should have been included in the portion elided by Pseudogapping.",330,4,48,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Since the constituent elided in VP ellipsis, by assumption, is smaller than vP and all is external to ellipsis site, the sentence in ( 11) is received as acceptable.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"Tanaka (2011), however, consulted three native speakers to verify the acceptability of ( 13) and ( 14), which are identical to (11) and ( 12), but except for one modification by placing the aspectual adverb yet not before but after the floating quantifier all: (13) Many of them have turned in their assignment already, but they haven't all yet.",NC,
2474,"Tanaka (2011), however, consulted three native speakers to verify the acceptability of ( 13) and ( 14), which are identical to (11) and ( 12), but except for one modification by placing the aspectual adverb yet not before but after the floating quantifier all: (13) Many of them have turned in their assignment already, but they haven't all yet.",331,4,49,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"By contrast, the sentence in (12) involving Pseudogapping, according to Merchant, is ruled out because Pseudogapping elides a vP that includes the position all moves through; thus, the floating quantifier all should have been included in the portion elided by Pseudogapping.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"(14) ?Many of them have turned in their assignment already, but they haven't all yet their paper None of the native speakers that Tanaka consulted ruled out these two sentences.",NC,
2475,"(14) ?Many of them have turned in their assignment already, but they haven't all yet their paper None of the native speakers that Tanaka consulted ruled out these two sentences.",332,4,50,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Tanaka (2011), however, consulted three native speakers to verify the acceptability of ( 13) and ( 14), which are identical to (11) and ( 12), but except for one modification by placing the aspectual adverb yet not before but after the floating quantifier all: (13) Many of them have turned in their assignment already, but they haven't all yet.",No asymmetry in voice match between VP ellipsis and Pseudogapping,Tanaka (2011) takes the acceptability of these examples to indicate that both VP ellipsis and Pseudogapping may delete a VP.,NC,
2476,Tanaka (2011) takes the acceptability of these examples to indicate that both VP ellipsis and Pseudogapping may delete a VP.,333,4,51,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(14) ?Many of them have turned in their assignment already, but they haven't all yet their paper None of the native speakers that Tanaka consulted ruled out these two sentences.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"It may also be the case that all in (13) and ( 14) occupies a position outside a vP, in which case the entire vP can be deleted (See Tanaka (2011: 473)).",NC,
2477,"It may also be the case that all in (13) and ( 14) occupies a position outside a vP, in which case the entire vP can be deleted (See Tanaka (2011: 473)).",334,4,52,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,Tanaka (2011) takes the acceptability of these examples to indicate that both VP ellipsis and Pseudogapping may delete a VP.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Second, Merchant (2008: 170) notes that such Pseudogapping examples with voice mismatch as (15)-( 16) are unacceptable.",NC,
2478,"Second, Merchant (2008: 170) notes that such Pseudogapping examples with voice mismatch as (15)-( 16) are unacceptable.",335,4,53,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"It may also be the case that all in (13) and ( 14) occupies a position outside a vP, in which case the entire vP can be deleted (See Tanaka (2011: 473)).",No asymmetry in voice match between VP ellipsis and Pseudogapping,"(15) *Roses were brought by some, and others did bring lilies.",NC,
2479,"(15) *Roses were brought by some, and others did bring lilies.",336,4,54,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Second, Merchant (2008: 170) notes that such Pseudogapping examples with voice mismatch as (15)-( 16) are unacceptable.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"( 16) *Some brought roses, and lilies were brought by others.",NC,
2480,"( 16) *Some brought roses, and lilies were brought by others.",337,4,55,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(15) *Roses were brought by some, and others did bring lilies.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"Importantly, however, Tanaka (2011: 475) reports that their VP ellipsis counterparts in (17)-( 18) are also unacceptable: (17) *Roses were brought by some boys, and some girls did bring roses, too.",NC,
2481,"Importantly, however, Tanaka (2011: 475) reports that their VP ellipsis counterparts in (17)-( 18) are also unacceptable: (17) *Roses were brought by some boys, and some girls did bring roses, too.",338,4,56,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"( 16) *Some brought roses, and lilies were brought by others.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"(18) *Some brought roses, and lilies were brought by some, too.",NC,
2482,"(18) *Some brought roses, and lilies were brought by some, too.",339,4,57,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Importantly, however, Tanaka (2011: 475) reports that their VP ellipsis counterparts in (17)-( 18) are also unacceptable: (17) *Roses were brought by some boys, and some girls did bring roses, too.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"Since ungrammatical Pseudogapping examples remain to be ungrammatical even under VP ellipsis, it may safely be concluded that there is no asymmetry between the two constructions in terms of the size of ellipsis.",NC,
2483,"Since ungrammatical Pseudogapping examples remain to be ungrammatical even under VP ellipsis, it may safely be concluded that there is no asymmetry between the two constructions in terms of the size of ellipsis.",340,4,58,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(18) *Some brought roses, and lilies were brought by some, too.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"Tanaka (2011: 476)  The additional pairs in ( 21)-( 22), which are taken from Tanaka (2011: 476), do not display asymmetry in voice mismatch between Pseudogapping and VP ellipsis: (21) Actually, I have implemented a computer system with a manager, but it doesn't have to be implemented with a manager.",NC,
2484,"Tanaka (2011: 476)  The additional pairs in ( 21)-( 22), which are taken from Tanaka (2011: 476), do not display asymmetry in voice mismatch between Pseudogapping and VP ellipsis: (21) Actually, I have implemented a computer system with a manager, but it doesn't have to be implemented with a manager.",341,4,59,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Since ungrammatical Pseudogapping examples remain to be ungrammatical even under VP ellipsis, it may safely be concluded that there is no asymmetry between the two constructions in terms of the size of ellipsis.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"( 22) ?Actually, I have implemented a computer system with a manager, but it should have been implemented by a computer technician.",NC,
2485,"( 22) ?Actually, I have implemented a computer system with a manager, but it should have been implemented by a computer technician.",342,4,60,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Tanaka (2011: 476)  The additional pairs in ( 21)-( 22), which are taken from Tanaka (2011: 476), do not display asymmetry in voice mismatch between Pseudogapping and VP ellipsis: (21) Actually, I have implemented a computer system with a manager, but it doesn't have to be implemented with a manager.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"Third, the additional rebuttal of Merchant's (2008)  (big, resemblance, mismatched) c. because she told me who.",NC,
2486,"Third, the additional rebuttal of Merchant's (2008)  (big, resemblance, mismatched) c. because she told me who.",343,4,61,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"( 22) ?Actually, I have implemented a computer system with a manager, but it should have been implemented by a computer technician.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"(big, cause/effect, matched) d. because she told me by who.",NC,
2487,"(big, cause/effect, matched) d. because she told me by who.",344,4,62,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Third, the additional rebuttal of Merchant's (2008)  (big, resemblance, mismatched) c. because she told me who.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"(big, cause/effect, mismatched) e. and Lisa also knows that someone did.",NC,
2488,"(big, cause/effect, mismatched) e. and Lisa also knows that someone did.",345,4,63,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(big, cause/effect, matched) d. because she told me by who.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"(small, resemblance, matched) f. and Lisa also knows that it was.",NC,
2489,"(small, resemblance, matched) f. and Lisa also knows that it was.",346,4,64,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(big, cause/effect, mismatched) e. and Lisa also knows that someone did.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"(small, resemblance, mismatched) g. because she told me that someone did.",NC,
2490,"(small, resemblance, mismatched) g. because she told me that someone did.",347,4,65,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(small, resemblance, matched) f. and Lisa also knows that it was.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"(small, cause/effect, matched) h. because she told me that it was.",NC,
2491,"(small, cause/effect, matched) h. because she told me that it was.",348,4,66,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(small, resemblance, mismatched) g. because she told me that someone did.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"(small, cause/effect, mismatched) The results of the experiment (cited from SanPietro et al.",NC,
2492,"(small, cause/effect, mismatched) The results of the experiment (cited from SanPietro et al.",349,4,67,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(small, cause/effect, matched) h. because she told me that it was.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"(2012: 310)) are: first, the interaction between ellipsis size (small VP vs. big TP) and discourse relations (resemblance vs. cause/effect relations, which we will turn to shortly in the next section) shows that in the small elliptical conditions only, cause/effect conditions (conditions (g) and (h) of ( 23); mean rating of 4.94 out of the highest score 7) were rated higher than resemblance conditions (conditions (e) and (f) above; mean rating of 4.32).",NC,
2493,"(2012: 310)) are: first, the interaction between ellipsis size (small VP vs. big TP) and discourse relations (resemblance vs. cause/effect relations, which we will turn to shortly in the next section) shows that in the small elliptical conditions only, cause/effect conditions (conditions (g) and (h) of ( 23); mean rating of 4.94 out of the highest score 7) were rated higher than resemblance conditions (conditions (e) and (f) above; mean rating of 4.32).",350,4,68,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(small, cause/effect, mismatched) The results of the experiment (cited from SanPietro et al.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"Second, most critically, pairwise comparisons show a significant difference (p < .001) between the mismatched cause/effect condition (condition (h) above; mean rating of 4.42) and the mismatched resemblance condition (condition (f) above; mean rating of 3.69), but only in the VP ellipsis conditions.",NC,
2494,"Second, most critically, pairwise comparisons show a significant difference (p < .001) between the mismatched cause/effect condition (condition (h) above; mean rating of 4.42) and the mismatched resemblance condition (condition (f) above; mean rating of 3.69), but only in the VP ellipsis conditions.",351,4,69,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(2012: 310)) are: first, the interaction between ellipsis size (small VP vs. big TP) and discourse relations (resemblance vs. cause/effect relations, which we will turn to shortly in the next section) shows that in the small elliptical conditions only, cause/effect conditions (conditions (g) and (h) of ( 23); mean rating of 4.94 out of the highest score 7) were rated higher than resemblance conditions (conditions (e) and (f) above; mean rating of 4.32).",No asymmetry in voice match between VP ellipsis and Pseudogapping,"No effect of coherence (i.e., discourse relation) is found in the big elliptical conditions (conditions (a-d) above).",NC,
2495,"No effect of coherence (i.e., discourse relation) is found in the big elliptical conditions (conditions (a-d) above).",352,4,70,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Second, most critically, pairwise comparisons show a significant difference (p < .001) between the mismatched cause/effect condition (condition (h) above; mean rating of 4.42) and the mismatched resemblance condition (condition (f) above; mean rating of 3.69), but only in the VP ellipsis conditions.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"These results of the experiment show that voice mismatch in VP ellipsis is not always permissible, unlike what Merchant (2008) argues.",NC,
2496,"These results of the experiment show that voice mismatch in VP ellipsis is not always permissible, unlike what Merchant (2008) argues.",353,4,71,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"No effect of coherence (i.e., discourse relation) is found in the big elliptical conditions (conditions (a-d) above).",No asymmetry in voice match between VP ellipsis and Pseudogapping,"Instead, discourse relations are a determining factor in ruling in or out voice mismatch in VP ellipsis.",NC,rapport détaillé des résultats d'un autre papier
2497,"Instead, discourse relations are a determining factor in ruling in or out voice mismatch in VP ellipsis.",354,4,72,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"These results of the experiment show that voice mismatch in VP ellipsis is not always permissible, unlike what Merchant (2008) argues.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"The conclusion drawn from the review of Merchant (2007Merchant ( , 2008) ) and Tanaka (2011) is that the former analysis based on the different sizes of ellipsis for VP ellipsis and Pseudogapping overgenerates and under-generates.",NC,
2498,"The conclusion drawn from the review of Merchant (2007Merchant ( , 2008) ) and Tanaka (2011) is that the former analysis based on the different sizes of ellipsis for VP ellipsis and Pseudogapping overgenerates and under-generates.",355,4,73,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Instead, discourse relations are a determining factor in ruling in or out voice mismatch in VP ellipsis.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"It over-predicts that all the examples involving mismatch in VP are acceptable, and at the same time it cannot predict that some of those involving voice mismatch in VP ellipsis are unacceptable.",POS,
2499,"It over-predicts that all the examples involving mismatch in VP are acceptable, and at the same time it cannot predict that some of those involving voice mismatch in VP ellipsis are unacceptable.",356,4,74,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"The conclusion drawn from the review of Merchant (2007Merchant ( , 2008) ) and Tanaka (2011) is that the former analysis based on the different sizes of ellipsis for VP ellipsis and Pseudogapping overgenerates and under-generates.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"In the next section, building on Kehler's (2000) insight into discourse relations between ellipsis and antecedent clauses, we argue that sizes of ellipsis for both VP ellipsis and Pseudogapping interact with such discourse relations.",POS,
2500,"In the next section, building on Kehler's (2000) insight into discourse relations between ellipsis and antecedent clauses, we argue that sizes of ellipsis for both VP ellipsis and Pseudogapping interact with such discourse relations.",357,4,75,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"It over-predicts that all the examples involving mismatch in VP are acceptable, and at the same time it cannot predict that some of those involving voice mismatch in VP ellipsis are unacceptable.",No asymmetry in voice match between VP ellipsis and Pseudogapping,3 Towards an analysis Kehler (2000) argues that sentences/clauses in a discourse are linked together by (discourse) coherence relations.,NC,
2501,3 Towards an analysis Kehler (2000) argues that sentences/clauses in a discourse are linked together by (discourse) coherence relations.,358,4,76,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"In the next section, building on Kehler's (2000) insight into discourse relations between ellipsis and antecedent clauses, we argue that sizes of ellipsis for both VP ellipsis and Pseudogapping interact with such discourse relations.",No asymmetry in voice match between VP ellipsis and Pseudogapping,Coherence refers to the ways in which the hearer attempts to link together the sentences/clauses that form a discourse (Kehler (2000: 539)).,NC,
2502,Coherence refers to the ways in which the hearer attempts to link together the sentences/clauses that form a discourse (Kehler (2000: 539)).,359,4,77,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,3 Towards an analysis Kehler (2000) argues that sentences/clauses in a discourse are linked together by (discourse) coherence relations.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"For example, in a discourse, the hearer does not interpret the two sentences in (24a) to be unrelated, but he/she infers that Mary is upset at Bill because Bill forgot her birthday.",NC,
2503,"For example, in a discourse, the hearer does not interpret the two sentences in (24a) to be unrelated, but he/she infers that Mary is upset at Bill because Bill forgot her birthday.",360,4,78,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,Coherence refers to the ways in which the hearer attempts to link together the sentences/clauses that form a discourse (Kehler (2000: 539)).,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Because it is more difficult to infer how the two sentences in (24b) could be linked together, the discourse is less coherent.",NC,
2504,"Because it is more difficult to infer how the two sentences in (24b) could be linked together, the discourse is less coherent.",361,4,79,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"For example, in a discourse, the hearer does not interpret the two sentences in (24a) to be unrelated, but he/she infers that Mary is upset at Bill because Bill forgot her birthday.",No asymmetry in voice match between VP ellipsis and Pseudogapping,(24) a. Mary is upset with Bill.,NC,
2505,(24) a. Mary is upset with Bill.,362,4,80,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Because it is more difficult to infer how the two sentences in (24b) could be linked together, the discourse is less coherent.",No asymmetry in voice match between VP ellipsis and Pseudogapping,Bill forgot her birthday.,NC,
2506,Bill forgot her birthday.,363,4,81,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,(24) a. Mary is upset with Bill.,No asymmetry in voice match between VP ellipsis and Pseudogapping,b. Mary is upset with Bill.,NC,
2507,b. Mary is upset with Bill.,364,4,82,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,Bill forgot her birthday.,No asymmetry in voice match between VP ellipsis and Pseudogapping,#Jupiter has 63 moons.,NC,
2508,#Jupiter has 63 moons.,365,4,83,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,b. Mary is upset with Bill.,No asymmetry in voice match between VP ellipsis and Pseudogapping,Kehler (2000) discusses two types of coherence relations relevant to ellipsis: resemblance and cause/effect.,NC,
2509,Kehler (2000) discusses two types of coherence relations relevant to ellipsis: resemblance and cause/effect.,366,4,84,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,#Jupiter has 63 moons.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"When a resemblance relation holds, the entities or properties in the elided material are interpreted as in some way parallel to those in its antecedent.",NC,
2510,"When a resemblance relation holds, the entities or properties in the elided material are interpreted as in some way parallel to those in its antecedent.",367,4,85,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,Kehler (2000) discusses two types of coherence relations relevant to ellipsis: resemblance and cause/effect.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"For example, in (25), John and Bill are the entities, and they are parallel in that they both went to the store.",NC,
2511,"For example, in (25), John and Bill are the entities, and they are parallel in that they both went to the store.",368,4,86,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"When a resemblance relation holds, the entities or properties in the elided material are interpreted as in some way parallel to those in its antecedent.",No asymmetry in voice match between VP ellipsis and Pseudogapping,(25) John went to the store because Bill did <go to the store>.,NC,
2512,(25) John went to the store because Bill did <go to the store>.,369,4,87,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"For example, in (25), John and Bill are the entities, and they are parallel in that they both went to the store.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"There is a class of connectives and adverbs which serve as markers for the resemblance coherence relation, including and, also, as well, too, likewise, etc.",NC,
2513,"There is a class of connectives and adverbs which serve as markers for the resemblance coherence relation, including and, also, as well, too, likewise, etc.",370,4,88,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,(25) John went to the store because Bill did <go to the store>.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"When a cause/effect relation holds, by contrast, the proposition expressed by the elided material has some sort of causal relationship to the proposition in the antecedent.",NC,
2514,"When a cause/effect relation holds, by contrast, the proposition expressed by the elided material has some sort of causal relationship to the proposition in the antecedent.",371,4,89,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"There is a class of connectives and adverbs which serve as markers for the resemblance coherence relation, including and, also, as well, too, likewise, etc.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"For example, in (26), the fact that Bill went to the store is the cause for John to do so.",NC,
2515,"For example, in (26), the fact that Bill went to the store is the cause for John to do so.",372,4,90,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"When a cause/effect relation holds, by contrast, the proposition expressed by the elided material has some sort of causal relationship to the proposition in the antecedent.",No asymmetry in voice match between VP ellipsis and Pseudogapping,(26) John went to the store because Bill did <go to the store>.,NC,
2516,(26) John went to the store because Bill did <go to the store>.,373,4,91,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"For example, in (26), the fact that Bill went to the store is the cause for John to do so.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"As with the resemblance relations, certain adverbs and connectives regularly occur in cause/effect sentences which can serve as markers of this coherence relation, including but, even though, because, as a result, therefore, so, consequently, etc.",NC,
2517,"As with the resemblance relations, certain adverbs and connectives regularly occur in cause/effect sentences which can serve as markers of this coherence relation, including but, even though, because, as a result, therefore, so, consequently, etc.",374,4,92,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,(26) John went to the store because Bill did <go to the store>.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Kehler (2000) argues that when there is a voice mismatch in ellipsis, sentences where there is a cause/effect relation between antecedent and ellipsis sites are licit, while sentences where there is a resemblance relation are illicit.",NC,
2518,"Kehler (2000) argues that when there is a voice mismatch in ellipsis, sentences where there is a cause/effect relation between antecedent and ellipsis sites are licit, while sentences where there is a resemblance relation are illicit.",375,4,93,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"As with the resemblance relations, certain adverbs and connectives regularly occur in cause/effect sentences which can serve as markers of this coherence relation, including but, even though, because, as a result, therefore, so, consequently, etc.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"The contrast can be found in (27a) and (27b) below, where the acceptable (27a) contains a cause/effect relation, and the unacceptable (27b) contains a resemblance relation.",NC,
2519,"The contrast can be found in (27a) and (27b) below, where the acceptable (27a) contains a cause/effect relation, and the unacceptable (27b) contains a resemblance relation.",376,4,94,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Kehler (2000) argues that when there is a voice mismatch in ellipsis, sentences where there is a cause/effect relation between antecedent and ellipsis sites are licit, while sentences where there is a resemblance relation are illicit.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"In March, four fireworks manufacturers asked that the decision be reversed, and on Monday, the ICC did <reverse the decision>.",NC,
2520,"In March, four fireworks manufacturers asked that the decision be reversed, and on Monday, the ICC did <reverse the decision>.",377,4,95,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"The contrast can be found in (27a) and (27b) below, where the acceptable (27a) contains a cause/effect relation, and the unacceptable (27b) contains a resemblance relation.",No asymmetry in voice match between VP ellipsis and Pseudogapping,(Dalrymple et al.,NC,
2521,(Dalrymple et al.,378,4,96,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"In March, four fireworks manufacturers asked that the decision be reversed, and on Monday, the ICC did <reverse the decision>.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"* This problem was looked into by John, and Bob did <look into the problem>, too.",NC,
2522,"* This problem was looked into by John, and Bob did <look into the problem>, too.",379,4,97,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,(Dalrymple et al.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(Kehler 2000: 551, example 34) Kehler (2000: 543-46) ascribes this contrast to the fact that cause/effect relations require only semantic identity, which tolerates voice mismatch, while resemblance relations require syntactic identity in addition to semantic identity.",NC,
2523,"(Kehler 2000: 551, example 34) Kehler (2000: 543-46) ascribes this contrast to the fact that cause/effect relations require only semantic identity, which tolerates voice mismatch, while resemblance relations require syntactic identity in addition to semantic identity.",380,4,98,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"* This problem was looked into by John, and Bob did <look into the problem>, too.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"We depart from Kehler (2000), suggesting that a cause/effect relation as well as a resemblance relation requires syntactic identity in ellipsis, but that they are distinguished in terms of the category that undergoes ellipsis.",NC,
2524,"We depart from Kehler (2000), suggesting that a cause/effect relation as well as a resemblance relation requires syntactic identity in ellipsis, but that they are distinguished in terms of the category that undergoes ellipsis.",381,4,99,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"(Kehler 2000: 551, example 34) Kehler (2000: 543-46) ascribes this contrast to the fact that cause/effect relations require only semantic identity, which tolerates voice mismatch, while resemblance relations require syntactic identity in addition to semantic identity.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"In particular, when a resemblance relation holds, the bigger category vP is a target of ellipsis.",POS,claim principal d'une argumentation qui continue sur plusieurs lignes ... est-ce qu'on garde seulement le claim initial ?
2525,"In particular, when a resemblance relation holds, the bigger category vP is a target of ellipsis.",382,4,100,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"We depart from Kehler (2000), suggesting that a cause/effect relation as well as a resemblance relation requires syntactic identity in ellipsis, but that they are distinguished in terms of the category that undergoes ellipsis.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"By contrast, when a causeeffect relation holds, the smaller category VP can be elided, as schematized below: (28) a. vP ellipsis in ""parallel resemblance (or contrast) relations"" [ TP < vP [ VP ] >]... [ TP [ vP [ VP ] ]] b. VP ellipsis in ""non-parallel cause-effect relations"" [ TP [ vP < VP > ]]... [ TP [ vP [ VP ] ]] The difference between the two types of relations in terms of the category of ellipsis is justified on the basis of the following reasoning.",POS,
2526,"By contrast, when a causeeffect relation holds, the smaller category VP can be elided, as schematized below: (28) a. vP ellipsis in ""parallel resemblance (or contrast) relations"" [ TP < vP [ VP ] >]... [ TP [ vP [ VP ] ]] b. VP ellipsis in ""non-parallel cause-effect relations"" [ TP [ vP < VP > ]]... [ TP [ vP [ VP ] ]] The difference between the two types of relations in terms of the category of ellipsis is justified on the basis of the following reasoning.",383,4,101,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"In particular, when a resemblance relation holds, the bigger category vP is a target of ellipsis.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"First, a parallel resemblance relation relates two clauses/sentences; the ellipsis clause and its antecedent clause.",POS,
2527,"First, a parallel resemblance relation relates two clauses/sentences; the ellipsis clause and its antecedent clause.",384,4,102,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"By contrast, when a causeeffect relation holds, the smaller category VP can be elided, as schematized below: (28) a. vP ellipsis in ""parallel resemblance (or contrast) relations"" [ TP < vP [ VP ] >]... [ TP [ vP [ VP ] ]] b. VP ellipsis in ""non-parallel cause-effect relations"" [ TP [ vP < VP > ]]... [ TP [ vP [ VP ] ]] The difference between the two types of relations in terms of the category of ellipsis is justified on the basis of the following reasoning.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"The proposition of the former clause holds true, in a parallel fashion as that of the latter clause does.",NC,
2528,"The proposition of the former clause holds true, in a parallel fashion as that of the latter clause does.",385,4,103,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"First, a parallel resemblance relation relates two clauses/sentences; the ellipsis clause and its antecedent clause.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"Now the wisdom we has about the syntax of a clause is that a small clause vP, as a proxy of a full clause CP/TP, may have a parallel relation with another small clause vP.",NC,
2529,"Now the wisdom we has about the syntax of a clause is that a small clause vP, as a proxy of a full clause CP/TP, may have a parallel relation with another small clause vP.",386,4,104,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"The proposition of the former clause holds true, in a parallel fashion as that of the latter clause does.",No asymmetry in voice match between VP ellipsis and Pseudogapping,This is exactly what happens in the case of vP ellipsis when a resemblance relation holds.,NC,
2530,This is exactly what happens in the case of vP ellipsis when a resemblance relation holds.,387,4,105,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Now the wisdom we has about the syntax of a clause is that a small clause vP, as a proxy of a full clause CP/TP, may have a parallel relation with another small clause vP.",No asymmetry in voice match between VP ellipsis and Pseudogapping,The ellipsis of a vP is the only option to respect the full clause-tosmall clause correspondence in the case of a resemblance relation between the ellipsis and the corresponding antecedent clauses.,NC,
2531,The ellipsis of a vP is the only option to respect the full clause-tosmall clause correspondence in the case of a resemblance relation between the ellipsis and the corresponding antecedent clauses.,388,4,106,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,This is exactly what happens in the case of vP ellipsis when a resemblance relation holds.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"When a cause/effect relation holds, it also relates two clauses.",NC,
2532,"When a cause/effect relation holds, it also relates two clauses.",389,4,107,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,The ellipsis of a vP is the only option to respect the full clause-tosmall clause correspondence in the case of a resemblance relation between the ellipsis and the corresponding antecedent clauses.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"However, the two clauses involved are non-parallel.",NC,
2533,"However, the two clauses involved are non-parallel.",390,4,108,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"When a cause/effect relation holds, it also relates two clauses.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"Thus, no full clause-to-small clause correspondence is called for.",NC,
2534,"Thus, no full clause-to-small clause correspondence is called for.",391,4,109,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"However, the two clauses involved are non-parallel.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"Since the two clauses involved are non-parallel, one clause may relate not to another clause but to a constituent inside it.",NC,
2535,"Since the two clauses involved are non-parallel, one clause may relate not to another clause but to a constituent inside it.",392,4,110,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Thus, no full clause-to-small clause correspondence is called for.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"In other words, it is possible that one clause may, for example, modify the constituent inside another clause.",NC,
2536,"In other words, it is possible that one clause may, for example, modify the constituent inside another clause.",393,4,111,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Since the two clauses involved are non-parallel, one clause may relate not to another clause but to a constituent inside it.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"This is the reason that VP ellipsis instead of vP ellipsis is permissible when a cause/effect relation holds, even though two clauses are related.",NC,
2537,"This is the reason that VP ellipsis instead of vP ellipsis is permissible when a cause/effect relation holds, even though two clauses are related.",394,4,112,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"In other words, it is possible that one clause may, for example, modify the constituent inside another clause.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"The cause/effect, non-parallel relation gets away with not respecting the full clause-to-small clause correspondence.",NC,
2538,"The cause/effect, non-parallel relation gets away with not respecting the full clause-to-small clause correspondence.",395,4,113,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"This is the reason that VP ellipsis instead of vP ellipsis is permissible when a cause/effect relation holds, even though two clauses are related.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"Given the asymmetry between resemblance and cause/effect relations in terms of the size of ellipsis, we are now in a position to account for their contrast in voice mismatch when a verbal domain (VP or vP) undergoes ellipsis.",NC,
2539,"Given the asymmetry between resemblance and cause/effect relations in terms of the size of ellipsis, we are now in a position to account for their contrast in voice mismatch when a verbal domain (VP or vP) undergoes ellipsis.",396,4,114,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"The cause/effect, non-parallel relation gets away with not respecting the full clause-to-small clause correspondence.",No asymmetry in voice match between VP ellipsis and Pseudogapping,The ideas we rely on are summarized below: (29) Identity condition on VP or vP ellipsis: a. Case/case mismatch (between the copy of the survivor/remnant and its correlate) is not allowed for ellipsis (as part of syntactic isomorphism in ellipsis).,NC,
2540,The ideas we rely on are summarized below: (29) Identity condition on VP or vP ellipsis: a. Case/case mismatch (between the copy of the survivor/remnant and its correlate) is not allowed for ellipsis (as part of syntactic isomorphism in ellipsis).,397,4,115,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Given the asymmetry between resemblance and cause/effect relations in terms of the size of ellipsis, we are now in a position to account for their contrast in voice mismatch when a verbal domain (VP or vP) undergoes ellipsis.",No asymmetry in voice match between VP ellipsis and Pseudogapping,"b. Nominative and Accusative Case are checked outside VP, whereas inherent case is checked inside VP.",POS,
2541,"b. Nominative and Accusative Case are checked outside VP, whereas inherent case is checked inside VP.",398,4,116,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,The ideas we rely on are summarized below: (29) Identity condition on VP or vP ellipsis: a. Case/case mismatch (between the copy of the survivor/remnant and its correlate) is not allowed for ellipsis (as part of syntactic isomorphism in ellipsis).,No asymmetry in voice match between VP ellipsis and Pseudogapping,c. vP undergoes 'VP ellipsis' in a resemblance relation.,POS,
2542,c. vP undergoes 'VP ellipsis' in a resemblance relation.,399,4,117,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"b. Nominative and Accusative Case are checked outside VP, whereas inherent case is checked inside VP.",No asymmetry in voice match between VP ellipsis and Pseudogapping,The key ingredient we rely on in this analysis is Case/case (mis)match in ellipsis.,POS,
2543,The key ingredient we rely on in this analysis is Case/case (mis)match in ellipsis.,400,4,118,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,c. vP undergoes 'VP ellipsis' in a resemblance relation.,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Simply stated, Case/case mismatch is not allowed between a survivor/remnant and its antecedent constituent (or correlate).",POS,
2544,"Simply stated, Case/case mismatch is not allowed between a survivor/remnant and its antecedent constituent (or correlate).",401,4,119,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,The key ingredient we rely on in this analysis is Case/case (mis)match in ellipsis.,No asymmetry in voice match between VP ellipsis and Pseudogapping,This means that in the following structure one argument element A inside the ellipsis constituent and its correlate A' inside the antecedent constituent are required to be identical in terms of Case/case feature.,NC,
2545,This means that in the following structure one argument element A inside the ellipsis constituent and its correlate A' inside the antecedent constituent are required to be identical in terms of Case/case feature.,402,4,120,No asymmetry in voice match between VP ellipsis and Pseudogapping,No asymmetry in voice match between VP ellipsis and Pseudogapping,"Simply stated, Case/case mismatch is not allowed between a survivor/remnant and its antecedent constituent (or correlate).",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"A ] Now a question is what happens when A and A' are base-generated inside the ellipsis and antecedent constituents, but they participate in Case-checking relation outside them.",NC,
2546,"A ] Now a question is what happens when A and A' are base-generated inside the ellipsis and antecedent constituents, but they participate in Case-checking relation outside them.",403,4,121,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,No asymmetry in voice match between VP ellipsis and Pseudogapping,This means that in the following structure one argument element A inside the ellipsis constituent and its correlate A' inside the antecedent constituent are required to be identical in terms of Case/case feature.,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"We suppose that this situation holds exactly in such examples as ( 19) and ( 20), repeated below ( 31) and ( 32): (31) ?My problem will be looked into by Tom, but he won't look into yours.",NC,
2547,"We suppose that this situation holds exactly in such examples as ( 19) and ( 20), repeated below ( 31) and ( 32): (31) ?My problem will be looked into by Tom, but he won't look into yours.",404,4,122,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"A ] Now a question is what happens when A and A' are base-generated inside the ellipsis and antecedent constituents, but they participate in Case-checking relation outside them.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"PG (32) This problem was to have been looked into, but obviously nobody did look into this problem.",NC,
2548,"PG (32) This problem was to have been looked into, but obviously nobody did look into this problem.",405,4,123,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"We suppose that this situation holds exactly in such examples as ( 19) and ( 20), repeated below ( 31) and ( 32): (31) ?My problem will be looked into by Tom, but he won't look into yours.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"VPE As stated in (29b), in English either Nominative or Accusative Case is checked outside VP (cf.",NC,
2549,"VPE As stated in (29b), in English either Nominative or Accusative Case is checked outside VP (cf.",406,4,124,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"PG (32) This problem was to have been looked into, but obviously nobody did look into this problem.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,Chomsky (1995)).,NC,
2550,Chomsky (1995)).,407,4,125,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"VPE As stated in (29b), in English either Nominative or Accusative Case is checked outside VP (cf.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"Thus, if in ( 31) and ( 32) the ellipsis clause has a cause/effect relation with its antecedent clause and what is elided is VP (as stated in (29c)), the apparent Case mismatch between the object element in the ellipsis clause and its correlate subject element in the antecedent clause is not harmful at all.",NC,
2551,"Thus, if in ( 31) and ( 32) the ellipsis clause has a cause/effect relation with its antecedent clause and what is elided is VP (as stated in (29c)), the apparent Case mismatch between the object element in the ellipsis clause and its correlate subject element in the antecedent clause is not harmful at all.",408,4,126,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,Chomsky (1995)).,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"This is because at the point of derivation where VP is elided, the former and the latter have not yet have its Case feature valued, thus being not distinct in form.",NC,
2552,"This is because at the point of derivation where VP is elided, the former and the latter have not yet have its Case feature valued, thus being not distinct in form.",409,4,127,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"Thus, if in ( 31) and ( 32) the ellipsis clause has a cause/effect relation with its antecedent clause and what is elided is VP (as stated in (29c)), the apparent Case mismatch between the object element in the ellipsis clause and its correlate subject element in the antecedent clause is not harmful at all.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"Now, we turn to the examples of Pseudogapping and VP ellipsis in a resemblance relation.",NC,
2553,"Now, we turn to the examples of Pseudogapping and VP ellipsis in a resemblance relation.",410,4,128,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"This is because at the point of derivation where VP is elided, the former and the latter have not yet have its Case feature valued, thus being not distinct in form.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"( 15) and ( 17), repeated below as ( 33) and ( 34), represent those examples: (33) *Roses were brought by some, and others did bring lilies.",NC,
2554,"( 15) and ( 17), repeated below as ( 33) and ( 34), represent those examples: (33) *Roses were brought by some, and others did bring lilies.",411,4,129,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"Now, we turn to the examples of Pseudogapping and VP ellipsis in a resemblance relation.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"PG (34) *Roses were brought by some boys, and some girls did bring roses, too.",NC,
2555,"PG (34) *Roses were brought by some boys, and some girls did bring roses, too.",412,4,130,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"( 15) and ( 17), repeated below as ( 33) and ( 34), represent those examples: (33) *Roses were brought by some, and others did bring lilies.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"VPE As argued above, both Pseudogapping and VP ellipsis in a resemblance relation involve an elision of vP rather than VP.",NC,
2556,"VPE As argued above, both Pseudogapping and VP ellipsis in a resemblance relation involve an elision of vP rather than VP.",413,4,131,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"PG (34) *Roses were brought by some boys, and some girls did bring roses, too.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"Since vP is a domain where Accusative Case is checked, the object in the ellipsis clause is bound to relate to its correlate object in the antecedent clause.",NC,
2557,"Since vP is a domain where Accusative Case is checked, the object in the ellipsis clause is bound to relate to its correlate object in the antecedent clause.",414,4,132,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"VPE As argued above, both Pseudogapping and VP ellipsis in a resemblance relation involve an elision of vP rather than VP.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"The unacceptability of ( 33) and ( 34) follows from the fact that in the examples, the object element in the ellipsis clause which is Case-checked in Spec of vP relates to its correlate in the antecedent clause, which is the subject element that cannot be Casechecked in Spec of vP.",NC,
2558,"The unacceptability of ( 33) and ( 34) follows from the fact that in the examples, the object element in the ellipsis clause which is Case-checked in Spec of vP relates to its correlate in the antecedent clause, which is the subject element that cannot be Casechecked in Spec of vP.",415,4,133,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"Since vP is a domain where Accusative Case is checked, the object in the ellipsis clause is bound to relate to its correlate object in the antecedent clause.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"Therefore, there is bound to arise a Case mismatch in both Pseudogapping and VP ellipsis in a resemblance relation that holds for (33) and (34).",NC,
2559,"Therefore, there is bound to arise a Case mismatch in both Pseudogapping and VP ellipsis in a resemblance relation that holds for (33) and (34).",416,4,134,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"The unacceptability of ( 33) and ( 34) follows from the fact that in the examples, the object element in the ellipsis clause which is Case-checked in Spec of vP relates to its correlate in the antecedent clause, which is the subject element that cannot be Casechecked in Spec of vP.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"In other words, voice mismatch for vP ellipsis in a resemblance relation is not permissible, because it always invites Case mismatch between an object element and its corresponding subject or vice versus, ultimately infringing on the syntactic isomorphism on ellipsis.",NC,
2560,"In other words, voice mismatch for vP ellipsis in a resemblance relation is not permissible, because it always invites Case mismatch between an object element and its corresponding subject or vice versus, ultimately infringing on the syntactic isomorphism on ellipsis.",417,4,135,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"Therefore, there is bound to arise a Case mismatch in both Pseudogapping and VP ellipsis in a resemblance relation that holds for (33) and (34).",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,We now turn to the examples where a VPinternal element is assigned not structural Case but inherent case.,POS,
2561,We now turn to the examples where a VPinternal element is assigned not structural Case but inherent case.,418,4,136,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"In other words, voice mismatch for vP ellipsis in a resemblance relation is not permissible, because it always invites Case mismatch between an object element and its corresponding subject or vice versus, ultimately infringing on the syntactic isomorphism on ellipsis.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,*She embroiders peace signs on jackets more often than she does <embroider jackets> with swastikas.,NC,
2562,*She embroiders peace signs on jackets more often than she does <embroider jackets> with swastikas.,419,4,137,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,We now turn to the examples where a VPinternal element is assigned not structural Case but inherent case.,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,?She embroiders peace signs on jackets more often than she does <embroider peace signs on> shirt sleeves.,NC,
2563,?She embroiders peace signs on jackets more often than she does <embroider peace signs on> shirt sleeves.,420,4,138,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,*She embroiders peace signs on jackets more often than she does <embroider jackets> with swastikas.,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,*He'd give Yale money more readily than he would <give money> to charity.,NC,
2564,*He'd give Yale money more readily than he would <give money> to charity.,421,4,139,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,?She embroiders peace signs on jackets more often than she does <embroider peace signs on> shirt sleeves.,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,?He'd give money more readily to Yale than he would <give money to> charity.,NC,
2565,?He'd give money more readily to Yale than he would <give money to> charity.,422,4,140,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,*He'd give Yale money more readily than he would <give money> to charity.,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,*Abby flirted more often in general than Beth did <flirt with> Max.,NC,
2566,*Abby flirted more often in general than Beth did <flirt with> Max.,423,4,141,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,?He'd give money more readily to Yale than he would <give money to> charity.,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,?Abby flirted with Ben more often than she did <flirt with> Ryan.,NC,
2567,?Abby flirted with Ben more often than she did <flirt with> Ryan.,424,4,142,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,*Abby flirted more often in general than Beth did <flirt with> Max.,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"Note that unlike structural Accusative Case that is checked outside VP but inside vP, inherent case is presumably determined by a verbal head inside VP and realized with an appropriate preposition.",NC,
2568,"Note that unlike structural Accusative Case that is checked outside VP but inside vP, inherent case is presumably determined by a verbal head inside VP and realized with an appropriate preposition.",425,4,143,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,?Abby flirted with Ben more often than she did <flirt with> Ryan.,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,All the examples in ( 35)-( 37) involve Pseudogapping because we cannot test out case forms of VP-internal argument elements inside the portion elided by VP ellipsis.,NC,
2569,All the examples in ( 35)-( 37) involve Pseudogapping because we cannot test out case forms of VP-internal argument elements inside the portion elided by VP ellipsis.,426,4,144,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"Note that unlike structural Accusative Case that is checked outside VP but inside vP, inherent case is presumably determined by a verbal head inside VP and realized with an appropriate preposition.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"The (b)-examples of ( 35)-( 37) are a little bit degraded (we conjecture that, as noted by Levin (1979Levin ( /1986) ) and Lasnik (1995), the degradedness of these examples are due to the general degradedness of Pseudogapping), but they are still acceptable.",NC,
2570,"The (b)-examples of ( 35)-( 37) are a little bit degraded (we conjecture that, as noted by Levin (1979Levin ( /1986) ) and Lasnik (1995), the degradedness of these examples are due to the general degradedness of Pseudogapping), but they are still acceptable.",427,4,145,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,All the examples in ( 35)-( 37) involve Pseudogapping because we cannot test out case forms of VP-internal argument elements inside the portion elided by VP ellipsis.,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"This is because in these examples, the VP in the ellipsis clause is identical to that in the antecedent clause in terms of inherent case realization of the argument elements inside them.",NC,
2571,"This is because in these examples, the VP in the ellipsis clause is identical to that in the antecedent clause in terms of inherent case realization of the argument elements inside them.",428,4,146,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"The (b)-examples of ( 35)-( 37) are a little bit degraded (we conjecture that, as noted by Levin (1979Levin ( /1986) ) and Lasnik (1995), the degradedness of these examples are due to the general degradedness of Pseudogapping), but they are still acceptable.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"Unlike these (b)-examples of ( 35)-( 37), however, their (a)-examples are ruled out owing to case mismatch between a VP-internal argument element in the ellipsis clause and its correlate in the antecedent clause.",NC,
2572,"Unlike these (b)-examples of ( 35)-( 37), however, their (a)-examples are ruled out owing to case mismatch between a VP-internal argument element in the ellipsis clause and its correlate in the antecedent clause.",429,4,147,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"This is because in these examples, the VP in the ellipsis clause is identical to that in the antecedent clause in terms of inherent case realization of the argument elements inside them.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"For example, in (35a) neither jackets nor with swastikas inside the VP of the ellipsis clause matches with on jackets and signs in terms of case/Case feature, thereby inviting a violation of the syntactic isomorphism on ellipsis.",NC,
2573,"For example, in (35a) neither jackets nor with swastikas inside the VP of the ellipsis clause matches with on jackets and signs in terms of case/Case feature, thereby inviting a violation of the syntactic isomorphism on ellipsis.",430,4,148,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"Unlike these (b)-examples of ( 35)-( 37), however, their (a)-examples are ruled out owing to case mismatch between a VP-internal argument element in the ellipsis clause and its correlate in the antecedent clause.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"In leaving this section, let us note that Takita (2015: 14) proposed the revised Case condition on ellipsis, which states that a DP must be Caselicensed in the ellipsis site by a head identical to the corresponding head that Case-licenses the correlating DP in the antecedent.",NC,
2574,"In leaving this section, let us note that Takita (2015: 14) proposed the revised Case condition on ellipsis, which states that a DP must be Caselicensed in the ellipsis site by a head identical to the corresponding head that Case-licenses the correlating DP in the antecedent.",431,4,149,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"For example, in (35a) neither jackets nor with swastikas inside the VP of the ellipsis clause matches with on jackets and signs in terms of case/Case feature, thereby inviting a violation of the syntactic isomorphism on ellipsis.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"Simply speaking, Takita (ibid.)",NC,
2575,"Simply speaking, Takita (ibid.)",432,4,150,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"In leaving this section, let us note that Takita (2015: 14) proposed the revised Case condition on ellipsis, which states that a DP must be Caselicensed in the ellipsis site by a head identical to the corresponding head that Case-licenses the correlating DP in the antecedent.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,argues that a Case-licensing head rather than the Case/case form of a DP determined by it is critical in meeting the syntactic isomorphism on ellipsis.,NC,
2576,argues that a Case-licensing head rather than the Case/case form of a DP determined by it is critical in meeting the syntactic isomorphism on ellipsis.,433,4,151,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"Simply speaking, Takita (ibid.)",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,Takita's analysis works fine for (37b).,NC,
2577,Takita's analysis works fine for (37b).,434,4,152,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,argues that a Case-licensing head rather than the Case/case form of a DP determined by it is critical in meeting the syntactic isomorphism on ellipsis.,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"Since in (37b) the same verb flirt Case-licenses Ryan and its correlate Ben with the realization of the preposition with, it meets the revised Case condition on ellipsis.",NC,
2578,"Since in (37b) the same verb flirt Case-licenses Ryan and its correlate Ben with the realization of the preposition with, it meets the revised Case condition on ellipsis.",435,4,153,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,Takita's analysis works fine for (37b).,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"To rule out (37a), however, Takita has to say that the verb flirt in the ellipsis clause is different from the verb flirt in the antecedent clause.",NC,
2579,"To rule out (37a), however, Takita has to say that the verb flirt in the ellipsis clause is different from the verb flirt in the antecedent clause.",436,4,154,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"Since in (37b) the same verb flirt Case-licenses Ryan and its correlate Ben with the realization of the preposition with, it meets the revised Case condition on ellipsis.",(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"Unlike Takita's analysis, we have argued that the Case/case form of a DP matters for ellipsis.",NC,
2580,"Unlike Takita's analysis, we have argued that the Case/case form of a DP matters for ellipsis.",437,4,155,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"To rule out (37a), however, Takita has to say that the verb flirt in the ellipsis clause is different from the verb flirt in the antecedent clause.",Consequences,If causative and unaccusatives also differ in their v (cf.,POS,
2581,If causative and unaccusatives also differ in their v (cf.,438,4,156,Consequences,(30) ..[ antecedent constituent A' ] ...[ ellipsis constituent,"Unlike Takita's analysis, we have argued that the Case/case form of a DP matters for ellipsis.",Consequences,"Chomsky (1995) Why is there a contrast between passives, on the one hand, and unaccusatives and middles, on the other hand?",NC,
2582,"Chomsky (1995) Why is there a contrast between passives, on the one hand, and unaccusatives and middles, on the other hand?",439,4,157,Consequences,Consequences,If causative and unaccusatives also differ in their v (cf.,Consequences,"We saw that passive-active alternation (i.e., voice mismatch) in the antecedent and ellipsis pair is permissible in a cause/effect relation.",NC,
2583,"We saw that passive-active alternation (i.e., voice mismatch) in the antecedent and ellipsis pair is permissible in a cause/effect relation.",440,4,158,Consequences,Consequences,"Chomsky (1995) Why is there a contrast between passives, on the one hand, and unaccusatives and middles, on the other hand?",Consequences,"However, neither causative-unaccusative nor transitive-middle alternation in the antecedent and ellipsis pair is allowed.",NC,
2584,"However, neither causative-unaccusative nor transitive-middle alternation in the antecedent and ellipsis pair is allowed.",441,4,159,Consequences,Consequences,"We saw that passive-active alternation (i.e., voice mismatch) in the antecedent and ellipsis pair is permissible in a cause/effect relation.",Consequences,"We suggest on the basis of the following do so replacement that in English, passives involve syntactic movement, but neither unaccusatives nor middles do so.",NC,
2585,"We suggest on the basis of the following do so replacement that in English, passives involve syntactic movement, but neither unaccusatives nor middles do so.",442,4,160,Consequences,Consequences,"However, neither causative-unaccusative nor transitive-middle alternation in the antecedent and ellipsis pair is allowed.",Consequences,"%John told Steve to hang the horseshoe over the door, and it does so now.",POS,
2586,"%John told Steve to hang the horseshoe over the door, and it does so now.",443,4,161,Consequences,Consequences,"We suggest on the basis of the following do so replacement that in English, passives involve syntactic movement, but neither unaccusatives nor middles do so.",Consequences,"%I was told that this new peanut butter spreads very easily, and I am very excited to do so.",NC,
2587,"%I was told that this new peanut butter spreads very easily, and I am very excited to do so.",444,4,162,Consequences,Consequences,"%John told Steve to hang the horseshoe over the door, and it does so now.",Consequences,"((12a-d) from Thompson (2012)) c. %Mary claimed that I closed the door, but it actually did so on its own.",NC,
2588,"((12a-d) from Thompson (2012)) c. %Mary claimed that I closed the door, but it actually did so on its own.",445,4,163,Consequences,Consequences,"%I was told that this new peanut butter spreads very easily, and I am very excited to do so.",Consequences,(from Thompson ( 2012)) The contrast between ( 44) and ( 45) can be accounted for by the assumption that the VPreplacing anaphor so (while the light verb do of do so occupies the little v position (cf.,NC,
2589,(from Thompson ( 2012)) The contrast between ( 44) and ( 45) can be accounted for by the assumption that the VPreplacing anaphor so (while the light verb do of do so occupies the little v position (cf.,446,4,164,Consequences,Consequences,"((12a-d) from Thompson (2012)) c. %Mary claimed that I closed the door, but it actually did so on its own.",Consequences,"Stroik (2001), among others) cannot replace a VP that contains a gap left behind by A or A'-movement.",NC,
2590,"Stroik (2001), among others) cannot replace a VP that contains a gap left behind by A or A'-movement.",447,4,165,Consequences,Consequences,(from Thompson ( 2012)) The contrast between ( 44) and ( 45) can be accounted for by the assumption that the VPreplacing anaphor so (while the light verb do of do so occupies the little v position (cf.,Consequences,"This account implies that passive verbs are potentially transitive verbs, thus being able to meet the identity condition on ellipsis with transitive verbs.",NC,
2591,"This account implies that passive verbs are potentially transitive verbs, thus being able to meet the identity condition on ellipsis with transitive verbs.",448,4,166,Consequences,Consequences,"Stroik (2001), among others) cannot replace a VP that contains a gap left behind by A or A'-movement.",Consequences,"However, unaccusative and middle verbs are in fact intransitive verbs, thus not being able to meet the identity condition on ellipsis with causative or transitive verbs.",NC,
2592,"However, unaccusative and middle verbs are in fact intransitive verbs, thus not being able to meet the identity condition on ellipsis with causative or transitive verbs.",449,4,167,Consequences,Consequences,"This account implies that passive verbs are potentially transitive verbs, thus being able to meet the identity condition on ellipsis with transitive verbs.",Consequences,"This is how we account for the unacceptability of ( 38), (42), and (43).",NC,
2593,"This is how we account for the unacceptability of ( 38), (42), and (43).",450,4,168,Consequences,Consequences,"However, unaccusative and middle verbs are in fact intransitive verbs, thus not being able to meet the identity condition on ellipsis with causative or transitive verbs.",Consequences,All these examples are ruled out independently of Case/case mismatch but because of verb-type mismatch between intransitive and causative/transitive verbs.,NC,
2594,All these examples are ruled out independently of Case/case mismatch but because of verb-type mismatch between intransitive and causative/transitive verbs.,451,4,169,Consequences,Consequences,"This is how we account for the unacceptability of ( 38), (42), and (43).",Consequences,There is an additional alternation between an implicit argument-taking verb and its passive variant in an antecedent and ellipsis pair.,NC,
2595,There is an additional alternation between an implicit argument-taking verb and its passive variant in an antecedent and ellipsis pair.,452,4,170,Consequences,Consequences,All these examples are ruled out independently of Case/case mismatch but because of verb-type mismatch between intransitive and causative/transitive verbs.,Consequences,"This mismatch is not allowed, as follows: ( We assume that the implicit argument selected by verbs such as eat, win, and read implicitly carries Accusative-like inherent case.",NC,
2596,"This mismatch is not allowed, as follows: ( We assume that the implicit argument selected by verbs such as eat, win, and read implicitly carries Accusative-like inherent case.",453,4,171,Consequences,Consequences,There is an additional alternation between an implicit argument-taking verb and its passive variant in an antecedent and ellipsis pair.,Consequences,"This inherent case is lexically assigned by such verbs to the implicit argument in-situ within VP without moving to [Spec, vP].",NC,
2597,"This inherent case is lexically assigned by such verbs to the implicit argument in-situ within VP without moving to [Spec, vP].",454,4,172,Consequences,Consequences,"This mismatch is not allowed, as follows: ( We assume that the implicit argument selected by verbs such as eat, win, and read implicitly carries Accusative-like inherent case.",Consequences,This assumption accounts for the contrast in acceptability between ( 46) and (47).,NC,
2598,This assumption accounts for the contrast in acceptability between ( 46) and (47).,455,4,173,Consequences,Consequences,"This inherent case is lexically assigned by such verbs to the implicit argument in-situ within VP without moving to [Spec, vP].",Consequences,"In ( 46), the lexical-case-carrying implicit argument within the VP of the antecedent clause cannot meet a Case/case match with the complement of the passive verb within that of the ellipsis clause.",NC,
2599,"In ( 46), the lexical-case-carrying implicit argument within the VP of the antecedent clause cannot meet a Case/case match with the complement of the passive verb within that of the ellipsis clause.",456,4,174,Consequences,Consequences,This assumption accounts for the contrast in acceptability between ( 46) and (47).,Consequences,"In (47), by contrast, the whsurvivor/remnant in the ellipsis clause and its correlate implicit argument in the antecedent clause are understood to carry the same feature of Case/case, meeting syntactic isomorphism on ellipsis.",NC,
2600,"In (47), by contrast, the whsurvivor/remnant in the ellipsis clause and its correlate implicit argument in the antecedent clause are understood to carry the same feature of Case/case, meeting syntactic isomorphism on ellipsis.",457,4,175,Consequences,Consequences,"In ( 46), the lexical-case-carrying implicit argument within the VP of the antecedent clause cannot meet a Case/case match with the complement of the passive verb within that of the ellipsis clause.",Conclusion,"In this paper, we first started with reviewing Merchant's (2008) analysis of voice mismatch in ellipsis constructions and Tanaka's (2011) reply to this analysis.",NC,
2601,"In this paper, we first started with reviewing Merchant's (2008) analysis of voice mismatch in ellipsis constructions and Tanaka's (2011) reply to this analysis.",458,4,176,Conclusion,Consequences,"In (47), by contrast, the whsurvivor/remnant in the ellipsis clause and its correlate implicit argument in the antecedent clause are understood to carry the same feature of Case/case, meeting syntactic isomorphism on ellipsis.",Conclusion,We took Tanaka's rebuttal of Merchant's dichotomy in voice mismatch between VP and Pseudogapping to be valid.,FACT,
2602,We took Tanaka's rebuttal of Merchant's dichotomy in voice mismatch between VP and Pseudogapping to be valid.,459,4,177,Conclusion,Conclusion,"In this paper, we first started with reviewing Merchant's (2008) analysis of voice mismatch in ellipsis constructions and Tanaka's (2011) reply to this analysis.",Conclusion,"Departing from Kehler's (2000) insight that the distinction between resemblance vs. cause/effect discourse coherence relations rather than between VP and Pseudogapping come into place in apparent voice mismatch, we argued that VP undergoes ellipsis in a resemblance relation, whereas vP does so in a cause/effect relation.",POS,
2603,"Departing from Kehler's (2000) insight that the distinction between resemblance vs. cause/effect discourse coherence relations rather than between VP and Pseudogapping come into place in apparent voice mismatch, we argued that VP undergoes ellipsis in a resemblance relation, whereas vP does so in a cause/effect relation.",460,4,178,Conclusion,Conclusion,We took Tanaka's rebuttal of Merchant's dichotomy in voice mismatch between VP and Pseudogapping to be valid.,Conclusion,"Given the different sizes of ellipsis interacting with discourse relations, we went further to argue that apparent voice mismatch in VP ellipsis is attributed to the fact that structural Accusative Case is checked not within the VP domain that undergoes ellipsis.",POS,
2604,"Given the different sizes of ellipsis interacting with discourse relations, we went further to argue that apparent voice mismatch in VP ellipsis is attributed to the fact that structural Accusative Case is checked not within the VP domain that undergoes ellipsis.",461,4,179,Conclusion,Conclusion,"Departing from Kehler's (2000) insight that the distinction between resemblance vs. cause/effect discourse coherence relations rather than between VP and Pseudogapping come into place in apparent voice mismatch, we argued that VP undergoes ellipsis in a resemblance relation, whereas vP does so in a cause/effect relation.",Conclusion,"Thus, the object element in the ellipsis clause and the subject element in the antecedent clause, or vice versus, count as identical within a VP in terms of Case feature, meeting the identity condition on ellipsis.",POS,
2605,"Thus, the object element in the ellipsis clause and the subject element in the antecedent clause, or vice versus, count as identical within a VP in terms of Case feature, meeting the identity condition on ellipsis.",462,4,180,Conclusion,Conclusion,"Given the different sizes of ellipsis interacting with discourse relations, we went further to argue that apparent voice mismatch in VP ellipsis is attributed to the fact that structural Accusative Case is checked not within the VP domain that undergoes ellipsis.",Conclusion,"Unlike structural Case, however, a difference in case feature or argument structure (or verb type) within a VP always invites a violation of identity in ellipsis.",POS,
2606,"Unlike structural Case, however, a difference in case feature or argument structure (or verb type) within a VP always invites a violation of identity in ellipsis.",463,4,181,Conclusion,Conclusion,"Thus, the object element in the ellipsis clause and the subject element in the antecedent clause, or vice versus, count as identical within a VP in terms of Case feature, meeting the identity condition on ellipsis.",Conclusion,"In addition, Case/case mismatch in the case of an elision of a larger constituent such as TP under Sluicing was shown to induce fatal effects on the acceptability of sentences involving such a type of ellipsis.",POS,
2607,"In addition, Case/case mismatch in the case of an elision of a larger constituent such as TP under Sluicing was shown to induce fatal effects on the acceptability of sentences involving such a type of ellipsis.",464,4,182,Conclusion,Conclusion,"Unlike structural Case, however, a difference in case feature or argument structure (or verb type) within a VP always invites a violation of identity in ellipsis.",,,POS,
2608,"Due to the ability of encoding and mapping semantic information into a highdimensional latent feature space, neural networks have been successfully used for detecting events to a certain extent.",465,5,0,abstract,,,abstract,"However, such a feature space can be easily contaminated by spurious features inherent in event detection.",NC,
2609,"However, such a feature space can be easily contaminated by spurious features inherent in event detection.",466,5,1,abstract,abstract,"Due to the ability of encoding and mapping semantic information into a highdimensional latent feature space, neural networks have been successfully used for detecting events to a certain extent.",abstract,"In this paper, we propose a self-regulated learning approach by utilizing a generative adversarial network to generate spurious features.",NC,
2610,"In this paper, we propose a self-regulated learning approach by utilizing a generative adversarial network to generate spurious features.",467,5,2,abstract,abstract,"However, such a feature space can be easily contaminated by spurious features inherent in event detection.",abstract,"On the basis, we employ a recurrent network to eliminate the fakes.",FACT,
2611,"On the basis, we employ a recurrent network to eliminate the fakes.",468,5,3,abstract,abstract,"In this paper, we propose a self-regulated learning approach by utilizing a generative adversarial network to generate spurious features.",abstract,Detailed experiments on the ACE 2005 and TAC-KBP 2015 corpora show that our proposed method is highly effective and adaptable.,FACT,
2612,Detailed experiments on the ACE 2005 and TAC-KBP 2015 corpora show that our proposed method is highly effective and adaptable.,469,5,4,abstract,abstract,"On the basis, we employ a recurrent network to eliminate the fakes.",Introduction,Event detection aims to locate the event triggers of specified types in text.,POS,
2613,Event detection aims to locate the event triggers of specified types in text.,470,5,5,Introduction,abstract,Detailed experiments on the ACE 2005 and TAC-KBP 2015 corpora show that our proposed method is highly effective and adaptable.,Introduction,"Normally, triggers are words or nuggets that evoke the events of interest.",NC,
2614,"Normally, triggers are words or nuggets that evoke the events of interest.",471,5,6,Introduction,Introduction,Event detection aims to locate the event triggers of specified types in text.,Introduction,"Detecting events in an automatic way is challenging, not only because an event can be expressed in different words, but also because a word may express a variety of events in different contexts.",NC,
2615,"Detecting events in an automatic way is challenging, not only because an event can be expressed in different words, but also because a word may express a variety of events in different contexts.",472,5,7,Introduction,Introduction,"Normally, triggers are words or nuggets that evoke the events of interest.",Introduction,"In particular, the frequent utilization of common words, ambiguous words and pronouns in event mentions makes them harder to detect: 1) Generalitytaken home <Transport> Ambiguity 1campaign in Iraq <Attack> Ambiguity 2political campaign <Elect> Coreference -Either its bad or good <Marry> A promising solution to this challenge is through semantic understanding.",NC,
2616,"In particular, the frequent utilization of common words, ambiguous words and pronouns in event mentions makes them harder to detect: 1) Generalitytaken home <Transport> Ambiguity 1campaign in Iraq <Attack> Ambiguity 2political campaign <Elect> Coreference -Either its bad or good <Marry> A promising solution to this challenge is through semantic understanding.",473,5,8,Introduction,Introduction,"Detecting events in an automatic way is challenging, not only because an event can be expressed in different words, but also because a word may express a variety of events in different contexts.",Introduction,"Recently, neural networks have been widely used in this direction (Nguyen and Grishman, 2016; Ghaeini et al.,    *  Corresponding author 2016; Feng et al., 2016;Liu et al., 2017b;Chen et al., 2017), which allows semantics of event mentions (trigger plus context) to be encoded in a high-dimensional latent feature space.",NC,
2617,"Recently, neural networks have been widely used in this direction (Nguyen and Grishman, 2016; Ghaeini et al.,    *  Corresponding author 2016; Feng et al., 2016;Liu et al., 2017b;Chen et al., 2017), which allows semantics of event mentions (trigger plus context) to be encoded in a high-dimensional latent feature space.",474,5,9,Introduction,Introduction,"In particular, the frequent utilization of common words, ambiguous words and pronouns in event mentions makes them harder to detect: 1) Generalitytaken home <Transport> Ambiguity 1campaign in Iraq <Attack> Ambiguity 2political campaign <Elect> Coreference -Either its bad or good <Marry> A promising solution to this challenge is through semantic understanding.",Introduction,This facilitates the learning of deep-level semantics.,NC,
2618,This facilitates the learning of deep-level semantics.,475,5,10,Introduction,Introduction,"Recently, neural networks have been widely used in this direction (Nguyen and Grishman, 2016; Ghaeini et al.,    *  Corresponding author 2016; Feng et al., 2016;Liu et al., 2017b;Chen et al., 2017), which allows semantics of event mentions (trigger plus context) to be encoded in a high-dimensional latent feature space.",Introduction,"Besides, the use of neural networks not only strengthens current supervised classification of events but alleviates the complexity of feature engineering.",NC,
2619,"Besides, the use of neural networks not only strengthens current supervised classification of events but alleviates the complexity of feature engineering.",476,5,11,Introduction,Introduction,This facilitates the learning of deep-level semantics.,Introduction,"However, compared to the earlier study (Liao and Grishman, 2010;Hong et al., 2011;Li et al., 2013), in which the features are carefully designed by experts, the neural network based methods suffer more from spurious features.",NC,
2620,"However, compared to the earlier study (Liao and Grishman, 2010;Hong et al., 2011;Li et al., 2013), in which the features are carefully designed by experts, the neural network based methods suffer more from spurious features.",477,5,12,Introduction,Introduction,"Besides, the use of neural networks not only strengthens current supervised classification of events but alleviates the complexity of feature engineering.",Introduction,"Here, spurious feature is specified as the latent information which looks like the semantically related information to an event, but actually not (Liu et al., 2017a).",NC,
2621,"Here, spurious feature is specified as the latent information which looks like the semantically related information to an event, but actually not (Liu et al., 2017a).",478,5,13,Introduction,Introduction,"However, compared to the earlier study (Liao and Grishman, 2010;Hong et al., 2011;Li et al., 2013), in which the features are carefully designed by experts, the neural network based methods suffer more from spurious features.",Introduction,"For example, in the following sample, the semantic information of the word ""prison"" most probably enables spurious features to come into being, because the word often co-occurs with the trigger ""taken"" to evoke an Arrest-jail event instead of the ground-truth event Transport: 2) Prison authorities have given the nod for Anwar to be taken home later in the afternoon.",NC,
2622,"For example, in the following sample, the semantic information of the word ""prison"" most probably enables spurious features to come into being, because the word often co-occurs with the trigger ""taken"" to evoke an Arrest-jail event instead of the ground-truth event Transport: 2) Prison authorities have given the nod for Anwar to be taken home later in the afternoon.",479,5,14,Introduction,Introduction,"Here, spurious feature is specified as the latent information which looks like the semantically related information to an event, but actually not (Liu et al., 2017a).",Introduction,Trigger: taken.,NC,
2623,Trigger: taken.,480,5,15,Introduction,Introduction,"For example, in the following sample, the semantic information of the word ""prison"" most probably enables spurious features to come into being, because the word often co-occurs with the trigger ""taken"" to evoke an Arrest-jail event instead of the ground-truth event Transport: 2) Prison authorities have given the nod for Anwar to be taken home later in the afternoon.",Introduction,"Event Type: Transport It is certain that spurious features often result from the semantically pseudo-related context, and during training, a neural network may mistakenly and unconsciously preserve the memory to produce the fakes.",NC,
2624,"Event Type: Transport It is certain that spurious features often result from the semantically pseudo-related context, and during training, a neural network may mistakenly and unconsciously preserve the memory to produce the fakes.",481,5,16,Introduction,Introduction,Trigger: taken.,Introduction,"However, it is difficult to determine which words are pseudo-related in a specific case, and when they will ""jump out"" to mislead the generation of latent features during testing.",NC,
2625,"However, it is difficult to determine which words are pseudo-related in a specific case, and when they will ""jump out"" to mislead the generation of latent features during testing.",482,5,17,Introduction,Introduction,"Event Type: Transport It is certain that spurious features often result from the semantically pseudo-related context, and during training, a neural network may mistakenly and unconsciously preserve the memory to produce the fakes.",Introduction,"To address the challenge, we suggest to regulate the learning process with a two-channel selfregulated learning strategy.",NC,
2626,"To address the challenge, we suggest to regulate the learning process with a two-channel selfregulated learning strategy.",483,5,18,Introduction,Introduction,"However, it is difficult to determine which words are pseudo-related in a specific case, and when they will ""jump out"" to mislead the generation of latent features during testing.",Introduction,"In the self-regulation process, on one hand, a generative adversarial network is trained to produce the most spurious features, while on the other hand, a neural network Figure 1: Self-regulated learning scheme is equipped with a memory suppressor to eliminate the fakes.",FACT,
2627,"In the self-regulation process, on one hand, a generative adversarial network is trained to produce the most spurious features, while on the other hand, a neural network Figure 1: Self-regulated learning scheme is equipped with a memory suppressor to eliminate the fakes.",484,5,19,Introduction,Introduction,"To address the challenge, we suggest to regulate the learning process with a two-channel selfregulated learning strategy.",Introduction,"Detailed experiments on event detection show that our proposed method achieves a substantial performance gain, and is capable of robust domain adaptation.",FACT,
2628,"Detailed experiments on event detection show that our proposed method achieves a substantial performance gain, and is capable of robust domain adaptation.",485,5,20,Introduction,Introduction,"In the self-regulation process, on one hand, a generative adversarial network is trained to produce the most spurious features, while on the other hand, a neural network Figure 1: Self-regulated learning scheme is equipped with a memory suppressor to eliminate the fakes.",Task Definition,The task of event detection is to determine whether there is one or more event triggers in a sentence.,POS,
2629,"SELF is a double-channel model (Figure 1), consisted of a cooperative network (Islam et al., 2003) and a generative adversarial net (GAN) (Goodfellow et al., 2014).",486,5,25,Self-Regulated Learning (SELF),Task Definition,"Given a sentence, we classify every token of the sentence into one of the predefined event classes (Doddington et al., 2004) or non-trigger class.",Self-Regulated Learning (SELF),A memory suppressor S is used to regulate communication between the channels.,NC,
2630,A memory suppressor S is used to regulate communication between the channels.,487,5,26,Self-Regulated Learning (SELF),Self-Regulated Learning (SELF),"SELF is a double-channel model (Figure 1), consisted of a cooperative network (Islam et al., 2003) and a generative adversarial net (GAN) (Goodfellow et al., 2014).",Cooperative Network,"In channel 1, the generator G is specified as a multilayer perceptron.",NC,
2631,"In channel 1, the generator G is specified as a multilayer perceptron.",488,5,27,Cooperative Network,Self-Regulated Learning (SELF),A memory suppressor S is used to regulate communication between the channels.,Cooperative Network,"It plays a role of a ""diligent student"".",NC,
2632,"It plays a role of a ""diligent student"".",489,5,28,Cooperative Network,Cooperative Network,"In channel 1, the generator G is specified as a multilayer perceptron.",Cooperative Network,"By a differentiable function G(x, θ g ) with parameters θ g , the generator learns to produce a vector of latent features o g that may best characterize the token x, i.e., o g = G(x, θ g ).",NC,
2633,"By a differentiable function G(x, θ g ) with parameters θ g , the generator learns to produce a vector of latent features o g that may best characterize the token x, i.e., o g = G(x, θ g ).",490,5,29,Cooperative Network,Cooperative Network,"It plays a role of a ""diligent student"".",Cooperative Network,"The discriminator D (called ""a lucky professor"") is a single-layer perceptron, implemented as a differentiable function D(o g , θ d ) with parameters θ d .",NC,
2634,"The discriminator D (called ""a lucky professor"") is a single-layer perceptron, implemented as a differentiable function D(o g , θ d ) with parameters θ d .",491,5,30,Cooperative Network,Cooperative Network,"By a differentiable function G(x, θ g ) with parameters θ g , the generator learns to produce a vector of latent features o g that may best characterize the token x, i.e., o g = G(x, θ g ).",Cooperative Network,"Relying on the feature vector o g , it attempts to accurately predict the probability of the token x triggering an event for all event classes, i.e., ŷ = D(o g , θ d ), and assigns x to the most probable class c (iff ŷc > ∀ŷ c, c = c).",NC,
2635,"Relying on the feature vector o g , it attempts to accurately predict the probability of the token x triggering an event for all event classes, i.e., ŷ = D(o g , θ d ), and assigns x to the most probable class c (iff ŷc > ∀ŷ c, c = c).",492,5,31,Cooperative Network,Cooperative Network,"The discriminator D (called ""a lucky professor"") is a single-layer perceptron, implemented as a differentiable function D(o g , θ d ) with parameters θ d .",Cooperative Network,"Therefore, G and D cooperate with each other during training, developing the parameters θ g and θ d with the same goal -to minimize the performance loss L(ŷ, y) in the detection task: θ g θ d = argmin L(ŷ, y) (1) where, y denotes the ground-truth probability distribution over event classes, and L indicates the deviation of the prediction from the ground truth.",NC,
2636,"Therefore, G and D cooperate with each other during training, developing the parameters θ g and θ d with the same goal -to minimize the performance loss L(ŷ, y) in the detection task: θ g θ d = argmin L(ŷ, y) (1) where, y denotes the ground-truth probability distribution over event classes, and L indicates the deviation of the prediction from the ground truth.",493,5,32,Cooperative Network,Cooperative Network,"Relying on the feature vector o g , it attempts to accurately predict the probability of the token x triggering an event for all event classes, i.e., ŷ = D(o g , θ d ), and assigns x to the most probable class c (iff ŷc > ∀ŷ c, c = c).",Generative Adversarial Network,"In channel 2, the generator Ǧ and discriminator Ď have the same perceptual structures as G and D. They also perform learning by differentiable functions, respectively Ǧ(x, θ ǧ) and Ď(o ǧ, θ ď).",NC,
2637,"In channel 2, the generator Ǧ and discriminator Ď have the same perceptual structures as G and D. They also perform learning by differentiable functions, respectively Ǧ(x, θ ǧ) and Ď(o ǧ, θ ď).",494,5,33,Generative Adversarial Network,Cooperative Network,"Therefore, G and D cooperate with each other during training, developing the parameters θ g and θ d with the same goal -to minimize the performance loss L(ŷ, y) in the detection task: θ g θ d = argmin L(ŷ, y) (1) where, y denotes the ground-truth probability distribution over event classes, and L indicates the deviation of the prediction from the ground truth.",Generative Adversarial Network,"A major difference, however, is that they are caught into a cycle of highly adversarial competition.",NC,
2638,"A major difference, however, is that they are caught into a cycle of highly adversarial competition.",495,5,34,Generative Adversarial Network,Generative Adversarial Network,"In channel 2, the generator Ǧ and discriminator Ď have the same perceptual structures as G and D. They also perform learning by differentiable functions, respectively Ǧ(x, θ ǧ) and Ď(o ǧ, θ ď).",Generative Adversarial Network,"The generator Ǧ is a ""trouble maker"".",NC,
2639,"The generator Ǧ is a ""trouble maker"".",496,5,35,Generative Adversarial Network,Generative Adversarial Network,"A major difference, however, is that they are caught into a cycle of highly adversarial competition.",Generative Adversarial Network,"It learns to produce spurious features, and utilizes them to contaminate the feature vector o ǧ of the token x.",NC,
2640,"It learns to produce spurious features, and utilizes them to contaminate the feature vector o ǧ of the token x.",497,5,36,Generative Adversarial Network,Generative Adversarial Network,"The generator Ǧ is a ""trouble maker"".",Generative Adversarial Network,"Thus Ǧ changes a real sample x into a fake zsometimes successfully, sometimes less so.",NC,
2641,"Thus Ǧ changes a real sample x into a fake zsometimes successfully, sometimes less so.",498,5,37,Generative Adversarial Network,Generative Adversarial Network,"It learns to produce spurious features, and utilizes them to contaminate the feature vector o ǧ of the token x.",Generative Adversarial Network,"Using the fakes, Ǧ repeatedly instigates the discriminator Ď to make mistakes.",NC,
2642,"Using the fakes, Ǧ repeatedly instigates the discriminator Ď to make mistakes.",499,5,38,Generative Adversarial Network,Generative Adversarial Network,"Thus Ǧ changes a real sample x into a fake zsometimes successfully, sometimes less so.",Generative Adversarial Network,"On the other side, Ď (""a hapless professor"") has to avoid being deceived, and struggles to correctly detect events no matter whether it encounters x or z.",NC,
2643,"On the other side, Ď (""a hapless professor"") has to avoid being deceived, and struggles to correctly detect events no matter whether it encounters x or z.",500,5,39,Generative Adversarial Network,Generative Adversarial Network,"Using the fakes, Ǧ repeatedly instigates the discriminator Ď to make mistakes.",Generative Adversarial Network,"In order to outsmart the adversary, Ǧ develops the parameters θ ǧ during training to maximize the performance loss, but on the contrary, Ď develops the parameters θ ď to minimize the loss: θ ǧ = argmax L(ŷ, y) (2) θ ď = argmin L(ŷ, y) Numerous studies have confirmed that the twoplayer minmax game enables both Ǧ and Ď to improve their methods (Goodfellow et al., 2014;Liu and Tuzel, 2016;Huang et al., 2017).",NC,
2644,"In order to outsmart the adversary, Ǧ develops the parameters θ ǧ during training to maximize the performance loss, but on the contrary, Ď develops the parameters θ ď to minimize the loss: θ ǧ = argmax L(ŷ, y) (2) θ ď = argmin L(ŷ, y) Numerous studies have confirmed that the twoplayer minmax game enables both Ǧ and Ď to improve their methods (Goodfellow et al., 2014;Liu and Tuzel, 2016;Huang et al., 2017).",501,5,40,Generative Adversarial Network,Generative Adversarial Network,"On the other side, Ď (""a hapless professor"") has to avoid being deceived, and struggles to correctly detect events no matter whether it encounters x or z.",Regulation with Memory Suppressor,"Using a memory suppressor, we try to optimize the diligent student G. The goal is to enable G to be as dissimilar as possible to the troublemaker Ǧ.",NC,
2645,"Using a memory suppressor, we try to optimize the diligent student G. The goal is to enable G to be as dissimilar as possible to the troublemaker Ǧ.",502,5,41,Regulation with Memory Suppressor,Generative Adversarial Network,"In order to outsmart the adversary, Ǧ develops the parameters θ ǧ during training to maximize the performance loss, but on the contrary, Ď develops the parameters θ ď to minimize the loss: θ ǧ = argmax L(ŷ, y) (2) θ ď = argmin L(ŷ, y) Numerous studies have confirmed that the twoplayer minmax game enables both Ǧ and Ď to improve their methods (Goodfellow et al., 2014;Liu and Tuzel, 2016;Huang et al., 2017).",Regulation with Memory Suppressor,The suppressor uses the output o ǧ of Ǧ as a reference resource which should be full of spurious features.,NC,
2646,The suppressor uses the output o ǧ of Ǧ as a reference resource which should be full of spurious features.,503,5,42,Regulation with Memory Suppressor,Regulation with Memory Suppressor,"Using a memory suppressor, we try to optimize the diligent student G. The goal is to enable G to be as dissimilar as possible to the troublemaker Ǧ.",Regulation with Memory Suppressor,"On the basis, it looks over the output o g of G, so as to verify whether the features in o g are different to those in o ǧ.",NC,
2647,"On the basis, it looks over the output o g of G, so as to verify whether the features in o g are different to those in o ǧ.",504,5,43,Regulation with Memory Suppressor,Regulation with Memory Suppressor,The suppressor uses the output o ǧ of Ǧ as a reference resource which should be full of spurious features.,Regulation with Memory Suppressor,"If very different, the suppressor allows G to preserve the memory (viz., θ g in G(x, θ g )), otherwise update.",NC,
2648,"If very different, the suppressor allows G to preserve the memory (viz., θ g in G(x, θ g )), otherwise update.",505,5,44,Regulation with Memory Suppressor,Regulation with Memory Suppressor,"On the basis, it looks over the output o g of G, so as to verify whether the features in o g are different to those in o ǧ.",Regulation with Memory Suppressor,"In other word, for G, the suppressor forcibly erases the memory which may result in the generation of spurious features.",NC,
2649,"In other word, for G, the suppressor forcibly erases the memory which may result in the generation of spurious features.",506,5,45,Regulation with Memory Suppressor,Regulation with Memory Suppressor,"If very different, the suppressor allows G to preserve the memory (viz., θ g in G(x, θ g )), otherwise update.",Regulation with Memory Suppressor,We call this the self-regulation.,NC,
2650,We call this the self-regulation.,507,5,46,Regulation with Memory Suppressor,Regulation with Memory Suppressor,"In other word, for G, the suppressor forcibly erases the memory which may result in the generation of spurious features.",Regulation with Memory Suppressor,Self-regulation is performed for the whole sentence which is fed into G and Ǧ.,NC,
2651,Self-regulation is performed for the whole sentence which is fed into G and Ǧ.,508,5,47,Regulation with Memory Suppressor,Regulation with Memory Suppressor,We call this the self-regulation.,Regulation with Memory Suppressor,"Assume that O g is a matrix, constituted with a series of feature vectors, i.e., the vectors generated by G for all the tokens in an input sentence (o g ∈ O g ), while O ǧ is another feature matrix, generated by Ǧ for the tokens (o ǧ ∈ O ǧ).",NC,
2652,"Assume that O g is a matrix, constituted with a series of feature vectors, i.e., the vectors generated by G for all the tokens in an input sentence (o g ∈ O g ), while O ǧ is another feature matrix, generated by Ǧ for the tokens (o ǧ ∈ O ǧ).",509,5,48,Regulation with Memory Suppressor,Regulation with Memory Suppressor,Self-regulation is performed for the whole sentence which is fed into G and Ǧ.,Regulation with Memory Suppressor,"Thus, we utilize the matrix approximation between O g and O ǧ for measuring the loss of self-regulation learning L dif f .",NC,
2653,"Thus, we utilize the matrix approximation between O g and O ǧ for measuring the loss of self-regulation learning L dif f .",510,5,49,Regulation with Memory Suppressor,Regulation with Memory Suppressor,"Assume that O g is a matrix, constituted with a series of feature vectors, i.e., the vectors generated by G for all the tokens in an input sentence (o g ∈ O g ), while O ǧ is another feature matrix, generated by Ǧ for the tokens (o ǧ ∈ O ǧ).",Regulation with Memory Suppressor,"The higher the similarity, the greater the loss.",NC,
2654,"The higher the similarity, the greater the loss.",511,5,50,Regulation with Memory Suppressor,Regulation with Memory Suppressor,"Thus, we utilize the matrix approximation between O g and O ǧ for measuring the loss of self-regulation learning L dif f .",Regulation with Memory Suppressor,"During training, the generator G is required to develop the parameters θ g to minimize the loss: θ g = argmin L dif f (o g , o ǧ) (4) We present in detail the matrix approximate calculation in section 4.4, where the squared Frobenius norm (Bousmalis et al., 2016) is used.",NC,
2655,"During training, the generator G is required to develop the parameters θ g to minimize the loss: θ g = argmin L dif f (o g , o ǧ) (4) We present in detail the matrix approximate calculation in section 4.4, where the squared Frobenius norm (Bousmalis et al., 2016) is used.",512,5,51,Regulation with Memory Suppressor,Regulation with Memory Suppressor,"The higher the similarity, the greater the loss.",Learning to Predict,"We incorporate the cooperative network with the GAN, and enhance their learning by joint training.",NC,
2656,"We incorporate the cooperative network with the GAN, and enhance their learning by joint training.",513,5,52,Learning to Predict,Regulation with Memory Suppressor,"During training, the generator G is required to develop the parameters θ g to minimize the loss: θ g = argmin L dif f (o g , o ǧ) (4) We present in detail the matrix approximate calculation in section 4.4, where the squared Frobenius norm (Bousmalis et al., 2016) is used.",Learning to Predict,"In the 4-member incorporation, i.e., {G, Ǧ, D and Ď}, the primary beneficiary is the lucky professor D. It can benefit from both the cooperation in channel 1 and the competition in channel 2.",NC,
2657,"In the 4-member incorporation, i.e., {G, Ǧ, D and Ď}, the primary beneficiary is the lucky professor D. It can benefit from both the cooperation in channel 1 and the competition in channel 2.",514,5,53,Learning to Predict,Learning to Predict,"We incorporate the cooperative network with the GAN, and enhance their learning by joint training.",Learning to Predict,"The latent features it uses are well-produced by G, and decontaminated by eliminating possible fakes like those made by Ǧ.",NC,
2658,"The latent features it uses are well-produced by G, and decontaminated by eliminating possible fakes like those made by Ǧ.",515,5,54,Learning to Predict,Learning to Predict,"In the 4-member incorporation, i.e., {G, Ǧ, D and Ď}, the primary beneficiary is the lucky professor D. It can benefit from both the cooperation in channel 1 and the competition in channel 2.",Learning to Predict,"Therefore, in experiments, we choose to output the prediction results of D. In this paper, we use two recurrent neural networks (RNN) (Sutskever et al., 2014;Chung et al., 2014) of the same structure as the generators.",NC,
2659,"Therefore, in experiments, we choose to output the prediction results of D. In this paper, we use two recurrent neural networks (RNN) (Sutskever et al., 2014;Chung et al., 2014) of the same structure as the generators.",516,5,55,Learning to Predict,Learning to Predict,"The latent features it uses are well-produced by G, and decontaminated by eliminating possible fakes like those made by Ǧ.",Learning to Predict,And both the discriminators are implemented as a fullyconnected layer followed by a softmax layer.,NC,
2660,And both the discriminators are implemented as a fullyconnected layer followed by a softmax layer.,517,5,56,Learning to Predict,Learning to Predict,"Therefore, in experiments, we choose to output the prediction results of D. In this paper, we use two recurrent neural networks (RNN) (Sutskever et al., 2014;Chung et al., 2014) of the same structure as the generators.",Recurrent Models for SELF,"RNN with long short-term memory (abbr., LSTM) is adopted due to the superior performance in a variety of NLP tasks (Liu et al., 2016a;Lin et al., 2017;Liu et al., 2017a).",NC,
2661,The state-of-the-art models proposed in the past decade are compared with ours.,518,5,110,Compared Systems,Hyperparameter Settings,The source code of SELF 2 to reproduce the experiments has been made publicly available.,Compared Systems,"By taking learning framework as the criterion, we divide the models into three classes: Minimally supervised approach: is Peng et al ( 2016)'s MSEP-EMD.",NC,
2662,"By taking learning framework as the criterion, we divide the models into three classes: Minimally supervised approach: is Peng et al ( 2016)'s MSEP-EMD.",519,5,111,Compared Systems,Compared Systems,The state-of-the-art models proposed in the past decade are compared with ours.,Compared Systems,"Feature based approaches: primarily including Liao and Grishman (2010)'s Cross-Event inference model, which is based on the max-entropy classification and embeds the document-level confident information in the feature space; Hong et al (2011)'s Cross-Entity inference model, in which existential backgrounds of name entities are employed as the additional discriminant features; and Li et al ( 2013)'s Joint model, a sophisticated predictor frequently ranked among the top 3 in recent TAC-KBP evaluations for nugget and coreference detection (Hong et al., 2014(Hong et al., , 2015;;Yu et al., 2016).",NC,
2663,"Feature based approaches: primarily including Liao and Grishman (2010)'s Cross-Event inference model, which is based on the max-entropy classification and embeds the document-level confident information in the feature space; Hong et al (2011)'s Cross-Entity inference model, in which existential backgrounds of name entities are employed as the additional discriminant features; and Li et al ( 2013)'s Joint model, a sophisticated predictor frequently ranked among the top 3 in recent TAC-KBP evaluations for nugget and coreference detection (Hong et al., 2014(Hong et al., , 2015;;Yu et al., 2016).",520,5,112,Compared Systems,Compared Systems,"By taking learning framework as the criterion, we divide the models into three classes: Minimally supervised approach: is Peng et al ( 2016)'s MSEP-EMD.",Compared Systems,It is based on structured perceptron and combines the local and global features.,NC,
2664,It is based on structured perceptron and combines the local and global features.,521,5,113,Compared Systems,Compared Systems,"Feature based approaches: primarily including Liao and Grishman (2010)'s Cross-Event inference model, which is based on the max-entropy classification and embeds the document-level confident information in the feature space; Hong et al (2011)'s Cross-Entity inference model, in which existential backgrounds of name entities are employed as the additional discriminant features; and Li et al ( 2013)'s Joint model, a sophisticated predictor frequently ranked among the top 3 in recent TAC-KBP evaluations for nugget and coreference detection (Hong et al., 2014(Hong et al., , 2015;;Yu et al., 2016).",Compared Systems,"Neural network based approaches: including the convolutional neural network (CNN) (Nguyen and Grishman, 2015), the non-consecutive Ngrams based CNN (NC-CNN) (Nguyen and Grishman, 2016) and the CNN that is assembled with a dynamic multi-pooling layer (DM-CNN) (Chen et al., 2015).",NC,
2665,"Neural network based approaches: including the convolutional neural network (CNN) (Nguyen and Grishman, 2015), the non-consecutive Ngrams based CNN (NC-CNN) (Nguyen and Grishman, 2016) and the CNN that is assembled with a dynamic multi-pooling layer (DM-CNN) (Chen et al., 2015).",522,5,114,Compared Systems,Compared Systems,It is based on structured perceptron and combines the local and global features.,Compared Systems,Others include Ghaeini et al (2016) FrameNet (FN) and Wikipeida (Wiki).,NC,
2666,Others include Ghaeini et al (2016) FrameNet (FN) and Wikipeida (Wiki).,523,5,115,Compared Systems,Compared Systems,"Neural network based approaches: including the convolutional neural network (CNN) (Nguyen and Grishman, 2015), the non-consecutive Ngrams based CNN (NC-CNN) (Nguyen and Grishman, 2016) and the CNN that is assembled with a dynamic multi-pooling layer (DM-CNN) (Chen et al., 2015).",Experimental Results,"We evaluate our model using Precision (P), Recall (R) and F-score (F).",NC,
2667,"We evaluate our model using Precision (P), Recall (R) and F-score (F).",524,5,116,Experimental Results,Compared Systems,Others include Ghaeini et al (2016) FrameNet (FN) and Wikipeida (Wiki).,Experimental Results,"To facilitate the comparison, we review the best performance of the competitors, which has been evaluated using the same metrics, and publicly reported earlier.",NC,
2668,"To facilitate the comparison, we review the best performance of the competitors, which has been evaluated using the same metrics, and publicly reported earlier.",525,5,117,Experimental Results,Experimental Results,"We evaluate our model using Precision (P), Recall (R) and F-score (F).",Trigger identification,Table 1 shows the trigger identification performance.,NC,
2669,Table 1 shows the trigger identification performance.,526,5,118,Trigger identification,Experimental Results,"To facilitate the comparison, we review the best performance of the competitors, which has been evaluated using the same metrics, and publicly reported earlier.",Trigger identification,"It can be observed that SELF outperforms other models, with a performance gain of no less than 1.1% F-score.",NC,
2670,"It can be observed that SELF outperforms other models, with a performance gain of no less than 1.1% F-score.",527,5,119,Trigger identification,Trigger identification,Table 1 shows the trigger identification performance.,Trigger identification,"Frankly, the performance mainly benefits from the higher recall (78.8%).",POS,
2671,"Frankly, the performance mainly benefits from the higher recall (78.8%).",528,5,120,Trigger identification,Trigger identification,"It can be observed that SELF outperforms other models, with a performance gain of no less than 1.1% F-score.",Trigger identification,But in fact the relatively comparable precision (75.3%) to the recall reinforces the advantages.,POS,
2672,But in fact the relatively comparable precision (75.3%) to the recall reinforces the advantages.,529,5,121,Trigger identification,Trigger identification,"Frankly, the performance mainly benefits from the higher recall (78.8%).",Trigger identification,"By contrast, although most of the compared models achieve much higher precision over SELF, they suffer greatly from the substantial gaps between precision and recall.",POS,
2673,"By contrast, although most of the compared models achieve much higher precision over SELF, they suffer greatly from the substantial gaps between precision and recall.",530,5,122,Trigger identification,Trigger identification,But in fact the relatively comparable precision (75.3%) to the recall reinforces the advantages.,Trigger identification,The advantage is offset by the greater loss of recall.,POS,
2674,The advantage is offset by the greater loss of recall.,531,5,123,Trigger identification,Trigger identification,"By contrast, although most of the compared models achieve much higher precision over SELF, they suffer greatly from the substantial gaps between precision and recall.",Trigger identification,GAN plays an important role in optimizing Bi-RNN.,POS,
2675,GAN plays an important role in optimizing Bi-RNN.,532,5,124,Trigger identification,Trigger identification,The advantage is offset by the greater loss of recall.,Trigger identification,This is proven by the fact that SELF (Bi-LSTM+GAN) outperforms Nguyen et al (2016)'s Bi-RNN.,POS,
2676,This is proven by the fact that SELF (Bi-LSTM+GAN) outperforms Nguyen et al (2016)'s Bi-RNN.,533,5,125,Trigger identification,Trigger identification,GAN plays an important role in optimizing Bi-RNN.,Trigger identification,"To be honest, the models use two different kinds of recurrent units.",POS,
2677,"To be honest, the models use two different kinds of recurrent units.",534,5,126,Trigger identification,Trigger identification,This is proven by the fact that SELF (Bi-LSTM+GAN) outperforms Nguyen et al (2016)'s Bi-RNN.,Trigger identification,"Bi-RNN uses GRUs, but SELF uses the units that possess LSTM.",NEG,
2678,"Bi-RNN uses GRUs, but SELF uses the units that possess LSTM.",535,5,127,Trigger identification,Trigger identification,"To be honest, the models use two different kinds of recurrent units.",Trigger identification,"Nevertheless, GRU has been experimentally proven to be comparable in performance to LSTM (Chung et al., 2014;Jozefowicz et al., 2015).",NEG,
2679,"Nevertheless, GRU has been experimentally proven to be comparable in performance to LSTM (Chung et al., 2014;Jozefowicz et al., 2015).",536,5,128,Trigger identification,Trigger identification,"Bi-RNN uses GRUs, but SELF uses the units that possess LSTM.",Trigger identification,This allows a fair comparison between Bi-RNN and SELF.,NC,
2680,This allows a fair comparison between Bi-RNN and SELF.,537,5,129,Trigger identification,Trigger identification,"Nevertheless, GRU has been experimentally proven to be comparable in performance to LSTM (Chung et al., 2014;Jozefowicz et al., 2015).",Event classification,Table 2 shows the performance of multi-class classification.,POS,
2681,Table 2 shows the performance of multi-class classification.,538,5,130,Event classification,Trigger identification,This allows a fair comparison between Bi-RNN and SELF.,Event classification,"SELF achieves nearly the same F-score as Feng et al (2016)'s Hybrid, and outperforms the others.",NC,
2682,"SELF achieves nearly the same F-score as Feng et al (2016)'s Hybrid, and outperforms the others.",539,5,131,Event classification,Event classification,Table 2 shows the performance of multi-class classification.,Event classification,"More importantly, SELF is the only one which obtains a performance higher than 70% for both precision and recall.",POS,
2683,"More importantly, SELF is the only one which obtains a performance higher than 70% for both precision and recall.",540,5,132,Event classification,Event classification,"SELF achieves nearly the same F-score as Feng et al (2016)'s Hybrid, and outperforms the others.",Event classification,"Besides, by analyzing the experimental results, we have identified the following regularities: • Similar to the pattern classifiers that are based on hand-designed features, the CNN models enable higher precision to be obtained.",POS,
2684,"Besides, by analyzing the experimental results, we have identified the following regularities: • Similar to the pattern classifiers that are based on hand-designed features, the CNN models enable higher precision to be obtained.",541,5,133,Event classification,Event classification,"More importantly, SELF is the only one which obtains a performance higher than 70% for both precision and recall.",Event classification,However the recall is lower.,POS,
2685,However the recall is lower.,542,5,134,Event classification,Event classification,"Besides, by analyzing the experimental results, we have identified the following regularities: • Similar to the pattern classifiers that are based on hand-designed features, the CNN models enable higher precision to be obtained.",Event classification,• The RNN models contribute to achieving a higher recall.,POS,
2686,• The RNN models contribute to achieving a higher recall.,543,5,135,Event classification,Event classification,However the recall is lower.,Event classification,However the precision is lower.,POS,
2687,However the precision is lower.,544,5,136,Event classification,Event classification,• The RNN models contribute to achieving a higher recall.,Event classification,• Expansion of the training data set helps to increase the precision.,POS,
2688,• Expansion of the training data set helps to increase the precision.,545,5,137,Event classification,Event classification,However the precision is lower.,Event classification,"Let us turn to the structurally more complicated models, SELF and Hybrid.",POS,
2689,"Let us turn to the structurally more complicated models, SELF and Hybrid.",546,5,138,Event classification,Event classification,• Expansion of the training data set helps to increase the precision.,Event classification,"SELF inherits the merits of the RNN models, classifying the events with higher recall.",NC,
2690,"SELF inherits the merits of the RNN models, classifying the events with higher recall.",547,5,139,Event classification,Event classification,"Let us turn to the structurally more complicated models, SELF and Hybrid.",Event classification,"Besides, by the utilization of GAN, SELF has evolved from the traditional learning strategies, being capable of learning from GAN and getting rid of the mistakenly generated spurious features.",POS,
2691,"Besides, by the utilization of GAN, SELF has evolved from the traditional learning strategies, being capable of learning from GAN and getting rid of the mistakenly generated spurious features.",548,5,140,Event classification,Event classification,"SELF inherits the merits of the RNN models, classifying the events with higher recall.",Event classification,"So that it outperforms other RNNs, with improvements of no less than 4.5% precision and 1.7% recall.",POS,
2692,"So that it outperforms other RNNs, with improvements of no less than 4.5% precision and 1.7% recall.",549,5,141,Event classification,Event classification,"Besides, by the utilization of GAN, SELF has evolved from the traditional learning strategies, being capable of learning from GAN and getting rid of the mistakenly generated spurious features.",Event classification,Hybrid is elaborately established by assembling a RNN with a CNN.,POS,
2693,Hybrid is elaborately established by assembling a RNN with a CNN.,550,5,142,Event classification,Event classification,"So that it outperforms other RNNs, with improvements of no less than 4.5% precision and 1.7% recall.",Event classification,It models an event from two perspectives: language generation and pragmatics.,NC,
2694,It models an event from two perspectives: language generation and pragmatics.,551,5,143,Event classification,Event classification,Hybrid is elaborately established by assembling a RNN with a CNN.,Event classification,"The former is deeply learned by using the continuous states hidden in the recurrent units, while the later the convolutional features.",NC,
2695,"The former is deeply learned by using the continuous states hidden in the recurrent units, while the later the convolutional features.",552,5,144,Event classification,Event classification,It models an event from two perspectives: language generation and pragmatics.,Event classification,Multi-angled cognition enables Hybrid to be more precise.,NC,
2696,Multi-angled cognition enables Hybrid to be more precise.,553,5,145,Event classification,Event classification,"The former is deeply learned by using the continuous states hidden in the recurrent units, while the later the convolutional features.",Event classification,"However it is built using a single-channel architecture, concatenating the RNN and the CNN.",NC,
2697,"However it is built using a single-channel architecture, concatenating the RNN and the CNN.",554,5,146,Event classification,Event classification,Multi-angled cognition enables Hybrid to be more precise.,Event classification,"This results in twofold accumulation of feature information, causing a serious overfitting problem.",NEG,
2698,"This results in twofold accumulation of feature information, causing a serious overfitting problem.",555,5,147,Event classification,Event classification,"However it is built using a single-channel architecture, concatenating the RNN and the CNN.",Event classification,"Therefore, Hybrid is localized to much higher precision but substantially lower recall.",NEG,
2699,"Therefore, Hybrid is localized to much higher precision but substantially lower recall.",556,5,148,Event classification,Event classification,"This results in twofold accumulation of feature information, causing a serious overfitting problem.",Event classification,Overfitting results in enlargement of the gap between precision and recall when the task changes to be more difficult.,POS,
2700,Overfitting results in enlargement of the gap between precision and recall when the task changes to be more difficult.,557,5,149,Event classification,Event classification,"Therefore, Hybrid is localized to much higher precision but substantially lower recall.",Event classification,"For Hybrid, as illustrated in  Figure 2, the gap becomes much wider (from 9% to 19.7%) when the binary classification task (trigger identification) is shifted to multi-class classification (event detection).",NC,
2701,"For Hybrid, as illustrated in  Figure 2, the gap becomes much wider (from 9% to 19.7%) when the binary classification task (trigger identification) is shifted to multi-class classification (event detection).",558,5,150,Event classification,Event classification,Overfitting results in enlargement of the gap between precision and recall when the task changes to be more difficult.,Event classification,"By contrast, other work shows a nearly constant gap.",NEG,
2702,"By contrast, other work shows a nearly constant gap.",559,5,151,Event classification,Event classification,"For Hybrid, as illustrated in  Figure 2, the gap becomes much wider (from 9% to 19.7%) when the binary classification task (trigger identification) is shifted to multi-class classification (event detection).",Event classification,"In particular, SELF yields a minimum gap in each task, which changes negligibly from 3.5% to 3.4%.",NEG,
2703,"In particular, SELF yields a minimum gap in each task, which changes negligibly from 3.5% to 3.4%.",560,5,152,Event classification,Event classification,"By contrast, other work shows a nearly constant gap.",Event classification,"It may be added that, similar to DM-CNN and FB-RNN, SELF is cost-effective.",POS,
2704,"It may be added that, similar to DM-CNN and FB-RNN, SELF is cost-effective.",561,5,153,Event classification,Event classification,"In particular, SELF yields a minimum gap in each task, which changes negligibly from 3.5% to 3.4%.",Event classification,"Compared to other models (Table 3), it either uses less training data, or is only required to learn two kinds of embeddings, such as that of words and entity types.",POS,
2705,"Compared to other models (Table 3), it either uses less training data, or is only required to learn two kinds of embeddings, such as that of words and entity types.",562,5,154,Event classification,Event classification,"It may be added that, similar to DM-CNN and FB-RNN, SELF is cost-effective.","Discussion: Adaptation, Robustness and Effectiveness",Domain adaptation is a key criteria for evaluating the utility of a model in practical application.,POS,
2706,Domain adaptation is a key criteria for evaluating the utility of a model in practical application.,563,5,155,"Discussion: Adaptation, Robustness and Effectiveness",Event classification,"Compared to other models (Table 3), it either uses less training data, or is only required to learn two kinds of embeddings, such as that of words and entity types.","Discussion: Adaptation, Robustness and Effectiveness","A model can be thought of being adaptable only if it works well for the unlabeled data in the target domain when trained on the source domain (Blitzer et al., 2006;Plank and Moschitti, 2013).",NC,
2707,"A model can be thought of being adaptable only if it works well for the unlabeled data in the target domain when trained on the source domain (Blitzer et al., 2006;Plank and Moschitti, 2013).",564,5,156,"Discussion: Adaptation, Robustness and Effectiveness","Discussion: Adaptation, Robustness and Effectiveness",Domain adaptation is a key criteria for evaluating the utility of a model in practical application.,"Discussion: Adaptation, Robustness and Effectiveness","We perform two groups of domain adaptation experiments, respectively, using the ACE 2005 corpus and the corpus for TAC-KBP 2015 event nugget track (Ellis et al., 2015).",NC,
2708,"We perform two groups of domain adaptation experiments, respectively, using the ACE 2005 corpus and the corpus for TAC-KBP 2015 event nugget track (Ellis et al., 2015).",565,5,157,"Discussion: Adaptation, Robustness and Effectiveness","Discussion: Adaptation, Robustness and Effectiveness","A model can be thought of being adaptable only if it works well for the unlabeled data in the target domain when trained on the source domain (Blitzer et al., 2006;Plank and Moschitti, 2013).","Discussion: Adaptation, Robustness and Effectiveness","The ACE corpus consists of 6 domains: broad-cast conversation (bc), broadcast news (bn), telephone conversation (cts), newswire (nw), usenet (un) and web blogs (wl).",FACT,
2709,"The ACE corpus consists of 6 domains: broad-cast conversation (bc), broadcast news (bn), telephone conversation (cts), newswire (nw), usenet (un) and web blogs (wl).",566,5,158,"Discussion: Adaptation, Robustness and Effectiveness","Discussion: Adaptation, Robustness and Effectiveness","We perform two groups of domain adaptation experiments, respectively, using the ACE 2005 corpus and the corpus for TAC-KBP 2015 event nugget track (Ellis et al., 2015).","Discussion: Adaptation, Robustness and Effectiveness","Following the common practice of adaptation research on this data (Nguyen and Grishman, 2014Grishman, , 2015;;Plank and Moschitti, 2013), we take the union of bn and nw as the source domain and bc, cts and wl as three different target domains.",NC,
2710,"Following the common practice of adaptation research on this data (Nguyen and Grishman, 2014Grishman, , 2015;;Plank and Moschitti, 2013), we take the union of bn and nw as the source domain and bc, cts and wl as three different target domains.",567,5,159,"Discussion: Adaptation, Robustness and Effectiveness","Discussion: Adaptation, Robustness and Effectiveness","The ACE corpus consists of 6 domains: broad-cast conversation (bc), broadcast news (bn), telephone conversation (cts), newswire (nw), usenet (un) and web blogs (wl).","Discussion: Adaptation, Robustness and Effectiveness",We randomly select half of the instances from bc to constitute the development set.,NC,
2711,We randomly select half of the instances from bc to constitute the development set.,568,5,160,"Discussion: Adaptation, Robustness and Effectiveness","Discussion: Adaptation, Robustness and Effectiveness","Following the common practice of adaptation research on this data (Nguyen and Grishman, 2014Grishman, , 2015;;Plank and Moschitti, 2013), we take the union of bn and nw as the source domain and bc, cts and wl as three different target domains.","Discussion: Adaptation, Robustness and Effectiveness",The TAC-KBP corpus consists of 2 domains: newswire (NW) and discussion forum (DF).,NC,
2712,The TAC-KBP corpus consists of 2 domains: newswire (NW) and discussion forum (DF).,569,5,161,"Discussion: Adaptation, Robustness and Effectiveness","Discussion: Adaptation, Robustness and Effectiveness",We randomly select half of the instances from bc to constitute the development set.,"Discussion: Adaptation, Robustness and Effectiveness","We follow Peng et al (2016) to use one of NW and DF in alternation as the source domain, while the other the target domain.",NC,
2713,"We follow Peng et al (2016) to use one of NW and DF in alternation as the source domain, while the other the target domain.",570,5,162,"Discussion: Adaptation, Robustness and Effectiveness","Discussion: Adaptation, Robustness and Effectiveness",The TAC-KBP corpus consists of 2 domains: newswire (NW) and discussion forum (DF).,"Discussion: Adaptation, Robustness and Effectiveness",We randomly select a proportion (20%) of the instances from the target domain to constitute the development set.,NC,
2714,We randomly select a proportion (20%) of the instances from the target domain to constitute the development set.,571,5,163,"Discussion: Adaptation, Robustness and Effectiveness","Discussion: Adaptation, Robustness and Effectiveness","We follow Peng et al (2016) to use one of NW and DF in alternation as the source domain, while the other the target domain.","Discussion: Adaptation, Robustness and Effectiveness","We compare with Joint, CNN, MSEP-EMD, SSED (Sammons et al., 2015) and Hybrid.",NC,
2715,"We compare with Joint, CNN, MSEP-EMD, SSED (Sammons et al., 2015) and Hybrid.",572,5,164,"Discussion: Adaptation, Robustness and Effectiveness","Discussion: Adaptation, Robustness and Effectiveness",We randomly select a proportion (20%) of the instances from the target domain to constitute the development set.,"Discussion: Adaptation, Robustness and Effectiveness",All the models except Hybrid have been reported for the performance assessment of domain adaptation.,NC,
2716,All the models except Hybrid have been reported for the performance assessment of domain adaptation.,573,5,165,"Discussion: Adaptation, Robustness and Effectiveness","Discussion: Adaptation, Robustness and Effectiveness","We compare with Joint, CNN, MSEP-EMD, SSED (Sammons et al., 2015) and Hybrid.","Discussion: Adaptation, Robustness and Effectiveness","In this section, we only cite the best performance they obtained.",NC,
2717,"In this section, we only cite the best performance they obtained.",574,5,166,"Discussion: Adaptation, Robustness and Effectiveness","Discussion: Adaptation, Robustness and Effectiveness",All the models except Hybrid have been reported for the performance assessment of domain adaptation.,"Discussion: Adaptation, Robustness and Effectiveness",We reproduce Hybrid by using the source code given by authors.,NC,
2718,We reproduce Hybrid by using the source code given by authors.,575,5,167,"Discussion: Adaptation, Robustness and Effectiveness","Discussion: Adaptation, Robustness and Effectiveness","In this section, we only cite the best performance they obtained.","Discussion: Adaptation, Robustness and Effectiveness","To ensure a fair comparison, we perform 3 runs, in each of which, both Hybrid and SELF were redeveloped on a new development set.",NC,
2719,"To ensure a fair comparison, we perform 3 runs, in each of which, both Hybrid and SELF were redeveloped on a new development set.",576,5,168,"Discussion: Adaptation, Robustness and Effectiveness","Discussion: Adaptation, Robustness and Effectiveness",We reproduce Hybrid by using the source code given by authors.,"Discussion: Adaptation, Robustness and Effectiveness",What we report herein is the average performance they obtained over the 3 runs.,NC,
2720,What we report herein is the average performance they obtained over the 3 runs.,577,5,169,"Discussion: Adaptation, Robustness and Effectiveness","Discussion: Adaptation, Robustness and Effectiveness","To ensure a fair comparison, we perform 3 runs, in each of which, both Hybrid and SELF were redeveloped on a new development set.",Adaptation Performance,We show the adaptation performance on the ACE corpus in Tables 4 and that on TAC-KBP in Table 5.,NC,
2721,We show the adaptation performance on the ACE corpus in Tables 4 and that on TAC-KBP in Table 5.,578,5,170,Adaptation Performance,"Discussion: Adaptation, Robustness and Effectiveness",What we report herein is the average performance they obtained over the 3 runs.,Adaptation Performance,It can be observed that SELF outperforms other models in the out-of-domain scenarios.,NC,
2722,It can be observed that SELF outperforms other models in the out-of-domain scenarios.,579,5,171,Adaptation Performance,Adaptation Performance,We show the adaptation performance on the ACE corpus in Tables 4 and that on TAC-KBP in Table 5.,Adaptation Performance,"Besides, when testing is performed on the outof-domain ACE corpus, the performance degradation of SELF is not much larger than that of CNN and Hybrid.",POS,
2723,"Besides, when testing is performed on the outof-domain ACE corpus, the performance degradation of SELF is not much larger than that of CNN and Hybrid.",580,5,172,Adaptation Performance,Adaptation Performance,It can be observed that SELF outperforms other models in the out-of-domain scenarios.,Adaptation Performance,"When the out-of-domain TAC-KBP corpus is used, the performance of SELF is impaired much less severely than SSED and Hybrid.",POS,
2724,"When the out-of-domain TAC-KBP corpus is used, the performance of SELF is impaired much less severely than SSED and Hybrid.",581,5,173,Adaptation Performance,Adaptation Performance,"Besides, when testing is performed on the outof-domain ACE corpus, the performance degradation of SELF is not much larger than that of CNN and Hybrid.",Adaptation Performance,"More importantly, the adaptability of SELF is relatively close to that of MSEP-EMD.",POS,
2725,"More importantly, the adaptability of SELF is relatively close to that of MSEP-EMD.",582,5,174,Adaptation Performance,Adaptation Performance,"When the out-of-domain TAC-KBP corpus is used, the performance of SELF is impaired much less severely than SSED and Hybrid.",Adaptation Performance,"Considering that MSEP-EMD is stable due to using minimal supervision (Peng et al., 2016), we suggest the fully trained networks in SELF may not appear to be extremely inflexible, but on the contrary, they should be transferable for use (Ge et al., 2016).",POS,
2726,"Considering that MSEP-EMD is stable due to using minimal supervision (Peng et al., 2016), we suggest the fully trained networks in SELF may not appear to be extremely inflexible, but on the contrary, they should be transferable for use (Ge et al., 2016).",583,5,175,Adaptation Performance,Adaptation Performance,"More importantly, the adaptability of SELF is relatively close to that of MSEP-EMD.",Robustness in Resource-Poor Settings,"There are two resource-poor conditions discussed in this section, including lack of in-domain training data and that of out-domain.",POS,
2727,"SELF is able to accurately recall the events whose occurrence is triggered by ambiguous words, such as ""fine"", ""charge"", ""campaign"", etc.",584,5,196,Recall and Missing,Robustness in Resource-Poor Settings,"In this case, SELF displays less performance degradation",Recall and Missing,These ambiguous words easily causes confusion.,POS,
2728,These ambiguous words easily causes confusion.,585,5,197,Recall and Missing,Recall and Missing,"SELF is able to accurately recall the events whose occurrence is triggered by ambiguous words, such as ""fine"", ""charge"", ""campaign"", etc.",Recall and Missing,"For example, ""campaign"" may trigger an Elect event or Attack in the ACE corpus.",NC,
2729,"For example, ""campaign"" may trigger an Elect event or Attack in the ACE corpus.",586,5,198,Recall and Missing,Recall and Missing,These ambiguous words easily causes confusion.,Recall and Missing,"More importantly, SELF fishes out the common words which serve as a trigger, although they are not closely related to any kind of events, such as ""take"", ""try"", ""acquire"", ""become"", ""create"", etc.",NC,
2730,"More importantly, SELF fishes out the common words which serve as a trigger, although they are not closely related to any kind of events, such as ""take"", ""try"", ""acquire"", ""become"", ""create"", etc.",587,5,199,Recall and Missing,Recall and Missing,"For example, ""campaign"" may trigger an Elect event or Attack in the ACE corpus.",Recall and Missing,"In general, it is very difficult to accurately recall such triggers because their meanings are not concrete enough, and the contexts may be full of kinds of noises (see example 2 in pg.",POS,
2731,"In general, it is very difficult to accurately recall such triggers because their meanings are not concrete enough, and the contexts may be full of kinds of noises (see example 2 in pg.",588,5,200,Recall and Missing,Recall and Missing,"More importantly, SELF fishes out the common words which serve as a trigger, although they are not closely related to any kind of events, such as ""take"", ""try"", ""acquire"", ""become"", ""create"", etc.",Recall and Missing,We observe that Bi-RNN and Hybrid seldom pick them up.,NC,
2732,We observe that Bi-RNN and Hybrid seldom pick them up.,589,5,201,Recall and Missing,Recall and Missing,"In general, it is very difficult to accurately recall such triggers because their meanings are not concrete enough, and the contexts may be full of kinds of noises (see example 2 in pg.",Recall and Missing,"However, SELF fails to recall the pronouns that act as a trigger.",POS,
2733,"However, SELF fails to recall the pronouns that act as a trigger.",590,5,202,Recall and Missing,Recall and Missing,We observe that Bi-RNN and Hybrid seldom pick them up.,Recall and Missing,This is because they occur in spoken language much more frequently than they occur in written language.,NEG,
2734,This is because they occur in spoken language much more frequently than they occur in written language.,591,5,203,Recall and Missing,Recall and Missing,"However, SELF fails to recall the pronouns that act as a trigger.",Recall and Missing,The lack of narrative content makes it difficult to learn the relationship between the pronouns and the events.,POS,
2735,The lack of narrative content makes it difficult to learn the relationship between the pronouns and the events.,592,5,204,Recall and Missing,Recall and Missing,This is because they occur in spoken language much more frequently than they occur in written language.,Recall and Missing,Some real examples collected from ACE are shown in Table 7.,NEG,
2736,Some real examples collected from ACE are shown in Table 7.,593,5,205,Recall and Missing,Recall and Missing,The lack of narrative content makes it difficult to learn the relationship between the pronouns and the events.,Related Work,"Event detection is an important subtask of event extraction (Doddington et al., 2004;Ahn, 2006).",NC,
2737,We use a self-regulated learning approach to improve event detection.,594,5,220,Conclusion,Related Work,"We follow the work to create spurious features, but use them to regulate the self-learning process in a single-task situation.",Conclusion,"In the learning process, the adversarial and cooperative models are utilized in decontaminating the latent feature space.",FACT,
2738,"In the learning process, the adversarial and cooperative models are utilized in decontaminating the latent feature space.",595,5,221,Conclusion,Conclusion,We use a self-regulated learning approach to improve event detection.,Conclusion,"In this study, the performance of the discriminator in the adversarial network is left to be evaluated.",FACT,
2739,"In this study, the performance of the discriminator in the adversarial network is left to be evaluated.",596,5,222,Conclusion,Conclusion,"In the learning process, the adversarial and cooperative models are utilized in decontaminating the latent feature space.",Conclusion,"Most probably, the discriminator also performs well because it is gradually enhanced by fierce competition.",NEG,
2740,"Most probably, the discriminator also performs well because it is gradually enhanced by fierce competition.",597,5,223,Conclusion,Conclusion,"In this study, the performance of the discriminator in the adversarial network is left to be evaluated.",Conclusion,"Considering this possibility, we suggest to drive the two discriminators in our self-regulation framework to cooperate with each other.",POS,
2741,"Considering this possibility, we suggest to drive the two discriminators in our self-regulation framework to cooperate with each other.",598,5,224,Conclusion,Conclusion,"Most probably, the discriminator also performs well because it is gradually enhanced by fierce competition.",Conclusion,"Besides, the global features extracted in Li et al (2013)'s work are potentially useful for detecting the event instances referred by pronouns, although involve noises.",POS,
2742,"Besides, the global features extracted in Li et al (2013)'s work are potentially useful for detecting the event instances referred by pronouns, although involve noises.",599,5,225,Conclusion,Conclusion,"Considering this possibility, we suggest to drive the two discriminators in our self-regulation framework to cooperate with each other.",Conclusion,"Therefore, in the future, we will encode the global information by neural networks and use the self-regulation strategy to reduce the negative influence of noises.",NC,
2743,"Therefore, in the future, we will encode the global information by neural networks and use the self-regulation strategy to reduce the negative influence of noises.",600,5,226,Conclusion,Conclusion,"Besides, the global features extracted in Li et al (2013)'s work are potentially useful for detecting the event instances referred by pronouns, although involve noises.",,,PROSP,
2744,  Recurrent neural networks (RNNs) serve as a fundamental building block for many sequence tasks across natural language processing.,601,6,0,abstract,,,abstract,Recent research has focused on recurrent dropout techniques or custom RNN cells in order to improve performance.,NC,
2745,Recent research has focused on recurrent dropout techniques or custom RNN cells in order to improve performance.,602,6,1,abstract,abstract,  Recurrent neural networks (RNNs) serve as a fundamental building block for many sequence tasks across natural language processing.,abstract,Both of these can require substantial modifications to the machine learning model or to the underlying RNN configurations.,NC,
2746,Both of these can require substantial modifications to the machine learning model or to the underlying RNN configurations.,603,6,2,abstract,abstract,Recent research has focused on recurrent dropout techniques or custom RNN cells in order to improve performance.,abstract,"We revisit traditional regularization techniques, specifically L2 regularization on RNN activations and slowness regularization over successive hidden states, to improve the performance of RNNs on the task of language modeling.",NC,
2747,"We revisit traditional regularization techniques, specifically L2 regularization on RNN activations and slowness regularization over successive hidden states, to improve the performance of RNNs on the task of language modeling.",604,6,3,abstract,abstract,Both of these can require substantial modifications to the machine learning model or to the underlying RNN configurations.,abstract,Both of these techniques require minimal modification to existing RNN architectures and result in performance improvements comparable or superior to more complicated regularization techniques or custom cell architectures.,FACT,
2748,Both of these techniques require minimal modification to existing RNN architectures and result in performance improvements comparable or superior to more complicated regularization techniques or custom cell architectures.,605,6,4,abstract,abstract,"We revisit traditional regularization techniques, specifically L2 regularization on RNN activations and slowness regularization over successive hidden states, to improve the performance of RNNs on the task of language modeling.",abstract,These regularization techniques can be used without any modification on optimized LSTM implementations such as the NVIDIA cuDNN LSTM.,POS,
2749,These regularization techniques can be used without any modification on optimized LSTM implementations such as the NVIDIA cuDNN LSTM.,606,6,5,abstract,abstract,Both of these techniques require minimal modification to existing RNN architectures and result in performance improvements comparable or superior to more complicated regularization techniques or custom cell architectures.,Introduction,The need for effective regularization methods for RNNs has seen extensive focus in recent years.,POS,
2750,The need for effective regularization methods for RNNs has seen extensive focus in recent years.,607,6,6,Introduction,abstract,These regularization techniques can be used without any modification on optimized LSTM implementations such as the NVIDIA cuDNN LSTM.,Introduction,"While application of dropout (Srivastava et al., 2014) to the input and output of an RNN has been shown to be effective (Zaremba et al., 2014), dropout is destructive when naively applied to the recurrent connections of an RNN.",NC,
2751,"While application of dropout (Srivastava et al., 2014) to the input and output of an RNN has been shown to be effective (Zaremba et al., 2014), dropout is destructive when naively applied to the recurrent connections of an RNN.",608,6,7,Introduction,Introduction,The need for effective regularization methods for RNNs has seen extensive focus in recent years.,Introduction,"When naive dropout is applied to the recurrent connections, it is almost impossible to retain information over long periods of time.",NC,
2752,"When naive dropout is applied to the recurrent connections, it is almost impossible to retain information over long periods of time.",609,6,8,Introduction,Introduction,"While application of dropout (Srivastava et al., 2014) to the input and output of an RNN has been shown to be effective (Zaremba et al., 2014), dropout is destructive when naively applied to the recurrent connections of an RNN.",Introduction,"Given this fundamental issue, substantial work has gone into understanding and improving dropout when applied to recurrent connections.",NC,
2753,"Given this fundamental issue, substantial work has gone into understanding and improving dropout when applied to recurrent connections.",610,6,9,Introduction,Introduction,"When naive dropout is applied to the recurrent connections, it is almost impossible to retain information over long periods of time.",Introduction,"Of these techniques, which we shall broadly refer to as recurrent dropout, some specific variations have gained popular usage.",NC,
2754,"Of these techniques, which we shall broadly refer to as recurrent dropout, some specific variations have gained popular usage.",611,6,10,Introduction,Introduction,"Given this fundamental issue, substantial work has gone into understanding and improving dropout when applied to recurrent connections.",Introduction,"Part of 34 th International Conference on Machine Learning's Workshop on Learning to Generate Natural Language, Sydney, Australia, 2017.",NC,
2755,"Part of 34 th International Conference on Machine Learning's Workshop on Learning to Generate Natural Language, Sydney, Australia, 2017.",612,6,11,Introduction,Introduction,"Of these techniques, which we shall broadly refer to as recurrent dropout, some specific variations have gained popular usage.",Introduction,Copyright 2017 by the author(s).,NC,
2756,Copyright 2017 by the author(s).,613,6,12,Introduction,Introduction,"Part of 34 th International Conference on Machine Learning's Workshop on Learning to Generate Natural Language, Sydney, Australia, 2017.",Introduction,"Variational RNNs (Gal & Ghahramani, 2016) drop the same network units at each timestep, as opposed to dropping different network units at each timestep.",NC,
2757,"Variational RNNs (Gal & Ghahramani, 2016) drop the same network units at each timestep, as opposed to dropping different network units at each timestep.",614,6,13,Introduction,Introduction,Copyright 2017 by the author(s).,Introduction,"By performing dropout on the same units at each timestep, destructive loss of the RNN hidden state is avoided and the same information is masked at each timestep.",NC,
2758,"By performing dropout on the same units at each timestep, destructive loss of the RNN hidden state is avoided and the same information is masked at each timestep.",615,6,14,Introduction,Introduction,"Variational RNNs (Gal & Ghahramani, 2016) drop the same network units at each timestep, as opposed to dropping different network units at each timestep.",Introduction,"Rather than dropping units, another tactic is to drop updates to given network units.",NC,
2759,"Rather than dropping units, another tactic is to drop updates to given network units.",616,6,15,Introduction,Introduction,"By performing dropout on the same units at each timestep, destructive loss of the RNN hidden state is avoided and the same information is masked at each timestep.",Introduction,Semeniuta et al.,NC,
2760,Semeniuta et al.,617,6,16,Introduction,Introduction,"Rather than dropping units, another tactic is to drop updates to given network units.",Introduction,"(2016) perform dropout on the input gate of the LSTM (Hochreiter & Schmidhuber, 1997) but allow the forget gate to discard portions of the existing hidden state.",NC,
2761,"(2016) perform dropout on the input gate of the LSTM (Hochreiter & Schmidhuber, 1997) but allow the forget gate to discard portions of the existing hidden state.",618,6,17,Introduction,Introduction,Semeniuta et al.,Introduction,"Zoneout (Krueger et al., 2016) prevents hidden state updates from occurring by setting a randomly selected subset of network unit activations in h t+1 to be equal to the previous activations from h t .",NC,
2762,"Zoneout (Krueger et al., 2016) prevents hidden state updates from occurring by setting a randomly selected subset of network unit activations in h t+1 to be equal to the previous activations from h t .",619,6,18,Introduction,Introduction,"(2016) perform dropout on the input gate of the LSTM (Hochreiter & Schmidhuber, 1997) but allow the forget gate to discard portions of the existing hidden state.",Introduction,Both of these act to prevent updates to the hidden state while preserving existing content.,NC,
2763,Both of these act to prevent updates to the hidden state while preserving existing content.,620,6,19,Introduction,Introduction,"Zoneout (Krueger et al., 2016) prevents hidden state updates from occurring by setting a randomly selected subset of network unit activations in h t+1 to be equal to the previous activations from h t .",Introduction,"On an extreme end, work has also been done to restrict the recurrent matrices in an RNN in order to limit their computational capacity.",NC,
2764,"On an extreme end, work has also been done to restrict the recurrent matrices in an RNN in order to limit their computational capacity.",621,6,20,Introduction,Introduction,Both of these act to prevent updates to the hidden state while preserving existing content.,Introduction,"Some RNN architectures only allow element-wise interactions (Balduzzi & Ghifary, 2016;Bradbury et al., 2016;Seo et al., 2016), removing the recurrent matrix entirely, while others act to restrict the capacity by parameterizing the recurrent matrix (Arjovsky et al., 2016;Wisdom et al., 2016;Jing et al., 2016).",NC,
2765,"Some RNN architectures only allow element-wise interactions (Balduzzi & Ghifary, 2016;Bradbury et al., 2016;Seo et al., 2016), removing the recurrent matrix entirely, while others act to restrict the capacity by parameterizing the recurrent matrix (Arjovsky et al., 2016;Wisdom et al., 2016;Jing et al., 2016).",622,6,21,Introduction,Introduction,"On an extreme end, work has also been done to restrict the recurrent matrices in an RNN in order to limit their computational capacity.",Introduction,"Other forms of regularization explicitly act upon activations such as such as batch normalization (Ioffe & Szegedy, 2015), recurrent batch normalization (Cooijmans et al., 2016), and layer normalization (Ba et al., 2016).",NC,
2766,"Other forms of regularization explicitly act upon activations such as such as batch normalization (Ioffe & Szegedy, 2015), recurrent batch normalization (Cooijmans et al., 2016), and layer normalization (Ba et al., 2016).",623,6,22,Introduction,Introduction,"Some RNN architectures only allow element-wise interactions (Balduzzi & Ghifary, 2016;Bradbury et al., 2016;Seo et al., 2016), removing the recurrent matrix entirely, while others act to restrict the capacity by parameterizing the recurrent matrix (Arjovsky et al., 2016;Wisdom et al., 2016;Jing et al., 2016).",Introduction,These all introduce additional training parameters and can complicate the training process while increasing the sensitivity of the model.,NC,
2767,These all introduce additional training parameters and can complicate the training process while increasing the sensitivity of the model.,624,6,23,Introduction,Introduction,"Other forms of regularization explicitly act upon activations such as such as batch normalization (Ioffe & Szegedy, 2015), recurrent batch normalization (Cooijmans et al., 2016), and layer normalization (Ba et al., 2016).",Introduction,"Norm stabilization (Krueger & Memisevic, 2015) penalizes the model when the norm of an RNN's hidden state changes substantially between timesteps, achieving strong results in character language modeling on and phoneme recognition.",NC,
2768,"Norm stabilization (Krueger & Memisevic, 2015) penalizes the model when the norm of an RNN's hidden state changes substantially between timesteps, achieving strong results in character language modeling on and phoneme recognition.",625,6,24,Introduction,Introduction,These all introduce additional training parameters and can complicate the training process while increasing the sensitivity of the model.,Introduction,"In this work, we revisit L 2 regularization in the form of activation regularization (AR) and temporal activation regularization (TAR).",NC,
2769,"In this work, we revisit L 2 regularization in the form of activation regularization (AR) and temporal activation regularization (TAR).",626,6,25,Introduction,Introduction,"Norm stabilization (Krueger & Memisevic, 2015) penalizes the model when the norm of an RNN's hidden state changes substantially between timesteps, achieving strong results in character language modeling on and phoneme recognition.",Introduction,"When applied to modern baselines that do not contain recurrent dropout or normalization techniques, AR and TAR achieve comparable or superior results.",FACT,
2770,"When applied to modern baselines that do not contain recurrent dropout or normalization techniques, AR and TAR achieve comparable or superior results.",627,6,26,Introduction,Introduction,"In this work, we revisit L 2 regularization in the form of activation regularization (AR) and temporal activation regularization (TAR).",Compared to other invasive regularization techniques,"which may require modifications to the RNN cell itself or complex model changes, both AR and TAR require no substantial modifications to the RNN or model.",POS,
2771,"which may require modifications to the RNN cell itself or complex model changes, both AR and TAR require no substantial modifications to the RNN or model.",628,6,27,Compared to other invasive regularization techniques,Introduction,"When applied to modern baselines that do not contain recurrent dropout or normalization techniques, AR and TAR achieve comparable or superior results.",Compared to other invasive regularization techniques,This enables AR and TAR to be applied to optimized RNN implementations such as the cuDNN LSTM which can be many times faster than naïve but flexible LSTM implementations.,POS,
2772,This enables AR and TAR to be applied to optimized RNN implementations such as the cuDNN LSTM which can be many times faster than naïve but flexible LSTM implementations.,629,6,28,Compared to other invasive regularization techniques,Compared to other invasive regularization techniques,"which may require modifications to the RNN cell itself or complex model changes, both AR and TAR require no substantial modifications to the RNN or model.",Activation Regularization,"L 2 activation regularization (AR) While L 2 regularization is traditionally used on the weights of machine learning models (L 2 weight decay), it could also be used on the activations.",POS,
2773,"L 2 activation regularization (AR) While L 2 regularization is traditionally used on the weights of machine learning models (L 2 weight decay), it could also be used on the activations.",630,6,29,Activation Regularization,Compared to other invasive regularization techniques,This enables AR and TAR to be applied to optimized RNN implementations such as the cuDNN LSTM which can be many times faster than naïve but flexible LSTM implementations.,Activation Regularization,"We define AR as α L 2 (m ⊙ h t ) where m is the dropout mask used by later parts of the model, L 2 (•) = • 2 (L 2 norm), h t is the output of the RNN at timestep t, and α is a scaling coefficient.",NC,
2774,"We define AR as α L 2 (m ⊙ h t ) where m is the dropout mask used by later parts of the model, L 2 (•) = • 2 (L 2 norm), h t is the output of the RNN at timestep t, and α is a scaling coefficient.",631,6,30,Activation Regularization,Activation Regularization,"L 2 activation regularization (AR) While L 2 regularization is traditionally used on the weights of machine learning models (L 2 weight decay), it could also be used on the activations.",Activation Regularization,"When applied to the output of a dense layer, AR penalizes activations that are substantially away from 0, encouraging the activations to remain small.",NC,
2775,"When applied to the output of a dense layer, AR penalizes activations that are substantially away from 0, encouraging the activations to remain small.",632,6,31,Activation Regularization,Activation Regularization,"We define AR as α L 2 (m ⊙ h t ) where m is the dropout mask used by later parts of the model, L 2 (•) = • 2 (L 2 norm), h t is the output of the RNN at timestep t, and α is a scaling coefficient.",Activation Regularization,"While acting implicitly rather than explicitly, this has similarities to the various batch or layer normalization techniques.",NC,
2776,"While acting implicitly rather than explicitly, this has similarities to the various batch or layer normalization techniques.",633,6,32,Activation Regularization,Activation Regularization,"When applied to the output of a dense layer, AR penalizes activations that are substantially away from 0, encouraging the activations to remain small.",Activation Regularization,The L 2 penalty on the RNN activations can be applied to h t or to m ⊙ h t (the dropped output used in the rest of the model).,NC,
2777,The L 2 penalty on the RNN activations can be applied to h t or to m ⊙ h t (the dropped output used in the rest of the model).,634,6,33,Activation Regularization,Activation Regularization,"While acting implicitly rather than explicitly, this has similarities to the various batch or layer normalization techniques.",Activation Regularization,"In our experiments, we found that applying AR to m ⊙ h t was more effective than applying it to neurons not updated during the current optimization step.",NC,
2778,"In our experiments, we found that applying AR to m ⊙ h t was more effective than applying it to neurons not updated during the current optimization step.",635,6,34,Activation Regularization,Activation Regularization,The L 2 penalty on the RNN activations can be applied to h t or to m ⊙ h t (the dropped output used in the rest of the model).,Temporal activation regularization (TAR),Adding a prior that minimizes differences between states has been explored in the past.,POS,
2779,Adding a prior that minimizes differences between states has been explored in the past.,636,6,35,Temporal activation regularization (TAR),Activation Regularization,"In our experiments, we found that applying AR to m ⊙ h t was more effective than applying it to neurons not updated during the current optimization step.",Temporal activation regularization (TAR),"This broad concept falls under the broad concept of slowness regularization (Hinton, 1989;Földiák, 1991;Luciw & Schmidhuber, 2012;Jonschkowski & Brock, 2015;Wen et al., 2015) which attempts to minimize L(f (x t ), f (x t+1 )) where L is a loss function describing the distance between f (x t ) and f (x t+1 ) and f is an arbitrary mapping function.",NC,
2780,"This broad concept falls under the broad concept of slowness regularization (Hinton, 1989;Földiák, 1991;Luciw & Schmidhuber, 2012;Jonschkowski & Brock, 2015;Wen et al., 2015) which attempts to minimize L(f (x t ), f (x t+1 )) where L is a loss function describing the distance between f (x t ) and f (x t+1 ) and f is an arbitrary mapping function.",637,6,36,Temporal activation regularization (TAR),Temporal activation regularization (TAR),Adding a prior that minimizes differences between states has been explored in the past.,Temporal activation regularization (TAR),"Temporal activation regularization (TAR) is a direct descendant of this slowness regularization, minimizing β L 2 (h t -h t+1 ) where L 2 (•) = • 2 (L 2 norm), h t is the output of the RNN at timestep t, and β is a scaling coefficient.",NC,
2781,"Temporal activation regularization (TAR) is a direct descendant of this slowness regularization, minimizing β L 2 (h t -h t+1 ) where L 2 (•) = • 2 (L 2 norm), h t is the output of the RNN at timestep t, and β is a scaling coefficient.",638,6,37,Temporal activation regularization (TAR),Temporal activation regularization (TAR),"This broad concept falls under the broad concept of slowness regularization (Hinton, 1989;Földiák, 1991;Luciw & Schmidhuber, 2012;Jonschkowski & Brock, 2015;Wen et al., 2015) which attempts to minimize L(f (x t ), f (x t+1 )) where L is a loss function describing the distance between f (x t ) and f (x t+1 ) and f is an arbitrary mapping function.",Temporal activation regularization (TAR),"TAR penalizes any large changes in hidden state between timesteps, encouraging the model to keep the output as consistent as possible.",NC,
2782,"TAR penalizes any large changes in hidden state between timesteps, encouraging the model to keep the output as consistent as possible.",639,6,38,Temporal activation regularization (TAR),Temporal activation regularization (TAR),"Temporal activation regularization (TAR) is a direct descendant of this slowness regularization, minimizing β L 2 (h t -h t+1 ) where L 2 (•) = • 2 (L 2 norm), h t is the output of the RNN at timestep t, and β is a scaling coefficient.",Temporal activation regularization (TAR),"For the LSTM, the hidden state which is regularized is only h t , not the long term memory c t , though this could optionally be regularized in a similar manner.",NC,
2783,"For the LSTM, the hidden state which is regularized is only h t , not the long term memory c t , though this could optionally be regularized in a similar manner.",640,6,39,Temporal activation regularization (TAR),Temporal activation regularization (TAR),"TAR penalizes any large changes in hidden state between timesteps, encouraging the model to keep the output as consistent as possible.",Model Parameters Validation,"Results over the Penn Treebank for testing α coefficients for AR with base model h = 650, β = 0, dp = 0.5, dp h = 0.5.",NC,
2784,"To understand the potential of AR and TAR, we investigate their impact on language model perplexity when used independently in Table 1 (AR) and Table 2 (TAR).",641,6,56,Evaluating AR and TAR independently on PTB:,Model,"All models use weight tying between the embedding and softmax layer (Inan et al., 2016;Press & Wolf, 2016).",Evaluating AR and TAR independently on PTB:,"While both result in a substantial reduction in perplexity, AR results in the strongest improvement of 5.3, while TAR only achieves 4.3.",FACT,
2785,"While both result in a substantial reduction in perplexity, AR results in the strongest improvement of 5.3, while TAR only achieves 4.3.",642,6,57,Evaluating AR and TAR independently on PTB:,Evaluating AR and TAR independently on PTB:,"To understand the potential of AR and TAR, we investigate their impact on language model perplexity when used independently in Table 1 (AR) and Table 2 (TAR).",Evaluating AR and TAR independently on PTB:,The drops achieved by this are equivalent to using an LSTM model with twice as many parameters -a substantial improvement given the simplicity of AR and TAR.,POS,
2786,The drops achieved by this are equivalent to using an LSTM model with twice as many parameters -a substantial improvement given the simplicity of AR and TAR.,643,6,58,Evaluating AR and TAR independently on PTB:,Evaluating AR and TAR independently on PTB:,"While both result in a substantial reduction in perplexity, AR results in the strongest improvement of 5.3, while TAR only achieves 4.3.",Evaluating AR and TAR independently on PTB:,"Evaluating AR and TAR jointly on PTB: When both AR and TAR are used together, we found the best result was achieved by decreasing α and β, likely as the model was over-regularized otherwise.",POS,
2787,"Evaluating AR and TAR jointly on PTB: When both AR and TAR are used together, we found the best result was achieved by decreasing α and β, likely as the model was over-regularized otherwise.",644,6,59,Evaluating AR and TAR independently on PTB:,Evaluating AR and TAR independently on PTB:,The drops achieved by this are equivalent to using an LSTM model with twice as many parameters -a substantial improvement given the simplicity of AR and TAR.,Evaluating AR and TAR independently on PTB:,In Table 3 we present PTB results for three different model sizes comparing models without AR/TAR to those which use both.,POS,
2788,In Table 3 we present PTB results for three different model sizes comparing models without AR/TAR to those which use both.,645,6,60,Evaluating AR and TAR independently on PTB:,Evaluating AR and TAR independently on PTB:,"Evaluating AR and TAR jointly on PTB: When both AR and TAR are used together, we found the best result was achieved by decreasing α and β, likely as the model was over-regularized otherwise.",Evaluating AR and TAR independently on PTB:,"The model sizes h ∈ [650, 950, 1500] were chosen to be comparable in size to other published results.",NC,
2789,"The model sizes h ∈ [650, 950, 1500] were chosen to be comparable in size to other published results.",646,6,61,Evaluating AR and TAR independently on PTB:,Evaluating AR and TAR independently on PTB:,In Table 3 we present PTB results for three different model sizes comparing models without AR/TAR to those which use both.,Evaluating AR and TAR independently on PTB:,"With both AR and TAR, the smallest model has an improvement of 6.2 over the baseline model.",NC,
2790,"With both AR and TAR, the smallest model has an improvement of 6.2 over the baseline model.",647,6,62,Evaluating AR and TAR independently on PTB:,Evaluating AR and TAR independently on PTB:,"The model sizes h ∈ [650, 950, 1500] were chosen to be comparable in size to other published results.",Evaluating AR and TAR independently on PTB:,"The improvements continue for the two larger size models, h = 950 and h = 1500, though the gains fall off as the model size is increased.",POS,
2791,"The improvements continue for the two larger size models, h = 950 and h = 1500, though the gains fall off as the model size is increased.",648,6,63,Evaluating AR and TAR independently on PTB:,Evaluating AR and TAR independently on PTB:,"With both AR and TAR, the smallest model has an improvement of 6.2 over the baseline model.",Evaluating AR and TAR independently on PTB:,Comparing to state-of-the-art PTB: In Table 5 we summarize the current state of the art models in language modeling over the Penn Treebank.,POS,
2792,Comparing to state-of-the-art PTB: In Table 5 we summarize the current state of the art models in language modeling over the Penn Treebank.,649,6,64,Evaluating AR and TAR independently on PTB:,Evaluating AR and TAR independently on PTB:,"The improvements continue for the two larger size models, h = 950 and h = 1500, though the gains fall off as the model size is increased.",Evaluating AR and TAR independently on PTB:,"The largest LSTM we train (h = 1500) achieves comparable results to the Recurrent Highway Network (RHN) (Zilly et al., 2016), a human developed custom RNN architecture, but with approximately double the number of parameters.",NC,
2793,"The largest LSTM we train (h = 1500) achieves comparable results to the Recurrent Highway Network (RHN) (Zilly et al., 2016), a human developed custom RNN architecture, but with approximately double the number of parameters.",650,6,65,Evaluating AR and TAR independently on PTB:,Evaluating AR and TAR independently on PTB:,Comparing to state-of-the-art PTB: In Table 5 we summarize the current state of the art models in language modeling over the Penn Treebank.,Evaluating AR and TAR independently on PTB:,"Although the LSTM uses twice as many parameters, the RHN runs a cell 10 times per timestep (referred to as recurrence depth), resulting in far more computation.",POS,
2794,"Although the LSTM uses twice as many parameters, the RHN runs a cell 10 times per timestep (referred to as recurrence depth), resulting in far more computation.",651,6,66,Evaluating AR and TAR independently on PTB:,Evaluating AR and TAR independently on PTB:,"The largest LSTM we train (h = 1500) achieves comparable results to the Recurrent Highway Network (RHN) (Zilly et al., 2016), a human developed custom RNN architecture, but with approximately double the number of parameters.",Evaluating AR and TAR independently on PTB:,"This would likely result in the RHN being slower than the larger LSTM model during both training and prediction, especially when factoring in optimized LSTM implementations such as NVIDIA's cuDNN LSTM.",NC,
2795,"This would likely result in the RHN being slower than the larger LSTM model during both training and prediction, especially when factoring in optimized LSTM implementations such as NVIDIA's cuDNN LSTM.",652,6,67,Evaluating AR and TAR independently on PTB:,Evaluating AR and TAR independently on PTB:,"Although the LSTM uses twice as many parameters, the RHN runs a cell 10 times per timestep (referred to as recurrence depth), resulting in far more computation.",Evaluating AR and TAR independently on PTB:,"We also compare to the Neural Architecture Search (NAS) cell (Zoph & Le, 2016).",POS,
2796,"We also compare to the Neural Architecture Search (NAS) cell (Zoph & Le, 2016).",653,6,68,Evaluating AR and TAR independently on PTB:,Evaluating AR and TAR independently on PTB:,"This would likely result in the RHN being slower than the larger LSTM model during both training and prediction, especially when factoring in optimized LSTM implementations such as NVIDIA's cuDNN LSTM.",Evaluating AR and TAR independently on PTB:,"While Zoph & Le (2016) do not report any of the hyperparameters or what type of dropout they used for their Penn Treebank result, they do note that they performed an extensive hyperparameter search over learning rate, weight initialization, dropout rates, and decay epoch in order to produce their best performing model.",NC,
2797,"While Zoph & Le (2016) do not report any of the hyperparameters or what type of dropout they used for their Penn Treebank result, they do note that they performed an extensive hyperparameter search over learning rate, weight initialization, dropout rates, and decay epoch in order to produce their best performing model.",654,6,69,Evaluating AR and TAR independently on PTB:,Evaluating AR and TAR independently on PTB:,"We also compare to the Neural Architecture Search (NAS) cell (Zoph & Le, 2016).",Evaluating AR and TAR independently on PTB:,It is possible that a large contributor to their improved result was in these tuned hyperparameters as they did not compare their NAS cell results to a standard or variational LSTM cell that was subjected to the same extensive hyperparameter search.,NC,
2798,It is possible that a large contributor to their improved result was in these tuned hyperparameters as they did not compare their NAS cell results to a standard or variational LSTM cell that was subjected to the same extensive hyperparameter search.,655,6,70,Evaluating AR and TAR independently on PTB:,Evaluating AR and TAR independently on PTB:,"While Zoph & Le (2016) do not report any of the hyperparameters or what type of dropout they used for their Penn Treebank result, they do note that they performed an extensive hyperparameter search over learning rate, weight initialization, dropout rates, and decay epoch in order to produce their best performing model.",Evaluating AR and TAR independently on PTB:,"Our largest LSTM results are 3 perplexity higher in comparison but have not undergone extensive hyperparameter search, do not use additional regularization techniques such as recurrent or embedding dropout, and do not use a custom RNN cell.",NC,
2799,"Our largest LSTM results are 3 perplexity higher in comparison but have not undergone extensive hyperparameter search, do not use additional regularization techniques such as recurrent or embedding dropout, and do not use a custom RNN cell.",656,6,71,Evaluating AR and TAR independently on PTB:,Evaluating AR and TAR independently on PTB:,It is possible that a large contributor to their improved result was in these tuned hyperparameters as they did not compare their NAS cell results to a standard or variational LSTM cell that was subjected to the same extensive hyperparameter search.,Model,WikiText-2 Results: We compare our WikiText-2 results to Inan et al.,POS,
2800,"In this work, we revisit L 2 regularization in the form of activation regularization (AR) and temporal activation regularization (TAR).",657,6,88,Conclusion,Model,"This would be important given the weights in this model were randomly initialized and suggests TAR acts as an implicit identity initialization constraint (Le et al., 2015).",Conclusion,"While simple to implement, activity regularization and temporal activity regularization are com-",FACT,
2801,"While simple to implement, activity regularization and temporal activity regularization are com-",658,6,89,Conclusion,Conclusion,"In this work, we revisit L 2 regularization in the form of activation regularization (AR) and temporal activation regularization (TAR).",Sample generated text,"For generating text samples, words were sampled using the standard generation script contained in the PyTorch word level language modeling example.",NC,
2802,"For generating text samples, words were sampled using the standard generation script contained in the PyTorch word level language modeling example.",659,6,90,Sample generated text,Conclusion,"While simple to implement, activity regularization and temporal activity regularization are com-",Sample generated text,WikiText-2 was used given the larger vocabulary and more realistic looking text.,NC,
2803,WikiText-2 was used given the larger vocabulary and more realistic looking text.,660,6,91,Sample generated text,Sample generated text,"For generating text samples, words were sampled using the standard generation script contained in the PyTorch word level language modeling example.",Sample generated text,Neither the eos token nor the unk were allowed to be selected.,NC,
2804,Neither the eos token nor the unk were allowed to be selected.,661,6,92,Sample generated text,Sample generated text,WikiText-2 was used given the larger vocabulary and more realistic looking text.,Sample generated text,"Each paragraph is a separate sample of text with the tokens following Moses (Koehn et al., 2007), joining words with @-@ and dot-decimal split to a @.",NC,
2805,"Each paragraph is a separate sample of text with the tokens following Moses (Koehn et al., 2007), joining words with @-@ and dot-decimal split to a @.",662,6,93,Sample generated text,Sample generated text,Neither the eos token nor the unk were allowed to be selected.,Sample generated text,"Something Borrowed "" is the second episode of the fourth season of the American comedy television series The X @-@ Files .",NC,
2806,"Something Borrowed "" is the second episode of the fourth season of the American comedy television series The X @-@ Files .",663,6,94,Sample generated text,Sample generated text,"Each paragraph is a separate sample of text with the tokens following Moses (Koehn et al., 2007), joining words with @-@ and dot-decimal split to a @.",Sample generated text,The episode was written by David McCarthy and directed by Mark Sacks .,NC,
2807,The episode was written by David McCarthy and directed by Mark Sacks .,664,6,95,Sample generated text,Sample generated text,"Something Borrowed "" is the second episode of the fourth season of the American comedy television series The X @-@ Files .",Sample generated text,"It aired in the United States on November 30 , 2011 , as a two @-@ episode episode, watched by 4 @.",NC,
2808,"It aired in the United States on November 30 , 2011 , as a two @-@ episode episode, watched by 4 @.",665,6,96,Sample generated text,Sample generated text,The episode was written by David McCarthy and directed by Mark Sacks .,Sample generated text,@ 9 million viewers and was the highest rated show on the Fox network .,NC,
2809,@ 9 million viewers and was the highest rated show on the Fox network .,666,6,97,Sample generated text,Sample generated text,"It aired in the United States on November 30 , 2011 , as a two @-@ episode episode, watched by 4 @.",Sample generated text,"The work of Olivier 's , a large 1950s table with the center of a vinyl beam , was used for bony motifs from the upper @-@ production model via the Club van X .",NC,
2810,"The work of Olivier 's , a large 1950s table with the center of a vinyl beam , was used for bony motifs from the upper @-@ production model via the Club van X .",667,6,98,Sample generated text,Sample generated text,@ 9 million viewers and was the highest rated show on the Fox network .,Sample generated text,"The modified works were released in the museum , which gave its namesake to the visual designers in Hong Kong .",NC,
2811,"The modified works were released in the museum , which gave its namesake to the visual designers in Hong Kong .",668,6,99,Sample generated text,Sample generated text,"The work of Olivier 's , a large 1950s table with the center of a vinyl beam , was used for bony motifs from the upper @-@ production model via the Club van X .",Sample generated text,"The first prototype was released for the PlayStation 4 , containing the 2 @.",NC,
2812,"The first prototype was released for the PlayStation 4 , containing the 2 @.",669,6,100,Sample generated text,Sample generated text,"The modified works were released in the museum , which gave its namesake to the visual designers in Hong Kong .",Sample generated text,"@ 5 part series , with 3 @.",NC,
2813,"@ 5 part series , with 3 @.",670,6,101,Sample generated text,Sample generated text,"The first prototype was released for the PlayStation 4 , containing the 2 @.",Sample generated text,@ 5 million copies sold .,NC,
2814,@ 5 million copies sold .,671,6,102,Sample generated text,Sample generated text,"@ 5 part series , with 3 @.",Sample generated text,"In October 2010 , Activision announced that both the game and the main gameplay was "" downloadable "" .",NC,
2815,"In October 2010 , Activision announced that both the game and the main gameplay was "" downloadable "" .",672,6,103,Sample generated text,Sample generated text,@ 5 million copies sold .,Sample generated text,"The first game , titled Snow : The Game of the Battlefield 2 : The Ultimate Warrior , was the third anime game , and was released in August 2016 .",NC,
2816,"The first game , titled Snow : The Game of the Battlefield 2 : The Ultimate Warrior , was the third anime game , and was released in August 2016 .",673,6,104,Sample generated text,Sample generated text,"In October 2010 , Activision announced that both the game and the main gameplay was "" downloadable "" .",Sample generated text,"The German Land Forces had been reversed in the early 1990s , although the Soviet Union continued to deter NDH forces in the nation .",NC,
2817,"The German Land Forces had been reversed in the early 1990s , although the Soviet Union continued to deter NDH forces in the nation .",674,6,105,Sample generated text,Sample generated text,"The first game , titled Snow : The Game of the Battlefield 2 : The Ultimate Warrior , was the third anime game , and was released in August 2016 .",Sample generated text,"The area was moved to Sarajevo , and the troops were despatched to the National Register of Historic Places in the summer of 1918 for the establishment of full political and social parties .",NC,
2818,"The area was moved to Sarajevo , and the troops were despatched to the National Register of Historic Places in the summer of 1918 for the establishment of full political and social parties .",675,6,106,Sample generated text,Sample generated text,"The German Land Forces had been reversed in the early 1990s , although the Soviet Union continued to deter NDH forces in the nation .",Sample generated text,"The Polish language was protected by the Soviet Union , which was the first Polish continental conflict of the newly formed Union in North America , and the Polish Front with the last of the Polish Communist Party .",NC,
2819,"The Polish language was protected by the Soviet Union , which was the first Polish continental conflict of the newly formed Union in North America , and the Polish Front with the last of the Polish Communist Party .",676,6,107,Sample generated text,Sample generated text,"The area was moved to Sarajevo , and the troops were despatched to the National Register of Historic Places in the summer of 1918 for the establishment of full political and social parties .",,,NC,
2820,"  Unsupervised models of dependency parsing typically require large amounts of clean, unlabeled data plus gold-standard part-of-speech tags.",677,7,0,abstract,,,abstract,Adding indirect supervision (e.g.,NC,
2821,Adding indirect supervision (e.g.,678,7,1,abstract,abstract,"  Unsupervised models of dependency parsing typically require large amounts of clean, unlabeled data plus gold-standard part-of-speech tags.",abstract,"language universals and rules) can help, but we show that obtaining small amounts of direct supervision - here, partial dependency annotations - provides a strong balance between zero and full supervision.",POS,
2822,"language universals and rules) can help, but we show that obtaining small amounts of direct supervision - here, partial dependency annotations - provides a strong balance between zero and full supervision.",679,7,2,abstract,abstract,Adding indirect supervision (e.g.,abstract,We adapt the unsupervised ConvexMST dependency parser to learn from partial dependencies expressed in the Graph Fragment Language.,POS,
2823,We adapt the unsupervised ConvexMST dependency parser to learn from partial dependencies expressed in the Graph Fragment Language.,680,7,3,abstract,abstract,"language universals and rules) can help, but we show that obtaining small amounts of direct supervision - here, partial dependency annotations - provides a strong balance between zero and full supervision.",abstract,"With less than 24 hours of total annotation, we obtain 7% and 17% absolute improvement in unlabeled dependency scores for English and Spanish, respectively, compared to the same parser using only universal grammar constraints.",FACT,
2824,"With less than 24 hours of total annotation, we obtain 7% and 17% absolute improvement in unlabeled dependency scores for English and Spanish, respectively, compared to the same parser using only universal grammar constraints.",681,7,4,abstract,abstract,We adapt the unsupervised ConvexMST dependency parser to learn from partial dependencies expressed in the Graph Fragment Language.,Introduction,Unsupervised parsing solutions are simultaneously an attractive yet troublesome method for handling low-data scenarios.,POS,
2825,Unsupervised parsing solutions are simultaneously an attractive yet troublesome method for handling low-data scenarios.,682,7,5,Introduction,abstract,"With less than 24 hours of total annotation, we obtain 7% and 17% absolute improvement in unlabeled dependency scores for English and Spanish, respectively, compared to the same parser using only universal grammar constraints.",Introduction,"The performance of unsupervised parsers has increased dramatically in recent years (Klein and Manning, 2004;Naseem et al., 2010), making them a potentially viable option for constructing labeled corpora on limited budgets.",NC,
2826,"The performance of unsupervised parsers has increased dramatically in recent years (Klein and Manning, 2004;Naseem et al., 2010), making them a potentially viable option for constructing labeled corpora on limited budgets.",683,7,6,Introduction,Introduction,Unsupervised parsing solutions are simultaneously an attractive yet troublesome method for handling low-data scenarios.,Introduction,"However, their performance is often outmatched by small amounts of labeled data (Blunsom and Cohn, 2010;Spitkovsky et al., 2012).",NC,
2827,"However, their performance is often outmatched by small amounts of labeled data (Blunsom and Cohn, 2010;Spitkovsky et al., 2012).",684,7,7,Introduction,Introduction,"The performance of unsupervised parsers has increased dramatically in recent years (Klein and Manning, 2004;Naseem et al., 2010), making them a potentially viable option for constructing labeled corpora on limited budgets.",Introduction,"Further, recent work using linguistically-informed error analysis on unsupervised Combinatory Categorial Grammar parsing shows that entire syntactic phenomena are outside the scope of existing unsupervised parsers (Bisk and Hockenmaier, 2015).",NC,
2828,"Further, recent work using linguistically-informed error analysis on unsupervised Combinatory Categorial Grammar parsing shows that entire syntactic phenomena are outside the scope of existing unsupervised parsers (Bisk and Hockenmaier, 2015).",685,7,8,Introduction,Introduction,"However, their performance is often outmatched by small amounts of labeled data (Blunsom and Cohn, 2010;Spitkovsky et al., 2012).",Introduction,"Accordingly, most recent work in this area has focused on methods of providing sources of indirect annotation, whether via linguistic world-knowledge (Naseem et al., 2010;Grave and Elhadad, 2015), partial annotations (Flannery et al., 2011;Mielens et al., 2015) or crosslingual information transfer (Naseem et al., 2012).",NC,
2829,"Accordingly, most recent work in this area has focused on methods of providing sources of indirect annotation, whether via linguistic world-knowledge (Naseem et al., 2010;Grave and Elhadad, 2015), partial annotations (Flannery et al., 2011;Mielens et al., 2015) or crosslingual information transfer (Naseem et al., 2012).",686,7,9,Introduction,Introduction,"Further, recent work using linguistically-informed error analysis on unsupervised Combinatory Categorial Grammar parsing shows that entire syntactic phenomena are outside the scope of existing unsupervised parsers (Bisk and Hockenmaier, 2015).",Introduction,"With unsupervised parsing, data collection is not entirely eliminated: a large amount of clean, relevant data is needed.",NC,
2830,"With unsupervised parsing, data collection is not entirely eliminated: a large amount of clean, relevant data is needed.",687,7,10,Introduction,Introduction,"Accordingly, most recent work in this area has focused on methods of providing sources of indirect annotation, whether via linguistic world-knowledge (Naseem et al., 2010;Grave and Elhadad, 2015), partial annotations (Flannery et al., 2011;Mielens et al., 2015) or crosslingual information transfer (Naseem et al., 2012).",Introduction,"Also, evaluations of unsupervised techniques typically rely on gold part-ofspeech tags.",NC,
2831,"Also, evaluations of unsupervised techniques typically rely on gold part-ofspeech tags.",688,7,11,Introduction,Introduction,"With unsupervised parsing, data collection is not entirely eliminated: a large amount of clean, relevant data is needed.",Introduction,"Obtaining clean data for many languages is actually a difficult process-complicated by issues such as language identification, digitization, and varying or absent orthographies.",NC,
2832,"Obtaining clean data for many languages is actually a difficult process-complicated by issues such as language identification, digitization, and varying or absent orthographies.",689,7,12,Introduction,Introduction,"Also, evaluations of unsupervised techniques typically rely on gold part-ofspeech tags.",Introduction,This challenge also exists in many domain adaptation scenarios.,NC,
2833,This challenge also exists in many domain adaptation scenarios.,690,7,13,Introduction,Introduction,"Obtaining clean data for many languages is actually a difficult process-complicated by issues such as language identification, digitization, and varying or absent orthographies.",Introduction,"We explore the effectiveness of creating small amounts of labeled data using the Graph Fragment Language (GFL), an annotation scheme designed for speed and ease (Schneider et al., 2013;Mordowanec et al., 2014).",NC,
2834,"We explore the effectiveness of creating small amounts of labeled data using the Graph Fragment Language (GFL), an annotation scheme designed for speed and ease (Schneider et al., 2013;Mordowanec et al., 2014).",691,7,14,Introduction,Introduction,This challenge also exists in many domain adaptation scenarios.,Introduction,"We create 270 English and 2297 Spanish partial sentence annotations using GFL, using a mix of expert and non-expert annotators.",FACT,
2835,"We create 270 English and 2297 Spanish partial sentence annotations using GFL, using a mix of expert and non-expert annotators.",692,7,15,Introduction,Introduction,"We explore the effectiveness of creating small amounts of labeled data using the Graph Fragment Language (GFL), an annotation scheme designed for speed and ease (Schneider et al., 2013;Mordowanec et al., 2014).",Introduction,We then adapt the minimum spanning tree based parsing technique of Grave & Elhadad (2015) to use these partial annotations in addition to universal dependency rules it already exploits.,FACT,
2836,We then adapt the minimum spanning tree based parsing technique of Grave & Elhadad (2015) to use these partial annotations in addition to universal dependency rules it already exploits.,693,7,16,Introduction,Introduction,"We create 270 English and 2297 Spanish partial sentence annotations using GFL, using a mix of expert and non-expert annotators.",Introduction,Throughout this work we will refer to this parser as ConvexMST.,FACT,
2837,Throughout this work we will refer to this parser as ConvexMST.,694,7,17,Introduction,Introduction,We then adapt the minimum spanning tree based parsing technique of Grave & Elhadad (2015) to use these partial annotations in addition to universal dependency rules it already exploits.,Introduction,1  We present parsing results with and without gold part-of-speech tags.,NC,
2838,1  We present parsing results with and without gold part-of-speech tags.,695,7,18,Introduction,Introduction,Throughout this work we will refer to this parser as ConvexMST.,Introduction,"When using predicted POS tags, our experiments show that exploiting cheap, incomplete direct supervision in addition to language universals provides large absolute performance im- provements for both English and Spanish: 6.3% for the former and 17.3% for the latter.",NC,
2839,"When using predicted POS tags, our experiments show that exploiting cheap, incomplete direct supervision in addition to language universals provides large absolute performance im- provements for both English and Spanish: 6.3% for the former and 17.3% for the latter.",696,7,19,Introduction,Introduction,1  We present parsing results with and without gold part-of-speech tags.,Introduction,"Furthermore, the ConvexMST parser dramatically outperforms the Gibbs sampler parser of Mielens et al.",POS,
2840,"Furthermore, the ConvexMST parser dramatically outperforms the Gibbs sampler parser of Mielens et al.",697,7,20,Introduction,Introduction,"When using predicted POS tags, our experiments show that exploiting cheap, incomplete direct supervision in addition to language universals provides large absolute performance im- provements for both English and Spanish: 6.3% for the former and 17.3% for the latter.",Introduction,(2015) using the supervision (English: +5.2%; Spanish: +14.4%).,POS,
2841,(2015) using the supervision (English: +5.2%; Spanish: +14.4%).,698,7,21,Introduction,Introduction,"Furthermore, the ConvexMST parser dramatically outperforms the Gibbs sampler parser of Mielens et al.",Introduction,"We also show that the extra supervision provided by gold POS tags heavily influences results; in particular, it inflates performance when only using language universals.",POS,
2842,"We also show that the extra supervision provided by gold POS tags heavily influences results; in particular, it inflates performance when only using language universals.",699,7,22,Introduction,Introduction,(2015) using the supervision (English: +5.2%; Spanish: +14.4%).,Introduction,Experiments that rely on gold POS tags alone are thus not reliable indicators of performance in true low-resource settings.,POS,
2843,Experiments that rely on gold POS tags alone are thus not reliable indicators of performance in true low-resource settings.,700,7,23,Introduction,Introduction,"We also show that the extra supervision provided by gold POS tags heavily influences results; in particular, it inflates performance when only using language universals.",Graph Fragment Language,"We use the Graph Fragment Language (GFL) (Schneider et al., 2013) to allow for light-weight, simple annotations that our annotators can easily learn and use confidently.",POS,
2844,"We use the Graph Fragment Language (GFL) (Schneider et al., 2013) to allow for light-weight, simple annotations that our annotators can easily learn and use confidently.",701,7,24,Graph Fragment Language,Introduction,Experiments that rely on gold POS tags alone are thus not reliable indicators of performance in true low-resource settings.,Graph Fragment Language,The choice of annotation scheme is particularly important: we seek to optimize annotation speed rather than full-specification or high accuracy.,NC,
2845,The choice of annotation scheme is particularly important: we seek to optimize annotation speed rather than full-specification or high accuracy.,702,7,25,Graph Fragment Language,Graph Fragment Language,"We use the Graph Fragment Language (GFL) (Schneider et al., 2013) to allow for light-weight, simple annotations that our annotators can easily learn and use confidently.",Graph Fragment Language,"In previous studies, the use of GFL has allowed for annotation rates of 2-3 times that of traditional dependency annotations while still maintaining a useful level of annotation density (Mordowanec et al., 2014;Mielens et al., 2015).",NC,
2846,"In previous studies, the use of GFL has allowed for annotation rates of 2-3 times that of traditional dependency annotations while still maintaining a useful level of annotation density (Mordowanec et al., 2014;Mielens et al., 2015).",703,7,26,Graph Fragment Language,Graph Fragment Language,The choice of annotation scheme is particularly important: we seek to optimize annotation speed rather than full-specification or high accuracy.,Graph Fragment Language,Hwa (1999) demonstrated that it is most effective to provide high-level sentence constituents to a parser and allow it to fill in the low-level information itself.,NC,
2847,Hwa (1999) demonstrated that it is most effective to provide high-level sentence constituents to a parser and allow it to fill in the low-level information itself.,704,7,27,Graph Fragment Language,Graph Fragment Language,"In previous studies, the use of GFL has allowed for annotation rates of 2-3 times that of traditional dependency annotations while still maintaining a useful level of annotation density (Mordowanec et al., 2014;Mielens et al., 2015).",Graph Fragment Language,The GFL annotation in Figure 1 shows two distinct notations.,NC,
2848,The GFL annotation in Figure 1 shows two distinct notations.,705,7,28,Graph Fragment Language,Graph Fragment Language,Hwa (1999) demonstrated that it is most effective to provide high-level sentence constituents to a parser and allow it to fill in the low-level information itself.,Graph Fragment Language,Constituent brackets are specified by parentheses and direct dependencies by angle brackets.,NC,
2849,Constituent brackets are specified by parentheses and direct dependencies by angle brackets.,706,7,29,Graph Fragment Language,Graph Fragment Language,The GFL annotation in Figure 1 shows two distinct notations.,Graph Fragment Language,Many words and phrases are underspecified.,NC,
2850,Many words and phrases are underspecified.,707,7,30,Graph Fragment Language,Graph Fragment Language,Constituent brackets are specified by parentheses and direct dependencies by angle brackets.,Graph Fragment Language,"Allowing partial annotations dramatically increases the speed at which annotators can work, while simultaneously reducing error rates.",NC,
2851,"Allowing partial annotations dramatically increases the speed at which annotators can work, while simultaneously reducing error rates.",708,7,31,Graph Fragment Language,Graph Fragment Language,Many words and phrases are underspecified.,Graph Fragment Language,These two effects both arise from being able to leave difficult or tedious portions of a sentence unspecified.,NC,
2852,These two effects both arise from being able to leave difficult or tedious portions of a sentence unspecified.,709,7,32,Graph Fragment Language,Graph Fragment Language,"Allowing partial annotations dramatically increases the speed at which annotators can work, while simultaneously reducing error rates.",Filling in Partial Dependencies,A partial annotation produces a set of dependency tree fragments.,NC,
2853,A partial annotation produces a set of dependency tree fragments.,710,7,33,Filling in Partial Dependencies,Graph Fragment Language,These two effects both arise from being able to leave difficult or tedious portions of a sentence unspecified.,Filling in Partial Dependencies,"Compared to an unlabeled sentence, this can substantially reduce the work a parser must do.",NC,
2854,"Compared to an unlabeled sentence, this can substantially reduce the work a parser must do.",711,7,34,Filling in Partial Dependencies,Filling in Partial Dependencies,A partial annotation produces a set of dependency tree fragments.,Filling in Partial Dependencies,"When working with partial dependencies, there are two paths that can be taken with regard to overall model-building.",NC,
2855,"When working with partial dependencies, there are two paths that can be taken with regard to overall model-building.",712,7,35,Filling in Partial Dependencies,Filling in Partial Dependencies,"Compared to an unlabeled sentence, this can substantially reduce the work a parser must do.",Filling in Partial Dependencies,"In a 'Fill-then-Parse' setup, the partial dependencies are first filled-in to produce full dependencies that are then used to train a standard dependency parser.",NC,
2856,"In a 'Fill-then-Parse' setup, the partial dependencies are first filled-in to produce full dependencies that are then used to train a standard dependency parser.",713,7,36,Filling in Partial Dependencies,Filling in Partial Dependencies,"When working with partial dependencies, there are two paths that can be taken with regard to overall model-building.",Filling in Partial Dependencies,"In a 'Fill+Parse' setup, one model both fills in and parses new sentences.",NC,
2857,"In a 'Fill+Parse' setup, one model both fills in and parses new sentences.",714,7,37,Filling in Partial Dependencies,Filling in Partial Dependencies,"In a 'Fill-then-Parse' setup, the partial dependencies are first filled-in to produce full dependencies that are then used to train a standard dependency parser.",Filling in Partial Dependencies,"We use a Fill+Parse setup, while previous work focused on Fill-then-Parse.",NC,
2858,"We use a Fill+Parse setup, while previous work focused on Fill-then-Parse.",715,7,38,Filling in Partial Dependencies,Filling in Partial Dependencies,"In a 'Fill+Parse' setup, one model both fills in and parses new sentences.",Filling in Partial Dependencies,"The major benefit of the former is that learning can be sensitive to the source of an arc in the training data-e.g., whether it came from an annotator or a universal rule.",NC,
2859,"The major benefit of the former is that learning can be sensitive to the source of an arc in the training data-e.g., whether it came from an annotator or a universal rule.",716,7,39,Filling in Partial Dependencies,Filling in Partial Dependencies,"We use a Fill+Parse setup, while previous work focused on Fill-then-Parse.",Filling in Partial Dependencies,Fill-then-Parse obscures this distinction and not knowing how trustworthy an arc is can lead to additional errors.,NC,
2860,Fill-then-Parse obscures this distinction and not knowing how trustworthy an arc is can lead to additional errors.,717,7,40,Filling in Partial Dependencies,Filling in Partial Dependencies,"The major benefit of the former is that learning can be sensitive to the source of an arc in the training data-e.g., whether it came from an annotator or a universal rule.",Filling in Partial Dependencies,"Indeed, Fill+Parse method produces better results for our datasets than Fill-then-Parse (see Section 4.2).",NC,
2861,"Indeed, Fill+Parse method produces better results for our datasets than Fill-then-Parse (see Section 4.2).",718,7,41,Filling in Partial Dependencies,Filling in Partial Dependencies,Fill-then-Parse obscures this distinction and not knowing how trustworthy an arc is can lead to additional errors.,Simulated Cost Comparison,Many factors influence the cost of creating a corpus.,POS,
2862,Many factors influence the cost of creating a corpus.,719,7,42,Simulated Cost Comparison,Filling in Partial Dependencies,"Indeed, Fill+Parse method produces better results for our datasets than Fill-then-Parse (see Section 4.2).",Simulated Cost Comparison,Our goal is to minimize cost relative to the performance of a parser trained with the corpus.,NC,
2863,Our goal is to minimize cost relative to the performance of a parser trained with the corpus.,720,7,43,Simulated Cost Comparison,Simulated Cost Comparison,Many factors influence the cost of creating a corpus.,Simulated Cost Comparison,"The actual cost of finding and paying annotators is the most obvious factor, and it will typically be higher for a lowresource language or highly specialized domain.",NC,
2864,"The actual cost of finding and paying annotators is the most obvious factor, and it will typically be higher for a lowresource language or highly specialized domain.",721,7,44,Simulated Cost Comparison,Simulated Cost Comparison,Our goal is to minimize cost relative to the performance of a parser trained with the corpus.,Simulated Cost Comparison,Using a light-weight partial annotation scheme like GFL has the potential to increase the pool of qualified annotators and alleviate this challenge.,NC,
2865,Using a light-weight partial annotation scheme like GFL has the potential to increase the pool of qualified annotators and alleviate this challenge.,722,7,45,Simulated Cost Comparison,Simulated Cost Comparison,"The actual cost of finding and paying annotators is the most obvious factor, and it will typically be higher for a lowresource language or highly specialized domain.",Simulated Cost Comparison,"Given a partial annotation scheme like GFL, an additional cost factor is that of obtaining a particular level of completion for each sentence.",NC,
2866,"Given a partial annotation scheme like GFL, an additional cost factor is that of obtaining a particular level of completion for each sentence.",723,7,46,Simulated Cost Comparison,Simulated Cost Comparison,Using a light-weight partial annotation scheme like GFL has the potential to increase the pool of qualified annotators and alleviate this challenge.,Simulated Cost Comparison,"Consider that for any sentence there are both 'low-hanging fruit' dependencies such as determiner attachment, and more difficult dependencies such as preposition attachment and long-distance relations.",NC,
2867,"Consider that for any sentence there are both 'low-hanging fruit' dependencies such as determiner attachment, and more difficult dependencies such as preposition attachment and long-distance relations.",724,7,47,Simulated Cost Comparison,Simulated Cost Comparison,"Given a partial annotation scheme like GFL, an additional cost factor is that of obtaining a particular level of completion for each sentence.",Simulated Cost Comparison,"Harder dependencies take longer to annotate (and thus cost more), so it is worth considering cost metrics that incorporate completion percentage.",NC,
2868,"Harder dependencies take longer to annotate (and thus cost more), so it is worth considering cost metrics that incorporate completion percentage.",725,7,48,Simulated Cost Comparison,Simulated Cost Comparison,"Consider that for any sentence there are both 'low-hanging fruit' dependencies such as determiner attachment, and more difficult dependencies such as preposition attachment and long-distance relations.",Simulated Cost Comparison,"In the absence of timing/expense data, we can simulate this intuition with a variable cost model for which each an additional dependency annotated in a sentence is more expensive than the previous one.",NC,
2869,"In the absence of timing/expense data, we can simulate this intuition with a variable cost model for which each an additional dependency annotated in a sentence is more expensive than the previous one.",726,7,49,Simulated Cost Comparison,Simulated Cost Comparison,"Harder dependencies take longer to annotate (and thus cost more), so it is worth considering cost metrics that incorporate completion percentage.",Simulated Cost Comparison,Figure 2 demonstrates the impact of completion cost.,NC,
2870,Figure 2 demonstrates the impact of completion cost.,727,7,50,Simulated Cost Comparison,Simulated Cost Comparison,"In the absence of timing/expense data, we can simulate this intuition with a variable cost model for which each an additional dependency annotated in a sentence is more expensive than the previous one.",Simulated Cost Comparison,"Parsing accuracies (for our parser introduced in  We simulated the construction of various corpora by deriving partial dependencies from gold standard annotations), and show the cost curves for different sentence completion rates.",NC,
2871,"Parsing accuracies (for our parser introduced in  We simulated the construction of various corpora by deriving partial dependencies from gold standard annotations), and show the cost curves for different sentence completion rates.",728,7,51,Simulated Cost Comparison,Simulated Cost Comparison,Figure 2 demonstrates the impact of completion cost.,Simulated Cost Comparison,"100% completion produces the best performance with equal costs, but under the more realistic variable cost model, 30% and 50% completion win.",NC,
2872,"100% completion produces the best performance with equal costs, but under the more realistic variable cost model, 30% and 50% completion win.",729,7,52,Simulated Cost Comparison,Simulated Cost Comparison,"Parsing accuracies (for our parser introduced in  We simulated the construction of various corpora by deriving partial dependencies from gold standard annotations), and show the cost curves for different sentence completion rates.",Simulated Cost Comparison,We show later that this pattern holds under actual timed annotation.,POS,
2873,We show later that this pattern holds under actual timed annotation.,730,7,53,Simulated Cost Comparison,Simulated Cost Comparison,"100% completion produces the best performance with equal costs, but under the more realistic variable cost model, 30% and 50% completion win.",Simulated Cost Comparison,Garrette (2015) demonstrated the benefit of partial annotations for CCG parsing.,POS,
2874,Garrette (2015) demonstrated the benefit of partial annotations for CCG parsing.,731,7,54,Simulated Cost Comparison,Simulated Cost Comparison,We show later that this pattern holds under actual timed annotation.,Simulated Cost Comparison,"They focused on the number of (partial) bracket annotations (as a proxy for annotation time), holding this fixed while varying the number of sentences.",NC,
2875,"They focused on the number of (partial) bracket annotations (as a proxy for annotation time), holding this fixed while varying the number of sentences.",732,7,55,Simulated Cost Comparison,Simulated Cost Comparison,Garrette (2015) demonstrated the benefit of partial annotations for CCG parsing.,Simulated Cost Comparison,"Strikingly, they found that having 40% of brackets across the full dataset was better than full brackets for 80% of the corpus.",NC,
2876,"Strikingly, they found that having 40% of brackets across the full dataset was better than full brackets for 80% of the corpus.",733,7,56,Simulated Cost Comparison,Simulated Cost Comparison,"They focused on the number of (partial) bracket annotations (as a proxy for annotation time), holding this fixed while varying the number of sentences.",Simulated Cost Comparison,"This result uses an equal cost-per-bracket assumption, so the difference would be even more favorable to partial annotations with a variable cost.",NC,
2877,"This result uses an equal cost-per-bracket assumption, so the difference would be even more favorable to partial annotations with a variable cost.",734,7,57,Simulated Cost Comparison,Simulated Cost Comparison,"Strikingly, they found that having 40% of brackets across the full dataset was better than full brackets for 80% of the corpus.",Unsupervised vs. Partial Annotations,"Without any direct annotations, we must rely on indirect supervision such as universal grammar rules, cross-lingual information transfer, and domain adaptation.",NC,
2878,"Without any direct annotations, we must rely on indirect supervision such as universal grammar rules, cross-lingual information transfer, and domain adaptation.",735,7,58,Unsupervised vs. Partial Annotations,Simulated Cost Comparison,"This result uses an equal cost-per-bracket assumption, so the difference would be even more favorable to partial annotations with a variable cost.",Unsupervised vs. Partial Annotations,"Following Grave & Elhadad (2015), we use the universal grammar rules in Table 1.",NC,
2879,"Following Grave & Elhadad (2015), we use the universal grammar rules in Table 1.",736,7,59,Unsupervised vs. Partial Annotations,Unsupervised vs. Partial Annotations,"Without any direct annotations, we must rely on indirect supervision such as universal grammar rules, cross-lingual information transfer, and domain adaptation.",Unsupervised vs. Partial Annotations,Indirect supervision via these rules is achieved by biasing produced trees to conform to the rules.,NC,
2880,Indirect supervision via these rules is achieved by biasing produced trees to conform to the rules.,737,7,60,Unsupervised vs. Partial Annotations,Unsupervised vs. Partial Annotations,"Following Grave & Elhadad (2015), we use the universal grammar rules in Table 1.",Unsupervised vs. Partial Annotations,"This is the Verb → Verb Noun → Noun Verb → Noun Noun → Adj Verb → Pron Noun → Det Verb → Adv Noun → Num Verb → Adp Noun → Conj Adj → Adv Adp → Noun Table 1: Universal Grammar Rules only form of dependency supervision considered by Grave & Elhadad, though they do provide additional direct supervision via gold part-of-speech tags.",NC,
2881,"This is the Verb → Verb Noun → Noun Verb → Noun Noun → Adj Verb → Pron Noun → Det Verb → Adv Noun → Num Verb → Adp Noun → Conj Adj → Adv Adp → Noun Table 1: Universal Grammar Rules only form of dependency supervision considered by Grave & Elhadad, though they do provide additional direct supervision via gold part-of-speech tags.",738,7,61,Unsupervised vs. Partial Annotations,Unsupervised vs. Partial Annotations,Indirect supervision via these rules is achieved by biasing produced trees to conform to the rules.,Data,We use two sources of data.,NC,
2882,Our goal is to minimize real-world costs associated with producing a finished parsing model.,739,7,83,POS-Tagging,Data,"Efforts not using an existing parser proceed even slower; for instance the Ancient Greek Dependency Treebank reported rates of 100-200 tokens/hr (Bamman and Crane, 2011).",POS-Tagging,"To this end, we trained our own POS taggers using type label annotations (Garrette and Baldridge, 2013)  We trained taggers for all languages using a limited amount of the available gold data-ensuring that the accuracy is comparable with low-resource human-sourced taggers.",NC,
2883,"To this end, we trained our own POS taggers using type label annotations (Garrette and Baldridge, 2013)  We trained taggers for all languages using a limited amount of the available gold data-ensuring that the accuracy is comparable with low-resource human-sourced taggers.",740,7,84,POS-Tagging,POS-Tagging,Our goal is to minimize real-world costs associated with producing a finished parsing model.,POS-Tagging,"We extract types from the corpus, rank them by frequency, and take the most frequent types to train the tagger.",NC,
2884,"We extract types from the corpus, rank them by frequency, and take the most frequent types to train the tagger.",741,7,85,POS-Tagging,POS-Tagging,"To this end, we trained our own POS taggers using type label annotations (Garrette and Baldridge, 2013)  We trained taggers for all languages using a limited amount of the available gold data-ensuring that the accuracy is comparable with low-resource human-sourced taggers.",POS-Tagging,The cutoff on how many types to take is derived from the number of types the annotators in Garrette et al.,NC,
2885,The cutoff on how many types to take is derived from the number of types the annotators in Garrette et al.,742,7,86,POS-Tagging,POS-Tagging,"We extract types from the corpus, rank them by frequency, and take the most frequent types to train the tagger.",POS-Tagging,(2013) were able to produce in two hours.,NC,
2886,(2013) were able to produce in two hours.,743,7,87,POS-Tagging,POS-Tagging,The cutoff on how many types to take is derived from the number of types the annotators in Garrette et al.,POS-Tagging,The taggers all obtain around 80% accuracy.,NC,
2887,The taggers all obtain around 80% accuracy.,744,7,88,POS-Tagging,POS-Tagging,(2013) were able to produce in two hours.,Convex-MST,"This section provides a brief overview of the core parsing algorithm; for full details, see Grave & Elhadad (2015).",POS,
2888,"This section provides a brief overview of the core parsing algorithm; for full details, see Grave & Elhadad (2015).",745,7,89,Convex-MST,POS-Tagging,The taggers all obtain around 80% accuracy.,Convex-MST,"We begin by considering a binary vector y that encodes all of the dependencies in our corpus, such that y ijk = 1 if sentence i has an arc with dependent j and head k. This representation leads to the problem formulation in Equation 1, where Y is the convex hull of all the valid tree assignments for y, n is the number of possible dependency arcs in the corpus, u is a penalty vector that penalizes potential dependency arcs that are not in the set of universal dependency rules, and w is a weight vector learned during training min y∈Y min w 1 2n y -Xw 2 2 + λ 2 w 2 2 -µu T y (1) This problem can be solved using Algorithm 1 (Grave and Elhadad, 2015).",NC,
2889,"We begin by considering a binary vector y that encodes all of the dependencies in our corpus, such that y ijk = 1 if sentence i has an arc with dependent j and head k. This representation leads to the problem formulation in Equation 1, where Y is the convex hull of all the valid tree assignments for y, n is the number of possible dependency arcs in the corpus, u is a penalty vector that penalizes potential dependency arcs that are not in the set of universal dependency rules, and w is a weight vector learned during training min y∈Y min w 1 2n y -Xw 2 2 + λ 2 w 2 2 -µu T y (1) This problem can be solved using Algorithm 1 (Grave and Elhadad, 2015).",746,7,90,Convex-MST,Convex-MST,"This section provides a brief overview of the core parsing algorithm; for full details, see Grave & Elhadad (2015).",Partial Dependency Features,The main modification we make is to add an additional term to penalize arcs that disagree with partial  y t = γ t s t + (1 -γ t )y t annotations.,NC,
2890,We consider both simulated and actual partial annotations.,747,7,114,Experiments and Discussion,Partial Dependency Features,"Hence, arcs such as 'congress ← plan' must be in G b .",Experiments and Discussion,Results based on actual annotation are the most important as they provide our best measure of performance under a realistic annotation setting.,NC,
2891,Results based on actual annotation are the most important as they provide our best measure of performance under a realistic annotation setting.,748,7,115,Experiments and Discussion,Experiments and Discussion,We consider both simulated and actual partial annotations.,Experiments and Discussion,"However, our Spanish annotators had only six hours each, and there was no inter-annotator communication or creation of annotation conventions, and no attempt to have them adopt the conventions in the gold-standard AnCora dependencies we evaluate against.",NC,
2892,"However, our Spanish annotators had only six hours each, and there was no inter-annotator communication or creation of annotation conventions, and no attempt to have them adopt the conventions in the gold-standard AnCora dependencies we evaluate against.",749,7,116,Experiments and Discussion,Experiments and Discussion,Results based on actual annotation are the most important as they provide our best measure of performance under a realistic annotation setting.,Experiments and Discussion,"Because of this, we include simulation results to eliminate this source of divergence to better measure the effectiveness of different methods for filling in missing arcs in a partial annotation.",NEG,
2893,"Because of this, we include simulation results to eliminate this source of divergence to better measure the effectiveness of different methods for filling in missing arcs in a partial annotation.",750,7,117,Experiments and Discussion,Experiments and Discussion,"However, our Spanish annotators had only six hours each, and there was no inter-annotator communication or creation of annotation conventions, and no attempt to have them adopt the conventions in the gold-standard AnCora dependencies we evaluate against.",Experiments and Discussion,It of course also allows us to measure this for all the languages in the Universal Dependencies treebanks.,NC,
2894,It of course also allows us to measure this for all the languages in the Universal Dependencies treebanks.,751,7,118,Experiments and Discussion,Experiments and Discussion,"Because of this, we include simulation results to eliminate this source of divergence to better measure the effectiveness of different methods for filling in missing arcs in a partial annotation.",Experiments and Discussion,"We consider three different supervision settings for ConvexMST: • UG uses just the universal grammar based features, which is equivalent to the method used by Grave & Elhadad (2015).",NC,
2895,"We consider three different supervision settings for ConvexMST: • UG uses just the universal grammar based features, which is equivalent to the method used by Grave & Elhadad (2015).",752,7,119,Experiments and Discussion,Experiments and Discussion,It of course also allows us to measure this for all the languages in the Universal Dependencies treebanks.,Experiments and Discussion,• GFL uses just the human specified features.,NC,
2896,• GFL uses just the human specified features.,753,7,120,Experiments and Discussion,Experiments and Discussion,"We consider three different supervision settings for ConvexMST: • UG uses just the universal grammar based features, which is equivalent to the method used by Grave & Elhadad (2015).",Experiments and Discussion,• GFL+UG uses both.,NC,
2897,• GFL+UG uses both.,754,7,121,Experiments and Discussion,Experiments and Discussion,• GFL uses just the human specified features.,Experiments and Discussion,"Table 5: Directed dependency accuracy on English and Spanish universal treebanks using annotator provided GFL annotations, 10 or fewer words.",NC,
2898,"Table 5: Directed dependency accuracy on English and Spanish universal treebanks using annotator provided GFL annotations, 10 or fewer words.",755,7,122,Experiments and Discussion,Experiments and Discussion,• GFL+UG uses both.,Experiments and Discussion,"These three methods correspond with ξ = 0, µ = 0, and ξµ = 0 in Equation 2.",NC,
2899,"These three methods correspond with ξ = 0, µ = 0, and ξµ = 0 in Equation 2.",756,7,123,Experiments and Discussion,Experiments and Discussion,"Table 5: Directed dependency accuracy on English and Spanish universal treebanks using annotator provided GFL annotations, 10 or fewer words.",Experiments and Discussion,The training sets correspond with the 'Partial EN' and 'Partial ES' sets from Table 2.,NC,
2900,The training sets correspond with the 'Partial EN' and 'Partial ES' sets from Table 2.,757,7,124,Experiments and Discussion,Experiments and Discussion,"These three methods correspond with ξ = 0, µ = 0, and ξµ = 0 in Equation 2.",Experiments and Discussion,"The set of sentences annotated with GFL is used as the training set for the GFL, UG, and GFL+UG methods.",NC,
2901,"The set of sentences annotated with GFL is used as the training set for the GFL, UG, and GFL+UG methods.",758,7,125,Experiments and Discussion,Experiments and Discussion,The training sets correspond with the 'Partial EN' and 'Partial ES' sets from Table 2.,Simulated partial dependencies,Simulated partial dependencies are produced by removing dependencies via a stochastic process that approximates how we instructed human annotators to focus their efforts.,NC,
2902,Simulated partial dependencies are produced by removing dependencies via a stochastic process that approximates how we instructed human annotators to focus their efforts.,759,7,126,Simulated partial dependencies,Experiments and Discussion,"The set of sentences annotated with GFL is used as the training set for the GFL, UG, and GFL+UG methods.",Simulated partial dependencies,"Arcs are removed top-down, with arcs lower in the tree being more likely to be deleted.",NC,
2903,"Arcs are removed top-down, with arcs lower in the tree being more likely to be deleted.",760,7,127,Simulated partial dependencies,Simulated partial dependencies,Simulated partial dependencies are produced by removing dependencies via a stochastic process that approximates how we instructed human annotators to focus their efforts.,Simulated partial dependencies,This results in trees with more high-level structures and less lower-level information.,NC,
2904,This results in trees with more high-level structures and less lower-level information.,761,7,128,Simulated partial dependencies,Simulated partial dependencies,"Arcs are removed top-down, with arcs lower in the tree being more likely to be deleted.",Simulated partial dependencies,Figure 4 demonstrates the stability of our parser under varying levels of such gold tree degradation.,NC,
2905,Figure 4 demonstrates the stability of our parser under varying levels of such gold tree degradation.,762,7,129,Simulated partial dependencies,Simulated partial dependencies,This results in trees with more high-level structures and less lower-level information.,Simulated partial dependencies,"Missing arcs were recovered using our parse imputation scheme (using GFL+UG features), and the resulting parser was applied to the evaluation sentences.",POS,
2906,"Missing arcs were recovered using our parse imputation scheme (using GFL+UG features), and the resulting parser was applied to the evaluation sentences.",763,7,130,Simulated partial dependencies,Simulated partial dependencies,Figure 4 demonstrates the stability of our parser under varying levels of such gold tree degradation.,Simulated partial dependencies,"Accuracy decreases slightly to around 60% removal, and then degrades more rapidly after that.",NC,
2907,"Accuracy decreases slightly to around 60% removal, and then degrades more rapidly after that.",764,7,131,Simulated partial dependencies,Simulated partial dependencies,"Missing arcs were recovered using our parse imputation scheme (using GFL+UG features), and the resulting parser was applied to the evaluation sentences.",Simulated partial dependencies,Table 4 provides numeric data for the simulations.,POS,
2908,Table 4 provides numeric data for the simulations.,765,7,132,Simulated partial dependencies,Simulated partial dependencies,"Accuracy decreases slightly to around 60% removal, and then degrades more rapidly after that.",Annotator-sourced partial dependencies,Table 5 gives semi-supervised parsing results on the English and Spanish treebanks for sentences with 10 or fewer words.,NC,
2909,Table 5 gives semi-supervised parsing results on the English and Spanish treebanks for sentences with 10 or fewer words.,766,7,133,Annotator-sourced partial dependencies,Simulated partial dependencies,Table 4 provides numeric data for the simulations.,Annotator-sourced partial dependencies,"To investigate the impact of POS taggers on parsing results, we conducted two series of experiments using POS tags trained by our own tagger as discussed in Section 2.6 (Predicted Tag) and gold POS tags extracted from treebank (Gold Tag).",NC,
2910,"To investigate the impact of POS taggers on parsing results, we conducted two series of experiments using POS tags trained by our own tagger as discussed in Section 2.6 (Predicted Tag) and gold POS tags extracted from treebank (Gold Tag).",767,7,134,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,Table 5 gives semi-supervised parsing results on the English and Spanish treebanks for sentences with 10 or fewer words.,Annotator-sourced partial dependencies,We compare against a right-branching baseline and the Gibbs parser of Mielens et al.,NC,
2911,We compare against a right-branching baseline and the Gibbs parser of Mielens et al.,768,7,135,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,"To investigate the impact of POS taggers on parsing results, we conducted two series of experiments using POS tags trained by our own tagger as discussed in Section 2.6 (Predicted Tag) and gold POS tags extracted from treebank (Gold Tag).",Annotator-sourced partial dependencies,All the parsing methods handily beat the rightbranching baseline.,NC,
2912,All the parsing methods handily beat the rightbranching baseline.,769,7,136,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,We compare against a right-branching baseline and the Gibbs parser of Mielens et al.,Annotator-sourced partial dependencies,"ConvexMST-UG (the model of Grave and Elhadad ( 2015)) beats the Gibbs parser with gold POS tags, but the ranking switches with predicted POS tags.",POS,
2913,"ConvexMST-UG (the model of Grave and Elhadad ( 2015)) beats the Gibbs parser with gold POS tags, but the ranking switches with predicted POS tags.",770,7,137,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,All the parsing methods handily beat the rightbranching baseline.,Annotator-sourced partial dependencies,"This shows the effectiveness of ConvexMST, but highlights its brittleness with respect to tagging errors: bad tags lead to poor guidance from language universals.",POS,
2914,"This shows the effectiveness of ConvexMST, but highlights its brittleness with respect to tagging errors: bad tags lead to poor guidance from language universals.",771,7,138,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,"ConvexMST-UG (the model of Grave and Elhadad ( 2015)) beats the Gibbs parser with gold POS tags, but the ranking switches with predicted POS tags.",Annotator-sourced partial dependencies,ConvexMST-GFL easily beats both these approaches: it exploits partial annotations much more effectively than the Gibbs parser and learns effectively without language universals.,NEG#POS,
2915,ConvexMST-GFL easily beats both these approaches: it exploits partial annotations much more effectively than the Gibbs parser and learns effectively without language universals.,772,7,139,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,"This shows the effectiveness of ConvexMST, but highlights its brittleness with respect to tagging errors: bad tags lead to poor guidance from language universals.",Annotator-sourced partial dependencies,The difference is especially marked for predicted POS tags: ConvexMST-GFL beats ConvexMST-UG by 4.3% for English and 17.1% for Spanish.,POS,
2916,The difference is especially marked for predicted POS tags: ConvexMST-GFL beats ConvexMST-UG by 4.3% for English and 17.1% for Spanish.,773,7,140,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,ConvexMST-GFL easily beats both these approaches: it exploits partial annotations much more effectively than the Gibbs parser and learns effectively without language universals.,Annotator-sourced partial dependencies,(Recall that there were 8 hours of annotation for English and 72 hours for Spanish.),POS,
2917,(Recall that there were 8 hours of annotation for English and 72 hours for Spanish.),774,7,141,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,The difference is especially marked for predicted POS tags: ConvexMST-GFL beats ConvexMST-UG by 4.3% for English and 17.1% for Spanish.,Annotator-sourced partial dependencies,The best method of all uses both partial annotations and language universals: ConvexMST-UG+GFL improves on ConvexMST-GFL for both languages and POS conditions.,NC,
2918,The best method of all uses both partial annotations and language universals: ConvexMST-UG+GFL improves on ConvexMST-GFL for both languages and POS conditions.,775,7,142,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,(Recall that there were 8 hours of annotation for English and 72 hours for Spanish.),Annotator-sourced partial dependencies,"The impact of the combination is greater for English, which has less GFL annotation.",POS,
2919,"The impact of the combination is greater for English, which has less GFL annotation.",776,7,143,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,The best method of all uses both partial annotations and language universals: ConvexMST-UG+GFL improves on ConvexMST-GFL for both languages and POS conditions.,Annotator-sourced partial dependencies,"Overall, these results show that this combination is robust to varying amounts of partial annotations: the UG constraints are strong on their own and provide a strong basis without annotations, they contribute when there are not many annotations available, and eventually become less essential (but remain unharmful) as more are provided.",POS,
2920,"Overall, these results show that this combination is robust to varying amounts of partial annotations: the UG constraints are strong on their own and provide a strong basis without annotations, they contribute when there are not many annotations available, and eventually become less essential (but remain unharmful) as more are provided.",777,7,144,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,"The impact of the combination is greater for English, which has less GFL annotation.",Annotator-sourced partial dependencies,It is important to recall that the GFL annotations have no specific conformity to the gold standards of either original corpus.,POS,
2921,It is important to recall that the GFL annotations have no specific conformity to the gold standards of either original corpus.,778,7,145,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,"Overall, these results show that this combination is robust to varying amounts of partial annotations: the UG constraints are strong on their own and provide a strong basis without annotations, they contribute when there are not many annotations available, and eventually become less essential (but remain unharmful) as more are provided.",Annotator-sourced partial dependencies,"Our goal was to understand the overall behavior of different methods given the same free-wheeling, diverse annotations; it is likely that higher numbers would have been achieved had we guided annotators to use corpus conventions, or used full annotations provided by our annotators as the evaluation set.",NC,
2922,"Our goal was to understand the overall behavior of different methods given the same free-wheeling, diverse annotations; it is likely that higher numbers would have been achieved had we guided annotators to use corpus conventions, or used full annotations provided by our annotators as the evaluation set.",779,7,146,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,It is important to recall that the GFL annotations have no specific conformity to the gold standards of either original corpus.,Annotator-sourced partial dependencies,"The former defeats the spirit of our exercise, and we did not have sufficient budget for the latter.",POS,
2923,"The former defeats the spirit of our exercise, and we did not have sufficient budget for the latter.",780,7,147,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,"Our goal was to understand the overall behavior of different methods given the same free-wheeling, diverse annotations; it is likely that higher numbers would have been achieved had we guided annotators to use corpus conventions, or used full annotations provided by our annotators as the evaluation set.",Annotator-sourced partial dependencies,"For Spanish, we also considered the performance of individual annotators alongside the full training set.",NEG,
2924,"For Spanish, we also considered the performance of individual annotators alongside the full training set.",781,7,148,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,"The former defeats the spirit of our exercise, and we did not have sufficient budget for the latter.",Annotator-sourced partial dependencies,The learning curves for individual annotators are shown in Figure 5.,NC,
2925,The learning curves for individual annotators are shown in Figure 5.,782,7,149,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,"For Spanish, we also considered the performance of individual annotators alongside the full training set.",Annotator-sourced partial dependencies,"There is substantial variation in the curves for the individual annotators; however, the curve based on the union of all annotations at each time step is smooth and is better than any individual past the three hour mark.",NC,
2926,"There is substantial variation in the curves for the individual annotators; however, the curve based on the union of all annotations at each time step is smooth and is better than any individual past the three hour mark.",783,7,150,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,The learning curves for individual annotators are shown in Figure 5.,Annotator-sourced partial dependencies,"One way to consider this is in terms of building an accurate parser quickly with multiple, diverse annotators, where wall clock time matters.",POS,
2927,"One way to consider this is in terms of building an accurate parser quickly with multiple, diverse annotators, where wall clock time matters.",784,7,151,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,"There is substantial variation in the curves for the individual annotators; however, the curve based on the union of all annotations at each time step is smooth and is better than any individual past the three hour mark.",Annotator-sourced partial dependencies,Another way is to consider robustness with respect to possibly bad annotators.,NC,
2928,Another way is to consider robustness with respect to possibly bad annotators.,785,7,152,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,"One way to consider this is in terms of building an accurate parser quickly with multiple, diverse annotators, where wall clock time matters.",Annotator-sourced partial dependencies,The next obvious steps would be to use active learning and to detect disagreement in annotators to either drop some or intervene improve their quality.,NC,
2929,The next obvious steps would be to use active learning and to detect disagreement in annotators to either drop some or intervene improve their quality.,786,7,153,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,Another way is to consider robustness with respect to possibly bad annotators.,Annotator-sourced partial dependencies,"(Again, keep in mind that we are considering a ""cold start"" to this process, so there can be no gold standard for checking annotator quality.)",PROSP,
2930,"(Again, keep in mind that we are considering a ""cold start"" to this process, so there can be no gold standard for checking annotator quality.)",787,7,154,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,The next obvious steps would be to use active learning and to detect disagreement in annotators to either drop some or intervene improve their quality.,Annotator-sourced partial dependencies,"Comparison to Full Annotation To this point, all performance comparisons have been between different parse feature sets; we have demonstrated that the GFL features are complimentary to the UG features, and that when standing alone the GFL features are stronger than the UG features.",NEG,
2931,"Comparison to Full Annotation To this point, all performance comparisons have been between different parse feature sets; we have demonstrated that the GFL features are complimentary to the UG features, and that when standing alone the GFL features are stronger than the UG features.",788,7,155,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,"(Again, keep in mind that we are considering a ""cold start"" to this process, so there can be no gold standard for checking annotator quality.)",Annotator-sourced partial dependencies,The question of whether it might be more effective to simply have annotators produce full annotations is not addressed by these comparisons.,POS,
2932,The question of whether it might be more effective to simply have annotators produce full annotations is not addressed by these comparisons.,789,7,156,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,"Comparison to Full Annotation To this point, all performance comparisons have been between different parse feature sets; we have demonstrated that the GFL features are complimentary to the UG features, and that when standing alone the GFL features are stronger than the UG features.",Annotator-sourced partial dependencies,"To answer this question, we had our most experienced annotator fully annotate the same section that the other annotators did partially.",NEG,
2933,"To answer this question, we had our most experienced annotator fully annotate the same section that the other annotators did partially.",790,7,157,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,The question of whether it might be more effective to simply have annotators produce full annotations is not addressed by these comparisons.,Annotator-sourced partial dependencies,Producing these full annotations required roughly 13 hours of time from the single expert annotator.,NC,
2934,Producing these full annotations required roughly 13 hours of time from the single expert annotator.,791,7,158,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,"To answer this question, we had our most experienced annotator fully annotate the same section that the other annotators did partially.",Annotator-sourced partial dependencies,"In comparison, the other annotators were able to partially annotate the same section in roughly two hours each -a total of 24 hours.",NC,
2935,"In comparison, the other annotators were able to partially annotate the same section in roughly two hours each -a total of 24 hours.",792,7,159,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,Producing these full annotations required roughly 13 hours of time from the single expert annotator.,Annotator-sourced partial dependencies,"However, the theoretical wall clock time of the group of annotators could be as low as two hours if the sessions were run in parallel.",NC,
2936,"However, the theoretical wall clock time of the group of annotators could be as low as two hours if the sessions were run in parallel.",793,7,160,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,"In comparison, the other annotators were able to partially annotate the same section in roughly two hours each -a total of 24 hours.",Annotator-sourced partial dependencies,These different training sets were once again used to train ConvexMST models that were evaluated on a held out test set.,POS,
2937,These different training sets were once again used to train ConvexMST models that were evaluated on a held out test set.,794,7,161,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,"However, the theoretical wall clock time of the group of annotators could be as low as two hours if the sessions were run in parallel.",Annotator-sourced partial dependencies,"Table 6 contains the results of this experiment, demonstrating that the group of inexperienced annotators producing partial annotations was able to achieve similar performance levels to the single annotator producing full annotations.",NC,
2938,"Table 6 contains the results of this experiment, demonstrating that the group of inexperienced annotators producing partial annotations was able to achieve similar performance levels to the single annotator producing full annotations.",795,7,162,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,These different training sets were once again used to train ConvexMST models that were evaluated on a held out test set.,Annotator-sourced partial dependencies,It should be noted that this comparison does not weight the results using the extrinsic costs associated with the production of the training data.,POS,
2939,It should be noted that this comparison does not weight the results using the extrinsic costs associated with the production of the training data.,796,7,163,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,"Table 6 contains the results of this experiment, demonstrating that the group of inexperienced annotators producing partial annotations was able to achieve similar performance levels to the single annotator producing full annotations.",Annotator-sourced partial dependencies,"In a real-world environment, the expert annotator would likely be more expensive than the inexperienced annotators, and possibly all of them combined (especially in a crowd-sourcing scenario).",NEG,
2940,"In a real-world environment, the expert annotator would likely be more expensive than the inexperienced annotators, and possibly all of them combined (especially in a crowd-sourcing scenario).",797,7,164,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,It should be noted that this comparison does not weight the results using the extrinsic costs associated with the production of the training data.,Annotator-sourced partial dependencies,This makes the performance per unit cost for partial annotators even higher than of these extrinsic cost effects.,NEG,
2941,This makes the performance per unit cost for partial annotators even higher than of these extrinsic cost effects.,798,7,165,Annotator-sourced partial dependencies,Annotator-sourced partial dependencies,"In a real-world environment, the expert annotator would likely be more expensive than the inexperienced annotators, and possibly all of them combined (especially in a crowd-sourcing scenario).",Longer Sentences,We also evaluated ConvexMST with longer sentences: those with 20 words or less.,NEG,
2942,We also evaluated ConvexMST with longer sentences: those with 20 words or less.,799,7,166,Longer Sentences,Annotator-sourced partial dependencies,This makes the performance per unit cost for partial annotators even higher than of these extrinsic cost effects.,Longer Sentences,"For this, the right-branching baseline is 25.8%.",NC,
2943,"For this, the right-branching baseline is 25.8%.",800,7,167,Longer Sentences,Longer Sentences,We also evaluated ConvexMST with longer sentences: those with 20 words or less.,Longer Sentences,"When using all the annotations on the common set for all annotators, the scores for ConvexMST with UG, GFL, and GFL+UG are 47.6%, 54.4%, and 55.3%, respectively.",NC,
2944,"When using all the annotations on the common set for all annotators, the scores for ConvexMST with UG, GFL, and GFL+UG are 47.6%, 54.4%, and 55.3%, respectively.",801,7,168,Longer Sentences,Longer Sentences,"For this, the right-branching baseline is 25.8%.",Longer Sentences,"The values are worse than for shorter sentences, as expected, but the pattern observed in Table 5 still holds: GFL annotations best UG alone, and their combination is the best of all.",POS,
2945,"The values are worse than for shorter sentences, as expected, but the pattern observed in Table 5 still holds: GFL annotations best UG alone, and their combination is the best of all.",802,7,169,Longer Sentences,Longer Sentences,"When using all the annotations on the common set for all annotators, the scores for ConvexMST with UG, GFL, and GFL+UG are 47.6%, 54.4%, and 55.3%, respectively.",Discussion & Error Analysis,POS-Tagging Impact We thought it important to consider imperfect POS-taggings because this entire framework is based off of the assumption that the user is working from essentially no pre-existing resources.,POS,
2946,POS-Tagging Impact We thought it important to consider imperfect POS-taggings because this entire framework is based off of the assumption that the user is working from essentially no pre-existing resources.,803,7,170,Discussion & Error Analysis,Longer Sentences,"The values are worse than for shorter sentences, as expected, but the pattern observed in Table 5 still holds: GFL annotations best UG alone, and their combination is the best of all.",Discussion & Error Analysis,"Assuming the availability of gold-standard POS tags is antithetical to this idea, and is one way in which direct supervision can show up in otherwise unsupervised (or indirectly supervised) systems.",NC,
2947,"Assuming the availability of gold-standard POS tags is antithetical to this idea, and is one way in which direct supervision can show up in otherwise unsupervised (or indirectly supervised) systems.",804,7,171,Discussion & Error Analysis,Discussion & Error Analysis,POS-Tagging Impact We thought it important to consider imperfect POS-taggings because this entire framework is based off of the assumption that the user is working from essentially no pre-existing resources.,Discussion & Error Analysis,"Many tagger errors are not likely to cause major problems during parsing; for instance mislabeling pronouns as nouns, or adverbs as adjectives, is unlikely to lead to major structural issues.",NC,
2948,"Many tagger errors are not likely to cause major problems during parsing; for instance mislabeling pronouns as nouns, or adverbs as adjectives, is unlikely to lead to major structural issues.",805,7,172,Discussion & Error Analysis,Discussion & Error Analysis,"Assuming the availability of gold-standard POS tags is antithetical to this idea, and is one way in which direct supervision can show up in otherwise unsupervised (or indirectly supervised) systems.",Discussion & Error Analysis,"However, more unlikely errors can cause more dramatic effects, as shown in Figure 6.",POS,
2949,"However, more unlikely errors can cause more dramatic effects, as shown in Figure 6.",806,7,173,Discussion & Error Analysis,Discussion & Error Analysis,"Many tagger errors are not likely to cause major problems during parsing; for instance mislabeling pronouns as nouns, or adverbs as adjectives, is unlikely to lead to major structural issues.",Discussion & Error Analysis,"Here, the phrase 'beating politically' (gold tags 'NOUN ADV') is mistagged as 'ADJ VERB', leading to the attachment of 'politically' to the root word and the reorganization of a substantial chunk of the sentence.",NEG,
2950,"Here, the phrase 'beating politically' (gold tags 'NOUN ADV') is mistagged as 'ADJ VERB', leading to the attachment of 'politically' to the root word and the reorganization of a substantial chunk of the sentence.",807,7,174,Discussion & Error Analysis,Discussion & Error Analysis,"However, more unlikely errors can cause more dramatic effects, as shown in Figure 6.",Discussion & Error Analysis,"Weighting Constraint Violations For feature sets with both GFL and UG-based constraints, a weighting factor can bias the parser towards being more likely to respect either GFL or UG constraints.",NC,
2951,"Weighting Constraint Violations For feature sets with both GFL and UG-based constraints, a weighting factor can bias the parser towards being more likely to respect either GFL or UG constraints.",808,7,175,Discussion & Error Analysis,Discussion & Error Analysis,"Here, the phrase 'beating politically' (gold tags 'NOUN ADV') is mistagged as 'ADJ VERB', leading to the attachment of 'politically' to the root word and the reorganization of a substantial chunk of the sentence.",Discussion & Error Analysis,"We experimented with this, and found that for the  datasets we considered, the best results were obtained when we weighted violations of GFL constraints as worse than violations of UG constraints.",NEG,
2952,"We experimented with this, and found that for the  datasets we considered, the best results were obtained when we weighted violations of GFL constraints as worse than violations of UG constraints.",809,7,176,Discussion & Error Analysis,Discussion & Error Analysis,"Weighting Constraint Violations For feature sets with both GFL and UG-based constraints, a weighting factor can bias the parser towards being more likely to respect either GFL or UG constraints.",Discussion & Error Analysis,"This result is not entirely unexpected given the relative performances of the constraints on their own, but it provides more evidence that direct supervision even in small amounts can beat indirect supervision.",POS,
2953,"This result is not entirely unexpected given the relative performances of the constraints on their own, but it provides more evidence that direct supervision even in small amounts can beat indirect supervision.",810,7,177,Discussion & Error Analysis,Discussion & Error Analysis,"We experimented with this, and found that for the  datasets we considered, the best results were obtained when we weighted violations of GFL constraints as worse than violations of UG constraints.",5,We have shown that human-sourced partial annotations can be exploited to learn effective dependency parsers in short period of time.,POS,
2954,We have shown that human-sourced partial annotations can be exploited to learn effective dependency parsers in short period of time.,811,7,178,5,Discussion & Error Analysis,"This result is not entirely unexpected given the relative performances of the constraints on their own, but it provides more evidence that direct supervision even in small amounts can beat indirect supervision.",5,"The ConvexMST method we adapt from Grave and Elhadad easily combines constraints from both language universals and partial annotations, providing greater robustness from starting annotation until one runs out of budget or time.",POS,
2955,"The ConvexMST method we adapt from Grave and Elhadad easily combines constraints from both language universals and partial annotations, providing greater robustness from starting annotation until one runs out of budget or time.",812,7,179,5,5,We have shown that human-sourced partial annotations can be exploited to learn effective dependency parsers in short period of time.,5,"We demonstrate this with actual annotations produced for English and Spanish, using annotators with a range of experience.",POS,
2956,"We demonstrate this with actual annotations produced for English and Spanish, using annotators with a range of experience.",813,7,180,5,5,"The ConvexMST method we adapt from Grave and Elhadad easily combines constraints from both language universals and partial annotations, providing greater robustness from starting annotation until one runs out of budget or time.",5,"Overall, we present a case for working in realistic settings by paying close attention the various sources of annotation and tracking the real costs associated with that supervision.",FACT,
2957,"Overall, we present a case for working in realistic settings by paying close attention the various sources of annotation and tracking the real costs associated with that supervision.",814,7,181,5,5,"We demonstrate this with actual annotations produced for English and Spanish, using annotators with a range of experience.",5,"We believe that overreliance on creeping supervision of this type may lead to an inaccurate picture of the cross-lingual and low-resource applicability of various models, and are encouraged by recent work on character-based models by Gillick et al.",FACT,
2958,"We believe that overreliance on creeping supervision of this type may lead to an inaccurate picture of the cross-lingual and low-resource applicability of various models, and are encouraged by recent work on character-based models by Gillick et al.",815,7,182,5,5,"Overall, we present a case for working in realistic settings by paying close attention the various sources of annotation and tracking the real costs associated with that supervision.",5,"(2015) and Ballesteros et al (2015), among others.",POS,
2959,"(2015) and Ballesteros et al (2015), among others.",816,7,183,5,5,"We believe that overreliance on creeping supervision of this type may lead to an inaccurate picture of the cross-lingual and low-resource applicability of various models, and are encouraged by recent work on character-based models by Gillick et al.",5,"Their work shows viable models can be produced without relying on having annotations a priori, but rather learning representations on the fly that need not conform to any one set of standards.",POS,
2960,"Their work shows viable models can be produced without relying on having annotations a priori, but rather learning representations on the fly that need not conform to any one set of standards.",817,7,184,5,5,"(2015) and Ballesteros et al (2015), among others.",,,NC,
2961,"  In this paper, we explore the use of convolutional networks (ConvNets) for the purpose of cognate identification.",818,8,0,abstract,,,abstract,We compare our architecture with binary classifiers based on string similarity measures on different language families.,FACT,
2962,We compare our architecture with binary classifiers based on string similarity measures on different language families.,819,8,1,abstract,abstract,"  In this paper, we explore the use of convolutional networks (ConvNets) for the purpose of cognate identification.",abstract,Our experiments show that convolutional networks achieve competitive results across concepts and across language families at the task of cognate identification.,FACT,
2963,Our experiments show that convolutional networks achieve competitive results across concepts and across language families at the task of cognate identification.,820,8,2,abstract,abstract,We compare our architecture with binary classifiers based on string similarity measures on different language families.,Introduction,Cognates are words that are known to have descended from a common ancestral language.,POS,
2964,Cognates are words that are known to have descended from a common ancestral language.,821,8,3,Introduction,abstract,Our experiments show that convolutional networks achieve competitive results across concepts and across language families at the task of cognate identification.,Introduction,"In historical linguistics, identification of cognates is an important step for positing relationships between languages.",NC,
2965,"In historical linguistics, identification of cognates is an important step for positing relationships between languages.",822,8,4,Introduction,Introduction,Cognates are words that are known to have descended from a common ancestral language.,Introduction,"Historical linguists apply the comparative method (Trask, 1996) for positing relationships between languages.",NC,
2966,"Historical linguists apply the comparative method (Trask, 1996) for positing relationships between languages.",823,8,5,Introduction,Introduction,"In historical linguistics, identification of cognates is an important step for positing relationships between languages.",Introduction,"In NLP, automatic identification of cognates is associated with the task of determining if two words are descended from a common ancestor or not.",NC,
2967,"In NLP, automatic identification of cognates is associated with the task of determining if two words are descended from a common ancestor or not.",824,8,6,Introduction,Introduction,"Historical linguists apply the comparative method (Trask, 1996) for positing relationships between languages.",Introduction,There are at least two ways to achieve automatic identification of cognates.,NC,
2968,There are at least two ways to achieve automatic identification of cognates.,825,8,7,Introduction,Introduction,"In NLP, automatic identification of cognates is associated with the task of determining if two words are descended from a common ancestor or not.",Introduction,"One way is to modify a well-known string alignment technique such as Longest Common Subsequence or Needleman-Wunsch algorithm (Needleman and Wunsch, 1970) to weigh the alignments differentially (Kondrak, 2001;List, 2012).",NC,
2969,"One way is to modify a well-known string alignment technique such as Longest Common Subsequence or Needleman-Wunsch algorithm (Needleman and Wunsch, 1970) to weigh the alignments differentially (Kondrak, 2001;List, 2012).",826,8,8,Introduction,Introduction,There are at least two ways to achieve automatic identification of cognates.,Introduction,The weights are determined through the linguistic knowledge of the sound changes that occurred in the language family.,NC,
2970,The weights are determined through the linguistic knowledge of the sound changes that occurred in the language family.,827,8,9,Introduction,Introduction,"One way is to modify a well-known string alignment technique such as Longest Common Subsequence or Needleman-Wunsch algorithm (Needleman and Wunsch, 1970) to weigh the alignments differentially (Kondrak, 2001;List, 2012).",Introduction,The second approach employs a machine learning perspective that is widely employed in NLP.,NC,
2971,The second approach employs a machine learning perspective that is widely employed in NLP.,828,8,10,Introduction,Introduction,The weights are determined through the linguistic knowledge of the sound changes that occurred in the language family.,Introduction,The cognate identification is achieved by training a linear classifier or a sequence labeler on a set of labeled positive and negative examples; and then employ the trained classifier to classify new word pairs.,NC,
2972,The cognate identification is achieved by training a linear classifier or a sequence labeler on a set of labeled positive and negative examples; and then employ the trained classifier to classify new word pairs.,829,8,11,Introduction,Introduction,The second approach employs a machine learning perspective that is widely employed in NLP.,Introduction,"The features for a classifier consist of word similarity measures based on number of shared bigrams, edit distance, and longest common subsequence (Hauer and Kondrak, 2011;Inkpen et al., 2005).",NC,
2973,"The features for a classifier consist of word similarity measures based on number of shared bigrams, edit distance, and longest common subsequence (Hauer and Kondrak, 2011;Inkpen et al., 2005).",830,8,12,Introduction,Introduction,The cognate identification is achieved by training a linear classifier or a sequence labeler on a set of labeled positive and negative examples; and then employ the trained classifier to classify new word pairs.,Introduction,The above procedures provide an estimate of the similarity between a pair of words and cannot directly be used to infer a phylogeny based on models of trait evolution.,NC,
2974,The above procedures provide an estimate of the similarity between a pair of words and cannot directly be used to infer a phylogeny based on models of trait evolution.,831,8,13,Introduction,Introduction,"The features for a classifier consist of word similarity measures based on number of shared bigrams, edit distance, and longest common subsequence (Hauer and Kondrak, 2011;Inkpen et al., 2005).",Introduction,The pairwise judgments have to be converted into multiple cognate judgments so that the multiple judgments can be supplied to a automatic tree building program for inferring a phylogeny for the languages under study.,NC,
2975,The pairwise judgments have to be converted into multiple cognate judgments so that the multiple judgments can be supplied to a automatic tree building program for inferring a phylogeny for the languages under study.,832,8,14,Introduction,Introduction,The above procedures provide an estimate of the similarity between a pair of words and cannot directly be used to infer a phylogeny based on models of trait evolution.,Introduction,"It has to be noted that the Indo-European dating studies (Bouckaert et al., 2012;Chang et al., 2015) employ human expert cognacy judgments for inferring phylogeny and dates of a very well-studied language family.",NC,
2976,"It has to be noted that the Indo-European dating studies (Bouckaert et al., 2012;Chang et al., 2015) employ human expert cognacy judgments for inferring phylogeny and dates of a very well-studied language family.",833,8,15,Introduction,Introduction,The pairwise judgments have to be converted into multiple cognate judgments so that the multiple judgments can be supplied to a automatic tree building program for inferring a phylogeny for the languages under study.,Introduction,"Hence, there is a need for developing automated cognate identification methods that can be applied to under-studied languages of the world.",NC,
2977,"Hence, there is a need for developing automated cognate identification methods that can be applied to under-studied languages of the world.",834,8,16,Introduction,Introduction,"It has to be noted that the Indo-European dating studies (Bouckaert et al., 2012;Chang et al., 2015) employ human expert cognacy judgments for inferring phylogeny and dates of a very well-studied language family.",Related work,"The earlier computational effort of (Jäger, 2013;Rama et al., 2013) employs Pointwise Mutual Information (PMI) to compute transition matrices between sounds.",NC,
2978,This article is the first to apply convolutional networks (ConvNets) to phonemes by treating each phoneme as a vector of binary valued phonetic features.,835,8,39,Convolutional networks,Related work,"All the above outlined approaches employ a scoring matrix that is derived automatically or manually; or, employ a SVM to train form similarity based features for the purpose of cognate identification.",Convolutional networks,"This approach has the advantage that it does not require explicit feature engineering, alignments, and a sound transition matrix.",FACT,
2979,"This approach has the advantage that it does not require explicit feature engineering, alignments, and a sound transition matrix.",836,8,40,Convolutional networks,Convolutional networks,This article is the first to apply convolutional networks (ConvNets) to phonemes by treating each phoneme as a vector of binary valued phonetic features.,Convolutional networks,The approach requires cognacy statements and phonetic descriptions of sounds used to transcribe the words.,NC,should we consider it a fact ?
2980,The approach requires cognacy statements and phonetic descriptions of sounds used to transcribe the words.,837,8,41,Convolutional networks,Convolutional networks,"This approach has the advantage that it does not require explicit feature engineering, alignments, and a sound transition matrix.",Convolutional networks,The cognacy statements can be obtained from etymological dictionaries and the quality of the phonemes can be obtained from Ladefoged and Maddieson (1998).,NC,
2981,The cognacy statements can be obtained from etymological dictionaries and the quality of the phonemes can be obtained from Ladefoged and Maddieson (1998).,838,8,42,Convolutional networks,Convolutional networks,The approach requires cognacy statements and phonetic descriptions of sounds used to transcribe the words.,Convolutional networks,Collobert et al.,NC,
2982,Collobert et al.,839,8,43,Convolutional networks,Convolutional networks,The cognacy statements can be obtained from etymological dictionaries and the quality of the phonemes can be obtained from Ladefoged and Maddieson (1998).,Convolutional networks,"(2011) proposed ConvNets for NLP tasks in 2011 and were since applied for sentence classification (Kim, 2014;Johnson and Zhang, 2015;Kalchbrenner et al., 2014;Zhang et al., 2015), part-of-speech tagging (Santos and Zadrozny, 2014), and information retrieval (Shen et al., 2014).",NC,
2983,"(2011) proposed ConvNets for NLP tasks in 2011 and were since applied for sentence classification (Kim, 2014;Johnson and Zhang, 2015;Kalchbrenner et al., 2014;Zhang et al., 2015), part-of-speech tagging (Santos and Zadrozny, 2014), and information retrieval (Shen et al., 2014).",840,8,44,Convolutional networks,Convolutional networks,Collobert et al.,Convolutional networks,Kim (2014) applied convolutional networks to pre-trained word embeddings in a sentence for the task of sentence classification.,NC,
2984,Kim (2014) applied convolutional networks to pre-trained word embeddings in a sentence for the task of sentence classification.,841,8,45,Convolutional networks,Convolutional networks,"(2011) proposed ConvNets for NLP tasks in 2011 and were since applied for sentence classification (Kim, 2014;Johnson and Zhang, 2015;Kalchbrenner et al., 2014;Zhang et al., 2015), part-of-speech tagging (Santos and Zadrozny, 2014), and information retrieval (Shen et al., 2014).",Convolutional networks,Johnson and Zhang (2015) train their convolutional network from scratch by using a one-hot vector for each word.,NC,
2985,Johnson and Zhang (2015) train their convolutional network from scratch by using a one-hot vector for each word.,842,8,46,Convolutional networks,Convolutional networks,Kim (2014) applied convolutional networks to pre-trained word embeddings in a sentence for the task of sentence classification.,Convolutional networks,The authors show that their convolutional network performs better than a SVM classifier trained on bag-of-words features.,NC,
2986,The authors show that their convolutional network performs better than a SVM classifier trained on bag-of-words features.,843,8,47,Convolutional networks,Convolutional networks,Johnson and Zhang (2015) train their convolutional network from scratch by using a one-hot vector for each word.,Convolutional networks,Santos and Zadrozny (2014) use character embeddings to train their POS-tagger.,NC,
2987,Santos and Zadrozny (2014) use character embeddings to train their POS-tagger.,844,8,48,Convolutional networks,Convolutional networks,The authors show that their convolutional network performs better than a SVM classifier trained on bag-of-words features.,Convolutional networks,"The authors find that the POS-tagger performs better than the accuracies reported in (Manning, 2011).",NC,
2988,"The authors find that the POS-tagger performs better than the accuracies reported in (Manning, 2011).",845,8,49,Convolutional networks,Convolutional networks,Santos and Zadrozny (2014) use character embeddings to train their POS-tagger.,Convolutional networks,"In a recent work, Zhang et al.",NC,
2989,"In a recent work, Zhang et al.",846,8,50,Convolutional networks,Convolutional networks,"The authors find that the POS-tagger performs better than the accuracies reported in (Manning, 2011).",Convolutional networks,(2015) treat documents as a sequence of characters and transform each document into a sequence of one-hot character vectors.,NC,
2990,(2015) treat documents as a sequence of characters and transform each document into a sequence of one-hot character vectors.,847,8,51,Convolutional networks,Convolutional networks,"In a recent work, Zhang et al.",Convolutional networks,The authors designed and trained two 9-layer convolutional networks for the purpose of sentiment classification.,NC,
2991,The authors designed and trained two 9-layer convolutional networks for the purpose of sentiment classification.,848,8,52,Convolutional networks,Convolutional networks,(2015) treat documents as a sequence of characters and transform each document into a sequence of one-hot character vectors.,Convolutional networks,The authors report competitive or state-of-the art performance on a wide range of benchmark sentiment classification datasets.,NC,
2992,The authors report competitive or state-of-the art performance on a wide range of benchmark sentiment classification datasets.,849,8,53,Convolutional networks,Convolutional networks,The authors designed and trained two 9-layer convolutional networks for the purpose of sentiment classification.,Character convolutional networks,Chopra et al.,NC,
2993,Chopra et al.,850,8,54,Character convolutional networks,Convolutional networks,The authors report competitive or state-of-the art performance on a wide range of benchmark sentiment classification datasets.,Character convolutional networks,( 2005) extended the traditional Con-vNets to classify if two images belong to the same person.,NC,
2994,( 2005) extended the traditional Con-vNets to classify if two images belong to the same person.,851,8,55,Character convolutional networks,Character convolutional networks,Chopra et al.,Character convolutional networks,These ConvNets are known as Siamese Networks (inspired from Siamese twins) and share weights for independent but identical layers of convolutional networks.,NC,
2995,These ConvNets are known as Siamese Networks (inspired from Siamese twins) and share weights for independent but identical layers of convolutional networks.,852,8,56,Character convolutional networks,Character convolutional networks,( 2005) extended the traditional Con-vNets to classify if two images belong to the same person.,Character convolutional networks,"Siamese networks and their variants have been employed for identifying if two images are from the same person or different persons (Zagoruyko and Komodakis, 2015); and for recognizing if two speech segments belong to the same word class (Kamper et al., 2015).",NC,
2996,"Siamese networks and their variants have been employed for identifying if two images are from the same person or different persons (Zagoruyko and Komodakis, 2015); and for recognizing if two speech segments belong to the same word class (Kamper et al., 2015).",853,8,57,Character convolutional networks,Character convolutional networks,These ConvNets are known as Siamese Networks (inspired from Siamese twins) and share weights for independent but identical layers of convolutional networks.,Word as image,Historical linguists perform cognate identification based on regular correspondences which are described as changes in phonetic features of phonemes.,NC,
2997,Historical linguists perform cognate identification based on regular correspondences which are described as changes in phonetic features of phonemes.,854,8,58,Word as image,Character convolutional networks,"Siamese networks and their variants have been employed for identifying if two images are from the same person or different persons (Zagoruyko and Komodakis, 2015); and for recognizing if two speech segments belong to the same word class (Kamper et al., 2015).",Word as image,"For instance, Grimm's law b h ∼ b is described as loss of aspiration; p ∼ f is described as change from plosives to fricatives; and devoicing d ∼ t in English ten ∼ Latin decem.",NC,
2998,"For instance, Grimm's law b h ∼ b is described as loss of aspiration; p ∼ f is described as change from plosives to fricatives; and devoicing d ∼ t in English ten ∼ Latin decem.",855,8,59,Word as image,Word as image,Historical linguists perform cognate identification based on regular correspondences which are described as changes in phonetic features of phonemes.,Word as image,Learning criteria for cognacy through phonetic features from a set of training examples implies that there is no need for explicit alignment and design/learning of sound scoring matrices.,NC,
2999,Learning criteria for cognacy through phonetic features from a set of training examples implies that there is no need for explicit alignment and design/learning of sound scoring matrices.,856,8,60,Word as image,Word as image,"For instance, Grimm's law b h ∼ b is described as loss of aspiration; p ∼ f is described as change from plosives to fricatives; and devoicing d ∼ t in English ten ∼ Latin decem.",Word as image,"In this article, we represent each phoneme as a binaryvalued vector of phonetic features and then perform convolution on the two-dimensional matrix.",NC,
3000,"In this article, we represent each phoneme as a binaryvalued vector of phonetic features and then perform convolution on the two-dimensional matrix.",857,8,61,Word as image,Word as image,Learning criteria for cognacy through phonetic features from a set of training examples implies that there is no need for explicit alignment and design/learning of sound scoring matrices.,Siamese network,"Intuitively, a network should learn a similarity function such that words that diverged due to accountable sound shifts are placed close to one another than two words that are not cognates.",NC,
3001,"Intuitively, a network should learn a similarity function such that words that diverged due to accountable sound shifts are placed close to one another than two words that are not cognates.",858,8,62,Siamese network,Word as image,"In this article, we represent each phoneme as a binaryvalued vector of phonetic features and then perform convolution on the two-dimensional matrix.",Siamese network,"And, Siamese networks are suitable for this task since, they learn a similarity function that has a higher similarity between cognates as compared to noncognates.",NC,
3002,"And, Siamese networks are suitable for this task since, they learn a similarity function that has a higher similarity between cognates as compared to noncognates.",859,8,63,Siamese network,Siamese network,"Intuitively, a network should learn a similarity function such that words that diverged due to accountable sound shifts are placed close to one another than two words that are not cognates.",Siamese network,The weight tying ensures that two cognate words sharing similar phonetic features in a local context tend to be get higher weights than words that are not cognate.,NC,
3003,The weight tying ensures that two cognate words sharing similar phonetic features in a local context tend to be get higher weights than words that are not cognate.,860,8,64,Siamese network,Siamese network,"And, Siamese networks are suitable for this task since, they learn a similarity function that has a higher similarity between cognates as compared to noncognates.",Phoneme vectorization,"In this article, we work with the ASJP alphabet (Brown et al., 2013).",NC,
3004,"In this article, we work with the ASJP alphabet (Brown et al., 2013).",861,8,65,Phoneme vectorization,Siamese network,The weight tying ensures that two cognate words sharing similar phonetic features in a local context tend to be get higher weights than words that are not cognate.,Phoneme vectorization,The ASJP alphabet is coarser than IPA but is designed with the aim to capture highly frequent sounds in the world's languages.,NC,
3005,The ASJP alphabet is coarser than IPA but is designed with the aim to capture highly frequent sounds in the world's languages.,862,8,66,Phoneme vectorization,Phoneme vectorization,"In this article, we work with the ASJP alphabet (Brown et al., 2013).",Phoneme vectorization,"The ASJP database has word lists for 60% of the world's languages but only has cognate judgments for some selected families (Wichmann and Holman, 2013).",NC,
3006,"The ASJP database has word lists for 60% of the world's languages but only has cognate judgments for some selected families (Wichmann and Holman, 2013).",863,8,67,Phoneme vectorization,Phoneme vectorization,The ASJP alphabet is coarser than IPA but is designed with the aim to capture highly frequent sounds in the world's languages.,Phoneme vectorization,We composed a binary vector for each phoneme based on the description given in table 1.,NC,
3007,We composed a binary vector for each phoneme based on the description given in table 1.,864,8,68,Phoneme vectorization,Phoneme vectorization,"The ASJP database has word lists for 60% of the world's languages but only has cognate judgments for some selected families (Wichmann and Holman, 2013).",Phoneme vectorization,"In total, there are 16 binary valued features.",NC,
3008,"In total, there are 16 binary valued features.",865,8,69,Phoneme vectorization,Phoneme vectorization,We composed a binary vector for each phoneme based on the description given in table 1.,Phoneme vectorization,We also reduced all vowels to a single vowel that has a value of 1 for voicing feature and 0 for the rest of the features.,NC,
3009,We also reduced all vowels to a single vowel that has a value of 1 for voicing feature and 0 for the rest of the features.,866,8,70,Phoneme vectorization,Phoneme vectorization,"In total, there are 16 binary valued features.",Phoneme vectorization,"The main motivation for such decision is that vowels are diachronically unstable than consonants (Kessler, 2007).",NC,
3010,"The main motivation for such decision is that vowels are diachronically unstable than consonants (Kessler, 2007).",867,8,71,Phoneme vectorization,Phoneme vectorization,We also reduced all vowels to a single vowel that has a value of 1 for voicing feature and 0 for the rest of the features.,Phoneme vectorization,"A word such as ""fat"" would be represented as 3×16 matrix where each column provides a binary value for the phonetic feature (cf.",NC,
3011,"A word such as ""fat"" would be represented as 3×16 matrix where each column provides a binary value for the phonetic feature (cf.",868,8,72,Phoneme vectorization,Phoneme vectorization,"The main motivation for such decision is that vowels are diachronically unstable than consonants (Kessler, 2007).",Phoneme vectorization,Table 1: ASJP consonants.,NC,
3012,Table 1: ASJP consonants.,869,8,73,Phoneme vectorization,Phoneme vectorization,"A word such as ""fat"" would be represented as 3×16 matrix where each column provides a binary value for the phonetic feature (cf.",Phoneme vectorization,ASJP has 6 vowels which we collapsed to a single vowel V.,NC,
3013,ASJP has 6 vowels which we collapsed to a single vowel V.,870,8,74,Phoneme vectorization,Phoneme vectorization,Table 1: ASJP consonants.,ConvNet Models,"In this subsection, we describe the ConvNet models used in our experiments.",NC,
3014,"Until now, each word is treated as a separate input.",871,8,82,2-channel Convnet,ConvNet Models,1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 V 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0,2-channel Convnet,Zagoruyko and Komodakis (2015) introduced a 2-channel architecture which treats a pair of image patches as a 2-channel image.,NC,
3015,Zagoruyko and Komodakis (2015) introduced a 2-channel architecture which treats a pair of image patches as a 2-channel image.,872,8,83,2-channel Convnet,2-channel Convnet,"Until now, each word is treated as a separate input.",2-channel Convnet,This can also be applied to words.,NC,
3016,This can also be applied to words.,873,8,84,2-channel Convnet,2-channel Convnet,Zagoruyko and Komodakis (2015) introduced a 2-channel architecture which treats a pair of image patches as a 2-channel image.,2-channel Convnet,"The 2-channel ConvNet has two convolutional layers, a maxpooling layer, and a fully connected layer with 8 units.",NC,
3017,"The 2-channel ConvNet has two convolutional layers, a maxpooling layer, and a fully connected layer with 8 units.",874,8,85,2-channel Convnet,2-channel Convnet,This can also be applied to words.,2-channel Convnet,The number of feature maps in each convolutional layer is fixed at 10 with a kernel size of 2 × 3.,NC,
3018,The number of feature maps in each convolutional layer is fixed at 10 with a kernel size of 2 × 3.,875,8,86,2-channel Convnet,2-channel Convnet,"The 2-channel ConvNet has two convolutional layers, a maxpooling layer, and a fully connected layer with 8 units.",2-channel Convnet,The max-pooling layer halves the output of the previous convolutional layer.,NC,
3019,The max-pooling layer halves the output of the previous convolutional layer.,876,8,87,2-channel Convnet,2-channel Convnet,The number of feature maps in each convolutional layer is fixed at 10 with a kernel size of 2 × 3.,2-channel Convnet,"We also inserted a dropout layer with 0.5 probability (Srivastava et al., 2014) after a fully-connected layer to avoid over-fitting.",NC,
3020,"We also inserted a dropout layer with 0.5 probability (Srivastava et al., 2014) after a fully-connected layer to avoid over-fitting.",877,8,88,2-channel Convnet,2-channel Convnet,The max-pooling layer halves the output of the previous convolutional layer.,2-channel Convnet,The convolutional layers were trained with ReLU non-linearity.,NC,
3021,The convolutional layers were trained with ReLU non-linearity.,878,8,89,2-channel Convnet,2-channel Convnet,"We also inserted a dropout layer with 0.5 probability (Srivastava et al., 2014) after a fully-connected layer to avoid over-fitting.",2-channel Convnet,We zero-padded each word to obtain a length of 10 for all the words to apply the filter equally about a word.,NC,
3022,We zero-padded each word to obtain a length of 10 for all the words to apply the filter equally about a word.,879,8,90,2-channel Convnet,2-channel Convnet,The convolutional layers were trained with ReLU non-linearity.,2-channel Convnet,"We used adadelta optimizer (Zeiler, 2012) with learning rate of 1.0, ρ = 0.95, and = 10 -6 .",NC,
3023,"We used adadelta optimizer (Zeiler, 2012) with learning rate of 1.0, ρ = 0.95, and = 10 -6 .",880,8,91,2-channel Convnet,2-channel Convnet,We zero-padded each word to obtain a length of 10 for all the words to apply the filter equally about a word.,2-channel Convnet,We fixed the mini-batch size to 128 in all our experiments.,NC,
3024,We fixed the mini-batch size to 128 in all our experiments.,881,8,92,2-channel Convnet,2-channel Convnet,"We used adadelta optimizer (Zeiler, 2012) with learning rate of 1.0, ρ = 0.95, and = 10 -6 .",2-channel Convnet,"We experimented with different batch sizes ([32, 64, 128, 256]) and did not observe any significant deviation in the validation loss.",NC,
3025,"We experimented with different batch sizes ([32, 64, 128, 256]) and did not observe any significant deviation in the validation loss.",882,8,93,2-channel Convnet,2-channel Convnet,We fixed the mini-batch size to 128 in all our experiments.,2-channel Convnet,"Both, Manhattan and 2-stream ConvNets were trained using the log-loss function.",NC,
3026,"Both, Manhattan and 2-stream ConvNets were trained using the log-loss function.",883,8,94,2-channel Convnet,2-channel Convnet,"We experimented with different batch sizes ([32, 64, 128, 256]) and did not observe any significant deviation in the validation loss.",2-channel Convnet,Both our architectures are relatively shallow (3) as compared to the text classification architecture of Zhang et al.,NC,
3027,Both our architectures are relatively shallow (3) as compared to the text classification architecture of Zhang et al.,884,8,95,2-channel Convnet,2-channel Convnet,"Both, Manhattan and 2-stream ConvNets were trained using the log-loss function.",2-channel Convnet,"We trained all our networks using Keras (Chollet, 2015) and Theano (Bergstra et al., 2010).",NC,
3028,"We trained all our networks using Keras (Chollet, 2015) and Theano (Bergstra et al., 2010).",885,8,96,2-channel Convnet,2-channel Convnet,Both our architectures are relatively shallow (3) as compared to the text classification architecture of Zhang et al.,Comparison methods,We compare the ConvNet architectures with SVM classifiers trained with different string similarities as features.,NC,
3029,We compare the ConvNet architectures with SVM classifiers trained with different string similarities as features.,886,8,97,Comparison methods,2-channel Convnet,"We trained all our networks using Keras (Chollet, 2015) and Theano (Bergstra et al., 2010).",Comparison methods,"Other sound classes/alphabets Apart from ASJP alphabet, there are two other alphabets that have been designed by historical linguists for the purpose of modeling sound change.",NC,
3030,"Other sound classes/alphabets Apart from ASJP alphabet, there are two other alphabets that have been designed by historical linguists for the purpose of modeling sound change.",887,8,98,Comparison methods,Comparison methods,We compare the ConvNet architectures with SVM classifiers trained with different string similarities as features.,Comparison methods,"As mentioned before, the main idea behind the design of sound classes is to discourage transitions between partic-ular classes of sounds but allow transitions within a sound class.",NC,
3031,"As mentioned before, the main idea behind the design of sound classes is to discourage transitions between partic-ular classes of sounds but allow transitions within a sound class.",888,8,99,Comparison methods,Comparison methods,"Other sound classes/alphabets Apart from ASJP alphabet, there are two other alphabets that have been designed by historical linguists for the purpose of modeling sound change.",Comparison methods,Dolgopolsky (1986) proposed a ten sound class system based on the empirical data of 140 languages.,NC,
3032,Dolgopolsky (1986) proposed a ten sound class system based on the empirical data of 140 languages.,889,8,100,Comparison methods,Comparison methods,"As mentioned before, the main idea behind the design of sound classes is to discourage transitions between partic-ular classes of sounds but allow transitions within a sound class.",Comparison methods,"SCA alphabet (List, 2012) has a size of 25 and attempts to address some issues with the ASJP alphabet (lack of tones) and also extend Dolgopolsky's sound classes based on evidence from more number of languages.",NC,
3033,"SCA alphabet (List, 2012) has a size of 25 and attempts to address some issues with the ASJP alphabet (lack of tones) and also extend Dolgopolsky's sound classes based on evidence from more number of languages.",890,8,101,Comparison methods,Comparison methods,Dolgopolsky (1986) proposed a ten sound class system based on the empirical data of 140 languages.,Comparison methods,Orthographic measures as features We converted all the datasets into all the three sound classes and computed the following string similarity scores: • Edit distance.,NC,
3034,Orthographic measures as features We converted all the datasets into all the three sound classes and computed the following string similarity scores: • Edit distance.,891,8,102,Comparison methods,Comparison methods,"SCA alphabet (List, 2012) has a size of 25 and attempts to address some issues with the ASJP alphabet (lack of tones) and also extend Dolgopolsky's sound classes based on evidence from more number of languages.",Comparison methods,• Common number of bigrams.,NC,
3035,• Common number of bigrams.,892,8,103,Comparison methods,Comparison methods,Orthographic measures as features We converted all the datasets into all the three sound classes and computed the following string similarity scores: • Edit distance.,Comparison methods,• Length of the longest common subsequence.,NC,
3036,• Length of the longest common subsequence.,893,8,104,Comparison methods,Comparison methods,• Common number of bigrams.,Comparison methods,• Length of longest common prefix.,NC,
3037,• Length of longest common prefix.,894,8,105,Comparison methods,Comparison methods,• Length of the longest common subsequence.,Comparison methods,• Common number of trigrams.,NC,
3038,• Common number of trigrams.,895,8,106,Comparison methods,Comparison methods,• Length of longest common prefix.,Comparison methods,"• Global alignment based on Needlman-Wunch algorithm (Needleman and Wunsch, 1970).",NC,
3039,"• Global alignment based on Needlman-Wunch algorithm (Needleman and Wunsch, 1970).",896,8,107,Comparison methods,Comparison methods,• Common number of trigrams.,Comparison methods,"• Local alignment score based on Smith-Waterman algorithm (Smith and Waterman, 1981).",NC,
3040,"• Local alignment score based on Smith-Waterman algorithm (Smith and Waterman, 1981).",897,8,108,Comparison methods,Comparison methods,"• Global alignment based on Needlman-Wunch algorithm (Needleman and Wunsch, 1970).",Comparison methods,"• Semi-global alignment score is a compromise between global and local alignments (Durbin et al., 2002).2 • Common number of skipped bigrams (XDICE).",NC,
3041,"• Semi-global alignment score is a compromise between global and local alignments (Durbin et al., 2002).2 • Common number of skipped bigrams (XDICE).",898,8,109,Comparison methods,Comparison methods,"• Local alignment score based on Smith-Waterman algorithm (Smith and Waterman, 1981).",Comparison methods,"• A positional extension of XDICE known as XXDICE (Brew and McKelvie, 1996).",NC,
3042,"• A positional extension of XDICE known as XXDICE (Brew and McKelvie, 1996).",899,8,110,Comparison methods,Comparison methods,"• Semi-global alignment score is a compromise between global and local alignments (Durbin et al., 2002).2 • Common number of skipped bigrams (XDICE).",Comparison methods,Pair-wise Mutual Information (PMI) We also computed a PMI score for a pair of ASJP transcribed words using the PMI scoring matrix developed by Jäger (2013).,NC,
3043,Pair-wise Mutual Information (PMI) We also computed a PMI score for a pair of ASJP transcribed words using the PMI scoring matrix developed by Jäger (2013).,900,8,111,Comparison methods,Comparison methods,"• A positional extension of XDICE known as XXDICE (Brew and McKelvie, 1996).",Comparison methods,This system is referred to as PMI system.,NC,
3044,This system is referred to as PMI system.,901,8,112,Comparison methods,Comparison methods,Pair-wise Mutual Information (PMI) We also computed a PMI score for a pair of ASJP transcribed words using the PMI scoring matrix developed by Jäger (2013).,Comparison methods,We included length of each word and the absolute difference in length between the words as features for both the Orthographic and PMI systems.,NC,
3045,We included length of each word and the absolute difference in length between the words as features for both the Orthographic and PMI systems.,902,8,113,Comparison methods,Comparison methods,This system is referred to as PMI system.,Comparison methods,"The sound class orthographic scores system attempts to combine the previous cognate identification systems developed by (Inkpen et al., 2005;Hauer and Kondrak, 2011) and the insights from applying string similarities to sound classes for language comparison (Kessler, 2007).",NC,
3046,"The sound class orthographic scores system attempts to combine the previous cognate identification systems developed by (Inkpen et al., 2005;Hauer and Kondrak, 2011) and the insights from applying string similarities to sound classes for language comparison (Kessler, 2007).",903,8,114,Comparison methods,Comparison methods,We included length of each word and the absolute difference in length between the words as features for both the Orthographic and PMI systems.,Datasets,"In this section, we describe the datasets used in our experiments.",NC,
3047,The Manhattan ConvNet competes with PMI and orthographic models at cross-concept cognate identification task.,904,8,141,Discussion,Cross-Family experiments,The results of our experiments are given in table 5,Discussion,The Manhattan ConvNet performs better than PMI and orthographic models in terms of overall accuracy in all the three language families.,POS,
3048,The Manhattan ConvNet performs better than PMI and orthographic models in terms of overall accuracy in all the three language families.,905,8,142,Discussion,Discussion,The Manhattan ConvNet competes with PMI and orthographic models at cross-concept cognate identification task.,Discussion,"In terms of averaged F-scores, Manhattan ConvNet performs slightly better than orthographic model and only performs worse than the other models at Austronesian language family.",POS,
3049,"In terms of averaged F-scores, Manhattan ConvNet performs slightly better than orthographic model and only performs worse than the other models at Austronesian language family.",906,8,143,Discussion,Discussion,The Manhattan ConvNet performs better than PMI and orthographic models in terms of overall accuracy in all the three language families.,Discussion,The Manhattan ConvNet shows mixed performance at the task of cross-family cognate identification.,POS,
3050,The Manhattan ConvNet shows mixed performance at the task of cross-family cognate identification.,907,8,144,Discussion,Discussion,"In terms of averaged F-scores, Manhattan ConvNet performs slightly better than orthographic model and only performs worse than the other models at Austronesian language family.",Discussion,The Manhattan ConvNet does not turn up as the best system across all the evaluation metrics in a single language family.,POS,
3051,The Manhattan ConvNet does not turn up as the best system across all the evaluation metrics in a single language family.,908,8,145,Discussion,Discussion,The Manhattan ConvNet shows mixed performance at the task of cross-family cognate identification.,Discussion,The ConvNet performs better than PMI but is not as good as Orthographic measures at Indo-European language family.,POS,exemple de résultat négatif (ici catégorisé en POS)
3052,The ConvNet performs better than PMI but is not as good as Orthographic measures at Indo-European language family.,909,8,146,Discussion,Discussion,The Manhattan ConvNet does not turn up as the best system across all the evaluation metrics in a single language family.,Discussion,"In terms of accuracies, the ConvNet comes closer to PMI than the orthographic system.",POS,
3053,"In terms of accuracies, the ConvNet comes closer to PMI than the orthographic system.",910,8,147,Discussion,Discussion,The ConvNet performs better than PMI but is not as good as Orthographic measures at Indo-European language family.,Discussion,These experiments suggest that ConvNets can compete with a classifier trained on different orthographic measures and different sound classes.,POS,
3054,These experiments suggest that ConvNets can compete with a classifier trained on different orthographic measures and different sound classes.,911,8,148,Discussion,Discussion,"In terms of accuracies, the ConvNet comes closer to PMI than the orthographic system.",Discussion,ConvNets can also compete with a data driven method like PMI which was trained in an EM-like fashion on millions of word pairs.,POS,
3055,ConvNets can also compete with a data driven method like PMI which was trained in an EM-like fashion on millions of word pairs.,912,8,149,Discussion,Discussion,These experiments suggest that ConvNets can compete with a classifier trained on different orthographic measures and different sound classes.,Discussion,ConvNets can certainly perform better than a classifier trained on word similarity scores at cross-concept experiments.,POS,
3056,ConvNets can certainly perform better than a classifier trained on word similarity scores at cross-concept experiments.,913,8,150,Discussion,Discussion,ConvNets can also compete with a data driven method like PMI which was trained in an EM-like fashion on millions of word pairs.,Discussion,The Orthographic system and PMI system show similar performance at the Austronesian crossconcept task.,POS,
3057,The Orthographic system and PMI system show similar performance at the Austronesian crossconcept task.,914,8,151,Discussion,Discussion,ConvNets can certainly perform better than a classifier trained on word similarity scores at cross-concept experiments.,Discussion,"However, ConvNets do not perform as well as orthographic and PMI systems.",POS,
3058,"However, ConvNets do not perform as well as orthographic and PMI systems.",915,8,152,Discussion,Discussion,The Orthographic system and PMI system show similar performance at the Austronesian crossconcept task.,Discussion,The reason for this could be due to the differential transcriptions in the database.,POS,exemple de résultat négatif (ici catégorisé comme POS)
3059,The reason for this could be due to the differential transcriptions in the database.,916,8,153,Discussion,Discussion,"However, ConvNets do not perform as well as orthographic and PMI systems.",Conclusion,"In this article, we explored the use of phonetic feature convolutional networks for the task of pairwise cognate identification.",POS,explication de résultat
3060,"In this article, we explored the use of phonetic feature convolutional networks for the task of pairwise cognate identification.",917,8,154,Conclusion,Discussion,The reason for this could be due to the differential transcriptions in the database.,Conclusion,Our experiments with convolutional networks show that phonetic features can be directly used for classifying if two words are related or not.,FACT,
3061,Our experiments with convolutional networks show that phonetic features can be directly used for classifying if two words are related or not.,918,8,155,Conclusion,Conclusion,"In this article, we explored the use of phonetic feature convolutional networks for the task of pairwise cognate identification.",Conclusion,"In the future, we intend to work directly with speech recordings and include language relatedness information into ConvNets to improve the performance.",POS,
3062,"In the future, we intend to work directly with speech recordings and include language relatedness information into ConvNets to improve the performance.",919,8,156,Conclusion,Conclusion,Our experiments with convolutional networks show that phonetic features can be directly used for classifying if two words are related or not.,Conclusion,We are currently working towards building a larger database of word lists in IPA transcription.,PROSP,
3063,We are currently working towards building a larger database of word lists in IPA transcription.,920,8,157,Conclusion,Conclusion,"In the future, we intend to work directly with speech recordings and include language relatedness information into ConvNets to improve the performance.",,,PROSP,PROSP mais déjà commencé dans le présent
3064,"  The task of information retrieval is an important component of many natural language processing systems, such as open domain question answering.",921,9,0,abstract,,,abstract,"While traditional methods were based on hand-crafted features, continuous representations based on neural networks recently obtained competitive results.",NC,
3065,"While traditional methods were based on hand-crafted features, continuous representations based on neural networks recently obtained competitive results.",922,9,1,abstract,abstract,"  The task of information retrieval is an important component of many natural language processing systems, such as open domain question answering.",abstract,"A challenge of using such methods is to obtain supervised data to train the retriever model, corresponding to pairs of query and support documents.",NC,
3066,"A challenge of using such methods is to obtain supervised data to train the retriever model, corresponding to pairs of query and support documents.",923,9,2,abstract,abstract,"While traditional methods were based on hand-crafted features, continuous representations based on neural networks recently obtained competitive results.",abstract,"In this paper, we propose a technique to learn retriever models for downstream tasks, inspired by knowledge distillation, and which does not require annotated pairs of query and documents.",NC,
3067,"In this paper, we propose a technique to learn retriever models for downstream tasks, inspired by knowledge distillation, and which does not require annotated pairs of query and documents.",924,9,3,abstract,abstract,"A challenge of using such methods is to obtain supervised data to train the retriever model, corresponding to pairs of query and support documents.",abstract,"Our approach leverages attention scores of a reader model, used to solve the task based on retrieved documents, to obtain synthetic labels for the retriever.",FACT,
3068,"Our approach leverages attention scores of a reader model, used to solve the task based on retrieved documents, to obtain synthetic labels for the retriever.",925,9,4,abstract,abstract,"In this paper, we propose a technique to learn retriever models for downstream tasks, inspired by knowledge distillation, and which does not require annotated pairs of query and documents.",abstract,"We evaluate our method on question answering, obtaining state-of-the-art results.",FACT,
3069,"We evaluate our method on question answering, obtaining state-of-the-art results.",926,9,5,abstract,abstract,"Our approach leverages attention scores of a reader model, used to solve the task based on retrieved documents, to obtain synthetic labels for the retriever.",INTRODUCTION,"Information retrieval is an important component for many natural language processing tasks, such as question answering (Voorhees et al., 1999) or fact checking (Thorne et al., 2018).",POS,
3070,"Information retrieval is an important component for many natural language processing tasks, such as question answering (Voorhees et al., 1999) or fact checking (Thorne et al., 2018).",927,9,6,INTRODUCTION,abstract,"We evaluate our method on question answering, obtaining state-of-the-art results.",INTRODUCTION,"For example, many real world question answering systems start by retrieving a set of support documents from a large source of knowledge such as Wikipedia.",NC,
3071,"For example, many real world question answering systems start by retrieving a set of support documents from a large source of knowledge such as Wikipedia.",928,9,7,INTRODUCTION,INTRODUCTION,"Information retrieval is an important component for many natural language processing tasks, such as question answering (Voorhees et al., 1999) or fact checking (Thorne et al., 2018).",INTRODUCTION,"Then, a finer-grained model processes these documents to extract the answer.",NC,
3072,"Then, a finer-grained model processes these documents to extract the answer.",929,9,8,INTRODUCTION,INTRODUCTION,"For example, many real world question answering systems start by retrieving a set of support documents from a large source of knowledge such as Wikipedia.",INTRODUCTION,"Traditionally, information retrieval systems were based on hand-crafted sparse representations of text documents, such as TF-IDF or BM25 (Jones, 1972;Robertson et al., 1995).",NC,
3073,"Traditionally, information retrieval systems were based on hand-crafted sparse representations of text documents, such as TF-IDF or BM25 (Jones, 1972;Robertson et al., 1995).",930,9,9,INTRODUCTION,INTRODUCTION,"Then, a finer-grained model processes these documents to extract the answer.",INTRODUCTION,"Recently, methods based on dense vectors and machine learning have shown promising results (Karpukhin et al., 2020;Khattab et al., 2020).",NC,
3074,"Recently, methods based on dense vectors and machine learning have shown promising results (Karpukhin et al., 2020;Khattab et al., 2020).",931,9,10,INTRODUCTION,INTRODUCTION,"Traditionally, information retrieval systems were based on hand-crafted sparse representations of text documents, such as TF-IDF or BM25 (Jones, 1972;Robertson et al., 1995).",INTRODUCTION,"Deep neural networks based on pre-training, such as BERT (Devlin et al., 2019), have been used to encode documents into fixed-size representations.",NC,
3075,"Deep neural networks based on pre-training, such as BERT (Devlin et al., 2019), have been used to encode documents into fixed-size representations.",932,9,11,INTRODUCTION,INTRODUCTION,"Recently, methods based on dense vectors and machine learning have shown promising results (Karpukhin et al., 2020;Khattab et al., 2020).",INTRODUCTION,"These representations are then queried using approximate nearest neighbors (Johnson et al., 2019).",NC,
3076,"These representations are then queried using approximate nearest neighbors (Johnson et al., 2019).",933,9,12,INTRODUCTION,INTRODUCTION,"Deep neural networks based on pre-training, such as BERT (Devlin et al., 2019), have been used to encode documents into fixed-size representations.",INTRODUCTION,These techniques have lead to improved performance on various question answering tasks.,NC,
3077,These techniques have lead to improved performance on various question answering tasks.,934,9,13,INTRODUCTION,INTRODUCTION,"These representations are then queried using approximate nearest neighbors (Johnson et al., 2019).",INTRODUCTION,A challenge of applying machine learning to information retrieval is to obtain training data for the retriever.,NC,
3078,A challenge of applying machine learning to information retrieval is to obtain training data for the retriever.,935,9,14,INTRODUCTION,INTRODUCTION,These techniques have lead to improved performance on various question answering tasks.,INTRODUCTION,"To train such models, one needs pairs of queries and the corresponding list of documents that contains the information corresponding to the queries.",NC,
3079,"To train such models, one needs pairs of queries and the corresponding list of documents that contains the information corresponding to the queries.",936,9,15,INTRODUCTION,INTRODUCTION,A challenge of applying machine learning to information retrieval is to obtain training data for the retriever.,INTRODUCTION,"Unfortunately, hand-labeling data to that end is time consuming, and many datasets and applications lack such annotations.",NC,
3080,"Unfortunately, hand-labeling data to that end is time consuming, and many datasets and applications lack such annotations.",937,9,16,INTRODUCTION,INTRODUCTION,"To train such models, one needs pairs of queries and the corresponding list of documents that contains the information corresponding to the queries.",INTRODUCTION,"An alternative approach is to resort to heuristics, or weakly supervised learning, for example by considering that all documents containing the answer are positive examples.",NC,
3081,"An alternative approach is to resort to heuristics, or weakly supervised learning, for example by considering that all documents containing the answer are positive examples.",938,9,17,INTRODUCTION,INTRODUCTION,"Unfortunately, hand-labeling data to that end is time consuming, and many datasets and applications lack such annotations.",INTRODUCTION,"However, these approaches suffer from the following limitations.",NC,
3082,"However, these approaches suffer from the following limitations.",939,9,18,INTRODUCTION,INTRODUCTION,"An alternative approach is to resort to heuristics, or weakly supervised learning, for example by considering that all documents containing the answer are positive examples.",INTRODUCTION,"First, frequent answers or entities might lead to false positive examples.",NC,
3083,"First, frequent answers or entities might lead to false positive examples.",940,9,19,INTRODUCTION,INTRODUCTION,"However, these approaches suffer from the following limitations.",INTRODUCTION,"As an example, consider the question ""where was Ada Lovelace born?"".",NC,
3084,"As an example, consider the question ""where was Ada Lovelace born?"".",941,9,20,INTRODUCTION,INTRODUCTION,"First, frequent answers or entities might lead to false positive examples.",INTRODUCTION,"The sentence ""Ada Lovelace died in 1852 in London"" would be considered as a positive example, because it contains the answer ""London"".",NC,
3085,"The sentence ""Ada Lovelace died in 1852 in London"" would be considered as a positive example, because it contains the answer ""London"".",942,9,21,INTRODUCTION,INTRODUCTION,"As an example, consider the question ""where was Ada Lovelace born?"".",INTRODUCTION,"A second limitation is that for some tasks, such as fact checking or long form question answering, such heuristics might not be applicable directly.",NC,
3086,"A second limitation is that for some tasks, such as fact checking or long form question answering, such heuristics might not be applicable directly.",943,9,22,INTRODUCTION,INTRODUCTION,"The sentence ""Ada Lovelace died in 1852 in London"" would be considered as a positive example, because it contains the answer ""London"".",INTRODUCTION,"In this paper, we propose a procedure to learn retriever systems without strong supervision in the form of pairs of queries and documents.",NC,
3087,"In this paper, we propose a procedure to learn retriever systems without strong supervision in the form of pairs of queries and documents.",944,9,23,INTRODUCTION,INTRODUCTION,"A second limitation is that for some tasks, such as fact checking or long form question answering, such heuristics might not be applicable directly.",INTRODUCTION,"Following previous work (Chen et al., 2017), our approach uses two models: the first one retrieves documents from a large source of knowledge (the retriever), the second one processes the support documents to solve the task (the reader).",FACT,
3088,"Following previous work (Chen et al., 2017), our approach uses two models: the first one retrieves documents from a large source of knowledge (the retriever), the second one processes the support documents to solve the task (the reader).",945,9,24,INTRODUCTION,INTRODUCTION,"In this paper, we propose a procedure to learn retriever systems without strong supervision in the form of pairs of queries and documents.",INTRODUCTION,"Our method is inspired by knowledge distillation (Hinton et al., 2015), and uses the reader model to obtain synthetic labels to train the retriever model.",NC,
3089,"Our method is inspired by knowledge distillation (Hinton et al., 2015), and uses the reader model to obtain synthetic labels to train the retriever model.",946,9,25,INTRODUCTION,INTRODUCTION,"Following previous work (Chen et al., 2017), our approach uses two models: the first one retrieves documents from a large source of knowledge (the retriever), the second one processes the support documents to solve the task (the reader).",INTRODUCTION,"More precisely, we use a sequence-to-sequence model as the reader, and use the attention activations over the input documents as synthetic labels to train the retriever.",NC,
3090,"More precisely, we use a sequence-to-sequence model as the reader, and use the attention activations over the input documents as synthetic labels to train the retriever.",947,9,26,INTRODUCTION,INTRODUCTION,"Our method is inspired by knowledge distillation (Hinton et al., 2015), and uses the reader model to obtain synthetic labels to train the retriever model.",INTRODUCTION,"Said otherwise, we assume that attention activations are a good proxy for the relevance of documents.",NC,
3091,"Said otherwise, we assume that attention activations are a good proxy for the relevance of documents.",948,9,27,INTRODUCTION,INTRODUCTION,"More precisely, we use a sequence-to-sequence model as the reader, and use the attention activations over the input documents as synthetic labels to train the retriever.",INTRODUCTION,We then train the retriever to reproduce the ranking of documents corresponding to that metric.,POS,
3092,We then train the retriever to reproduce the ranking of documents corresponding to that metric.,949,9,28,INTRODUCTION,INTRODUCTION,"Said otherwise, we assume that attention activations are a good proxy for the relevance of documents.",INTRODUCTION,"We make the following contributions: • First, we show that attention scores from a sequence-to-sequence reader model are a good measure of document relevance (Sec.",NC,
3093,"We make the following contributions: • First, we show that attention scores from a sequence-to-sequence reader model are a good measure of document relevance (Sec.",950,9,29,INTRODUCTION,INTRODUCTION,We then train the retriever to reproduce the ranking of documents corresponding to that metric.,INTRODUCTION,"3.2) ; • Second, inspired by knowledge distillation, we propose to iteratively train the retriever from these activations, and compare different loss functions (Sec.",POS,
3094,"3.2) ; • Second, inspired by knowledge distillation, we propose to iteratively train the retriever from these activations, and compare different loss functions (Sec.",951,9,30,INTRODUCTION,INTRODUCTION,"We make the following contributions: • First, we show that attention scores from a sequence-to-sequence reader model are a good measure of document relevance (Sec.",INTRODUCTION,"3.4) ; • Finally, we evaluate our method on three question-answering benchmarks, obtaining stateof-the-art results (Sec.",FACT,
3095,"3.4) ; • Finally, we evaluate our method on three question-answering benchmarks, obtaining stateof-the-art results (Sec.",952,9,31,INTRODUCTION,INTRODUCTION,"3.2) ; • Second, inspired by knowledge distillation, we propose to iteratively train the retriever from these activations, and compare different loss functions (Sec.",INTRODUCTION,Our code is available at: github.com/facebookresearch/FiD.,POS,
3096,Our code is available at: github.com/facebookresearch/FiD.,953,9,32,INTRODUCTION,INTRODUCTION,"3.4) ; • Finally, we evaluate our method on three question-answering benchmarks, obtaining stateof-the-art results (Sec.",RELATED WORK,We briefly review information retrieval based on machine learning.,FACT,
3097,"In Table 1, we report the performance of our approach for different number of self-training iterations.",954,9,199,RESULTS,TECHNICAL DETAILS,More details on the hyperparameters and the training procedure are reported in Appendix A.2.,RESULTS,"Generally, we observe that the accuracy of our system increases with the number of iterations, obtaining strong performance after a few iterations.",NC,
3098,"Generally, we observe that the accuracy of our system increases with the number of iterations, obtaining strong performance after a few iterations.",955,9,200,RESULTS,RESULTS,"In Table 1, we report the performance of our approach for different number of self-training iterations.",RESULTS,"Interestingly, while the initial performance with documents retrieved with BERT is very poor, our method still reach competitive scores on TriviaQA, and to a lesser extent, NaturalQuestions.",POS,
3099,"Interestingly, while the initial performance with documents retrieved with BERT is very poor, our method still reach competitive scores on TriviaQA, and to a lesser extent, NaturalQuestions.",956,9,201,RESULTS,RESULTS,"Generally, we observe that the accuracy of our system increases with the number of iterations, obtaining strong performance after a few iterations.",RESULTS,"However, a second observation is that the quality of the initial document sets plays an important role on the performance of the end system.",POS,
3100,"However, a second observation is that the quality of the initial document sets plays an important role on the performance of the end system.",957,9,202,RESULTS,RESULTS,"Interestingly, while the initial performance with documents retrieved with BERT is very poor, our method still reach competitive scores on TriviaQA, and to a lesser extent, NaturalQuestions.",RESULTS,"Indeed, we observe that starting the procedure from BM25 documents, which are higher quality as indicated by the performance of the system at iteration 0, leads to stronger results than using BERT documents.",POS,
3101,"Indeed, we observe that starting the procedure from BM25 documents, which are higher quality as indicated by the performance of the system at iteration 0, leads to stronger results than using BERT documents.",958,9,203,RESULTS,RESULTS,"However, a second observation is that the quality of the initial document sets plays an important role on the performance of the end system.",RESULTS,"An interesting research question would be to explore pre-training of the initial BERT model for retrieval, for example by using the inverse cloze task.",POS,
3102,"An interesting research question would be to explore pre-training of the initial BERT model for retrieval, for example by using the inverse cloze task.",959,9,204,RESULTS,RESULTS,"Indeed, we observe that starting the procedure from BM25 documents, which are higher quality as indicated by the performance of the system at iteration 0, leads to stronger results than using BERT documents.",RESULTS,"In Table 2, we report the performance of our approach, as well as existing state-of-the-art systems on TriviaQA and NaturalQuestions.",PROSP,
3103,"In Table 2, we report the performance of our approach, as well as existing state-of-the-art systems on TriviaQA and NaturalQuestions.",960,9,205,RESULTS,RESULTS,"An interesting research question would be to explore pre-training of the initial BERT model for retrieval, for example by using the inverse cloze task.",RESULTS,"In addition to initializing our method with documents retrieved with BM25 and BERT, we also train a system by starting from DPR documents.",NC,
3104,"In addition to initializing our method with documents retrieved with BM25 and BERT, we also train a system by starting from DPR documents.",961,9,206,RESULTS,RESULTS,"In Table 2, we report the performance of our approach, as well as existing state-of-the-art systems on TriviaQA and NaturalQuestions.",RESULTS,"First, we observe that our method improve the performance over the state-of-the-art, even when starting from BM25 documents.",NC,
3105,"First, we observe that our method improve the performance over the state-of-the-art, even when starting from BM25 documents.",962,9,207,RESULTS,RESULTS,"In addition to initializing our method with documents retrieved with BM25 and BERT, we also train a system by starting from DPR documents.",RESULTS,This validates our assumption that it is possible to obtain strong retrievers without the need of supervision for the documents.,POS,
3106,This validates our assumption that it is possible to obtain strong retrievers without the need of supervision for the documents.,963,9,208,RESULTS,RESULTS,"First, we observe that our method improve the performance over the state-of-the-art, even when starting from BM25 documents.",RESULTS,"Second, when starting from DPR passages, our method leads to a +4.5 EM improvement on TriviaQA and +2.3 EM improvement on NaturalQuestions when the final evaluation is carried out with a large reader.",POS,
3107,"Second, when starting from DPR passages, our method leads to a +4.5 EM improvement on TriviaQA and +2.3 EM improvement on NaturalQuestions when the final evaluation is carried out with a large reader.",964,9,209,RESULTS,RESULTS,This validates our assumption that it is possible to obtain strong retrievers without the need of supervision for the documents.,RESULTS,In Table 3 we report retrieval results on the test set depending on the initial passages and compare to the state-of-the-art.,POS,
3108,In Table 3 we report retrieval results on the test set depending on the initial passages and compare to the state-of-the-art.,965,9,210,RESULTS,RESULTS,"Second, when starting from DPR passages, our method leads to a +4.5 EM improvement on TriviaQA and +2.3 EM improvement on NaturalQuestions when the final evaluation is carried out with a large reader.",RESULTS,Published as a conference paper at ICLR 2021,NC,
3109,Published as a conference paper at ICLR 2021,966,9,211,RESULTS,RESULTS,In Table 3 we report retrieval results on the test set depending on the initial passages and compare to the state-of-the-art.,NaturalQuestions,"TriviaQA R@20 R@100 R@20 R@100 DPR (Karpukhin et al., 2020) 79.4 86.0 79.4 85.0 ANCE (Xiong et al.)",NC,
3110,"TriviaQA R@20 R@100 R@20 R@100 DPR (Karpukhin et al., 2020) 79.4 86.0 79.4 85.0 ANCE (Xiong et al.)",967,9,212,NaturalQuestions,RESULTS,Published as a conference paper at ICLR 2021,NaturalQuestions,"82 In Table 4, we report the performance of our method on the NarrativeQA dataset.",NC,
3111,"82 In Table 4, we report the performance of our method on the NarrativeQA dataset.",968,9,213,NaturalQuestions,NaturalQuestions,"TriviaQA R@20 R@100 R@20 R@100 DPR (Karpukhin et al., 2020) 79.4 86.0 79.4 85.0 ANCE (Xiong et al.)",NaturalQuestions,"We use the setting where the knowledge source corresponds to the whole document, and in particular, we do not use the summary.",NC,
3112,"We use the setting where the knowledge source corresponds to the whole document, and in particular, we do not use the summary.",969,9,214,NaturalQuestions,NaturalQuestions,"82 In Table 4, we report the performance of our method on the NarrativeQA dataset.",NaturalQuestions,We compare our results to the best ones reported in the original paper for this setting.,NC,
3113,We compare our results to the best ones reported in the original paper for this setting.,970,9,215,NaturalQuestions,NaturalQuestions,"We use the setting where the knowledge source corresponds to the whole document, and in particular, we do not use the summary.",NaturalQuestions,"Similar to results obtained on NaturalQuestions and TriviaQA, we observe that training the retriever by using the attention scores of the reader leads to improvements, compared to the BM25 baseline.",NC,
3114,"Similar to results obtained on NaturalQuestions and TriviaQA, we observe that training the retriever by using the attention scores of the reader leads to improvements, compared to the BM25 baseline.",971,9,216,NaturalQuestions,NaturalQuestions,We compare our results to the best ones reported in the original paper for this setting.,ABLATIONS,"In this section, we investigate design choices regarding two key elements of our approach: the training objective and the aggregation of cross-attention scores.",POS,
3115,"In this section, we investigate design choices regarding two key elements of our approach: the training objective and the aggregation of cross-attention scores.",972,9,217,ABLATIONS,NaturalQuestions,"Similar to results obtained on NaturalQuestions and TriviaQA, we observe that training the retriever by using the attention scores of the reader leads to improvements, compared to the BM25 baseline.",ABLATIONS,"For all experiments, we consider a simplified experimental setting: a single training iteration is performed on NaturalQuestions, starting from BM25 passages.",NC,
3116,"For all experiments, we consider a simplified experimental setting: a single training iteration is performed on NaturalQuestions, starting from BM25 passages.",973,9,218,ABLATIONS,ABLATIONS,"In this section, we investigate design choices regarding two key elements of our approach: the training objective and the aggregation of cross-attention scores.",TRAINING OBJECTIVES,In Table 5 we report the performance of our model trained with the different training objectives described in Sec.,NC,
3117,"In Section 4 the cross-attention scores α are aggregated in a specific way, in order to obtain a single scalar used to train the retriever.",974,9,222,HOW TO AGGREGATE CROSS-ATTENTION SCORES?,TRAINING OBJECTIVES,Method R@5 R@20 R@100 Dev EM We report all the metrics on the validation set.,HOW TO AGGREGATE CROSS-ATTENTION SCORES?,"Formally let us denote by α i,j,k,h the cross-attention scores between token i of the output and token j of the input, for the k-th layer and h-th head.",NC,
3118,"Formally let us denote by α i,j,k,h the cross-attention scores between token i of the output and token j of the input, for the k-th layer and h-th head.",975,9,223,HOW TO AGGREGATE CROSS-ATTENTION SCORES?,HOW TO AGGREGATE CROSS-ATTENTION SCORES?,"In Section 4 the cross-attention scores α are aggregated in a specific way, in order to obtain a single scalar used to train the retriever.",HOW TO AGGREGATE CROSS-ATTENTION SCORES?,"Then, the scores G q,p for p ∈ D q used in Section 4 are computed as follows: G q,p = mean j,k,h α 0,j,k,h , where j describes the input tokens corresponding to p. In Table 6 we explore alternatives to this choice by considering different aggregation schemes.",NC,
3119,"Then, the scores G q,p for p ∈ D q used in Section 4 are computed as follows: G q,p = mean j,k,h α 0,j,k,h , where j describes the input tokens corresponding to p. In Table 6 we explore alternatives to this choice by considering different aggregation schemes.",976,9,224,HOW TO AGGREGATE CROSS-ATTENTION SCORES?,HOW TO AGGREGATE CROSS-ATTENTION SCORES?,"Formally let us denote by α i,j,k,h the cross-attention scores between token i of the output and token j of the input, for the k-th layer and h-th head.",HOW TO AGGREGATE CROSS-ATTENTION SCORES?,"In particular, we consider (1) taking the max over the input tokens corresponding to passage p instead of the average, (2) taking the average over the output tokens instead of taking the score of the first token, (3) taking the mean over the last six layers instead of all the layers, (4) taking the max over the layers instead of the average, (5) taking the max over the heads instead of the average.",NC,
3120,"In particular, we consider (1) taking the max over the input tokens corresponding to passage p instead of the average, (2) taking the average over the output tokens instead of taking the score of the first token, (3) taking the mean over the last six layers instead of all the layers, (4) taking the max over the layers instead of the average, (5) taking the max over the heads instead of the average.",977,9,225,HOW TO AGGREGATE CROSS-ATTENTION SCORES?,HOW TO AGGREGATE CROSS-ATTENTION SCORES?,"Then, the scores G q,p for p ∈ D q used in Section 4 are computed as follows: G q,p = mean j,k,h α 0,j,k,h , where j describes the input tokens corresponding to p. In Table 6 we explore alternatives to this choice by considering different aggregation schemes.",HOW TO AGGREGATE CROSS-ATTENTION SCORES?,"We observe that the performance of our approach is relatively stable to the choice of aggregation, and that the best result is obtained by averaging, except over the output tokens where it is best to only consider the first token.",NC,
3121,"We observe that the performance of our approach is relatively stable to the choice of aggregation, and that the best result is obtained by averaging, except over the output tokens where it is best to only consider the first token.",978,9,226,HOW TO AGGREGATE CROSS-ATTENTION SCORES?,HOW TO AGGREGATE CROSS-ATTENTION SCORES?,"In particular, we consider (1) taking the max over the input tokens corresponding to passage p instead of the average, (2) taking the average over the output tokens instead of taking the score of the first token, (3) taking the mean over the last six layers instead of all the layers, (4) taking the max over the layers instead of the average, (5) taking the max over the heads instead of the average.",HOW TO AGGREGATE CROSS-ATTENTION SCORES?,"Method R@5 R@20 R@100 Dev EM (0) mean The index i corresponds to output tokens, j corresponds to input tokens of a given passage, h to heads and k to layers of the decoder.",POS,
3122,"Method R@5 R@20 R@100 Dev EM (0) mean The index i corresponds to output tokens, j corresponds to input tokens of a given passage, h to heads and k to layers of the decoder.",979,9,227,HOW TO AGGREGATE CROSS-ATTENTION SCORES?,HOW TO AGGREGATE CROSS-ATTENTION SCORES?,"We observe that the performance of our approach is relatively stable to the choice of aggregation, and that the best result is obtained by averaging, except over the output tokens where it is best to only consider the first token.",HOW TO AGGREGATE CROSS-ATTENTION SCORES?,We report all metrics on the validation set.,NC,
3123,We report all metrics on the validation set.,980,9,228,HOW TO AGGREGATE CROSS-ATTENTION SCORES?,HOW TO AGGREGATE CROSS-ATTENTION SCORES?,"Method R@5 R@20 R@100 Dev EM (0) mean The index i corresponds to output tokens, j corresponds to input tokens of a given passage, h to heads and k to layers of the decoder.",CONCLUSION,"In this paper, we introduce a method to train an information retrieval module for downstream tasks, without using pairs of queries and documents as annotations.",NC,
3124,"In this paper, we introduce a method to train an information retrieval module for downstream tasks, without using pairs of queries and documents as annotations.",981,9,229,CONCLUSION,HOW TO AGGREGATE CROSS-ATTENTION SCORES?,We report all metrics on the validation set.,CONCLUSION,"Our approach is inspired by knowledge distillation, where the retriever module corresponds to the student model and the reader module corresponds to the teacher model.",FACT,
3125,"Our approach is inspired by knowledge distillation, where the retriever module corresponds to the student model and the reader module corresponds to the teacher model.",982,9,230,CONCLUSION,CONCLUSION,"In this paper, we introduce a method to train an information retrieval module for downstream tasks, without using pairs of queries and documents as annotations.",CONCLUSION,"In particular, we use the cross-attention scores, from a sequenceto-sequence reader, to obtain synthetic targets for the retriever.",NC,
3126,"In particular, we use the cross-attention scores, from a sequenceto-sequence reader, to obtain synthetic targets for the retriever.",983,9,231,CONCLUSION,CONCLUSION,"Our approach is inspired by knowledge distillation, where the retriever module corresponds to the student model and the reader module corresponds to the teacher model.",CONCLUSION,"We compare different ways to aggregate the scores, as well as different training objectives to learn the retriever.",NC,
3127,"We compare different ways to aggregate the scores, as well as different training objectives to learn the retriever.",984,9,232,CONCLUSION,CONCLUSION,"In particular, we use the cross-attention scores, from a sequenceto-sequence reader, to obtain synthetic targets for the retriever.",CONCLUSION,"We show that iteratively training the reader and the retriever leads to better performance, and obtain state-of-the-art performance on competitive question answering benchmarks.",NC,
3128,"We show that iteratively training the reader and the retriever leads to better performance, and obtain state-of-the-art performance on competitive question answering benchmarks.",985,9,233,CONCLUSION,CONCLUSION,"We compare different ways to aggregate the scores, as well as different training objectives to learn the retriever.",CONCLUSION,"In the future, we would like to explore better pre-training strategies for the retriever module, as well as better scoring functions for the retriever.",POS,
3129,"In the future, we would like to explore better pre-training strategies for the retriever module, as well as better scoring functions for the retriever.",986,9,234,CONCLUSION,CONCLUSION,"We show that iteratively training the reader and the retriever leads to better performance, and obtain state-of-the-art performance on competitive question answering benchmarks.",,,PROSP,
