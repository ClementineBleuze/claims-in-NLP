{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, \"../\") \n",
    "from utils.ClaimDB import ClaimDB\n",
    "from utils.Paper import Paper\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/cdb_IRC.pkl\", \"rb\") as f:\n",
    "    cdb = pickle.load(f)\n",
    "\n",
    "corpus_ACL, corpus_arxiv = cdb.corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noisy data: wrong language (so)',\n",
       " 'Noisy data: wrong language (it)',\n",
       " 'Noisy data: wrong language (pl)',\n",
       " 'Not following IRC structure',\n",
       " 'Noisy data: wrong language (hu)',\n",
       " 'Too many candidate sentences (more than Q3 + 1.5*IQR = 237.0)',\n",
       " 'Noisy data: wrong language (sl)',\n",
       " 'Too old (before 1986)',\n",
       " 'Noisy data: wrong language (nl)',\n",
       " 'Noisy data: wrong language (sk)',\n",
       " 'Noisy data: wrong language (vi)',\n",
       " 'Noisy data: wrong language (sw)',\n",
       " 'Parsing error: no abstract found',\n",
       " 'Noisy data: wrong language (bn)',\n",
       " 'Noisy data: wrong language (id)',\n",
       " 'Noisy data: wrong language (zh-tw)',\n",
       " 'Noisy data: wrong language (de)',\n",
       " 'Noisy data: wrong language (hr)',\n",
       " 'Noisy data: wrong language (ja)',\n",
       " 'Noisy data: wrong language (pt)',\n",
       " 'Noisy data: wrong language (no)',\n",
       " 'Noisy data: wrong language (hi)',\n",
       " 'Noisy data: wrong language (ro)',\n",
       " 'Noisy data: wrong language (lt)',\n",
       " 'Noisy data: wrong language (tr)',\n",
       " 'Noisy data: wrong language (sv)',\n",
       " 'Noisy data: wrong language (sq)',\n",
       " 'Noisy data: wrong language (da)',\n",
       " 'Noisy data: wrong language (cs)',\n",
       " 'parsing error: not enough paper content found (<2 distinct sections)',\n",
       " 'Noisy data: wrong language (et)',\n",
       " 'Noisy data: wrong language (fr)',\n",
       " 'Noisy data: wrong language (af)',\n",
       " 'Noisy data: wrong language (fi)',\n",
       " 'Noisy data: wrong language (ru)',\n",
       " 'Parsing error: XML file not well formed',\n",
       " 'Not enough candidate sentences (less than 20)',\n",
       " 'Noisy data: wrong language (es)',\n",
       " 'Noisy data: wrong language (zh-cn)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set([p.init_error for p in corpus_ACL.papers_with_errors]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57954\n",
      "29952\n"
     ]
    }
   ],
   "source": [
    "papers_ACL = [p for p in corpus_ACL.papers]\n",
    "papers_ACL.extend([p for p in corpus_ACL.papers_with_errors if p.init_error == \"Not following IRC structure\"])\n",
    "print(len(papers_ACL))\n",
    "\n",
    "papers_arxiv = [p for p in corpus_arxiv.papers]\n",
    "papers_arxiv.extend([p for p in corpus_arxiv.papers_with_errors if p.init_error == \"Not following IRC structure\"])\n",
    "print(len(papers_arxiv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "def parse_sections(xml_path):\n",
    "\n",
    "    with open(xml_path, \"r\", encoding = \"utf-8\") as f:\n",
    "        xml = f.read()\n",
    "\n",
    "    # Remove all ref tags but keep their content (<ref>content</ref> -> content)\n",
    "    ref_pattern = re.compile(r\"<ref.*?>(.*?)</ref>\")\n",
    "    content = re.sub(ref_pattern, r\"\\1\", xml)\n",
    "\n",
    "    root = ET.fromstring(content)\n",
    "    sections = {}\n",
    "    nb_sections = 0\n",
    "\n",
    "    for child in root[1][0]: # root.text.body\n",
    "            # check the <div> (sections identified by grobid) because they indicate the sections of the paper (but also figures or notes)\n",
    "            if \"div\" in child.tag:\n",
    "                if len(child) > 0: # if not empty\n",
    "                    header, n, head_n = child[0].text, None, None\n",
    "\n",
    "                    # we do not want to keep the figures and tables\n",
    "                    if not header.lower().startswith(\"figure\") and not header.lower().startswith(\"table\"):\n",
    "\n",
    "                        # extract the textual content of the section\n",
    "                        if len(child) > 0 :\n",
    "                            text = \"\\n\".join([Paper.clean_text(c.text) for c in child[1:]])\n",
    "                            \n",
    "                            # in case the section header is too long, we consider it as part of the content\n",
    "                            if not Paper.is_acceptable_section_header(header):\n",
    "                                if Paper.get_alpha_numerical_ratio(header) > 0.5:\n",
    "\n",
    "                                    header = \"unidentified-section\"\n",
    "\n",
    "\n",
    "                        # check if the section if numbered\n",
    "                        if \"n\" in list(child[0].attrib):\n",
    "                            n = child[0].attrib[\"n\"]\n",
    "                            # check if this section is actually a subsection\n",
    "                            head_n = re.search(re.compile(\"(.*)\\.\\d\"), n)\n",
    "                            if head_n:\n",
    "                                head_n = head_n.group(1)\n",
    "                        \n",
    "                        # update the sections oranisation\n",
    "                        sections[nb_sections] = {\"n\": n, \"header\": header, \"head_n\": head_n}\n",
    "                        nb_sections += 1\n",
    "\n",
    "    return sections\n",
    "\n",
    "def reorder_section_hierarchy(sections):\n",
    "\n",
    "    # initialize section hierarchy with abstract\n",
    "    d = {0: {\"header\" : \"abstract\", \"subsections\" : {}}}\n",
    "    i = 1\n",
    "\n",
    "    # add the other sections\n",
    "    for _, s in sections.items():\n",
    "        \n",
    "        if s[\"head_n\"] == None:\n",
    "\n",
    "            if s[\"n\"] != None or s[\"header\"] != \"unidentified-section\":\n",
    "                d[i] = {\"header\" : s[\"header\"],\n",
    "                        \"n\" : s[\"n\"],\n",
    "                        \"subsections\": {}}\n",
    "                i += 1\n",
    "            \n",
    "            else:\n",
    "                j = len(d[i-1][\"subsections\"])\n",
    "\n",
    "                if j > 0:\n",
    "                    k = len(d[i-1][\"subsections\"][j-1][\"subsections\"])\n",
    "                    if k > 0:\n",
    "                        d[i-1][\"subsections\"][j-1][\"subsections\"][k] = {\"header\" : s[\"header\"], \"n\": s[\"n\"], \"subsections\" : {}}\n",
    "                    else:\n",
    "                        d[i-1][\"subsections\"][j] = {\"header\" : s[\"header\"], \"n\": s[\"n\"], \"subsections\" : {}}\n",
    "                else:\n",
    "                    d[i-1][\"subsections\"][j] = {\"header\" : s[\"header\"], \"n\": s[\"n\"], \"subsections\" : {}}\n",
    "        \n",
    "        else:\n",
    "            j = len(d[i-1][\"subsections\"])\n",
    "            d[i-1][\"subsections\"][j] = {\"header\" : s[\"header\"], \"n\": s[\"n\"], \"subsections\" : {}}\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'n': '1', 'header': 'Introduction', 'head_n': None},\n",
       " 1: {'n': '2', 'header': 'Related work', 'head_n': None},\n",
       " 2: {'n': '2.1', 'header': 'Unsupervised sentence embeddings', 'head_n': '2'},\n",
       " 3: {'n': '2.2', 'header': 'Supervised sentence embeddings', 'head_n': '2'},\n",
       " 4: {'n': '2.3', 'header': 'Language models', 'head_n': '2'},\n",
       " 5: {'n': '2.4',\n",
       "  'header': 'Evaluation of sentence embedding models',\n",
       "  'head_n': '2'},\n",
       " 6: {'n': '3.1',\n",
       "  'header': 'Multiple Choice Question Answering (MCQA)',\n",
       "  'head_n': '3'},\n",
       " 7: {'n': '3.2',\n",
       "  'header': 'Multiple choice next sentence prediction (NSP)',\n",
       "  'head_n': '3'},\n",
       " 8: {'n': '3.3', 'header': 'Paraphrase identification (PI)', 'head_n': '3'},\n",
       " 9: {'n': '3.4', 'header': 'Dataset statistics', 'head_n': '3'},\n",
       " 10: {'n': '4', 'header': 'Methods', 'head_n': None},\n",
       " 11: {'n': '4.1', 'header': 'Unsupervised approach', 'head_n': '4'},\n",
       " 12: {'n': '4.2', 'header': 'Supervised approach', 'head_n': '4'},\n",
       " 13: {'n': '5.2', 'header': 'ELMo', 'head_n': '5'},\n",
       " 14: {'n': '5.3', 'header': 'BERT', 'head_n': '5'},\n",
       " 15: {'n': '6', 'header': 'Conclusion', 'head_n': None}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = [p for p in papers_arxiv if \"Russian NLU\" in p.title][0]\n",
    "p.sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'header': 'abstract', 'subsections': {}},\n",
       " 1: {'header': 'Introduction', 'n': '1', 'subsections': {}},\n",
       " 2: {'header': 'Related work',\n",
       "  'n': '2',\n",
       "  'subsections': {0: {'header': 'Unsupervised sentence embeddings',\n",
       "    'n': '2.1',\n",
       "    'subsections': {}},\n",
       "   1: {'header': 'Supervised sentence embeddings',\n",
       "    'n': '2.2',\n",
       "    'subsections': {}},\n",
       "   2: {'header': 'Language models', 'n': '2.3', 'subsections': {}},\n",
       "   3: {'header': 'Evaluation of sentence embedding models',\n",
       "    'n': '2.4',\n",
       "    'subsections': {}}}},\n",
       " 3: {'header': 'Datasets',\n",
       "  'n': '3',\n",
       "  'subsections': {0: {'header': 'Multiple Choice Question Answering (MCQA)',\n",
       "    'n': '3.1',\n",
       "    'subsections': {}},\n",
       "   1: {'header': 'Multiple choice next sentence prediction (NSP)',\n",
       "    'n': '3.2',\n",
       "    'subsections': {}},\n",
       "   2: {'header': 'Paraphrase identification (PI)',\n",
       "    'n': '3.3',\n",
       "    'subsections': {}},\n",
       "   3: {'header': 'Dataset statistics', 'n': '3.4', 'subsections': {}}}},\n",
       " 4: {'header': 'Methods',\n",
       "  'n': '4',\n",
       "  'subsections': {0: {'header': 'Unsupervised approach',\n",
       "    'n': '4.1',\n",
       "    'subsections': {}},\n",
       "   1: {'header': 'Supervised approach', 'n': '4.2', 'subsections': {}}}},\n",
       " 5: {'header': 'Experiments and results',\n",
       "  'n': '5',\n",
       "  'subsections': {0: {'header': 'FastText', 'n': '5.1', 'subsections': {}},\n",
       "   1: {'header': 'ELMo', 'n': '5.2', 'subsections': {}},\n",
       "   2: {'header': 'BERT', 'n': '5.3', 'subsections': {}}}},\n",
       " 6: {'header': 'Conclusion', 'n': '6', 'subsections': {}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reorder_section_hierarchy(parse_sections(p.xml_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'n': '1', 'header': 'Introduction', 'head_n': None},\n",
       " 1: {'n': '2', 'header': 'Related work', 'head_n': None},\n",
       " 2: {'n': '2.1', 'header': 'Unsupervised sentence embeddings', 'head_n': '2'},\n",
       " 3: {'n': '2.2', 'header': 'Supervised sentence embeddings', 'head_n': '2'},\n",
       " 4: {'n': '2.3', 'header': 'Language models', 'head_n': '2'},\n",
       " 5: {'n': '2.4',\n",
       "  'header': 'Evaluation of sentence embedding models',\n",
       "  'head_n': '2'},\n",
       " 6: {'n': '3', 'header': 'Datasets', 'head_n': None},\n",
       " 7: {'n': '3.1',\n",
       "  'header': 'Multiple Choice Question Answering (MCQA)',\n",
       "  'head_n': '3'},\n",
       " 8: {'n': '3.2',\n",
       "  'header': 'Multiple choice next sentence prediction (NSP)',\n",
       "  'head_n': '3'},\n",
       " 9: {'n': '3.3', 'header': 'Paraphrase identification (PI)', 'head_n': '3'},\n",
       " 10: {'n': '3.4', 'header': 'Dataset statistics', 'head_n': '3'},\n",
       " 11: {'n': '4', 'header': 'Methods', 'head_n': None},\n",
       " 12: {'n': '4.1', 'header': 'Unsupervised approach', 'head_n': '4'},\n",
       " 13: {'n': '4.2', 'header': 'Supervised approach', 'head_n': '4'},\n",
       " 14: {'n': '5', 'header': 'Experiments and results', 'head_n': None},\n",
       " 15: {'n': '5.1', 'header': 'FastText', 'head_n': '5'},\n",
       " 16: {'n': '5.2', 'header': 'ELMo', 'head_n': '5'},\n",
       " 17: {'n': '5.3', 'header': 'BERT', 'head_n': '5'},\n",
       " 18: {'n': '6', 'header': 'Conclusion', 'head_n': None}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_sections(p.xml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/57954 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57954/57954 [14:12<00:00, 67.94it/s]  \n"
     ]
    }
   ],
   "source": [
    "for p in tqdm(papers_ACL):\n",
    "    try:\n",
    "        p.sections = parse_sections(p.xml_path)\n",
    "        p.sections_hierarchy = reorder_section_hierarchy(p.sections)\n",
    "    except:\n",
    "        print(p.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602\n"
     ]
    }
   ],
   "source": [
    "old = [p for p in corpus_ACL.papers_with_errors if p.init_error.startswith(\"Too old\")]\n",
    "print(len(old))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 602/602 [00:07<00:00, 79.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58556\n"
     ]
    }
   ],
   "source": [
    "for p in tqdm(old):\n",
    "    try:\n",
    "        p.init_error = None\n",
    "        p.sections = parse_sections(p.xml_path)\n",
    "        p.sections_hierarchy = reorder_section_hierarchy(p.sections)\n",
    "    except:\n",
    "        print(p.id)\n",
    "\n",
    "papers_ACL.extend(old)\n",
    "print(len(papers_ACL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29952/29952 [08:10<00:00, 61.07it/s]  \n"
     ]
    }
   ],
   "source": [
    "for p in tqdm(papers_arxiv):\n",
    "    try:\n",
    "        p.sections = parse_sections(p.xml_path)\n",
    "        p.sections_hierarchy = reorder_section_hierarchy(p.sections)\n",
    "    except:\n",
    "        print(p.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 :  10\n",
      "v2 :  2\n",
      "v3 :  2\n",
      "v4 :  120\n",
      "v5 :  120\n",
      "40966\n",
      "22826\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/annotated_articles.json\", \"r\") as f:\n",
    "    anno_idx = json.load(f)\n",
    "\n",
    "for k,v in anno_idx.items():\n",
    "    print(k, \": \", len(v))\n",
    "\n",
    "print(len(corpus_ACL.papers))\n",
    "print(len(corpus_arxiv.papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_main_head(d, section, direct = False):\n",
    "    \n",
    "    for i, sec in d.items():\n",
    "\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        subsections = sec[\"subsections\"]\n",
    "        subsections_names = [v[\"header\"] for k, v in subsections.items()]\n",
    "\n",
    "        if section in subsections_names:\n",
    "            return sec[\"header\"]\n",
    "\n",
    "        else:\n",
    "            # check in the subsections\n",
    "            to_explore = list(subsections.items())\n",
    "            while len(to_explore) > 0:\n",
    "                k, v = to_explore.pop(0)\n",
    "                if section in [v[\"header\"] for k, v in v[\"subsections\"].items()]:\n",
    "                    return v[\"header\"]\n",
    "                else:\n",
    "                    to_explore.extend(v[\"subsections\"].items())\n",
    "\n",
    "    return None\n",
    "\n",
    "def find_all_children(d, section):\n",
    "    \n",
    "    for i, sec in d.items():\n",
    "\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        subsections = sec[\"subsections\"]\n",
    "        subsections_names = [v[\"header\"] for k, v in subsections.items()]\n",
    "\n",
    "        if sec[\"header\"] == section:\n",
    "            return subsections_names\n",
    "        \n",
    "        else:\n",
    "            # check in the subsections\n",
    "            to_explore = list(subsections.items())\n",
    "            while len(to_explore) > 0:\n",
    "                k, v = to_explore.pop(0)\n",
    "                if v[\"header\"] == section:\n",
    "                    return [v[\"header\"] for k, v in v[\"subsections\"].items()]\n",
    "                else:\n",
    "                    to_explore.extend(v[\"subsections\"].items())\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 'Not following IRC structure']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set([p.init_error for p in papers_ACL]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58556/58556 [00:15<00:00, 3712.45it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42759 / 58556 papers have an introduction, results and conclusion section\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "RES = [\"result\", \"performance\", \"evaluation\", \"experiment\"]\n",
    "CONCL = [\"analysis\", \"discussion\", \"limit\", \"ethic\", \"conclusion\", \"concluding\", \"future\"]\n",
    "all_IRC = []\n",
    "\n",
    "for p in tqdm(papers_ACL):\n",
    "\n",
    "    sections = [s[\"header\"] for k, s in p.sections.items()]\n",
    "    sections_d = p.sections_hierarchy\n",
    "    \n",
    "    found_intro = False\n",
    "    found_results = False\n",
    "    found_conclusion = False\n",
    "\n",
    "    sections_to_keep = set()\n",
    "\n",
    "    # introduction\n",
    "    for i, section in enumerate(sections):\n",
    "        if \"introduction\" in section.lower():\n",
    "            found_intro = True\n",
    "            sections_to_keep.add((i, section))\n",
    "            break\n",
    "\n",
    "    # results\n",
    "    for j, section in enumerate(sections):\n",
    "        if j > i:\n",
    "            for res in RES:\n",
    "                if res in section.lower():\n",
    "                    found_results = True\n",
    "\n",
    "\n",
    "                    head = find_main_head(sections_d, section)\n",
    "                    if head is None:\n",
    "                        head = section\n",
    "\n",
    "                    children = find_all_children(sections_d, head)\n",
    "\n",
    "                    if children is None:\n",
    "                        sections_to_keep.add((j, section))\n",
    "                    else:\n",
    "                        sections_to_keep.add((j, head))\n",
    "                        for child in children:\n",
    "                            sections_to_keep.add((j, child))\n",
    "\n",
    "\n",
    "    # conclusion\n",
    "    for k, section in enumerate(sections):\n",
    "        for concl in CONCL:\n",
    "            if concl in section.lower():\n",
    "                found_conclusion = True\n",
    "                \n",
    "                head = find_main_head(sections_d, section)\n",
    "                if head is None:\n",
    "                    head = section\n",
    "\n",
    "                children = find_all_children(sections_d, head)\n",
    "\n",
    "                if children is None:\n",
    "                    sections_to_keep.add((k, section))\n",
    "                else:\n",
    "                    sections_to_keep.add((k, head))\n",
    "                    for child in children:\n",
    "                        sections_to_keep.add((k, child))\n",
    "\n",
    "\n",
    "    \n",
    "    if found_intro and found_results and found_conclusion:\n",
    "        all_IRC.append(list(sections_to_keep))\n",
    "        n += 1\n",
    "        p.init_error = None\n",
    "        p.content[\"candidate\"] = p.content[\"section\"].apply(lambda x: x in [s[1] for s in sections_to_keep])\n",
    "\n",
    "    else:\n",
    "        p.init_error = \"Not following IRC structure\"\n",
    "\n",
    "print(f\"{n} / {len(papers_ACL)} papers have an introduction, results and conclusion section\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29952/29952 [00:13<00:00, 2283.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24117 / 29952 papers have an introduction, results and conclusion section\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "\n",
    "for p in tqdm(papers_arxiv):\n",
    "    \n",
    "    sections = [s[\"header\"] for k, s in p.sections.items()]\n",
    "    sections_d = p.sections_hierarchy\n",
    "    \n",
    "    found_intro = False\n",
    "    found_results = False\n",
    "    found_conclusion = False\n",
    "\n",
    "    sections_to_keep = set()\n",
    "\n",
    "    # introduction\n",
    "    for i, section in enumerate(sections):\n",
    "        if \"introduction\" in section.lower():\n",
    "            found_intro = True\n",
    "            sections_to_keep.add((i, section))\n",
    "            break\n",
    "\n",
    "    # results\n",
    "    for j, section in enumerate(sections):\n",
    "        if j > i:\n",
    "            for res in RES:\n",
    "                if res in section.lower():\n",
    "                    found_results = True\n",
    "\n",
    "\n",
    "                    head = find_main_head(sections_d, section)\n",
    "                    if head is None:\n",
    "                        head = section\n",
    "\n",
    "                    children = find_all_children(sections_d, head)\n",
    "\n",
    "                    if children is None:\n",
    "                        sections_to_keep.add((j, section))\n",
    "                    else:\n",
    "                        sections_to_keep.add((j, head))\n",
    "                        for child in children:\n",
    "                            sections_to_keep.add((j, child))\n",
    "\n",
    "\n",
    "    # conclusion\n",
    "    for k, section in enumerate(sections):\n",
    "        for concl in CONCL:\n",
    "            if concl in section.lower():\n",
    "                found_conclusion = True\n",
    "                \n",
    "                head = find_main_head(sections_d, section)\n",
    "                if head is None:\n",
    "                    head = section\n",
    "\n",
    "                children = find_all_children(sections_d, head)\n",
    "\n",
    "                if children is None:\n",
    "                    sections_to_keep.add((k, section))\n",
    "                else:\n",
    "                    sections_to_keep.add((k, head))\n",
    "                    for child in children:\n",
    "                        sections_to_keep.add((k, child))\n",
    "\n",
    "\n",
    "    \n",
    "    if found_intro and found_results and found_conclusion:\n",
    "        all_IRC.append(list(sections_to_keep))\n",
    "        n += 1\n",
    "        p.init_error = None\n",
    "        p.content[\"candidate\"] = p.content[\"section\"].apply(lambda x: x in [s[1] for s in sections_to_keep])\n",
    "\n",
    "    else:\n",
    "        p.init_error = \"Not following IRC structure\"\n",
    "\n",
    "print(f\"{n} / {len(papers_arxiv)} papers have an introduction, results and conclusion section\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30296\n",
      "42759\n"
     ]
    }
   ],
   "source": [
    "corpus_ACL.papers_with_errors = [p for p in corpus_ACL.papers_with_errors if p.init_error is not None]\n",
    "print(len(corpus_ACL.papers_with_errors))\n",
    "for p in [p for p in papers_ACL if p.init_error is not None]:\n",
    "    if p not in corpus_ACL.papers_with_errors:\n",
    "        corpus_ACL.papers_with_errors.append(p)\n",
    "corpus_ACL.papers = [p for p in papers_ACL if p.init_error is None]\n",
    "print(len(corpus_ACL.papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10862\n",
      "24117\n"
     ]
    }
   ],
   "source": [
    "corpus_arxiv.papers_with_errors = [p for p in corpus_arxiv.papers_with_errors if p.init_error is not None]\n",
    "print(len(corpus_arxiv.papers_with_errors))\n",
    "for p in [p for p in papers_arxiv if p.init_error is not None]:\n",
    "    if p not in corpus_arxiv.papers_with_errors:\n",
    "        corpus_arxiv.papers_with_errors.append(p)\n",
    "corpus_arxiv.papers = [p for p in papers_arxiv if p.init_error is None]\n",
    "print(len(corpus_arxiv.papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in corpus_ACL.papers:\n",
    "    p.content[\"candidate\"] = p.content.apply(lambda x: x[\"candidate\"] or x[\"section\"] == \"abstract\", axis = 1)\n",
    "\n",
    "for p in corpus_arxiv.papers:\n",
    "    p.content[\"candidate\"] = p.content.apply(lambda x: x[\"candidate\"] or x[\"section\"] == \"abstract\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42759/42759 [02:43<00:00, 262.06it/s]\n",
      "100%|██████████| 24117/24117 [01:44<00:00, 230.89it/s]\n",
      "100%|██████████| 2/2 [04:27<00:00, 133.81s/it]\n"
     ]
    }
   ],
   "source": [
    "cdb_IRC_corr = ClaimDB(corpora = [corpus_ACL, corpus_arxiv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>corpus</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>year</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ACL</td>\n",
       "      <td>O02-2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>There is a need to measure word similarity whe...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ACL</td>\n",
       "      <td>O02-2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>Usually, measures of similarity between two wo...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ACL</td>\n",
       "      <td>O02-2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>The taxonomy approaches are more or less seman...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ACL</td>\n",
       "      <td>O02-2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>3</td>\n",
       "      <td>However, in real applications, both semantic a...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ACL</td>\n",
       "      <td>O02-2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>4</td>\n",
       "      <td>Word similarity based on context vectors is a ...</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx corpus  paper_id  year  sentence_id  \\\n",
       "0    0    ACL  O02-2002  2002            0   \n",
       "1    1    ACL  O02-2002  2002            1   \n",
       "2    2    ACL  O02-2002  2002            2   \n",
       "3    3    ACL  O02-2002  2002            3   \n",
       "4    4    ACL  O02-2002  2002            4   \n",
       "\n",
       "                                            sentence   section  \n",
       "0  There is a need to measure word similarity whe...  abstract  \n",
       "1  Usually, measures of similarity between two wo...  abstract  \n",
       "2  The taxonomy approaches are more or less seman...  abstract  \n",
       "3  However, in real applications, both semantic a...  abstract  \n",
       "4  Word similarity based on context vectors is a ...  abstract  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdb_IRC_corr.candidates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/cdb_IRC_corr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cdb_IRC_corr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 10\n",
      "v2 2\n",
      "v3 2\n",
      "v4 120\n",
      "v5 120\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/annotated_articles.json\", \"r\") as f:\n",
    "    d = json.load(f)\n",
    "\n",
    "for k, v in d.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020.signlang-1.20', 'W17-4709', 'N19-1358', 'Y15-1047', 'P18-1048', 'W17-5513', '2022.naacl-main.19', '2022.in2writing-1.4', 'W18-3406', 'H89-1053', 'D15-1013', 'P97-1030', 'Y11-1012', 'W01-1826', 'D19-1210', 'W98-1507', 'W01-0812', 'W94-0305', 'P90-1033', 'A92-1020', 'P11-1048', 'P11-4022', '2020.emnlp-main.554', 'P13-1099', 'E87-1013', 'W03-0425', '2020.acl-main.413', 'W18-0527', 'C92-1030', 'W16-5818', 'W99-0402', 'W13-4420', '2001.mtsummit-papers.31', '1993.tmi-1.6', 'W00-1415', 'C98-2177', '2007.mtsummit-papers.40', 'N18-1107', 'Y03-1032', 'H89-2041', 'P19-1654', 'P93-1023', 'W08-1302', 'P11-1029', 'C90-1007', 'C92-2087', 'H89-2017', 'P91-1024', '2020.acl-demos.20', 'W00-0505', 'P07-2029', 'Q16-1037', 'I13-1029', 'J92-4001', 'P07-1088', 'J97-2004', 'W09-0809', 'E93-1027', 'E09-1027', 'W99-0609', 'J98-3005', '2020.lrec-1.826', 'W12-4402', 'C14-1028', 'Y09-2035', 'H93-1064', '2020.loresmt-1.4', 'D18-1087']\n",
      "68\n",
      "['2103.14302', '1708.01009', '1611.08765', '1605.05172', '2012.04584', '2108.06957', '2003.06634', 'cs/0412024', '2008.05282', 'cmp-lg/9612002', 'cmp-lg/9712002', 'cmp-lg/9610002', 'cs/9910011', '1312.0482', 'cmp-lg/9608017', '2312.06522', '1101.5494', '1010.2384', '2202.09509', '1210.5965', '2207.06403', 'cs/0703049', '2303.13375', 'cmp-lg/9412006', '1309.1125', '2302.07856', '1008.3667', '2401.04515', '2207.08988', '1303.2826', '1211.0498', '2001.10822', '1305.5918', '1310.4546', '1301.5686', '1312.0482', 'cmp-lg/9805006', '1910.13291', '1006.3271', '2311.09443', 'cs/0001020', '2108.02524', 'cmp-lg/9406037', 'cmp-lg/9506020', '2402.16654', '1309.4628', 'cs/0205067', 'cmp-lg/9611003', '1205.3316', '1508.03386', 'cmp-lg/9504004', '1207.5409', 'cmp-lg/9606024', 'cmp-lg/9605029', '1309.5174', '2311.16509', 'cmp-lg/9607024', 'cs/9904018', 'cs/0310018', '1512.01587', '2008.08901', 'cs/9906014', 'cs/9906014', '2307.08689', '1311.0833', '2307.08487']\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "ACL_annotated = []\n",
    "arxiv_annotated = []\n",
    "\n",
    "for v in d.keys():\n",
    "    if v != \"v5\":\n",
    "        for paper in d[v]:\n",
    "            if paper[0] == \"ACL\":\n",
    "                ACL_annotated.append(paper[1])\n",
    "            else:\n",
    "                arxiv_annotated.append(paper[1])\n",
    "\n",
    "print(ACL_annotated)\n",
    "print(len(ACL_annotated))\n",
    "print(arxiv_annotated)\n",
    "print(len(arxiv_annotated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_ACL_0 = [p for p in corpus_ACL.papers if p.year < 1994]\n",
    "corpus_ACL_1 = [p for p in corpus_ACL.papers if p.year >= 1994 and p.year < 2004]\n",
    "corpus_ACL_2 = [p for p in corpus_ACL.papers if p.year >= 2004 and p.year < 2014]\n",
    "corpus_ACL_3 = [p for p in corpus_ACL.papers if p.year >= 2014]\n",
    "\n",
    "corpus_ACL_by_year_slices = [corpus_ACL_0, corpus_ACL_1, corpus_ACL_2, corpus_ACL_3]\n",
    "\n",
    "corpus_arxiv_0 = [p for p in corpus_arxiv.papers if p.year < 1994]\n",
    "corpus_arxiv_1 = [p for p in corpus_arxiv.papers if p.year >= 1994 and p.year < 2004]\n",
    "corpus_arxiv_2 = [p for p in corpus_arxiv.papers if p.year >= 2004 and p.year < 2014]\n",
    "corpus_arxiv_3 = [p for p in corpus_arxiv.papers if p.year >= 2014]\n",
    "\n",
    "corpus_arxiv_by_year_slices = [corpus_arxiv_0, corpus_arxiv_1, corpus_arxiv_2, corpus_arxiv_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316\n",
      "2071\n",
      "11791\n",
      "28581\n",
      "total: 42759\n",
      "0\n",
      "109\n",
      "217\n",
      "23791\n",
      "total: 24117\n"
     ]
    }
   ],
   "source": [
    "acl_total = 0\n",
    "arxiv_total = 0\n",
    "\n",
    "for c_acl in corpus_ACL_by_year_slices:\n",
    "    c_acl = [p for p in c_acl if p.id not in ACL_annotated]\n",
    "\n",
    "for c_arx in corpus_arxiv_by_year_slices:\n",
    "    c_arx = [p for p in c_arx if p.id not in arxiv_annotated]\n",
    "\n",
    "for c_acl in corpus_ACL_by_year_slices:\n",
    "    n = len(c_acl)\n",
    "    acl_total += n\n",
    "    print(n)\n",
    "\n",
    "print(\"total:\", acl_total)\n",
    "\n",
    "for c_arxiv in corpus_arxiv_by_year_slices:\n",
    "    n = len(c_arxiv)\n",
    "    arxiv_total += n\n",
    "    print(n)\n",
    "\n",
    "print(\"total:\", arxiv_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "[['ACL', 'W16-0510'], ['arXiv', '2008.09513'], ['arXiv', '1203.3511'], ['ACL', 'C92-4182'], ['arXiv', '2112.01742'], ['ACL', 'W15-0626'], ['arXiv', 'cmp-lg/9606012'], ['ACL', 'W03-1314'], ['ACL', 'S13-2022'], ['ACL', 'W03-1012'], ['ACL', 'L16-1683'], ['arXiv', 'cmp-lg/9703003'], ['ACL', 'P98-2188'], ['arXiv', 'cmp-lg/9504020'], ['arXiv', 'cmp-lg/9607024'], ['ACL', '2000.tc-1.5'], ['arXiv', '1312.6192'], ['ACL', 'C96-2100'], ['ACL', 'J91-4001'], ['arXiv', 'cmp-lg/9405014'], ['ACL', 'H93-1004'], ['arXiv', '2402.07255'], ['ACL', 'P12-2059'], ['arXiv', '1002.0481'], ['arXiv', '1203.4605'], ['ACL', 'N09-2067'], ['ACL', 'W17-1903'], ['arXiv', '2306.09539'], ['arXiv', '1204.6362'], ['ACL', 'P13-1099'], ['ACL', 'A92-1027'], ['ACL', '2001.mtsummit-teach.5'], ['ACL', 'C18-1179'], ['ACL', '2022.bionlp-1.22'], ['arXiv', '1412.4846'], ['arXiv', '1105.1702'], ['ACL', 'A88-1002'], ['ACL', 'W19-2910'], ['ACL', 'W03-1729'], ['arXiv', '2309.10668'], ['arXiv', 'cmp-lg/9407002'], ['arXiv', '1101.5494'], ['ACL', 'W05-0501'], ['ACL', 'P94-1038'], ['ACL', '1993.iwpt-1.27'], ['arXiv', '2208.02531'], ['arXiv', '1109.6018'], ['ACL', 'N03-1023'], ['arXiv', '2012.02943'], ['arXiv', '1810.12085'], ['ACL', 'P03-2015'], ['ACL', '2009.mtsummit-wpt.4'], ['ACL', '2021.wmt-1.84'], ['arXiv', '1311.2702'], ['arXiv', '1001.4368'], ['ACL', 'C00-1024'], ['ACL', 'H91-1012'], ['arXiv', '1910.11005'], ['ACL', '2020.signlang-1.2'], ['arXiv', '1003.0628'], ['ACL', 'P88-1028'], ['arXiv', '1210.3926'], ['arXiv', '1303.5778'], ['ACL', 'R11-1011'], ['ACL', 'N09-1006'], ['arXiv', '1204.6362'], ['arXiv', 'cmp-lg/9603005'], ['ACL', 'P91-1017'], ['arXiv', '2211.07711'], ['ACL', 'P92-1024'], ['ACL', 'H91-1015'], ['arXiv', '1212.3493'], ['ACL', 'E91-1004'], ['arXiv', '2302.06951'], ['arXiv', 'cs/0307055'], ['ACL', 'P15-2117'], ['arXiv', '2212.07931'], ['arXiv', 'cmp-lg/9605029'], ['ACL', 'P01-1017'], ['arXiv', 'cs/9903008'], ['ACL', 'R11-1057'], ['ACL', '2021.acl-long.20'], ['arXiv', '2310.02249'], ['arXiv', '1205.1603'], ['arXiv', 'cmp-lg/9405014'], ['arXiv', 'cmp-lg/9504004'], ['ACL', '2012.amta-caas14.9'], ['arXiv', '1310.1426'], ['ACL', 'W93-0113'], ['arXiv', '2309.15512'], ['ACL', 'W11-0907'], ['ACL', 'E03-2008'], ['arXiv', 'cs/0109013'], ['arXiv', '1308.3243'], ['arXiv', 'cmp-lg/9710001'], ['ACL', 'W11-1910'], ['arXiv', 'cmp-lg/9505021'], ['ACL', 'P92-1021'], ['arXiv', '1301.3226'], ['arXiv', '2308.00158'], ['ACL', 'E09-1026'], ['ACL', 'W97-1311'], ['arXiv', 'cs/9811006'], ['ACL', 'C98-1097'], ['arXiv', 'cmp-lg/9608007'], ['ACL', 'S19-1026'], ['arXiv', 'cmp-lg/9712004'], ['ACL', 'W04-3229'], ['arXiv', '2004.12265'], ['arXiv', '2310.17956'], ['ACL', 'W14-0608'], ['arXiv', 'cmp-lg/9406012'], ['arXiv', 'cmp-lg/9502001'], ['ACL', 'W09-0211'], ['ACL', 'H91-1031'], ['ACL', '2022.acl-long.569'], ['arXiv', '2311.16764'], ['arXiv', '1011.4623'], ['ACL', 'D19-1163'], ['arXiv', '2310.04595']]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random_papers = []\n",
    "random.seed(0)\n",
    "\n",
    "for c_acl in corpus_ACL_by_year_slices:\n",
    "    random_papers.extend(np.random.choice(c_acl, 15))\n",
    "\n",
    "for c_arx in corpus_arxiv_by_year_slices[1:]:\n",
    "    random_papers.extend(np.random.choice(c_arx, 20))\n",
    "\n",
    "random.shuffle(random_papers)\n",
    "print(len(random_papers))\n",
    "\n",
    "random_papers_ids = [[p.corpus.name, p.id] for p in random_papers]\n",
    "print(random_papers_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10731, 7)\n"
     ]
    }
   ],
   "source": [
    "random_sentences_ids = []\n",
    "coord2idx = {v:k for k,v in cdb_IRC_corr.idx_map.items()}\n",
    "\n",
    "for rp in random_papers:\n",
    "\n",
    "    sentences_ids = rp.content[rp.content[\"candidate\"] == True][\"id\"].tolist()\n",
    "\n",
    "    random_sentences_ids.extend([coord2idx[(rp.corpus.name, rp.id, i)] for i in sentences_ids])\n",
    "\n",
    "df = cdb_IRC_corr.candidates.loc[random_sentences_ids]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_main_head(d, section):\n",
    "    \n",
    "    section_n = 0\n",
    "    head = section\n",
    "    head_n = 0\n",
    "\n",
    "    for i, sec in d.items():\n",
    "\n",
    "        if section == sec[\"header\"]:\n",
    "            head_n = i\n",
    "            section_n = i\n",
    "            break\n",
    "\n",
    "        subsections = sec[\"subsections\"]\n",
    "        subsections_names = [v[\"header\"] for k, v in subsections.items()]\n",
    "\n",
    "        if section in subsections_names:\n",
    "           head = sec[\"header\"]\n",
    "           head_n = i\n",
    "           section_n = subsections_names.index(section)\n",
    "           break\n",
    "\n",
    "        else:\n",
    "            # check in the subsections\n",
    "            to_explore = list(subsections.items())\n",
    "            ids = [[k] for k, v in subsections.items()]\n",
    "            while len(to_explore) > 0:\n",
    "                k, v = to_explore.pop(0)\n",
    "                id_ = ids.pop(0)\n",
    "\n",
    "                subsections_names = [v[\"header\"] for k, v in v[\"subsections\"].items()]\n",
    "\n",
    "                if section in subsections_names:\n",
    "                    head = sec[\"header\"]\n",
    "                    head_n = i\n",
    "                    section_n = id_\n",
    "                else:\n",
    "                    to_explore.extend(v[\"subsections\"].items())\n",
    "                    ids.extend([[k] + [k_] for k_, v in v[\"subsections\"].items()])\n",
    "\n",
    "\n",
    "    return section, section_n, head, head_n\n",
    "\n",
    "def prepare_for_doccano_format(cdb, df:pd.DataFrame)-> pd.DataFrame:\n",
    "    \"\"\"A function to prepare a dataframe of sentences for Doccano format\n",
    "    - df : a pandas DataFrame with columns {corpus, paper_id, sentence_id, sentence, section}\"\"\"\n",
    "\n",
    "    data = []\n",
    "    coord2idx = {v:k for k,v in cdb.idx_map.items()}\n",
    "\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        c = cdb.get_corpus_by_name(row[\"corpus\"])\n",
    "        p = c.get_paper_by_id(row[\"paper_id\"])\n",
    "\n",
    "        sections_d = p.sections_hierarchy\n",
    "        main_sections_str = \"\"\n",
    "\n",
    "        for i, sec in enumerate(sections_d.values()):\n",
    "            main_sections_str += str(i) + \". \" + sec[\"header\"] + \"\\n\"\n",
    "            \n",
    "        sec, sec_n, head, head_n = find_main_head(sections_d, row[\"section\"])\n",
    "        \n",
    "\n",
    "        idx = coord2idx[(c.name, p.id, row[\"sentence_id\"])]\n",
    "        text = row[\"sentence\"]\n",
    "\n",
    "        \n",
    "        prev_sent_id = int(row[\"sentence_id\"]) - 1\n",
    "        next_sent_id = int(row[\"sentence_id\"]) + 1\n",
    "\n",
    "        # get previous sentence\n",
    "        if prev_sent_id in p.content[\"id\"].values:\n",
    "            prev_doc = p.content.loc[prev_sent_id]\n",
    "            prev_text = prev_doc[\"sentence\"]\n",
    "            prev_sec = prev_doc[\"section\"]\n",
    "\n",
    "        else:\n",
    "            prev_text = \"\"\n",
    "            prev_sec = \"\"\n",
    "\n",
    "        # get next sentence\n",
    "        if next_sent_id in p.content[\"id\"].values:\n",
    "            next_doc = p.content.loc[next_sent_id]\n",
    "            next_text = next_doc[\"sentence\"]\n",
    "            next_sec = next_doc[\"section\"]\n",
    "        \n",
    "        else:\n",
    "            next_text = \"\"\n",
    "            next_sec = \"\"\n",
    "\n",
    "\n",
    "        data.append({\n",
    "            \"text\": text,\n",
    "            \"doc_id\": idx,\n",
    "            \"corpus\": p.corpus.name,\n",
    "            \"paper_title\" : p.title,\n",
    "            \"paper_id\" : p.id,\n",
    "            \"paper_structure\": main_sections_str,\n",
    "            \"year\": p.year,\n",
    "            \"section\": sec,\n",
    "            \"section_n\" : sec_n,\n",
    "            \"main_head\" : head,\n",
    "            \"main_head_n\" : head_n,\n",
    "            \"prev_text\": prev_text,\n",
    "            \"prev_section\": prev_sec,\n",
    "            \"next_text\": next_text,\n",
    "            \"next_section\": next_sec,\n",
    "            \"label\": \"\"\n",
    "        })\n",
    "\n",
    "    df_doccano = pd.DataFrame(data)\n",
    "\n",
    "    return df_doccano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>corpus</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>paper_structure</th>\n",
       "      <th>year</th>\n",
       "      <th>section</th>\n",
       "      <th>section_n</th>\n",
       "      <th>main_head</th>\n",
       "      <th>main_head_n</th>\n",
       "      <th>prev_text</th>\n",
       "      <th>prev_section</th>\n",
       "      <th>next_text</th>\n",
       "      <th>next_section</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The automated scoring of second-language (L2) ...</td>\n",
       "      <td>1143514</td>\n",
       "      <td>ACL</td>\n",
       "      <td>Unsupervised Modeling of Topical Relevance in ...</td>\n",
       "      <td>W16-0510</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Related Resea...</td>\n",
       "      <td>2016</td>\n",
       "      <td>abstract</td>\n",
       "      <td>0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>In this paper, we focus on determining the top...</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In this paper, we focus on determining the top...</td>\n",
       "      <td>1143515</td>\n",
       "      <td>ACL</td>\n",
       "      <td>Unsupervised Modeling of Topical Relevance in ...</td>\n",
       "      <td>W16-0510</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Related Resea...</td>\n",
       "      <td>2016</td>\n",
       "      <td>abstract</td>\n",
       "      <td>0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>0</td>\n",
       "      <td>The automated scoring of second-language (L2) ...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Given the burden involved in manually assignin...</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Given the burden involved in manually assignin...</td>\n",
       "      <td>1143516</td>\n",
       "      <td>ACL</td>\n",
       "      <td>Unsupervised Modeling of Topical Relevance in ...</td>\n",
       "      <td>W16-0510</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Related Resea...</td>\n",
       "      <td>2016</td>\n",
       "      <td>abstract</td>\n",
       "      <td>0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>0</td>\n",
       "      <td>In this paper, we focus on determining the top...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>We show that expanding prompts using topically...</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We show that expanding prompts using topically...</td>\n",
       "      <td>1143517</td>\n",
       "      <td>ACL</td>\n",
       "      <td>Unsupervised Modeling of Topical Relevance in ...</td>\n",
       "      <td>W16-0510</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Related Resea...</td>\n",
       "      <td>2016</td>\n",
       "      <td>abstract</td>\n",
       "      <td>0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>0</td>\n",
       "      <td>Given the burden involved in manually assignin...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Finally, we incorporate our prompt-relevance m...</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finally, we incorporate our prompt-relevance m...</td>\n",
       "      <td>1143518</td>\n",
       "      <td>ACL</td>\n",
       "      <td>Unsupervised Modeling of Topical Relevance in ...</td>\n",
       "      <td>W16-0510</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Related Resea...</td>\n",
       "      <td>2016</td>\n",
       "      <td>abstract</td>\n",
       "      <td>0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>0</td>\n",
       "      <td>We show that expanding prompts using topically...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Given the increase in demand for educational t...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   doc_id corpus  \\\n",
       "0  The automated scoring of second-language (L2) ...  1143514    ACL   \n",
       "1  In this paper, we focus on determining the top...  1143515    ACL   \n",
       "2  Given the burden involved in manually assignin...  1143516    ACL   \n",
       "3  We show that expanding prompts using topically...  1143517    ACL   \n",
       "4  Finally, we incorporate our prompt-relevance m...  1143518    ACL   \n",
       "\n",
       "                                         paper_title  paper_id  \\\n",
       "0  Unsupervised Modeling of Topical Relevance in ...  W16-0510   \n",
       "1  Unsupervised Modeling of Topical Relevance in ...  W16-0510   \n",
       "2  Unsupervised Modeling of Topical Relevance in ...  W16-0510   \n",
       "3  Unsupervised Modeling of Topical Relevance in ...  W16-0510   \n",
       "4  Unsupervised Modeling of Topical Relevance in ...  W16-0510   \n",
       "\n",
       "                                     paper_structure  year   section  \\\n",
       "0  0. abstract\\n1. Introduction\\n2. Related Resea...  2016  abstract   \n",
       "1  0. abstract\\n1. Introduction\\n2. Related Resea...  2016  abstract   \n",
       "2  0. abstract\\n1. Introduction\\n2. Related Resea...  2016  abstract   \n",
       "3  0. abstract\\n1. Introduction\\n2. Related Resea...  2016  abstract   \n",
       "4  0. abstract\\n1. Introduction\\n2. Related Resea...  2016  abstract   \n",
       "\n",
       "   section_n main_head  main_head_n  \\\n",
       "0          0  abstract            0   \n",
       "1          0  abstract            0   \n",
       "2          0  abstract            0   \n",
       "3          0  abstract            0   \n",
       "4          0  abstract            0   \n",
       "\n",
       "                                           prev_text prev_section  \\\n",
       "0                                                                   \n",
       "1  The automated scoring of second-language (L2) ...     abstract   \n",
       "2  In this paper, we focus on determining the top...     abstract   \n",
       "3  Given the burden involved in manually assignin...     abstract   \n",
       "4  We show that expanding prompts using topically...     abstract   \n",
       "\n",
       "                                           next_text  next_section label  \n",
       "0  In this paper, we focus on determining the top...      abstract        \n",
       "1  Given the burden involved in manually assignin...      abstract        \n",
       "2  We show that expanding prompts using topically...      abstract        \n",
       "3  Finally, we incorporate our prompt-relevance m...      abstract        \n",
       "4  Given the increase in demand for educational t...  Introduction        "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doccano = prepare_for_doccano_format(cdb_IRC_corr, df)\n",
    "df_doccano.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_children(d, section):\n",
    "    \n",
    "    children = [section]\n",
    "\n",
    "    for i, sec in d.items():\n",
    "\n",
    "        if sec[\"header\"] == section:\n",
    "\n",
    "            while \"subsections\" in sec.keys():\n",
    "                ss = sec[\"subsections\"]\n",
    "                children.extend([v[\"header\"] for k, v in ss.items()])\n",
    "                sec = ss\n",
    "\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = []\n",
    "import re\n",
    "\n",
    "current_head = \"\"\n",
    "current_section = \"\"\n",
    "h = 0\n",
    "s = 0\n",
    "total_head_len = 0\n",
    "total_section_len = 0\n",
    "\n",
    "for i, row in df_doccano.iterrows():\n",
    "    n = 90\n",
    "\n",
    "    sec = row[\"section\"] \n",
    "    sec_n = row[\"section_n\"]\n",
    "    head = row[\"main_head\"]\n",
    "    head_n = row[\"main_head_n\"]\n",
    "\n",
    "    if row[\"corpus\"] == \"ACL\":\n",
    "            p = corpus_ACL.get_paper_by_id(row[\"paper_id\"])\n",
    "    else:\n",
    "        p = corpus_arxiv.get_paper_by_id(row[\"paper_id\"])\n",
    "\n",
    "    if head != current_head:\n",
    "        current_head = head\n",
    "\n",
    "        cands = p.content[p.content[\"candidate\"] == True]\n",
    "        children = find_all_children(p.sections_hierarchy, head)\n",
    "        total_head_len = len(cands[cands[\"section\"].isin(children)])\n",
    "\n",
    "        h = 1\n",
    "\n",
    "    else:\n",
    "        h += 1\n",
    "\n",
    "    if sec != current_section:\n",
    "        current_section = sec\n",
    "        \n",
    "        if row[\"corpus\"] == \"ACL\":\n",
    "            p = corpus_ACL.get_paper_by_id(row[\"paper_id\"])\n",
    "        else:\n",
    "            p = corpus_arxiv.get_paper_by_id(row[\"paper_id\"])\n",
    "\n",
    "        cands = p.content[p.content[\"candidate\"] == True]\n",
    "        children = find_all_children(p.sections_hierarchy, sec)\n",
    "        total_section_len = len(cands[cands[\"section\"].isin(children)])\n",
    "\n",
    "        s = 1\n",
    "\n",
    "    else:\n",
    "        s += 1\n",
    "\n",
    "\n",
    "    text = p.title.replace(\"\\n\", \"\").replace(\"\\t\", \"\") + \"\\n\"\n",
    "    text += \"=\" * n + \"\\n\" + str(head_n) + \". \" + head + \" -- \" + str(h) + \"/\" + str(total_head_len) + \"\\n\" + \"=\" * n + \"\\n\"\n",
    "\n",
    "    if sec != head:\n",
    "        text += str(sec_n) + \". \" + sec + \" -- \" + str(s) + \"/\" + str(total_section_len) +\"\\n\" + \"-\" * n + \"\\n\" \n",
    "\n",
    "    text+= row[\"text\"]\n",
    "\n",
    "    text2.append(text)\n",
    "\n",
    "df_doccano[\"text\"] = text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feedback_on_article(p, n=90):\n",
    "    s = \"=\"*n + \"\\n\" + \"Annotator feedback\" + \"\\n\" + \"=\"*n + \"\\n\\n\"\n",
    "    s += f\"You just finished annotating the article entitled <<{p.title}>>. Please answer following questions: \\n\\n\"\n",
    "\n",
    "    s1 = \"1. Do you think that this article was difficult to understand, in a way that may have affected the quality of your annotations, because of its technicity / because it handles subjects you are unfamiliar with ?\\n\\n\"\n",
    "    s1 += \"Please add any label of your choice if your answer is yes.\"\n",
    "\n",
    "    s2 = \"2. Do you think that this article was difficult to understand, in a way that may have affected the quality of your annotations, because of its writing style / structure / parsing errors ?\\n\\n\"\n",
    "    s2 += \"Please add any label of your choice if your answer is yes.\"\n",
    "\n",
    "    s3 = \"3. Did you know / read the article before this annotation task, or do you think you have identified its authors ?\\n\\n\"\n",
    "    s3 += \"Please add any label of your choice if your answer is yes.\"\n",
    "\n",
    "    return [s + s1, s + s2, s + s3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert feedback questions in the dataset\n",
    "for rp in random_papers:\n",
    "    last_row= df_doccano[df_doccano[\"paper_title\"] == rp.title].iloc[-1]\n",
    "    last_index = float(last_row.name)\n",
    "    values = list(last_row.values)\n",
    "\n",
    "    fb = get_feedback_on_article(rp)\n",
    "    for fb_q, h in zip(fb, [0.25, 0.5, 0.75]):\n",
    "        values[0] = fb_q\n",
    "        for i in range(7, len(values)):\n",
    "            values[i] = \"\"\n",
    "        df_doccano.loc[last_index + h] = values\n",
    "\n",
    "df_doccano = df_doccano.sort_index().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doccano = df_doccano.drop(columns = [\"corpus\", \"paper_id\", \"section\",  \"section_n\", \"main_head\", \"main_head_n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_structure</th>\n",
       "      <th>year</th>\n",
       "      <th>prev_text</th>\n",
       "      <th>prev_section</th>\n",
       "      <th>next_text</th>\n",
       "      <th>next_section</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unsupervised Modeling of Topical Relevance in ...</td>\n",
       "      <td>1143514</td>\n",
       "      <td>Unsupervised Modeling of Topical Relevance in ...</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Related Resea...</td>\n",
       "      <td>2016</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>In this paper, we focus on determining the top...</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unsupervised Modeling of Topical Relevance in ...</td>\n",
       "      <td>1143515</td>\n",
       "      <td>Unsupervised Modeling of Topical Relevance in ...</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Related Resea...</td>\n",
       "      <td>2016</td>\n",
       "      <td>The automated scoring of second-language (L2) ...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Given the burden involved in manually assignin...</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unsupervised Modeling of Topical Relevance in ...</td>\n",
       "      <td>1143516</td>\n",
       "      <td>Unsupervised Modeling of Topical Relevance in ...</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Related Resea...</td>\n",
       "      <td>2016</td>\n",
       "      <td>In this paper, we focus on determining the top...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>We show that expanding prompts using topically...</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unsupervised Modeling of Topical Relevance in ...</td>\n",
       "      <td>1143517</td>\n",
       "      <td>Unsupervised Modeling of Topical Relevance in ...</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Related Resea...</td>\n",
       "      <td>2016</td>\n",
       "      <td>Given the burden involved in manually assignin...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Finally, we incorporate our prompt-relevance m...</td>\n",
       "      <td>abstract</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unsupervised Modeling of Topical Relevance in ...</td>\n",
       "      <td>1143518</td>\n",
       "      <td>Unsupervised Modeling of Topical Relevance in ...</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Related Resea...</td>\n",
       "      <td>2016</td>\n",
       "      <td>We show that expanding prompts using topically...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>Given the increase in demand for educational t...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11084</th>\n",
       "      <td>Segmented Harmonic Loss: Handling Class-Imbala...</td>\n",
       "      <td>5654074</td>\n",
       "      <td>Segmented Harmonic Loss: Handling Class-Imbala...</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Data\\n3. Comp...</td>\n",
       "      <td>2023</td>\n",
       "      <td>In our future work, those are the aspects we w...</td>\n",
       "      <td>Conclusion &amp; Future Work</td>\n",
       "      <td>// Compute the allowed standard deviation usin...</td>\n",
       "      <td>Conclusion &amp; Future Work</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11085</th>\n",
       "      <td>Segmented Harmonic Loss: Handling Class-Imbala...</td>\n",
       "      <td>5654075</td>\n",
       "      <td>Segmented Harmonic Loss: Handling Class-Imbala...</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Data\\n3. Comp...</td>\n",
       "      <td>2023</td>\n",
       "      <td>We believe that would unlock the full potentia...</td>\n",
       "      <td>Conclusion &amp; Future Work</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11086</th>\n",
       "      <td>==============================================...</td>\n",
       "      <td>5654075</td>\n",
       "      <td>Segmented Harmonic Loss: Handling Class-Imbala...</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Data\\n3. Comp...</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11087</th>\n",
       "      <td>==============================================...</td>\n",
       "      <td>5654075</td>\n",
       "      <td>Segmented Harmonic Loss: Handling Class-Imbala...</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Data\\n3. Comp...</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088</th>\n",
       "      <td>==============================================...</td>\n",
       "      <td>5654075</td>\n",
       "      <td>Segmented Harmonic Loss: Handling Class-Imbala...</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Data\\n3. Comp...</td>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11089 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text   doc_id  \\\n",
       "0      Unsupervised Modeling of Topical Relevance in ...  1143514   \n",
       "1      Unsupervised Modeling of Topical Relevance in ...  1143515   \n",
       "2      Unsupervised Modeling of Topical Relevance in ...  1143516   \n",
       "3      Unsupervised Modeling of Topical Relevance in ...  1143517   \n",
       "4      Unsupervised Modeling of Topical Relevance in ...  1143518   \n",
       "...                                                  ...      ...   \n",
       "11084  Segmented Harmonic Loss: Handling Class-Imbala...  5654074   \n",
       "11085  Segmented Harmonic Loss: Handling Class-Imbala...  5654075   \n",
       "11086  ==============================================...  5654075   \n",
       "11087  ==============================================...  5654075   \n",
       "11088  ==============================================...  5654075   \n",
       "\n",
       "                                             paper_title  \\\n",
       "0      Unsupervised Modeling of Topical Relevance in ...   \n",
       "1      Unsupervised Modeling of Topical Relevance in ...   \n",
       "2      Unsupervised Modeling of Topical Relevance in ...   \n",
       "3      Unsupervised Modeling of Topical Relevance in ...   \n",
       "4      Unsupervised Modeling of Topical Relevance in ...   \n",
       "...                                                  ...   \n",
       "11084  Segmented Harmonic Loss: Handling Class-Imbala...   \n",
       "11085  Segmented Harmonic Loss: Handling Class-Imbala...   \n",
       "11086  Segmented Harmonic Loss: Handling Class-Imbala...   \n",
       "11087  Segmented Harmonic Loss: Handling Class-Imbala...   \n",
       "11088  Segmented Harmonic Loss: Handling Class-Imbala...   \n",
       "\n",
       "                                         paper_structure  year  \\\n",
       "0      0. abstract\\n1. Introduction\\n2. Related Resea...  2016   \n",
       "1      0. abstract\\n1. Introduction\\n2. Related Resea...  2016   \n",
       "2      0. abstract\\n1. Introduction\\n2. Related Resea...  2016   \n",
       "3      0. abstract\\n1. Introduction\\n2. Related Resea...  2016   \n",
       "4      0. abstract\\n1. Introduction\\n2. Related Resea...  2016   \n",
       "...                                                  ...   ...   \n",
       "11084  0. abstract\\n1. Introduction\\n2. Data\\n3. Comp...  2023   \n",
       "11085  0. abstract\\n1. Introduction\\n2. Data\\n3. Comp...  2023   \n",
       "11086  0. abstract\\n1. Introduction\\n2. Data\\n3. Comp...  2023   \n",
       "11087  0. abstract\\n1. Introduction\\n2. Data\\n3. Comp...  2023   \n",
       "11088  0. abstract\\n1. Introduction\\n2. Data\\n3. Comp...  2023   \n",
       "\n",
       "                                               prev_text  \\\n",
       "0                                                          \n",
       "1      The automated scoring of second-language (L2) ...   \n",
       "2      In this paper, we focus on determining the top...   \n",
       "3      Given the burden involved in manually assignin...   \n",
       "4      We show that expanding prompts using topically...   \n",
       "...                                                  ...   \n",
       "11084  In our future work, those are the aspects we w...   \n",
       "11085  We believe that would unlock the full potentia...   \n",
       "11086                                                      \n",
       "11087                                                      \n",
       "11088                                                      \n",
       "\n",
       "                   prev_section  \\\n",
       "0                                 \n",
       "1                      abstract   \n",
       "2                      abstract   \n",
       "3                      abstract   \n",
       "4                      abstract   \n",
       "...                         ...   \n",
       "11084  Conclusion & Future Work   \n",
       "11085  Conclusion & Future Work   \n",
       "11086                             \n",
       "11087                             \n",
       "11088                             \n",
       "\n",
       "                                               next_text  \\\n",
       "0      In this paper, we focus on determining the top...   \n",
       "1      Given the burden involved in manually assignin...   \n",
       "2      We show that expanding prompts using topically...   \n",
       "3      Finally, we incorporate our prompt-relevance m...   \n",
       "4      Given the increase in demand for educational t...   \n",
       "...                                                  ...   \n",
       "11084  // Compute the allowed standard deviation usin...   \n",
       "11085                                                      \n",
       "11086                                                      \n",
       "11087                                                      \n",
       "11088                                                      \n",
       "\n",
       "                   next_section label  \n",
       "0                      abstract        \n",
       "1                      abstract        \n",
       "2                      abstract        \n",
       "3                      abstract        \n",
       "4                  Introduction        \n",
       "...                         ...   ...  \n",
       "11084  Conclusion & Future Work        \n",
       "11085                                  \n",
       "11086                                  \n",
       "11087                                  \n",
       "11088                                  \n",
       "\n",
       "[11089 rows x 10 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doccano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doccano.to_csv(\"to-annotate-Fanny-120_corr.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting my annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"CLEM-120-sauvegarde_27_05/\"\n",
    "admin = pd.read_csv(f\"{data_dir}admin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184, 12)\n"
     ]
    }
   ],
   "source": [
    "anno_admin = df[~df[\"label\"].isna()]\n",
    "print(anno_admin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Multi-Task Active Learning for Neural Semantic Role Labeling on Low Resource Conversational Corpus',\n",
       "       'Text Similarity Using Word Embeddings to Classify Misinformation',\n",
       "       'Learning Taxonomy for Text Segmentation by Formal Concept Analysis',\n",
       "       '{C}-Feel-It: A Sentiment Analyzer for Micro-blogs'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_admin[\"paper_title\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(anno_admin[\"paper_title\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3568, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Human-Level Performance on Word Analogy Questions by Latent Relational\\n  Analysis',\n",
       "       'Automatic Discovery of Contextual Factors Describing Phonological Variation',\n",
       "       'Text Classification based on Multi-granularity Attention Hybrid Neural\\n  Network',\n",
       "       'Specialized Language Models using Dialogue Predictions',\n",
       "       'Mistake-Driven Mixture of Hierarchical Tag Context Trees',\n",
       "       'Factual or Satisfactory: What Search Results Are Better?',\n",
       "       'Automatic Grammar Partitioning for Syntactic Parsing',\n",
       "       'Unsupervised Discovery of Multimodal Links in Multi-image, Multi-sentence Documents',\n",
       "       'Machine Learning of User Profiles: Representational Issues',\n",
       "       'Word-Sense Distinguishability and Inter-Coder Agreement',\n",
       "       'Gathering Statistics to Aspectually Classify Sentences with a Genetic\\n  Algorithm',\n",
       "       'A statistical model for word discovery in child directed speech',\n",
       "       'Reusing a Statistical Language Model for Generation',\n",
       "       'Learning Semantic Representations for the Phrase Translation Model',\n",
       "       'Discourse Planning as an Optimization Process',\n",
       "       'Disamibiguating and Interpreting Verb Definitions',\n",
       "       'Automatic Alignment of English-Chinese Bilingual Texts of CNS News',\n",
       "       'A Corpus-Based Statistical Approach to Automatic Book Indexing',\n",
       "       'Revisiting the Role of Label Smoothing in Enhanced Text Sentiment\\n  Classification',\n",
       "       'A Comparison of Loopy Belief Propagation and Dual Decomposition for Integrated {CCG} Supertagging and Parsing',\n",
       "       'Developing a New Approach for Arabic Morphological Analysis and\\n  Generation',\n",
       "       '{L}earning {M}usic {H}elps {Y}ou {R}ead: {U}sing Transfer to Study Linguistic Structure in Language Models',\n",
       "       'PETCI: A Parallel English Translation Dataset of Chinese Idioms',\n",
       "       'Classification Analysis Of Authorship Fiction Texts in The Space Of\\n  Semantic Fields',\n",
       "       'Using Supervised Bigram-based {ILP} for Extractive Summarization',\n",
       "       'Text Understanding With Multiple Knowledge Sources: An Experiment in Distributed Parsing',\n",
       "       'Named Entity Recognition through Classifier Combination',\n",
       "       'A Memory-Sensitive Classification Model of Errors in Early Second Language Learning',\n",
       "       '3D Concept Grounding on Neural Fields',\n",
       "       'Algorithm of Segment-Syllabic Synthesis in Speech Recognition Problem',\n",
       "       'An Empirical Study on Rule Granularity and Unification Interleaving Toward an Efficient Unification-Based Parsing System',\n",
       "       'Codeswitching language identification using Subword Information Enriched Word Vectors',\n",
       "       'Eliciting Natural Speech From Non-Native Users: Collecting Speech Data for {LVCSR}',\n",
       "       'Capabilities of GPT-4 on Medical Challenge Problems',\n",
       "       'Robust stochastic parsing using the inside-outside algorithm',\n",
       "       'Learning to answer questions',\n",
       "       'Candidate Scoring Using Web-Based Measure for {C}hinese Spelling Error Correction',\n",
       "       'Machine translation using bilingual term entries extracted from parallel texts',\n",
       "       'Combining Dictionary-Based and Example-Based Methods for Natural Language Analysis',\n",
       "       'Dictionary-based Phrase-level Prompting of Large Language Models for\\n  Machine Translation',\n",
       "       'Pattern Classification In Symbolic Streams via Semantic Annihilation of\\n  Information',\n",
       "       'An Empirical Analysis of Constructing Non-restrictive {NP} Modifiers to Express Semantic Relations',\n",
       "       'Exploring Prompt-Based Methods for Zero-Shot Hypernym Prediction with\\n  Large Language Models',\n",
       "       'Training Large-Vocabulary Neural Language Models by Private Federated\\n  Learning for Resource-Constrained Devices',\n",
       "       'Noun-phrase co-occurrence statistics for semi-automatic semantic lexicon construction',\n",
       "       'Comparing rule-based and data-driven approaches to {S}panish-to-{B}asque machine translation',\n",
       "       'End-to-End Graph-Based {TAG} Parsing with Neural Networks',\n",
       "       'Probabilistic Topic and Syntax Modeling with Part-of-Speech LDA',\n",
       "       'Detecting English Writing Styles For Non-native Speakers',\n",
       "       'Extracting {C}hinese Multi-Word Units from Large-Scale Balanced Corpus',\n",
       "       'Tied Mixtures in the {L}incoln Robust {CSR}',\n",
       "       'Lattice-based Improvements for Voice Triggering Using Graph Neural\\n  Networks',\n",
       "       '{VIFIDEL}: Evaluating the Visual Fidelity of Image Descriptions',\n",
       "       'Reduce Meaningless Words for Joint Chinese Word Segmentation and\\n  Part-of-speech Tagging',\n",
       "       'Towards the Automatic Identification of Adjectival Scales: Clustering Adjectives According to Meaning',\n",
       "       'Distributed Representations of Words and Phrases and their\\n  Compositionality',\n",
       "       'Transfer Topic Modeling with Ease and Scalability',\n",
       "       'Exploring an Auxiliary Distribution Based Approach to Domain Adaptation of a Syntactic Disambiguation Model',\n",
       "       'Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{data_dir}anno2.csv\")\n",
    "anno_df = df[~df[\"label\"].isna()]\n",
    "print(anno_df.shape)\n",
    "\n",
    "anno_df[\"paper_title\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "print(len(anno_df[\"paper_title\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,)\n",
      "(15,)\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "pbs = anno_df[anno_df[\"text\"].str.contains(\"Annotator feedback\")]\n",
    "pbs_1 = pbs[pbs[\"text\"].str.contains(\"technicity /\")].paper_title\n",
    "pbs_2 = pbs[pbs[\"text\"].str.contains(\"parsing error\")].paper_title\n",
    "pbs_3 = set(pbs_1) & set(pbs_2)\n",
    "print(pbs_1.shape)\n",
    "print(pbs_2.shape)\n",
    "print(len(pbs_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "result                                1230\n",
      "contribution-AIC                       620\n",
      "context-AIC                            528\n",
      "context-AIC#rw                         225\n",
      "outline-AIC                            133\n",
      "                                      ... \n",
      "contribution-AIC#error#outline-AIC       1\n",
      "contribution-AIC#directions              1\n",
      "context-AIC#limitation#rw                1\n",
      "context-AIC#result#rw                    1\n",
      "directions#impact                        1\n",
      "Name: label, Length: 61, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_counts = anno_df[\"label\"].groupby(anno_df[\"label\"]).count().sort_values(ascending=False)\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "result                                 1230\n",
       "contribution-AIC                        620\n",
       "context-AIC                             528\n",
       "context-AIC#rw                          225\n",
       "outline-AIC                             133\n",
       "directions                              124\n",
       "limitation#result                        87\n",
       "error#result                             72\n",
       "limitation                               69\n",
       "contribution-AIC#result                  55\n",
       "error                                    54\n",
       "context-AIC#error#rw                     49\n",
       "result#rw                                44\n",
       "contribution-AIC#rw                      43\n",
       "context-AIC#error                        32\n",
       "impact                                   22\n",
       "impact#result                            18\n",
       "contribution-AIC#outline-AIC             16\n",
       "contribution-AIC#error                   15\n",
       "contribution-AIC#impact                  14\n",
       "directions#limitation                    14\n",
       "directions#result                        10\n",
       "context-AIC#impact                       10\n",
       "contribution-AIC#error#rw                 9\n",
       "error#result#rw                           9\n",
       "directions#rw                             9\n",
       "contribution-AIC#limitation               6\n",
       "contribution-AIC#error#result             4\n",
       "outline-AIC#result                        3\n",
       "contribution-AIC#result#rw                3\n",
       "limitation#rw                             3\n",
       "error#outline-AIC                         3\n",
       "limitation#result#rw                      2\n",
       "context-AIC#directions#rw                 2\n",
       "contribution-AIC#outline-AIC#result       2\n",
       "directions#error#rw                       2\n",
       "impact#rw                                 2\n",
       "error#rw                                  2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts[label_counts > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/arxiv/corpus_arxiv_IRC.pkl\", \"rb\") as f:\n",
    "    corpus_arxiv = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [p for p in corpus_arxiv.papers if p.title.startswith(\"Sentence Embeddings for Russian\")][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abstract', 'Introduction', 'Related work',\n",
       "       'Unsupervised sentence embeddings',\n",
       "       'Supervised sentence embeddings', 'Language models',\n",
       "       'Evaluation of sentence embedding models',\n",
       "       'Multiple Choice Question Answering (MCQA)',\n",
       "       'Multiple choice next sentence prediction (NSP)',\n",
       "       'Paraphrase identification (PI)', 'Dataset statistics', 'Methods',\n",
       "       'Unsupervised approach', 'Supervised approach', 'ELMo', 'BERT',\n",
       "       'Conclusion'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.content[\"section\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'n': '1', 'header': 'Introduction', 'head_n': None},\n",
       " 1: {'n': '2', 'header': 'Related work', 'head_n': None},\n",
       " 2: {'n': '2.1', 'header': 'Unsupervised sentence embeddings', 'head_n': '2'},\n",
       " 3: {'n': '2.2', 'header': 'Supervised sentence embeddings', 'head_n': '2'},\n",
       " 4: {'n': '2.3', 'header': 'Language models', 'head_n': '2'},\n",
       " 5: {'n': '2.4',\n",
       "  'header': 'Evaluation of sentence embedding models',\n",
       "  'head_n': '2'},\n",
       " 6: {'n': '3.1',\n",
       "  'header': 'Multiple Choice Question Answering (MCQA)',\n",
       "  'head_n': '3'},\n",
       " 7: {'n': '3.2',\n",
       "  'header': 'Multiple choice next sentence prediction (NSP)',\n",
       "  'head_n': '3'},\n",
       " 8: {'n': '3.3', 'header': 'Paraphrase identification (PI)', 'head_n': '3'},\n",
       " 9: {'n': '3.4', 'header': 'Dataset statistics', 'head_n': '3'},\n",
       " 10: {'n': '4', 'header': 'Methods', 'head_n': None},\n",
       " 11: {'n': '4.1', 'header': 'Unsupervised approach', 'head_n': '4'},\n",
       " 12: {'n': '4.2', 'header': 'Supervised approach', 'head_n': '4'},\n",
       " 13: {'n': '5.2', 'header': 'ELMo', 'head_n': '5'},\n",
       " 14: {'n': '5.3', 'header': 'BERT', 'head_n': '5'},\n",
       " 15: {'n': '6', 'header': 'Conclusion', 'head_n': None}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'header': 'abstract', 'subsections': {}},\n",
       " 1: {'header': 'Introduction', 'subsections': {}},\n",
       " 2: {'header': 'Related work',\n",
       "  'subsections': {0: {'header': 'Unsupervised sentence embeddings',\n",
       "    'subsections': {}},\n",
       "   1: {'header': 'Supervised sentence embeddings', 'subsections': {}},\n",
       "   2: {'header': 'Language models', 'subsections': {}},\n",
       "   3: {'header': 'Evaluation of sentence embedding models', 'subsections': {}},\n",
       "   4: {'header': 'Multiple Choice Question Answering (MCQA)',\n",
       "    'subsections': {}},\n",
       "   5: {'header': 'Multiple choice next sentence prediction (NSP)',\n",
       "    'subsections': {}},\n",
       "   6: {'header': 'Paraphrase identification (PI)', 'subsections': {}},\n",
       "   7: {'header': 'Dataset statistics', 'subsections': {}}}},\n",
       " 3: {'header': 'Methods',\n",
       "  'subsections': {0: {'header': 'Unsupervised approach', 'subsections': {}},\n",
       "   1: {'header': 'Supervised approach', 'subsections': {}},\n",
       "   2: {'header': 'ELMo', 'subsections': {}},\n",
       "   3: {'header': 'BERT', 'subsections': {}}}},\n",
       " 4: {'header': 'Conclusion', 'subsections': {}}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reorder_section_hierarchy(sections):\n",
    "\n",
    "    # initialize section hierarchy with abstract\n",
    "    d = {0: {\"header\" : \"abstract\", \"subsections\" : {}}}\n",
    "    i = 1\n",
    "\n",
    "    # add the other sections\n",
    "    for _, s in sections.items():\n",
    "        \n",
    "        if s[\"head_n\"] == None:\n",
    "\n",
    "            if s[\"n\"] != None or s[\"header\"] != \"unidentified-section\":\n",
    "                d[i] = {\"header\" : s[\"header\"],\n",
    "                        \"subsections\": {}}\n",
    "                i += 1\n",
    "            \n",
    "            else:\n",
    "                j = len(d[i-1][\"subsections\"])\n",
    "\n",
    "                if j > 0:\n",
    "                    k = len(d[i-1][\"subsections\"][j-1][\"subsections\"])\n",
    "                    if k > 0:\n",
    "                        d[i-1][\"subsections\"][j-1][\"subsections\"][k] = {\"header\" : s[\"header\"], \"subsections\" : {}}\n",
    "                    else:\n",
    "                        d[i-1][\"subsections\"][j] = {\"header\" : s[\"header\"], \"subsections\" : {}}\n",
    "                else:\n",
    "                    d[i-1][\"subsections\"][j] = {\"header\" : s[\"header\"], \"subsections\" : {}}\n",
    "        \n",
    "        else:\n",
    "            j = len(d[i-1][\"subsections\"])\n",
    "            d[i-1][\"subsections\"][j] = {\"header\" : s[\"header\"], \"subsections\" : {}}\n",
    "\n",
    "    return d\n",
    "\n",
    "reorder_section_hierarchy(p.sections)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
