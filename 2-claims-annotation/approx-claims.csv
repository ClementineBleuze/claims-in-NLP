doccano_art_id,sentence_id,text,label
0,0,In this paper we report on a research effort focusing on recognition of static features of sign formation in single sign videos.,FACT
0,1,"Three sequential models have been developed for handshape, palm orientation and location of sign formation respectively, which make use of key-points extracted via OpenPose software.",FACT
0,2,"The models have been applied to a Danish and a Greek Sign Language dataset, providing results around 96%.",POS
0,4,"One of the problems relating to sign language recognition is the lack of appropriate datasets for algorithm training, since most datasets are recorded for academic purposes and as such, they concentrate in human learning rather than machine learning.",NC
0,5,"Therefore, most data collections contain a very large number of different glosses with very few repetitions of each.",NC
0,6,This characteristic makes it very unlikely for these datasets to be used as training sets for classification algorithms in sign recognition level.,NC
0,7,"Thus, we developed a system in the direction of ""phonological"" features recognition.",FACT
0,22,"OpenPose is a software freely distributed by Carnegie Melon University, Perceptual Computing Lab (Cao et al., 2018).",NC
0,23,It is used as a tool of human body keypoints extraction from a single image or video frame.,NC
0,24,"It offers an estimation of 25 body/foot keypoints, 2x21 hand keypoints and 70 face keypoints.",NC
0,25,"In the case of a 2D video input, for each keypoint it returns a vector containing 3 elements.",NC
0,26,"The first 2 correspond to the (x,y) coordinates with reference to the upper left corner of the image.",NC
0,27,"The third is a value in the range [0,1] which is quantification of the confidence given by the program that the specific keypoint is correctly located in the frame.",NC
0,28,The novelty behind OpenPose relies on the fact that it works for more than one person per image but more importantly the keypoint analysis is not affected when part of the individual's body is out of frame.,NC
0,29,This last feature is crucial for applications on sign language videos where the signer appears above the waist level (Figure 1).,NC
1,0,Pivot translation is a useful method for translating between languages with little or no parallel data by utilizing parallel data in an intermediate language such as English.,NC
1,1,"A popular approach for pivot translation used in phrase-based or tree-based translation models combines source-pivot and pivot-target translation models into a source-target model, as known as triangulation.",NC
1,2,"However, this combination is based on the constituent words' surface forms and often produces incorrect source-target phrase pairs due to semantic ambiguity in the pivot language, and interlingual differences.",NC
1,3,This degrades translation accuracy.,NC
1,5,"Experimental results on the United Nations Parallel Corpus show the proposed method gains in all tested combinations of language, up to 2.3 BLEU points.",POS
1,6,1,NC
1,7,"In statistical machine translation (SMT) (Brown et al., 1993), it is known that translation with models trained on larger parallel corpora can achieve greater accuracy (Dyer et al., 2008).",NC
1,8,"Unfortunately, large bilingual corpora are not readily available for many language pairs, particularly those that do not include English.",NC
1,9,"One effective solution to overcome the scarceness of bilingual data is to introduce a pivot language for which paral-1 Code to replicate the experiments can be found at https://github.com/akivajp/wmt2017 lel data with the source and target languages exists (de Gispert and Mariño, 2006).",NC
1,10,"Among various methods using pivot languages, one popular and effective method is the triangulation method (Utiyama and Isahara, 2007;Cohn and Lapata, 2007), which first combines sourcepivot and pivot-target translation models (TMs) into a source-target model, then translates using this combined model.",NC
1,11,"The procedure of triangulating two TMs into one has been examined for different frameworks of SMT and its effectiveness has been confirmed both in Phrase-Based SMT (PBMT) (Koehn et al., 2003;Utiyama and Isahara, 2007) and in Hierarchical Phrase-Based SMT (Hiero) (Chiang, 2007;Miura et al., 2015).",NC
1,12,"However, word sense ambiguity and interlingual differences of word usage cause difficulty in accurately learning correspondences between source and target phrases, and thus the accuracy obtained by triangulated models lags behind that of models trained on direct parallel corpora.",NC
1,13,"In the triangulation method, source-pivot and pivot-target phrase pairs are connected as a sourcetarget phrase pair when a common pivot-side phrase exists.",NC
1,14,"In Figure 1 (a), we show an example of standard triangulation on Hiero TMs that combines hierarchical rules of phrase pairs by matching pivot phrases with equivalent surface forms.",NC
1,15,"This example also demonstrates problems of ambiguity: the English word ""record"" can correspond to several different parts-of-speech according to the context.",NC
1,16,"More broadly, phrases including this word also have different possible grammatical structures, but it is impossible to uniquely identify this structure unless information about the surrounding context is given.",NC
1,17,This varying syntactic structure will affect translation.,NC
1,18,"For example, the French verb ""enregistrer"" corresponds to the English verb ""record"", but the French noun ""dossier"" also corresponds to ""record"" -as a noun.",NC
1,19,"As a more extreme example, Chinese is a languages that does not have inflections according to the part-of-speech of the word.",NC
1,20,"As a result, even in the contexts where ""record"" is used with different parts-of-speech, the Chinese word ""记录"" will be used, although the word order will change.",NC
1,21,"These facts might result in an incorrect connection of ""[X1] enregistrer [X2]"" and ""[X2] [X1] 记录"" even though proper correspondence of ""[X1] enregistrer [X2]"" and ""[X1] dossier [X2]"" would be ""[X1] 记 录 [X2]"" and ""[X2] [X1] 记 录"".",NC
1,22,"Hence a superficial phrase matching method based solely on the surface form of the pivot will often combine incorrect phrase pairs, causing translation errors if their translation scores are estimated to be higher than the proper correspondences.",NC
1,24,"To incorporate this intuition into our models, we propose a method that considers syntactic information of the pivot phrase, as shown in Figure 1  (b).",FACT
1,25,"In this way, the model will distinguish translation rules extracted in contexts in which the English symbol string ""[X1] record [X2]"" behaves as a verbal phrase, from contexts in which the same string acts as nominal phrase.",POS
1,28,"The first places a hard restriction on exact matching of parse trees ( §4.1) included in translation rules, while the second places a softer restriction allowing partial matches ( §4.2).",NC
1,31,"In this section, first we cover SCFGs, which are widely used in machine translation, particularly hierarchical phrase-based translation (Hiero) (Chiang, 2007).",NC
1,32,"In SCFGs, the elementary structures used in translation are synchronous rewrite rules with aligned pairs of source and target symbols on the right-hand side: X → ⟨ s, t ⟩ (1) where X is the head symbol of the rewrite rule, and s and t are both strings of terminals and nonterminals on the source and target side respectively.",NC
1,33,"Each string in the right side pair has the same number of indexed non-terminals, and identically indexed non-terminals correspond to eachother.",NC
1,34,"For example, a synchronous rule could take the form of: X → ⟨X 0 of X 1 , X 1 的 X 0 ⟩ .",NC
1,35,Synchronous rules can be extracted based on parallel sentences and automatically obtained word alignments.,NC
1,36,"Each extracted rule is scored with phrase translation probabilities in both directions ϕ(s|t) and ϕ(t|s), lexical translation probabilities in both directions ϕ lex (s|t) and ϕ lex (t|s), a word penalty counting the terminals in t, and a constant phrase penalty of 1.",NC
1,37,"At translation time, the decoder searches for the target sentence that maximizes the derivation probability, which is defined as the sum of the scores of the rules used in the derivation, and the log of the language model (LM) probability over the target strings.",NC
1,39,"When using an LM, the expanded search space is further reduced based on a limit on expanded edges, or total states per span, through a procedure such as cube pruning (Chiang, 2007).",NC
1,40,"In this section, we specifically cover the rules used in Hiero.",NC
1,41,"Hierarchical rules are composed of initial head symbol S, and synchronous rules containing terminals and single kind of non-terminals X.",NC
1,42,"2 Hierarchical rules are extracted using the same phrase extraction procedure used in phrase-based translation (Koehn et al., 2003) based on word alignments, followed by a step that performs recursive extraction of hierarchical phrases (Chiang, 2007).",NC
1,43,"For example, hierarchical rules could take the form of: X → ⟨Officers, 主席团 成員⟩ (3) X → ⟨the Committee, 委员会⟩ (4) X → ⟨X 0 of X 1 , X 1 的 X 0 ⟩ .",NC
1,44,"( ) From these rules, we can translate the input sentence by derivation: S → ⟨X 0 , X 0 ⟩ ⇒ ⟨X 1 of X 2 , X 2 的 X 1 ⟩ ⇒ ⟨Officers of X 2 , X 2 主席团 成員⟩ ⇒ ⟨Officers of the Committee, 委员会 的 主席团 成員⟩ The advantage of Hiero is that it is able to achieve relatively high word re-ordering accuracy (compared to other symbolic SMT alternatives such as standard phrase-based MT) without language-dependent processing.",NC
1,45,"On the other hand, since it does not use syntactic information and tries to extract all possible combinations of rules, it has the tendency to extract very large translation rule tables and also tends to be less syntactically faithful in its derivations.",NC
1,46,"An alternative to Hiero rules is the use of synchronous context-free grammar or synchronous tree-substitution grammar (Graehl and Knight, 2004) rules that explicitly take into account the syntax of the source side (tree-to-string rules), target side (string-to-tree rules), or both (tree-to-tree rules).",NC
1,47,"Taking the example of tree-to-string (T2S) rules, these use parse trees on the source language side, and the head symbols of the synchronous rules are not limited to S or X, but instead use non-terminal symbols corresponding to the phrase structure tags of a given parse tree.",NC
1,48,"For example, T2S rules could take the form of: X NP → ⟨(NP (NNS Officers)), 主席团 成員⟩ (6) X NP → ⟨(NP (DT the) (NNP Committee)), 委员会⟩ (7) X PP → ⟨ (PP (IN of) X NP,0 ), X0 的 ⟩ (8) X NP → ⟨ (NP X NP,0 X PP,1 ), X1 X0 ⟩ .",NC
1,49,"Here, parse subtrees of the source language rules are given in the form of S-expressions.",NC
1,50,"From these rules, we can translate from the parse tree of the input sentence by derivation: X ROOT → ⟨ X NP,0 , X0 ⟩ ⇒ ⟨ (NP X NP,1 X PP,2 ), X2 X1 ⟩ ⇒ ⟨ (NP (NP (NNS Officers) X PP,2 )), X2 主席团 成員 ⟩ * ⇒ ⟨ (NP (NP (NNS Officers)) (PP (IN of) (NP (DT the) (NNP Committee)))) , 委员会 的 主席团 成員 ⟩ In this way, it is possible in T2S translation to obtain a result conforming to the source language's grammar.",NC
1,51,"This method also has the advantage the number of less-useful synchronous rules extracted by syntax-agnostic methods such as Hiero are reduced, making it possible to learn more compact rule tables and allowing for faster translation.",NC
1,59,"In the previous section, we explained about the standard triangulation method and mentioned that the pivot-side ambiguity causes incorrect estimation of translation probability and the translation accuracy might decrease.",NC
1,61,"In the following two sections, we describe two methods to distinguish pivot phrases that have syntactically different roles, one based on exact matching of parse trees, and one based on soft matching.",NC
1,62,"In the exact matching method, we first train pivotsource and pivot-target T2S TMs by parsing the pivot side of parallel corpora, and store them into rule tables as T P S and T P T respectively.",NC
1,63,"Synchronous rules of T P S and T P T take the form of X → ⟨p, s⟩ and X → ⟨ p, t ⟩ respectively, where p is a symbol string that expresses pivot-side parse subtree (S-expression), s and t express source and target symbol strings.",NC
1,64,"The procedure of synthesizing source-target synchronous rules essentially follows equations ( 11)-( 14), except using T P S instead of T SP (direction of probability features is reversed) and pivot subtree p instead of pivot phrase p. Here s and t do not have syntactic information, therefore the synthesized synchronous rules should be hierarchical rules explained in §2.2.",NC
1,65,"The matching condition of this method has harder constraints than matching of superficial symbols in standard triangulation, and has the potential to reduce incorrect connections of phrase pairs, resulting in a more reliable triangulated TM.",NC
1,68,"To prevent the problem of the reduction of coverage in the exact matching method, we also propose a partial matching method that keeps coverage just like standard triangulation by allowing connection of incompletely equivalent pivot subtrees.",FACT
1,69,"To estimate translation probabilities in partial matching, we first define weighted triangulation generalizing the equations ( 11)-( 14) of standard triangulation with weight function ψ(•): ϕ ( t|s ) = ∑ pT ∑ pS ϕ ( t| pT ) ψ ( pT | pS ) ϕ ( pS |s) , ϕ ( s|t ) = ∑ pS ∑ pT ϕ (s| pS ) ψ ( pS | pT ) ϕ ( pT |t ) , ϕ lex ( t|s ) = ∑ pT ∑ pS ϕ lex ( t| pT ) ψ ( pT | pS ) ϕ lex ( pS |s) , (19) ϕ lex ( s|t ) = ∑ pS ∑ pT ϕ lex (s| pS ) ψ ( pS | pT ) ϕ lex ( pT |t ) where pS ∈ T SP and pT ∈ P P T are pivot parse subtrees of source-pivot and pivot-target synchronous rules respectively.",NC
1,70,"By adjusting ψ(•), we can control the magnitude of the penalty for the case of incompletely matched connections.",NC
1,71,"If we define ψ( pT | pS ) = 1 when pT is equal to pS and ψ( pT | pS ) = 0 otherwise, equations ( 17)-( 20) are equivalent with equations ( 11)-( 14).",NC
1,72,"Better estimating ψ(•) is not trivial, and cooccurrence counts of pS and pT are not available.",NC
1,73,"Therefore we introduce a heuristic estimation method as follows: ψ( pT | pS) = w( pS, pT ) ∑ p∈T P T w( pS, p) • max p∈T P T w( pS, p) (21) ψ( pS| pT ) w( pS, pT ) ∑ p∈T SP w(p, pT ) • max p∈T SP w(p, pT ) (22) w( pS, pT ) =    0 (f lat( pS) ̸ = f lat( pT )) exp (−d ( pS, pT )) (otherwise) (23) d( pS, pT ) = T reeEditDistance( pS, pT ) where f lat(p) returns the symbol string of p keeping non-terminals, and T reeEditDistance( pS , pT ) is minimum cost of a sequence of operations (contract an edge, uncontract an edge, modify the label of an edge) needed to transform pS into pT (Klein, 1998).",NC
1,74,"According to equations ( 21)-( 24), we can assure that incomplete match of pivot subtrees leads d(•) ≥ 1 and penalizes such that ψ(•) ≤ 1/e d ≤ 1/e, while exact match of subtrees leads to a value of ψ(•) at least e ≈ 2.718 times larger than when using partially matched subtrees.",NC
1,92,Translating with a Hiero TM directly trained on the source-target parallel corpus without using pivot language (as an oracle).,NC
1,93,"Triangulating source-pivot and pivot-target Hiero TMs into a source-target Hiero TM using the traditional method (baseline, §3).",NC
1,94,"Triangulating pivot-source and pivot-target T2S TMs into a source-target Hiero TM using the proposed exact matching of pivot subtrees (proposed 1, §4.1).",NC
1,95,"Triangulating pivot-source and pivot-target T2S TMs into a source-target Hiero TM using the proposed partial matching of pivot subtrees (proposed 2, §4.2).",NC
1,96,The result of experiments using all combinations of pivot translation tasks for 5 languages via English is shown in Table 1.,NC
1,97,"From the results, we can see that the proposed partial matching method of pivot subtrees in triangulation outperforms the standard triangulation method for all language pairs and achieves higher or almost equal scores than proposed exact matching method.",POS
1,98,"The exact matching method also outperforms the standard triangulation method in the majority of the language pairs, but has a lesser improvement than partial matching method.",POS
1,99,In Table 2 we show the comparison of coverage of each proposed triangulated method.,NC
1,100,"From this table, we can see that the exact matching method reduces several percent in number of unique phrases while the partial matching method keeps the same coverage with surfaceform matching.",POS
1,101,We can consider that it is one of the reasons of the difference in improvement stability between the partial and exact matching methods.,POS
1,102,We show an example of a translated sentences for which pivot-side ambiguity is resolved in the the syntactic matching methods:,NC
1,107,"Recent results (Firat et al., 2016;Johnson et al., 2016) have found that neural machine translation systems can gain the ability to perform translation with zero parallel resources by training on multiple sets of bilingual data.",NC
1,108,"However, previous work has not examined the competitiveness of these methods with pivot-based symbolic SMT frameworks such as PBMT or Hiero.",NC
1,109,"In this section, we compare a zero-shot NMT model (detailed parameters in  Johnson et al.",NC
1,110,"To train and evaluate NMT models, we adopt NMTKit.",NC
1,111,"7 From the results we see the tendency of NMT that directly trained model achieves high translation accuracy even for translation between languages of different families, on the other hand, the accuracy is drastically reduced in the situation when there is no sourcetarget parallel corpora for training.",POS
1,113,"In our setting, while bilingually trained NMT systems were competitive or outperformed Hiero-based models, zeroshot translation is uniformly weaker.",POS
1,115,"Thus, we can posit that while zero-shot translation has demonstrated reasonable results in some settings, successful zero-shot translation systems are far from trivial to build, and pivot-based symbolic MT systems such as PBMT or Hiero may still be a competitive alternative.",POS
1,116,"In this paper, we have proposed a method of pivot translation using triangulation with exact or partial matching method of pivot-side parse subtrees.",FACT
1,117,"In experiments, we found that these triangulated models are effective in particular when allowing partial matching.",POS
1,119,"Therefore in the future, we plan to explore more refined estimation methods that utilize machine learning.",PROSP
2,0,"Text-based adventure games provide a platform on which to explore reinforcement learning in the context of a combinatorial action space, such as natural language.",NC
2,1,We present a deep reinforcement learning architecture that represents the game state as a knowledge graph which is learned during exploration.,FACT
2,2,"This graph is used to prune the action space, enabling more efficient exploration.",POS
2,4,"In experiments using the TextWorld framework, we show that our proposed technique can learn a control policy faster than baseline alternatives.",POS
2,6,Natural language communication can be used to affect change in the real world.,NC
2,7,"Text adventure games, in which players must make sense of the world through text descriptions and declare actions through natural language, can provide a stepping stone toward more real-world environments where agents must communicate to understand the state of the world and indirectly affect change in the world.",NC
2,8,"Text adventure games are also useful for developing and testing reinforcement learning algorithms that must deal with the partial observability of the world (Narasimhan et al., 2015;He et al., 2016).",NC
2,9,"In text adventure games, the agent receives an incomplete textual description of the current state of the world.",NC
2,10,"From this information, and previous interactions with the world, a player must determine the next best action to take to achieve some quest or goal.",NC
2,11,The player must then com-pose a textual description of the action they intend to make and receive textual feedback of the effects of the action.,NC
2,12,"Formally, a text-based game is a partially observable Markov decision process (POMDP), represented as a 7-tuple of S, T, A, Ω, O, R, γ representing the set of environment states, conditional transition probabilities between states, words used to compose text commands, observations, observation conditional probabilities, reward function, and the discount factor respectively (Côté et al., 2018).",NC
2,13,"In text-based games, the agent never has access to the true underlying world state and has to reason about how to act in the world based only on the textual observations.",NC
2,14,"Additionally, the agent's actions must be expressed through natural language commands, ensuring that the action space is combinatorially large.",NC
2,15,"Thus, text-based games pose a different set of challenges than traditional video games.",NC
2,16,Text-based games require a greater understanding of previous context to be able to explore the state-action space more effectively.,NC
2,17,"Such games have historically proven to be difficult to play for AI agents, and the more complex variants such as Zork still remain firmly out of the reach of existing approaches.",NC
2,19,"First, we show that a state representation in the form of a knowledge graph gives us the ability to effectively prune an action space.",POS
2,20,A knowledge graph captures the relationships between entities as a directed graph.,NC
2,24,"Finally, we take initial steps toward framing the POMDP as a questionanswering (QA) problem wherein a knowledgegraph can be used to not only prune actions but to answer the question of what action is most appropriate.",FACT
2,25,"Previous work has shown that many NLP tasks can be framed as instances of questionanswering and that we can transfer knowledge between these tasks (McCann et al., 2017).",NC
2,26,We show how pre-training certain parts of our KG-DQN network using existing QA methods improves performance and allows knowledge to be transferred from different games.,POS
2,28,Results show that incorporating a knowledge-graph into a reinforcement learning agent results in converges to the highest reward more than 40% faster than the best baseline.,POS
2,29,"With pre-training using a questionanswering paradigm, we achieve this fast convergence rate while also achieving high quality quest solutions as measured by the number of steps required to complete the quests.",POS
2,49,"In this section we introduce our knowledge graph representation, action pruning and deep Qnetwork architecture.",NC
2,50,"In our approach, our agent learns a knowledge graph, stored as a set of RDF triples, i.e.",NC
2,51,"3-tuples of subject, relation, object .",NC
2,52,"These triples are extracted from the observations using Stanford's Open Information Extraction (OpenIE) (Angeli et al., 2015).",NC
2,53,OpenIE is not optimized to the regularities of text adventure games and there are a lot of relations that can be inferred from the typical structure of descriptive texts.,NC
2,54,"For example, from a phrase such as ""There is an exit to the north"" one can infer a has relation between the current The knowledge graph is updated after every agent action (see Figure 1).",NC
2,55,The update rules are defined such that there are portions of the graph offering short and long-term context.,NC
2,56,"A special node-designated ""you""-represents the agent and relations out of this node are updated after every action with the exception of relations denoting the agent's inventory.",NC
2,57,Other relations persist after each action.,NC
2,59,They are: • Linking the current room type (e.g.,NC
2,60,"""basement"", ""chamber') to the items found in the room with the relation ""has"", e.g.",NC
2,61,"chamber, has, bed stand • Extracting information regarding entrances and exits and linking them to the current room, e.g.",NC
2,62,"basement, has, exit to north • Removing all relations relating to the ""you"" node with the exception of inventory every action, e.g.",NC
2,63,"you, have, cubical key • Linking rooms with directions based on the action taken to move between the rooms, e.g.",NC
2,64,"chamber, east of, basement after the action ""go east"" is taken to go from the basement to the chamber All other RDF triples generated are taken from OpenIE.",NC
2,65,"The number of actions available to an agent in a text adventure game can be quite large: A = O(|V | × |O| 2 ) where V is the number of action verbs, and O is the number of distinct objects in the world that the agent can interact with, assuming that verbs can take two arguments.",NC
2,66,"Some actions, such as movement, inspecting inventory, or observing the room, do not have arguments.",NC
2,67,The knowledge graph is used to prune the combinatorially large space of possible actions available to the agent as follows.,NC
2,68,"Given the current state graph representation G t , the action space is pruned by ranking the full set of actions and selecting the top-k. Our action scoring function is: • +1 for each object in the action that is present in the graph; and • +1 if there exists a valid directed path between the two objects in the graph.",NC
2,69,We assume that each action has at most two objects (for example inserting a key in a lock).,NC
2,103,"Previous work has shown that many NLP tasks can be framed as instances of question-answering and that in doing so, one can transfer knowledge between these tasks (McCann et al., 2017).",NC
2,104,"In the abstract, an agent playing a text adventure game can be thought of as continuously asking the question ""What is the right action to perform in this situation?""",NC
2,105,"When appropriately trained, the agent may be able to answer the question for itself and select a good next move to execute.",NC
2,109,"The data for the pre-training approach is generated using an oracle, an agent capable of finishing a game perfectly in the least number of steps possible.",NC
2,110,"Specifically, the agent knows exactly what action to take given the state observation in order to advance the game in the most optimal manner possible.",NC
2,111,"Through this process, we generate a set of traces consisting of state observations and actions such that the state observation provides the context for the implicit question of ""What action should be taken?""",NC
2,112,and the oracle's correct action is the answer.,NC
2,114,The weights from the SB-LSTM in the document encoder in the DrQA system are then used to initialize the weights of the SB-LSTM.,NC
2,115,"Similarly, embedding layers of both the graph and the LSTM action encoder are initialized with the weights from the embedding layer of same document encoder.",NC
2,116,"Since the DrQA embedding layers are initialized with GloVe, we are transferring word embeddings that are tuned during the training of the QA architecture.",NC
2,117,The game traces used to train the questionanswering come from a set of games of the same domain but have different specific configurations of the environment and different quests.,NC
2,118,"We use the TextWorld framework (Côté et al., 2018), which uses a grammar to generate random worlds and quests.",NC
2,119,"The types of rooms are the same, but their relative spatial configuration, the types of objects, and the specific sequence of actions needed to complete the quest are different each time.",NC
2,120,This means that the agent cannot simply memorize quests.,NC
2,121,"For pre-training to work, the agent must develop a general question-answering competence that can transfer to new quests.",NC
2,151,"G1 ← updateGraph(G0, o1); A1 ← pruneActions(A, G0) Section 3.2 6: for step t=1 to T do 7: if random() < 1 then 3.",NC
2,152,"Pruned actions with pre-training (full) Our models use 50-dimensional word embeddings, 2 heads on the graph attention layers, minibatch size of 16, and perform a gradient descent update every 5 steps taken by the agent.",NC
2,153,"All models are evaluated by observing the (a) time to reward convergence, and (b) the average number of steps required for the agent to finish the game with = 0.1 over 5 episodes after training has completed.",NC
2,154,Following Narasimhan et al.,NC
2,155,"(2015) we set to a non-zero value because text adventure games, by nature, require exploration to complete the quests.",NC
2,156,All results are reported based on multiple independent trials.,NC
2,157,"For the large set of games, we only perform experiments on the best performing models found in the small set of games.",NC
2,158,"Also note that for experiments on large games, we do not display the entire learning curve for the LSTM-DQN baseline, as it converges significantly more slowly than KG-DQN.",NC
2,159,We run each experiment 5 times and average the results.,NC
2,160,"Additionally, human performance on the both the games was measured by counting the number of steps taken to finish the game, with and without instructions on the exact quest.",NC
2,161,"We modified Textworld to give the human players reward feedback in the form of a score, the reward function itself is identical to that received by the deep reinforcement learning agents.",NC
2,162,"In one variation of this experiment, the human was given instructions on the potential sequence of steps that are required to finish the game in addition to the reward in the form of a score and in the other variation, the human received no instructions.",NC
2,163,Recall that the number of steps required to finish the game for the oracle agent is 5 and 10 for the small and large maps respectively.,NC
2,164,It is impossible to achieve this ideal performance due to the structure of the quest.,NC
2,165,The player needs to interact with objects and explore the environment in order to figure out the exact sequence of actions required to finish the quest.,NC
2,166,"To help benchmark our agent's performance, we observed people unaffiliated with the research playing through the same TextWorld ""home"" quests as the other models.",NC
2,169,Also note that none of the deep reinforcement learning agents received instructions.,NC
2,170,"On both small and large maps, all versions of KG-DQN tested converge faster than baselines (see Figure 3 for the small game and Figure 4 for the large game).",POS
2,172,KG-DQN converges 40% faster than baseline on the small game; both KG-DQN and the LSTM-DQN baseline reaches the maximum reward of five.,POS
2,174,"agents achieve the maximum reward of 10, and the LSTM-DQN requires more than 300 episodes to converge at the same level as KG-DQN.",POS
2,175,"Since all versions of KG-DQN converge at approximately the same rate, we conclude that the knowledge graph-i.e., persistent memory-is the main factor helping convergence time since it is the common element across all experiments.",POS
2,176,"After training is complete, we measure the number of steps each agent needs to complete each quest.",NC
2,177,Full KG-DQN requires an equivalent number of steps in the small game (Table 3) and in the large game (Table 4).,POS
2,179,The ablated versions of KG-DQN-unpruned KG-DQN and non-pre-trained KG-DQN-require many more steps to complete quests.,POS
2,181,"From these results, we conclude that the pre-training using our questionanswering paradigm is allowing the agent to find a general understanding of how to pick good actions even when the agent has never seen the final",POS
2,182,We have shown that incorporating knowledge graphs into an deep Q-network can reduce training time for agents playing text-adventure games of various lengths.,POS
2,183,We speculate that this is because the knowledge graph provides a persistent memory of the world as it is being explored.,POS
2,185,Action pruning using the knowledge graph and pre-training of the embeddings used in the deep Q-network result in shorter action sequences needed to complete quests.,POS
2,187,"That is, at every step, the agent is asking-and trying to answer-what is the most important thing to try.",NC
3,2,"In this paper, we remove the discrepancy between training and test phases by considering, in the training of MMA, the interactions across multiple heads that will occur in the test time.",FACT
3,3,"Specifically, we derive the expected alignments from monotonic attention by considering the boundaries of other heads and reflect them in the learning process.",FACT
3,5,"Online automatic speech recognition (ASR), which immediately recognizes incomplete speeches as humans do, is emerging as a core element of diverse ASR-based services such as teleconferences, AI secretaries, or AI booking services.",NC
3,6,"In particular, in these days, where the untact service market is rapidly growing due to the recent global outbreak of COVID-19, the importance of providing more realistic services by reducing latency is also growing.",NC
3,7,"However, of course, online ASR models [1,2] targeting real-time inference have concerns about performance degradation compared to traditional Copyright 2021 IEEE.",NC
3,8,"Published in ICASSP 2021 -2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), scheduled for 6-11 June 2021 in Toronto, Ontario, Canada.",NC
3,9,Personal use of this material is permitted.,NC
3,10,"However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works, must be obtained from the IEEE.",NC
3,11,"Contact: Manager, Copyrights and Permissions / IEEE Service Center / 445 Hoes Lane / P.O.",NC
3,12,"Box 1331 / Piscataway, NJ 08855-1331, USA.",NC
3,13,Telephone: + Intl.,NC
3,14,908-562-3966.,NC
3,15,"DNN-HMM hybrid models with pre-segmented alignments or offline models based on Transformer [3,4], which is the state-of-the-art in many sequence-sequence tasks nowadays.",NC
3,16,"In order to overcome this performance-delay trade-off, several attempts have been made to learn or find monotonic alignments between source and target via attention mechanism [5,6,7,8,9].",NC
3,17,"Especially, Monotonic Attention (MA), and Monotonic Chunkwise Attention (MoChA) [8,9] learn alignments in an end-to-end manner by calculating differentiable expected alignments in training phase and shows comparable performance to models using an offline attention.",NC
3,18,"Very recently, motivated by the success of Transformer architecture even in ASR [4], direct attempts to make it online by applying these learning alignment strategies to Transformer, not on the traditional RNN based models, are emerging [10,11,12,13].",NC
3,19,"Among others, Monotonic Multihead Attention (MMA) [14] converts each of multi-heads in Transformer to MA and exploits the diversity of alignments from multiple heads.",NC
3,20,"In order to resolve the issue of MMA that has to wait for all multi-heads to decode, HeadDrop [15] drops heads stochastically in the training stage.",NC
3,21,"[15] also proposed to use head-synchronous beam search decoding (HSD) which limits the difference in selection time between the heads in the same layer only in the inference phase, but resulting in the discrepancy between training and inference.",NC
3,22,"In this paper, we propose an algorithm, called ""Mutually-Constrained Monotonic Multihead Attention"" (MCMMA), that enables the model to learns alignments along with other heads by modifying expected alignments to consistently bring constrained alignments of the test time to the training time.",FACT
3,23,"By bridging the gap between the training and the test stages, MCMMA effectively improves performance.",POS
3,24,"We first review the main components which our model is based on, including monotonic attention, monotonic multihead attention, and HeadDrop with head-synchronous beam search decoding in Subsection 2.1, 2.2, and 2.3, respectively.",NC
3,25,MA [8] is the attention-based encoder-decoder RNN model which is able to learn monotonic alignments in an end-toend manner.,NC
3,26,"The encoder processes input sequence x = (x 1 , .",NC
3,27,", x T ) to encoder states h = (h 1 , .",NC
3,28,"At i-th arXiv:2103.14302v1 [cs.CL] 26 Mar 2021 output step, the decoder sequentially inspects encoder states from the last selected one in the previous step and decide whether to take it or not to produce current output.",NC
3,29,"The probability p i,j to select h j for i-th output is computed as e i,j = MonotonicEnergy (s i-1 , h j ) and p i,j = σ (e i,j ) where s i-1 is a decoder state of (i -1)-th output step.",NC
3,30,"If h j is selected, the RNN decoder takes it as context c i = h j with the previous decoder state s i-1 and output y i-1 to compute current state.",NC
3,31,"To make alignment learnable in the training phase, a hard selected context above is replaced by a expected context c i = L j=1 α i,j h j , the weighted sum of h with the expected alignment α computed as α i,j = p i,j j k=1 α i-1,k j-1 l=k (1 -p i,l ) .",NC
3,32,(1) MoChA [9] extends MA by performing soft attention over fixed-length chunks of encoder states preceding the position chosen by a MA mechanism.,NC
3,33,MMA [14] applies MA mechanism to Transformer [3] by making each of the multiple heads of decoder-encoder attention learn monotonic alignments as MA.,NC
3,34,MMA borrows scaled dot-product operation of Transformer.,NC
3,35,"Although MMA leads to considerable improvement in online machine translation, the latency is still high since the model should wait until all heads to select their contexts for every decoding step.",NC
3,36,"Thus, the authors of [14] proposed to use additional regularization to minimize the variance of expected alignments of all heads to reduce the latency.",NC
3,37,"Nevertheless, this approach does not model the dependency between heads explicitly.",NC
3,38,HeadDrop [15] is the method that drops each head stochastically for each individual to learn alignments correctly.,NC
3,39,This approach improves boundary coverage and streamability of MMA [15].,NC
3,40,"Head-synchronous decoding (HSD) [15] is the inference algorithm, where the leftmost head forces slow heads, which fail to choose any frames within waiting time threshold , to choose the rightmost of selected frames.",NC
3,41,"However, HSD considers alignments of other heads and only at the test phase.",NC
3,82,Boundary coverage and streamability [15] is the metric to evaluate whether the model is streamable.,NC
3,83,"However, it does not well suit with the MMA mechanism since predicting each output is done when the last head completes the selection.",NC
3,84,"Instead of the above, we utilize the relative latency (ReL) by  We note that ReL is the natural extension of the existing latency metric.",NC
3,85,[23] provides the utterance-level latency which is the same with ReL when replacing the boundaries produced by the reference model with the gold boundaries in the definition of relative latency.,NC
3,86,"However, acquiring the gold boundaries is complicated, so we utilize the boundaries of MMA without HSD as the reference boundaries.",NC
3,87,We present the results of our approach with baselines in table 1.,NC
3,88,"We train our model with = 10 and = 12 on Librispeech and AISHELL-1, respectively and evaluate it with = 8 to make the setting same with [15].",NC
3,89,Our model shows better performance than the baselines including HeadDrop [15].,POS
3,90,"Especially, we reduce 2.2% of WER than HeadDrop [15] on testother in Librispeech.",POS
3,91,These results show that training alignments together with other heads' selection time improves the performance.,POS
3,92,One very interesting and unexpected point we observed in table 1 is that the WER of Transformer is higher than online models (except for MMA) in test-clean experiments.,POS
3,93,We con- jecture that online attention mechanisms are beneficial to exploit locality since they strongly force models to attend small chunks of an input sequence from the training phase.,POS
3,94,"We provide trade-off graphs between quality and relative latency in fig 2 through adjusting ∈ {6, 8, 10, 12}, and ∈ {4, 8, 12} in inference time for Librispeech, and AISHELL-1, respectively.",NC
3,95,"To calculate relative latency with time units, we multiply frame-level relative latency by 80ms since the reducing factor of frames is 8 and the shifting size is 10ms.",NC
3,96,Our model outperforms baselines and is still faster than MMA without HSD even though there are small increases in relative latency compared to HeadDrop except for the case with extremely small text .,POS
3,97,The performance degradation with small occurs since accessible input information is very limited and training models with small restricts head diversity severely.,NC
3,98,"Thus, this result suggests that the practitioners should avoid choosing small .",POS
3,100,Our approach improves performance with only a small increase in latency by regularizing the intra-layer difference of boundaries effectively from the training phase.,POS
4,0,This paper develops a Case/case-theoretic acco unt for what Merchant (2008) calls voice mism atch in ellipsis constructions of English.,FACT
4,1,Merch ant (ibid.),NC
4,2,"reports that VP ellipsis as an elision o f smaller size VP allows voice mismatch, but Ps eudogapping and Sluicing as an elision of bigge r size vP/TP do not.",NC
4,4,"Given the asymmetry i n the size of ellipsis in tandem with discourse re lations, we argue that since Accusative as well as Nominative Case is checked outside VP, the VP to be elided can meet the identity condition on ellipsis with its antecedent VP as the object element in the former and the subject one in the latter or vice versus have not been Case-checke d yet, thus being identical in terms of Case-feat ure at the point of derivation building a VP.",POS
4,5,"According to Merchant (2008), VP ellipsis (VPE) in English allows mismatch between the voice of an elided constituent and that of its antecedent, whereas Sluicing and Pseudogapping do not.",NC
4,6,This holds for either direction of voice alternation between an elided constituent and its antecedent.,NC
4,7,"This is illustrated in (1) through (3) (( 1) and (3), taken from Merchant (2008: 169-170); (2), taken from Merchant (2013: 81)).",NC
4,8,"(1) Active antecedent, passive ellipsis (VPE) a.",NC
4,9,The janitor must <remove the trash 1 > whenever it is apparent that [it] 1 should be [ VP removed t 1 ].,NC
4,10,"Passive antecedent, active ellipsis (VPE) b.",NC
4,11,[The system] 1 can be <used t 1 > by anyone who wants to [ VP use it 1 ].,NC
4,12,"(2) Sluicing (TPE) *<Joe was murdered t>, but we don't know [who] 1 [ TP t 1 murdered Joe].",NC
4,13,"(3) Pseudogapping *Roses were brought by some, and others did bring lilies.",NC
4,15,"The next section reviews Merchant's (2007Merchant's ( , 2008) ) analysis of voice mismatch in ellipsis by postulating the functional category of Voice in the syntactic structure of a clause, and the subsequent rebuttal of Merchant's analysis by Tanaka (2011).",NC
4,16,"Departing from the empirical generalization made by Tanaka, section 3 proposes a not Voice-but Case/case-theoretic account for apparent voice mismatch in VP ellipsis and Pseudogapping.",NC
4,17,Section 4 investigates argument structure mismatch and its interaction with Pseudogapping.,NC
4,18,Section 5 explores a Case/casetheoretic account for voice mismatch in Sluicing.,NC
4,19,Section 6 wraps up with a conclusion.,NC
4,20,Consider the examples in (4) and (5).,NC
4,22,"Unlike in the ellipsis structure of (4), voice mismatch is permissible in the non-elliptical structure of ( 5).",NC
4,23,"(4) *Roses were brought by some, and others did bring roses, too.",NC
4,24,"(5) Roses were brought by some, and others brought roses, too.",NC
4,25,Merchant's (2008) explanation for the contrast in voice mismatch between VP ellipsis and Pseudogapping in (1) and (2) hinges on the following assumptions: (6) Syntactic isomorphism is required for ellipsis.,NC
4,26,(7) The v head hosts the feature [voi(ce)] responsible for active versus passive voice.,NC
4,27,"(8) VP ellipsis deletes a VP, but Pseudogapping deletes a vP.",NC
4,28,"Like most previous studies on ellipsis, Merchant first takes ellipsis to be subject to a syntactic identity condition demanding that an elided constituent be identical syntactically to its antecedent.",NC
4,29,"Given syntactic isomorphism for ellipsis, the uneven distribution in voice mismatch between VP ellipsis and Pseudogapping in (1) and (2) follows from the two specific components in ( 7) and (8).",NC
4,30,Merchant (2008) argues that Pseudogapping elides a vP rather than a VP.,NC
4,31,The elided constituent in Pseudogapping then includes the little v that has the value of the feature [voi] determined either as active or passive.,NC
4,32,"When the ellipsis and the antecedent clauses are not identical in voice, Pseudogapping won't meet identity in ellipsis, hence being ruled out.",NC
4,33,"In VPE, however, the little v hosting the feature [voi] is not included in the VPE site.",NC
4,34,"In other words, the head v is external to the VPE site.",NC
4,35,"Thus, voice mismatch does not matter for VP ellipsis, not being able to exert its effects on identity in ellipsis.",NC
4,36,"Though Merchant (2008) provides an effective account for the distributional generalization in voice mismatch between VP ellipsis and Pseudogapping, his account confronts several problems.",NC
4,37,The first problem concerns the size of ellipsis for Pseudogapping.,NC
4,38,"The previous works on Pseudogapping such as Jayaseelan (1990), Lansnik (1999: chap 3), Levin (1978), andTakahashi (2004) argue that Pseudogapping is an operation of VP ellipsis rather than vP ellipsis, as typical examples of Pseudogapping in ( 9) and (10) show.",NC
4,39,"(9) *Roses were brought by some, and others did bring lilies.",NC
4,40,"(10) *Some brought roses, and lilies were brought by others.",NC
4,41,Merchant (2008) in fact brings forth the examples in ( 11) and ( 12) to support his thesis that Pseudogapping applies to a larger category than VP ellipsis.,NC
4,42,The judgements reported in ( 11) and ( 12) are Merchant's.,NC
4,43,"(11) Many of them have turned in their assignment already, but they haven't yet all.",NC
4,44,"(12) Many of them have turned in their assignment already, but they haven't yet (*all) their paper (*all).",NC
4,45,Merchant assumes with Sportiche (1988) that a floating quantifier like all can be dropped off in the specifier position of any functional category it has moved through.,NC
4,46,"All in (11) presumably moves through [spec, vP].",NC
4,47,"Since the constituent elided in VP ellipsis, by assumption, is smaller than vP and all is external to ellipsis site, the sentence in ( 11) is received as acceptable.",NC
4,48,"By contrast, the sentence in (12) involving Pseudogapping, according to Merchant, is ruled out because Pseudogapping elides a vP that includes the position all moves through; thus, the floating quantifier all should have been included in the portion elided by Pseudogapping.",NC
4,49,"Tanaka (2011), however, consulted three native speakers to verify the acceptability of ( 13) and ( 14), which are identical to (11) and ( 12), but except for one modification by placing the aspectual adverb yet not before but after the floating quantifier all: (13) Many of them have turned in their assignment already, but they haven't all yet.",NC
4,50,"(14) ?Many of them have turned in their assignment already, but they haven't all yet their paper None of the native speakers that Tanaka consulted ruled out these two sentences.",NC
4,51,Tanaka (2011) takes the acceptability of these examples to indicate that both VP ellipsis and Pseudogapping may delete a VP.,NC
4,52,"It may also be the case that all in (13) and ( 14) occupies a position outside a vP, in which case the entire vP can be deleted (See Tanaka (2011: 473)).",NC
4,53,"Second, Merchant (2008: 170) notes that such Pseudogapping examples with voice mismatch as (15)-( 16) are unacceptable.",NC
4,54,"(15) *Roses were brought by some, and others did bring lilies.",NC
4,55,"( 16) *Some brought roses, and lilies were brought by others.",NC
4,56,"Importantly, however, Tanaka (2011: 475) reports that their VP ellipsis counterparts in (17)-( 18) are also unacceptable: (17) *Roses were brought by some boys, and some girls did bring roses, too.",NC
4,57,"(18) *Some brought roses, and lilies were brought by some, too.",NC
4,58,"Since ungrammatical Pseudogapping examples remain to be ungrammatical even under VP ellipsis, it may safely be concluded that there is no asymmetry between the two constructions in terms of the size of ellipsis.",NC
4,59,"Tanaka (2011: 476)  The additional pairs in ( 21)-( 22), which are taken from Tanaka (2011: 476), do not display asymmetry in voice mismatch between Pseudogapping and VP ellipsis: (21) Actually, I have implemented a computer system with a manager, but it doesn't have to be implemented with a manager.",NC
4,60,"( 22) ?Actually, I have implemented a computer system with a manager, but it should have been implemented by a computer technician.",NC
4,61,"Third, the additional rebuttal of Merchant's (2008)  (big, resemblance, mismatched) c. because she told me who.",NC
4,62,"(big, cause/effect, matched) d. because she told me by who.",NC
4,63,"(big, cause/effect, mismatched) e. and Lisa also knows that someone did.",NC
4,64,"(small, resemblance, matched) f. and Lisa also knows that it was.",NC
4,65,"(small, resemblance, mismatched) g. because she told me that someone did.",NC
4,66,"(small, cause/effect, matched) h. because she told me that it was.",NC
4,67,"(small, cause/effect, mismatched) The results of the experiment (cited from SanPietro et al.",NC
4,68,"(2012: 310)) are: first, the interaction between ellipsis size (small VP vs. big TP) and discourse relations (resemblance vs. cause/effect relations, which we will turn to shortly in the next section) shows that in the small elliptical conditions only, cause/effect conditions (conditions (g) and (h) of ( 23); mean rating of 4.94 out of the highest score 7) were rated higher than resemblance conditions (conditions (e) and (f) above; mean rating of 4.32).",NC
4,69,"Second, most critically, pairwise comparisons show a significant difference (p < .001) between the mismatched cause/effect condition (condition (h) above; mean rating of 4.42) and the mismatched resemblance condition (condition (f) above; mean rating of 3.69), but only in the VP ellipsis conditions.",NC
4,70,"No effect of coherence (i.e., discourse relation) is found in the big elliptical conditions (conditions (a-d) above).",NC
4,71,"These results of the experiment show that voice mismatch in VP ellipsis is not always permissible, unlike what Merchant (2008) argues.",NC
4,72,"Instead, discourse relations are a determining factor in ruling in or out voice mismatch in VP ellipsis.",NC
4,75,"In the next section, building on Kehler's (2000) insight into discourse relations between ellipsis and antecedent clauses, we argue that sizes of ellipsis for both VP ellipsis and Pseudogapping interact with such discourse relations.",NC
4,76,3 Towards an analysis Kehler (2000) argues that sentences/clauses in a discourse are linked together by (discourse) coherence relations.,NC
4,77,Coherence refers to the ways in which the hearer attempts to link together the sentences/clauses that form a discourse (Kehler (2000: 539)).,NC
4,78,"For example, in a discourse, the hearer does not interpret the two sentences in (24a) to be unrelated, but he/she infers that Mary is upset at Bill because Bill forgot her birthday.",NC
4,79,"Because it is more difficult to infer how the two sentences in (24b) could be linked together, the discourse is less coherent.",NC
4,80,(24) a. Mary is upset with Bill.,NC
4,81,Bill forgot her birthday.,NC
4,82,b. Mary is upset with Bill.,NC
4,83,#Jupiter has 63 moons.,NC
4,84,Kehler (2000) discusses two types of coherence relations relevant to ellipsis: resemblance and cause/effect.,NC
4,85,"When a resemblance relation holds, the entities or properties in the elided material are interpreted as in some way parallel to those in its antecedent.",NC
4,86,"For example, in (25), John and Bill are the entities, and they are parallel in that they both went to the store.",NC
4,87,(25) John went to the store because Bill did <go to the store>.,NC
4,88,"There is a class of connectives and adverbs which serve as markers for the resemblance coherence relation, including and, also, as well, too, likewise, etc.",NC
4,89,"When a cause/effect relation holds, by contrast, the proposition expressed by the elided material has some sort of causal relationship to the proposition in the antecedent.",NC
4,90,"For example, in (26), the fact that Bill went to the store is the cause for John to do so.",NC
4,91,(26) John went to the store because Bill did <go to the store>.,NC
4,92,"As with the resemblance relations, certain adverbs and connectives regularly occur in cause/effect sentences which can serve as markers of this coherence relation, including but, even though, because, as a result, therefore, so, consequently, etc.",NC
4,93,"Kehler (2000) argues that when there is a voice mismatch in ellipsis, sentences where there is a cause/effect relation between antecedent and ellipsis sites are licit, while sentences where there is a resemblance relation are illicit.",NC
4,94,"The contrast can be found in (27a) and (27b) below, where the acceptable (27a) contains a cause/effect relation, and the unacceptable (27b) contains a resemblance relation.",NC
4,95,"In March, four fireworks manufacturers asked that the decision be reversed, and on Monday, the ICC did <reverse the decision>.",NC
4,96,(Dalrymple et al.,NC
4,97,"* This problem was looked into by John, and Bob did <look into the problem>, too.",NC
4,98,"(Kehler 2000: 551, example 34) Kehler (2000: 543-46) ascribes this contrast to the fact that cause/effect relations require only semantic identity, which tolerates voice mismatch, while resemblance relations require syntactic identity in addition to semantic identity.",NC
4,102,"First, a parallel resemblance relation relates two clauses/sentences; the ellipsis clause and its antecedent clause.",NC
4,103,"The proposition of the former clause holds true, in a parallel fashion as that of the latter clause does.",NC
4,104,"Now the wisdom we has about the syntax of a clause is that a small clause vP, as a proxy of a full clause CP/TP, may have a parallel relation with another small clause vP.",NC
4,105,This is exactly what happens in the case of vP ellipsis when a resemblance relation holds.,NC
4,106,The ellipsis of a vP is the only option to respect the full clause-tosmall clause correspondence in the case of a resemblance relation between the ellipsis and the corresponding antecedent clauses.,NC
4,107,"When a cause/effect relation holds, it also relates two clauses.",NC
4,108,"However, the two clauses involved are non-parallel.",NC
4,109,"Thus, no full clause-to-small clause correspondence is called for.",NC
4,110,"Since the two clauses involved are non-parallel, one clause may relate not to another clause but to a constituent inside it.",NC
4,111,"In other words, it is possible that one clause may, for example, modify the constituent inside another clause.",NC
4,112,"This is the reason that VP ellipsis instead of vP ellipsis is permissible when a cause/effect relation holds, even though two clauses are related.",NC
4,113,"The cause/effect, non-parallel relation gets away with not respecting the full clause-to-small clause correspondence.",NC
4,114,"Given the asymmetry between resemblance and cause/effect relations in terms of the size of ellipsis, we are now in a position to account for their contrast in voice mismatch when a verbal domain (VP or vP) undergoes ellipsis.",NC
4,119,"Simply stated, Case/case mismatch is not allowed between a survivor/remnant and its antecedent constituent (or correlate).",NC
4,120,This means that in the following structure one argument element A inside the ellipsis constituent and its correlate A' inside the antecedent constituent are required to be identical in terms of Case/case feature.,NC
4,121,"A ] Now a question is what happens when A and A' are base-generated inside the ellipsis and antecedent constituents, but they participate in Case-checking relation outside them.",NC
4,122,"We suppose that this situation holds exactly in such examples as ( 19) and ( 20), repeated below ( 31) and ( 32): (31) ?My problem will be looked into by Tom, but he won't look into yours.",NC
4,123,"PG (32) This problem was to have been looked into, but obviously nobody did look into this problem.",NC
4,124,"VPE As stated in (29b), in English either Nominative or Accusative Case is checked outside VP (cf.",NC
4,125,Chomsky (1995)).,NC
4,126,"Thus, if in ( 31) and ( 32) the ellipsis clause has a cause/effect relation with its antecedent clause and what is elided is VP (as stated in (29c)), the apparent Case mismatch between the object element in the ellipsis clause and its correlate subject element in the antecedent clause is not harmful at all.",NC
4,127,"This is because at the point of derivation where VP is elided, the former and the latter have not yet have its Case feature valued, thus being not distinct in form.",NC
4,128,"Now, we turn to the examples of Pseudogapping and VP ellipsis in a resemblance relation.",NC
4,129,"( 15) and ( 17), repeated below as ( 33) and ( 34), represent those examples: (33) *Roses were brought by some, and others did bring lilies.",NC
4,130,"PG (34) *Roses were brought by some boys, and some girls did bring roses, too.",NC
4,131,"VPE As argued above, both Pseudogapping and VP ellipsis in a resemblance relation involve an elision of vP rather than VP.",NC
4,132,"Since vP is a domain where Accusative Case is checked, the object in the ellipsis clause is bound to relate to its correlate object in the antecedent clause.",NC
4,133,"The unacceptability of ( 33) and ( 34) follows from the fact that in the examples, the object element in the ellipsis clause which is Case-checked in Spec of vP relates to its correlate in the antecedent clause, which is the subject element that cannot be Casechecked in Spec of vP.",NC
4,134,"Therefore, there is bound to arise a Case mismatch in both Pseudogapping and VP ellipsis in a resemblance relation that holds for (33) and (34).",NC
4,136,We now turn to the examples where a VPinternal element is assigned not structural Case but inherent case.,NC
4,137,*She embroiders peace signs on jackets more often than she does <embroider jackets> with swastikas.,NC
4,138,?She embroiders peace signs on jackets more often than she does <embroider peace signs on> shirt sleeves.,NC
4,139,*He'd give Yale money more readily than he would <give money> to charity.,NC
4,140,?He'd give money more readily to Yale than he would <give money to> charity.,NC
4,141,*Abby flirted more often in general than Beth did <flirt with> Max.,NC
4,142,?Abby flirted with Ben more often than she did <flirt with> Ryan.,NC
4,143,"Note that unlike structural Accusative Case that is checked outside VP but inside vP, inherent case is presumably determined by a verbal head inside VP and realized with an appropriate preposition.",NC
4,144,All the examples in ( 35)-( 37) involve Pseudogapping because we cannot test out case forms of VP-internal argument elements inside the portion elided by VP ellipsis.,NC
4,145,"The (b)-examples of ( 35)-( 37) are a little bit degraded (we conjecture that, as noted by Levin (1979Levin ( /1986) ) and Lasnik (1995), the degradedness of these examples are due to the general degradedness of Pseudogapping), but they are still acceptable.",NC
4,146,"This is because in these examples, the VP in the ellipsis clause is identical to that in the antecedent clause in terms of inherent case realization of the argument elements inside them.",NC
4,147,"Unlike these (b)-examples of ( 35)-( 37), however, their (a)-examples are ruled out owing to case mismatch between a VP-internal argument element in the ellipsis clause and its correlate in the antecedent clause.",NC
4,148,"For example, in (35a) neither jackets nor with swastikas inside the VP of the ellipsis clause matches with on jackets and signs in terms of case/Case feature, thereby inviting a violation of the syntactic isomorphism on ellipsis.",NC
4,149,"In leaving this section, let us note that Takita (2015: 14) proposed the revised Case condition on ellipsis, which states that a DP must be Caselicensed in the ellipsis site by a head identical to the corresponding head that Case-licenses the correlating DP in the antecedent.",NC
4,150,"Simply speaking, Takita (ibid.)",NC
4,151,argues that a Case-licensing head rather than the Case/case form of a DP determined by it is critical in meeting the syntactic isomorphism on ellipsis.,NC
4,152,Takita's analysis works fine for (37b).,NC
4,153,"Since in (37b) the same verb flirt Case-licenses Ryan and its correlate Ben with the realization of the preposition with, it meets the revised Case condition on ellipsis.",NC
4,154,"To rule out (37a), however, Takita has to say that the verb flirt in the ellipsis clause is different from the verb flirt in the antecedent clause.",NC
4,155,"Unlike Takita's analysis, we have argued that the Case/case form of a DP matters for ellipsis.",POS
4,156,If causative and unaccusatives also differ in their v (cf.,NC
4,157,"Chomsky (1995) Why is there a contrast between passives, on the one hand, and unaccusatives and middles, on the other hand?",NC
4,160,"We suggest on the basis of the following do so replacement that in English, passives involve syntactic movement, but neither unaccusatives nor middles do so.",POS
4,161,"%John told Steve to hang the horseshoe over the door, and it does so now.",NC
4,162,"%I was told that this new peanut butter spreads very easily, and I am very excited to do so.",NC
4,163,"((12a-d) from Thompson (2012)) c. %Mary claimed that I closed the door, but it actually did so on its own.",NC
4,164,(from Thompson ( 2012)) The contrast between ( 44) and ( 45) can be accounted for by the assumption that the VPreplacing anaphor so (while the light verb do of do so occupies the little v position (cf.,NC
4,165,"Stroik (2001), among others) cannot replace a VP that contains a gap left behind by A or A'-movement.",NC
4,168,"This is how we account for the unacceptability of ( 38), (42), and (43).",NC
4,169,All these examples are ruled out independently of Case/case mismatch but because of verb-type mismatch between intransitive and causative/transitive verbs.,NC
4,170,There is an additional alternation between an implicit argument-taking verb and its passive variant in an antecedent and ellipsis pair.,NC
4,171,"This mismatch is not allowed, as follows: ( We assume that the implicit argument selected by verbs such as eat, win, and read implicitly carries Accusative-like inherent case.",NC
4,172,"This inherent case is lexically assigned by such verbs to the implicit argument in-situ within VP without moving to [Spec, vP].",NC
4,173,This assumption accounts for the contrast in acceptability between ( 46) and (47).,NC
4,174,"In ( 46), the lexical-case-carrying implicit argument within the VP of the antecedent clause cannot meet a Case/case match with the complement of the passive verb within that of the ellipsis clause.",NC
4,175,"In (47), by contrast, the whsurvivor/remnant in the ellipsis clause and its correlate implicit argument in the antecedent clause are understood to carry the same feature of Case/case, meeting syntactic isomorphism on ellipsis.",NC
4,176,"In this paper, we first started with reviewing Merchant's (2008) analysis of voice mismatch in ellipsis constructions and Tanaka's (2011) reply to this analysis.",FACT
4,178,"Departing from Kehler's (2000) insight that the distinction between resemblance vs. cause/effect discourse coherence relations rather than between VP and Pseudogapping come into place in apparent voice mismatch, we argued that VP undergoes ellipsis in a resemblance relation, whereas vP does so in a cause/effect relation.",POS
4,179,"Given the different sizes of ellipsis interacting with discourse relations, we went further to argue that apparent voice mismatch in VP ellipsis is attributed to the fact that structural Accusative Case is checked not within the VP domain that undergoes ellipsis.",POS
4,180,"Thus, the object element in the ellipsis clause and the subject element in the antecedent clause, or vice versus, count as identical within a VP in terms of Case feature, meeting the identity condition on ellipsis.",POS
4,181,"Unlike structural Case, however, a difference in case feature or argument structure (or verb type) within a VP always invites a violation of identity in ellipsis.",POS
4,182,"In addition, Case/case mismatch in the case of an elision of a larger constituent such as TP under Sluicing was shown to induce fatal effects on the acceptability of sentences involving such a type of ellipsis.",POS
5,0,"Due to the ability of encoding and mapping semantic information into a highdimensional latent feature space, neural networks have been successfully used for detecting events to a certain extent.",NC
5,1,"However, such a feature space can be easily contaminated by spurious features inherent in event detection.",NC
5,2,"In this paper, we propose a self-regulated learning approach by utilizing a generative adversarial network to generate spurious features.",FACT
5,4,Detailed experiments on the ACE 2005 and TAC-KBP 2015 corpora show that our proposed method is highly effective and adaptable.,POS
5,5,Event detection aims to locate the event triggers of specified types in text.,NC
5,6,"Normally, triggers are words or nuggets that evoke the events of interest.",NC
5,7,"Detecting events in an automatic way is challenging, not only because an event can be expressed in different words, but also because a word may express a variety of events in different contexts.",NC
5,8,"In particular, the frequent utilization of common words, ambiguous words and pronouns in event mentions makes them harder to detect: 1) Generalitytaken home <Transport> Ambiguity 1campaign in Iraq <Attack> Ambiguity 2political campaign <Elect> Coreference -Either its bad or good <Marry> A promising solution to this challenge is through semantic understanding.",NC
5,9,"Recently, neural networks have been widely used in this direction (Nguyen and Grishman, 2016; Ghaeini et al.,    *  Corresponding author 2016; Feng et al., 2016;Liu et al., 2017b;Chen et al., 2017), which allows semantics of event mentions (trigger plus context) to be encoded in a high-dimensional latent feature space.",NC
5,10,This facilitates the learning of deep-level semantics.,NC
5,11,"Besides, the use of neural networks not only strengthens current supervised classification of events but alleviates the complexity of feature engineering.",NC
5,12,"However, compared to the earlier study (Liao and Grishman, 2010;Hong et al., 2011;Li et al., 2013), in which the features are carefully designed by experts, the neural network based methods suffer more from spurious features.",NC
5,13,"Here, spurious feature is specified as the latent information which looks like the semantically related information to an event, but actually not (Liu et al., 2017a).",NC
5,14,"For example, in the following sample, the semantic information of the word ""prison"" most probably enables spurious features to come into being, because the word often co-occurs with the trigger ""taken"" to evoke an Arrest-jail event instead of the ground-truth event Transport: 2) Prison authorities have given the nod for Anwar to be taken home later in the afternoon.",NC
5,15,Trigger: taken.,NC
5,16,"Event Type: Transport It is certain that spurious features often result from the semantically pseudo-related context, and during training, a neural network may mistakenly and unconsciously preserve the memory to produce the fakes.",NC
5,17,"However, it is difficult to determine which words are pseudo-related in a specific case, and when they will ""jump out"" to mislead the generation of latent features during testing.",NC
5,20,"Detailed experiments on event detection show that our proposed method achieves a substantial performance gain, and is capable of robust domain adaptation.",POS
5,25,"SELF is a double-channel model (Figure 1), consisted of a cooperative network (Islam et al., 2003) and a generative adversarial net (GAN) (Goodfellow et al., 2014).",NC
5,26,A memory suppressor S is used to regulate communication between the channels.,NC
5,27,"In channel 1, the generator G is specified as a multilayer perceptron.",NC
5,28,"It plays a role of a ""diligent student"".",NC
5,29,"By a differentiable function G(x, θ g ) with parameters θ g , the generator learns to produce a vector of latent features o g that may best characterize the token x, i.e., o g = G(x, θ g ).",NC
5,30,"The discriminator D (called ""a lucky professor"") is a single-layer perceptron, implemented as a differentiable function D(o g , θ d ) with parameters θ d .",NC
5,31,"Relying on the feature vector o g , it attempts to accurately predict the probability of the token x triggering an event for all event classes, i.e., ŷ = D(o g , θ d ), and assigns x to the most probable class c (iff ŷc > ∀ŷ c, c = c).",NC
5,32,"Therefore, G and D cooperate with each other during training, developing the parameters θ g and θ d with the same goal -to minimize the performance loss L(ŷ, y) in the detection task: θ g θ d = argmin L(ŷ, y) (1) where, y denotes the ground-truth probability distribution over event classes, and L indicates the deviation of the prediction from the ground truth.",NC
5,33,"In channel 2, the generator Ǧ and discriminator Ď have the same perceptual structures as G and D. They also perform learning by differentiable functions, respectively Ǧ(x, θ ǧ) and Ď(o ǧ, θ ď).",NC
5,34,"A major difference, however, is that they are caught into a cycle of highly adversarial competition.",NC
5,35,"The generator Ǧ is a ""trouble maker"".",NC
5,36,"It learns to produce spurious features, and utilizes them to contaminate the feature vector o ǧ of the token x.",NC
5,37,"Thus Ǧ changes a real sample x into a fake zsometimes successfully, sometimes less so.",NC
5,38,"Using the fakes, Ǧ repeatedly instigates the discriminator Ď to make mistakes.",NC
5,39,"On the other side, Ď (""a hapless professor"") has to avoid being deceived, and struggles to correctly detect events no matter whether it encounters x or z.",NC
5,40,"In order to outsmart the adversary, Ǧ develops the parameters θ ǧ during training to maximize the performance loss, but on the contrary, Ď develops the parameters θ ď to minimize the loss: θ ǧ = argmax L(ŷ, y) (2) θ ď = argmin L(ŷ, y) Numerous studies have confirmed that the twoplayer minmax game enables both Ǧ and Ď to improve their methods (Goodfellow et al., 2014;Liu and Tuzel, 2016;Huang et al., 2017).",NC
5,41,"Using a memory suppressor, we try to optimize the diligent student G. The goal is to enable G to be as dissimilar as possible to the troublemaker Ǧ.",NC
5,42,The suppressor uses the output o ǧ of Ǧ as a reference resource which should be full of spurious features.,NC
5,43,"On the basis, it looks over the output o g of G, so as to verify whether the features in o g are different to those in o ǧ.",NC
5,44,"If very different, the suppressor allows G to preserve the memory (viz., θ g in G(x, θ g )), otherwise update.",NC
5,45,"In other word, for G, the suppressor forcibly erases the memory which may result in the generation of spurious features.",NC
5,46,We call this the self-regulation.,NC
5,47,Self-regulation is performed for the whole sentence which is fed into G and Ǧ.,NC
5,48,"Assume that O g is a matrix, constituted with a series of feature vectors, i.e., the vectors generated by G for all the tokens in an input sentence (o g ∈ O g ), while O ǧ is another feature matrix, generated by Ǧ for the tokens (o ǧ ∈ O ǧ).",NC
5,49,"Thus, we utilize the matrix approximation between O g and O ǧ for measuring the loss of self-regulation learning L dif f .",NC
5,50,"The higher the similarity, the greater the loss.",NC
5,51,"During training, the generator G is required to develop the parameters θ g to minimize the loss: θ g = argmin L dif f (o g , o ǧ) (4) We present in detail the matrix approximate calculation in section 4.4, where the squared Frobenius norm (Bousmalis et al., 2016) is used.",NC
5,52,"We incorporate the cooperative network with the GAN, and enhance their learning by joint training.",NC
5,53,"In the 4-member incorporation, i.e., {G, Ǧ, D and Ď}, the primary beneficiary is the lucky professor D. It can benefit from both the cooperation in channel 1 and the competition in channel 2.",NC
5,54,"The latent features it uses are well-produced by G, and decontaminated by eliminating possible fakes like those made by Ǧ.",NC
5,55,"Therefore, in experiments, we choose to output the prediction results of D. In this paper, we use two recurrent neural networks (RNN) (Sutskever et al., 2014;Chung et al., 2014) of the same structure as the generators.",NC
5,56,And both the discriminators are implemented as a fullyconnected layer followed by a softmax layer.,NC
5,110,The state-of-the-art models proposed in the past decade are compared with ours.,NC
5,111,"By taking learning framework as the criterion, we divide the models into three classes: Minimally supervised approach: is Peng et al ( 2016)'s MSEP-EMD.",NC
5,112,"Feature based approaches: primarily including Liao and Grishman (2010)'s Cross-Event inference model, which is based on the max-entropy classification and embeds the document-level confident information in the feature space; Hong et al (2011)'s Cross-Entity inference model, in which existential backgrounds of name entities are employed as the additional discriminant features; and Li et al ( 2013)'s Joint model, a sophisticated predictor frequently ranked among the top 3 in recent TAC-KBP evaluations for nugget and coreference detection (Hong et al., 2014(Hong et al., , 2015;;Yu et al., 2016).",NC
5,113,It is based on structured perceptron and combines the local and global features.,NC
5,114,"Neural network based approaches: including the convolutional neural network (CNN) (Nguyen and Grishman, 2015), the non-consecutive Ngrams based CNN (NC-CNN) (Nguyen and Grishman, 2016) and the CNN that is assembled with a dynamic multi-pooling layer (DM-CNN) (Chen et al., 2015).",NC
5,115,Others include Ghaeini et al (2016) FrameNet (FN) and Wikipeida (Wiki).,NC
5,116,"We evaluate our model using Precision (P), Recall (R) and F-score (F).",NC
5,117,"To facilitate the comparison, we review the best performance of the competitors, which has been evaluated using the same metrics, and publicly reported earlier.",NC
5,118,Table 1 shows the trigger identification performance.,NC
5,119,"It can be observed that SELF outperforms other models, with a performance gain of no less than 1.1% F-score.",POS
5,120,"Frankly, the performance mainly benefits from the higher recall (78.8%).",POS
5,121,But in fact the relatively comparable precision (75.3%) to the recall reinforces the advantages.,POS
5,122,"By contrast, although most of the compared models achieve much higher precision over SELF, they suffer greatly from the substantial gaps between precision and recall.",POS
5,123,The advantage is offset by the greater loss of recall.,POS
5,124,GAN plays an important role in optimizing Bi-RNN.,POS
5,125,This is proven by the fact that SELF (Bi-LSTM+GAN) outperforms Nguyen et al (2016)'s Bi-RNN.,POS
5,130,Table 2 shows the performance of multi-class classification.,NC
5,131,"SELF achieves nearly the same F-score as Feng et al (2016)'s Hybrid, and outperforms the others.",POS
5,132,"More importantly, SELF is the only one which obtains a performance higher than 70% for both precision and recall.",POS
5,133,"Besides, by analyzing the experimental results, we have identified the following regularities: • Similar to the pattern classifiers that are based on hand-designed features, the CNN models enable higher precision to be obtained.",POS
5,134,However the recall is lower.,POS
5,135,• The RNN models contribute to achieving a higher recall.,POS
5,136,However the precision is lower.,POS
5,137,• Expansion of the training data set helps to increase the precision.,POS
5,138,"Let us turn to the structurally more complicated models, SELF and Hybrid.",NC
5,141,"So that it outperforms other RNNs, with improvements of no less than 4.5% precision and 1.7% recall.",POS
5,142,Hybrid is elaborately established by assembling a RNN with a CNN.,NC
5,143,It models an event from two perspectives: language generation and pragmatics.,NC
5,144,"The former is deeply learned by using the continuous states hidden in the recurrent units, while the later the convolutional features.",NC
5,145,Multi-angled cognition enables Hybrid to be more precise.,NC
5,148,"Therefore, Hybrid is localized to much higher precision but substantially lower recall.",POS
5,149,Overfitting results in enlargement of the gap between precision and recall when the task changes to be more difficult.,NC
5,152,"In particular, SELF yields a minimum gap in each task, which changes negligibly from 3.5% to 3.4%.",POS
5,153,"It may be added that, similar to DM-CNN and FB-RNN, SELF is cost-effective.",POS
5,154,"Compared to other models (Table 3), it either uses less training data, or is only required to learn two kinds of embeddings, such as that of words and entity types.",POS
5,155,Domain adaptation is a key criteria for evaluating the utility of a model in practical application.,NC
5,156,"A model can be thought of being adaptable only if it works well for the unlabeled data in the target domain when trained on the source domain (Blitzer et al., 2006;Plank and Moschitti, 2013).",NC
5,157,"We perform two groups of domain adaptation experiments, respectively, using the ACE 2005 corpus and the corpus for TAC-KBP 2015 event nugget track (Ellis et al., 2015).",FACT
5,158,"The ACE corpus consists of 6 domains: broad-cast conversation (bc), broadcast news (bn), telephone conversation (cts), newswire (nw), usenet (un) and web blogs (wl).",NC
5,159,"Following the common practice of adaptation research on this data (Nguyen and Grishman, 2014Grishman, , 2015;;Plank and Moschitti, 2013), we take the union of bn and nw as the source domain and bc, cts and wl as three different target domains.",NC
5,160,We randomly select half of the instances from bc to constitute the development set.,NC
5,161,The TAC-KBP corpus consists of 2 domains: newswire (NW) and discussion forum (DF).,NC
5,162,"We follow Peng et al (2016) to use one of NW and DF in alternation as the source domain, while the other the target domain.",NC
5,163,We randomly select a proportion (20%) of the instances from the target domain to constitute the development set.,NC
5,164,"We compare with Joint, CNN, MSEP-EMD, SSED (Sammons et al., 2015) and Hybrid.",NC
5,165,All the models except Hybrid have been reported for the performance assessment of domain adaptation.,NC
5,166,"In this section, we only cite the best performance they obtained.",NC
5,167,We reproduce Hybrid by using the source code given by authors.,NC
5,168,"To ensure a fair comparison, we perform 3 runs, in each of which, both Hybrid and SELF were redeveloped on a new development set.",NC
5,169,What we report herein is the average performance they obtained over the 3 runs.,NC
5,170,We show the adaptation performance on the ACE corpus in Tables 4 and that on TAC-KBP in Table 5.,NC
5,171,It can be observed that SELF outperforms other models in the out-of-domain scenarios.,POS
5,172,"Besides, when testing is performed on the outof-domain ACE corpus, the performance degradation of SELF is not much larger than that of CNN and Hybrid.",POS
5,173,"When the out-of-domain TAC-KBP corpus is used, the performance of SELF is impaired much less severely than SSED and Hybrid.",POS
5,174,"More importantly, the adaptability of SELF is relatively close to that of MSEP-EMD.",POS
5,175,"Considering that MSEP-EMD is stable due to using minimal supervision (Peng et al., 2016), we suggest the fully trained networks in SELF may not appear to be extremely inflexible, but on the contrary, they should be transferable for use (Ge et al., 2016).",POS
5,196,"SELF is able to accurately recall the events whose occurrence is triggered by ambiguous words, such as ""fine"", ""charge"", ""campaign"", etc.",POS
5,197,These ambiguous words easily causes confusion.,NC
5,198,"For example, ""campaign"" may trigger an Elect event or Attack in the ACE corpus.",NC
5,199,"More importantly, SELF fishes out the common words which serve as a trigger, although they are not closely related to any kind of events, such as ""take"", ""try"", ""acquire"", ""become"", ""create"", etc.",POS
5,200,"In general, it is very difficult to accurately recall such triggers because their meanings are not concrete enough, and the contexts may be full of kinds of noises (see example 2 in pg.",NC
5,201,We observe that Bi-RNN and Hybrid seldom pick them up.,POS
5,205,Some real examples collected from ACE are shown in Table 7.,NC
5,226,"Therefore, in the future, we will encode the global information by neural networks and use the self-regulation strategy to reduce the negative influence of noises.",PROSP
6,0,  Recurrent neural networks (RNNs) serve as a fundamental building block for many sequence tasks across natural language processing.,NC
6,1,Recent research has focused on recurrent dropout techniques or custom RNN cells in order to improve performance.,NC
6,2,Both of these can require substantial modifications to the machine learning model or to the underlying RNN configurations.,NC
6,4,Both of these techniques require minimal modification to existing RNN architectures and result in performance improvements comparable or superior to more complicated regularization techniques or custom cell architectures.,POS
6,6,The need for effective regularization methods for RNNs has seen extensive focus in recent years.,NC
6,7,"While application of dropout (Srivastava et al., 2014) to the input and output of an RNN has been shown to be effective (Zaremba et al., 2014), dropout is destructive when naively applied to the recurrent connections of an RNN.",NC
6,8,"When naive dropout is applied to the recurrent connections, it is almost impossible to retain information over long periods of time.",NC
6,9,"Given this fundamental issue, substantial work has gone into understanding and improving dropout when applied to recurrent connections.",NC
6,10,"Of these techniques, which we shall broadly refer to as recurrent dropout, some specific variations have gained popular usage.",NC
6,11,"Part of 34 th International Conference on Machine Learning's Workshop on Learning to Generate Natural Language, Sydney, Australia, 2017.",NC
6,12,Copyright 2017 by the author(s).,NC
6,13,"Variational RNNs (Gal & Ghahramani, 2016) drop the same network units at each timestep, as opposed to dropping different network units at each timestep.",NC
6,14,"By performing dropout on the same units at each timestep, destructive loss of the RNN hidden state is avoided and the same information is masked at each timestep.",NC
6,15,"Rather than dropping units, another tactic is to drop updates to given network units.",NC
6,16,Semeniuta et al.,NC
6,17,"(2016) perform dropout on the input gate of the LSTM (Hochreiter & Schmidhuber, 1997) but allow the forget gate to discard portions of the existing hidden state.",NC
6,18,"Zoneout (Krueger et al., 2016) prevents hidden state updates from occurring by setting a randomly selected subset of network unit activations in h t+1 to be equal to the previous activations from h t .",NC
6,19,Both of these act to prevent updates to the hidden state while preserving existing content.,NC
6,20,"On an extreme end, work has also been done to restrict the recurrent matrices in an RNN in order to limit their computational capacity.",NC
6,21,"Some RNN architectures only allow element-wise interactions (Balduzzi & Ghifary, 2016;Bradbury et al., 2016;Seo et al., 2016), removing the recurrent matrix entirely, while others act to restrict the capacity by parameterizing the recurrent matrix (Arjovsky et al., 2016;Wisdom et al., 2016;Jing et al., 2016).",NC
6,22,"Other forms of regularization explicitly act upon activations such as such as batch normalization (Ioffe & Szegedy, 2015), recurrent batch normalization (Cooijmans et al., 2016), and layer normalization (Ba et al., 2016).",NC
6,23,These all introduce additional training parameters and can complicate the training process while increasing the sensitivity of the model.,NC
6,24,"Norm stabilization (Krueger & Memisevic, 2015) penalizes the model when the norm of an RNN's hidden state changes substantially between timesteps, achieving strong results in character language modeling on and phoneme recognition.",NC
6,29,"L 2 activation regularization (AR) While L 2 regularization is traditionally used on the weights of machine learning models (L 2 weight decay), it could also be used on the activations.",NC
6,30,"We define AR as α L 2 (m ⊙ h t ) where m is the dropout mask used by later parts of the model, L 2 (•) = • 2 (L 2 norm), h t is the output of the RNN at timestep t, and α is a scaling coefficient.",NC
6,31,"When applied to the output of a dense layer, AR penalizes activations that are substantially away from 0, encouraging the activations to remain small.",NC
6,32,"While acting implicitly rather than explicitly, this has similarities to the various batch or layer normalization techniques.",NC
6,33,The L 2 penalty on the RNN activations can be applied to h t or to m ⊙ h t (the dropped output used in the rest of the model).,NC
6,34,"In our experiments, we found that applying AR to m ⊙ h t was more effective than applying it to neurons not updated during the current optimization step.",POS
6,35,Adding a prior that minimizes differences between states has been explored in the past.,NC
6,36,"This broad concept falls under the broad concept of slowness regularization (Hinton, 1989;Földiák, 1991;Luciw & Schmidhuber, 2012;Jonschkowski & Brock, 2015;Wen et al., 2015) which attempts to minimize L(f (x t ), f (x t+1 )) where L is a loss function describing the distance between f (x t ) and f (x t+1 ) and f is an arbitrary mapping function.",NC
6,37,"Temporal activation regularization (TAR) is a direct descendant of this slowness regularization, minimizing β L 2 (h t -h t+1 ) where L 2 (•) = • 2 (L 2 norm), h t is the output of the RNN at timestep t, and β is a scaling coefficient.",NC
6,38,"TAR penalizes any large changes in hidden state between timesteps, encouraging the model to keep the output as consistent as possible.",NC
6,39,"For the LSTM, the hidden state which is regularized is only h t , not the long term memory c t , though this could optionally be regularized in a similar manner.",NC
6,57,"While both result in a substantial reduction in perplexity, AR results in the strongest improvement of 5.3, while TAR only achieves 4.3.",POS
6,58,The drops achieved by this are equivalent to using an LSTM model with twice as many parameters -a substantial improvement given the simplicity of AR and TAR.,POS
6,59,"Evaluating AR and TAR jointly on PTB: When both AR and TAR are used together, we found the best result was achieved by decreasing α and β, likely as the model was over-regularized otherwise.",POS
6,60,In Table 3 we present PTB results for three different model sizes comparing models without AR/TAR to those which use both.,NC
6,61,"The model sizes h ∈ [650, 950, 1500] were chosen to be comparable in size to other published results.",NC
6,62,"With both AR and TAR, the smallest model has an improvement of 6.2 over the baseline model.",POS
6,63,"The improvements continue for the two larger size models, h = 950 and h = 1500, though the gains fall off as the model size is increased.",POS
6,64,Comparing to state-of-the-art PTB: In Table 5 we summarize the current state of the art models in language modeling over the Penn Treebank.,NC
6,67,"This would likely result in the RHN being slower than the larger LSTM model during both training and prediction, especially when factoring in optimized LSTM implementations such as NVIDIA's cuDNN LSTM.",POS
6,68,"We also compare to the Neural Architecture Search (NAS) cell (Zoph & Le, 2016).",NC
6,69,"While Zoph & Le (2016) do not report any of the hyperparameters or what type of dropout they used for their Penn Treebank result, they do note that they performed an extensive hyperparameter search over learning rate, weight initialization, dropout rates, and decay epoch in order to produce their best performing model.",NC
6,71,"Our largest LSTM results are 3 perplexity higher in comparison but have not undergone extensive hyperparameter search, do not use additional regularization techniques such as recurrent or embedding dropout, and do not use a custom RNN cell.",POS
6,88,"In this work, we revisit L 2 regularization in the form of activation regularization (AR) and temporal activation regularization (TAR).",FACT
6,89,"While simple to implement, activity regularization and temporal activity regularization are com-",NC
6,90,"For generating text samples, words were sampled using the standard generation script contained in the PyTorch word level language modeling example.",NC
6,91,WikiText-2 was used given the larger vocabulary and more realistic looking text.,NC
6,92,Neither the eos token nor the unk were allowed to be selected.,NC
6,93,"Each paragraph is a separate sample of text with the tokens following Moses (Koehn et al., 2007), joining words with @-@ and dot-decimal split to a @.",NC
6,94,"Something Borrowed "" is the second episode of the fourth season of the American comedy television series The X @-@ Files .",NC
6,95,The episode was written by David McCarthy and directed by Mark Sacks .,NC
6,96,"It aired in the United States on November 30 , 2011 , as a two @-@ episode episode, watched by 4 @.",NC
6,97,@ 9 million viewers and was the highest rated show on the Fox network .,NC
6,98,"The work of Olivier 's , a large 1950s table with the center of a vinyl beam , was used for bony motifs from the upper @-@ production model via the Club van X .",NC
6,99,"The modified works were released in the museum , which gave its namesake to the visual designers in Hong Kong .",NC
6,100,"The first prototype was released for the PlayStation 4 , containing the 2 @.",NC
6,101,"@ 5 part series , with 3 @.",NC
6,102,@ 5 million copies sold .,NC
6,103,"In October 2010 , Activision announced that both the game and the main gameplay was "" downloadable "" .",NC
6,104,"The first game , titled Snow : The Game of the Battlefield 2 : The Ultimate Warrior , was the third anime game , and was released in August 2016 .",NC
6,105,"The German Land Forces had been reversed in the early 1990s , although the Soviet Union continued to deter NDH forces in the nation .",NC
6,106,"The area was moved to Sarajevo , and the troops were despatched to the National Register of Historic Places in the summer of 1918 for the establishment of full political and social parties .",NC
6,107,"The Polish language was protected by the Soviet Union , which was the first Polish continental conflict of the newly formed Union in North America , and the Polish Front with the last of the Polish Communist Party .",NC
7,0,"  Unsupervised models of dependency parsing typically require large amounts of clean, unlabeled data plus gold-standard part-of-speech tags.",NC
7,1,Adding indirect supervision (e.g.,POS
7,2,"language universals and rules) can help, but we show that obtaining small amounts of direct supervision - here, partial dependency annotations - provides a strong balance between zero and full supervision.",POS
7,3,We adapt the unsupervised ConvexMST dependency parser to learn from partial dependencies expressed in the Graph Fragment Language.,FACT
7,4,"With less than 24 hours of total annotation, we obtain 7% and 17% absolute improvement in unlabeled dependency scores for English and Spanish, respectively, compared to the same parser using only universal grammar constraints.",POS
7,6,"The performance of unsupervised parsers has increased dramatically in recent years (Klein and Manning, 2004;Naseem et al., 2010), making them a potentially viable option for constructing labeled corpora on limited budgets.",NC
7,7,"However, their performance is often outmatched by small amounts of labeled data (Blunsom and Cohn, 2010;Spitkovsky et al., 2012).",NC
7,8,"Further, recent work using linguistically-informed error analysis on unsupervised Combinatory Categorial Grammar parsing shows that entire syntactic phenomena are outside the scope of existing unsupervised parsers (Bisk and Hockenmaier, 2015).",NC
7,9,"Accordingly, most recent work in this area has focused on methods of providing sources of indirect annotation, whether via linguistic world-knowledge (Naseem et al., 2010;Grave and Elhadad, 2015), partial annotations (Flannery et al., 2011;Mielens et al., 2015) or crosslingual information transfer (Naseem et al., 2012).",NC
7,10,"With unsupervised parsing, data collection is not entirely eliminated: a large amount of clean, relevant data is needed.",NC
7,11,"Also, evaluations of unsupervised techniques typically rely on gold part-ofspeech tags.",NC
7,12,"Obtaining clean data for many languages is actually a difficult process-complicated by issues such as language identification, digitization, and varying or absent orthographies.",NC
7,13,This challenge also exists in many domain adaptation scenarios.,NC
7,14,"We explore the effectiveness of creating small amounts of labeled data using the Graph Fragment Language (GFL), an annotation scheme designed for speed and ease (Schneider et al., 2013;Mordowanec et al., 2014).",FACT
7,15,"We create 270 English and 2297 Spanish partial sentence annotations using GFL, using a mix of expert and non-expert annotators.",FACT
7,16,We then adapt the minimum spanning tree based parsing technique of Grave & Elhadad (2015) to use these partial annotations in addition to universal dependency rules it already exploits.,FACT
7,17,Throughout this work we will refer to this parser as ConvexMST.,NC
7,18,1  We present parsing results with and without gold part-of-speech tags.,NC
7,19,"When using predicted POS tags, our experiments show that exploiting cheap, incomplete direct supervision in addition to language universals provides large absolute performance im- provements for both English and Spanish: 6.3% for the former and 17.3% for the latter.",POS
7,20,"Furthermore, the ConvexMST parser dramatically outperforms the Gibbs sampler parser of Mielens et al.",POS
7,21,(2015) using the supervision (English: +5.2%; Spanish: +14.4%).,POS
7,22,"We also show that the extra supervision provided by gold POS tags heavily influences results; in particular, it inflates performance when only using language universals.",POS
7,23,Experiments that rely on gold POS tags alone are thus not reliable indicators of performance in true low-resource settings.,POS
7,24,"We use the Graph Fragment Language (GFL) (Schneider et al., 2013) to allow for light-weight, simple annotations that our annotators can easily learn and use confidently.",NC
7,25,The choice of annotation scheme is particularly important: we seek to optimize annotation speed rather than full-specification or high accuracy.,NC
7,26,"In previous studies, the use of GFL has allowed for annotation rates of 2-3 times that of traditional dependency annotations while still maintaining a useful level of annotation density (Mordowanec et al., 2014;Mielens et al., 2015).",NC
7,27,Hwa (1999) demonstrated that it is most effective to provide high-level sentence constituents to a parser and allow it to fill in the low-level information itself.,NC
7,28,The GFL annotation in Figure 1 shows two distinct notations.,NC
7,29,Constituent brackets are specified by parentheses and direct dependencies by angle brackets.,NC
7,30,Many words and phrases are underspecified.,NC
7,33,A partial annotation produces a set of dependency tree fragments.,NC
7,34,"Compared to an unlabeled sentence, this can substantially reduce the work a parser must do.",NC
7,35,"When working with partial dependencies, there are two paths that can be taken with regard to overall model-building.",NC
7,36,"In a 'Fill-then-Parse' setup, the partial dependencies are first filled-in to produce full dependencies that are then used to train a standard dependency parser.",NC
7,37,"In a 'Fill+Parse' setup, one model both fills in and parses new sentences.",NC
7,38,"We use a Fill+Parse setup, while previous work focused on Fill-then-Parse.",NC
7,39,"The major benefit of the former is that learning can be sensitive to the source of an arc in the training data-e.g., whether it came from an annotator or a universal rule.",NC
7,40,Fill-then-Parse obscures this distinction and not knowing how trustworthy an arc is can lead to additional errors.,NC
7,42,Many factors influence the cost of creating a corpus.,NC
7,43,Our goal is to minimize cost relative to the performance of a parser trained with the corpus.,NC
7,47,"Consider that for any sentence there are both 'low-hanging fruit' dependencies such as determiner attachment, and more difficult dependencies such as preposition attachment and long-distance relations.",NC
7,48,"Harder dependencies take longer to annotate (and thus cost more), so it is worth considering cost metrics that incorporate completion percentage.",NC
7,49,"In the absence of timing/expense data, we can simulate this intuition with a variable cost model for which each an additional dependency annotated in a sentence is more expensive than the previous one.",NC
7,50,Figure 2 demonstrates the impact of completion cost.,NC
7,51,"Parsing accuracies (for our parser introduced in  We simulated the construction of various corpora by deriving partial dependencies from gold standard annotations), and show the cost curves for different sentence completion rates.",NC
7,52,"100% completion produces the best performance with equal costs, but under the more realistic variable cost model, 30% and 50% completion win.",POS
7,53,We show later that this pattern holds under actual timed annotation.,POS
7,54,Garrette (2015) demonstrated the benefit of partial annotations for CCG parsing.,NC
7,55,"They focused on the number of (partial) bracket annotations (as a proxy for annotation time), holding this fixed while varying the number of sentences.",NC
7,56,"Strikingly, they found that having 40% of brackets across the full dataset was better than full brackets for 80% of the corpus.",NC
7,57,"This result uses an equal cost-per-bracket assumption, so the difference would be even more favorable to partial annotations with a variable cost.",NC
7,58,"Without any direct annotations, we must rely on indirect supervision such as universal grammar rules, cross-lingual information transfer, and domain adaptation.",NC
7,59,"Following Grave & Elhadad (2015), we use the universal grammar rules in Table 1.",NC
7,60,Indirect supervision via these rules is achieved by biasing produced trees to conform to the rules.,NC
7,61,"This is the Verb → Verb Noun → Noun Verb → Noun Noun → Adj Verb → Pron Noun → Det Verb → Adv Noun → Num Verb → Adp Noun → Conj Adj → Adv Adp → Noun Table 1: Universal Grammar Rules only form of dependency supervision considered by Grave & Elhadad, though they do provide additional direct supervision via gold part-of-speech tags.",NC
7,83,Our goal is to minimize real-world costs associated with producing a finished parsing model.,NC
7,85,"We extract types from the corpus, rank them by frequency, and take the most frequent types to train the tagger.",NC
7,86,The cutoff on how many types to take is derived from the number of types the annotators in Garrette et al.,NC
7,87,(2013) were able to produce in two hours.,NC
7,88,The taggers all obtain around 80% accuracy.,POS
7,89,"This section provides a brief overview of the core parsing algorithm; for full details, see Grave & Elhadad (2015).",NC
7,90,"We begin by considering a binary vector y that encodes all of the dependencies in our corpus, such that y ijk = 1 if sentence i has an arc with dependent j and head k. This representation leads to the problem formulation in Equation 1, where Y is the convex hull of all the valid tree assignments for y, n is the number of possible dependency arcs in the corpus, u is a penalty vector that penalizes potential dependency arcs that are not in the set of universal dependency rules, and w is a weight vector learned during training min y∈Y min w 1 2n y -Xw 2 2 + λ 2 w 2 2 -µu T y (1) This problem can be solved using Algorithm 1 (Grave and Elhadad, 2015).",NC
7,114,We consider both simulated and actual partial annotations.,NC
7,116,"However, our Spanish annotators had only six hours each, and there was no inter-annotator communication or creation of annotation conventions, and no attempt to have them adopt the conventions in the gold-standard AnCora dependencies we evaluate against.",NEG
7,117,"Because of this, we include simulation results to eliminate this source of divergence to better measure the effectiveness of different methods for filling in missing arcs in a partial annotation.",NC
7,118,It of course also allows us to measure this for all the languages in the Universal Dependencies treebanks.,NC
7,119,"We consider three different supervision settings for ConvexMST: • UG uses just the universal grammar based features, which is equivalent to the method used by Grave & Elhadad (2015).",NC
7,120,• GFL uses just the human specified features.,NC
7,121,• GFL+UG uses both.,NC
7,122,"Table 5: Directed dependency accuracy on English and Spanish universal treebanks using annotator provided GFL annotations, 10 or fewer words.",NC
7,123,"These three methods correspond with ξ = 0, µ = 0, and ξµ = 0 in Equation 2.",NC
7,124,The training sets correspond with the 'Partial EN' and 'Partial ES' sets from Table 2.,NC
7,125,"The set of sentences annotated with GFL is used as the training set for the GFL, UG, and GFL+UG methods.",NC
7,126,Simulated partial dependencies are produced by removing dependencies via a stochastic process that approximates how we instructed human annotators to focus their efforts.,NC
7,127,"Arcs are removed top-down, with arcs lower in the tree being more likely to be deleted.",NC
7,128,This results in trees with more high-level structures and less lower-level information.,NC
7,129,Figure 4 demonstrates the stability of our parser under varying levels of such gold tree degradation.,POS
7,130,"Missing arcs were recovered using our parse imputation scheme (using GFL+UG features), and the resulting parser was applied to the evaluation sentences.",NC
7,131,"Accuracy decreases slightly to around 60% removal, and then degrades more rapidly after that.",POS
7,132,Table 4 provides numeric data for the simulations.,NC
7,133,Table 5 gives semi-supervised parsing results on the English and Spanish treebanks for sentences with 10 or fewer words.,NC
7,135,We compare against a right-branching baseline and the Gibbs parser of Mielens et al.,NC
7,139,ConvexMST-GFL easily beats both these approaches: it exploits partial annotations much more effectively than the Gibbs parser and learns effectively without language universals.,POS
7,140,The difference is especially marked for predicted POS tags: ConvexMST-GFL beats ConvexMST-UG by 4.3% for English and 17.1% for Spanish.,POS
7,141,(Recall that there were 8 hours of annotation for English and 72 hours for Spanish.),NC
7,142,The best method of all uses both partial annotations and language universals: ConvexMST-UG+GFL improves on ConvexMST-GFL for both languages and POS conditions.,POS
7,143,"The impact of the combination is greater for English, which has less GFL annotation.",POS
7,144,"Overall, these results show that this combination is robust to varying amounts of partial annotations: the UG constraints are strong on their own and provide a strong basis without annotations, they contribute when there are not many annotations available, and eventually become less essential (but remain unharmful) as more are provided.",POS
7,145,It is important to recall that the GFL annotations have no specific conformity to the gold standards of either original corpus.,NC
7,147,"The former defeats the spirit of our exercise, and we did not have sufficient budget for the latter.",NEG
7,148,"For Spanish, we also considered the performance of individual annotators alongside the full training set.",NC
7,149,The learning curves for individual annotators are shown in Figure 5.,NC
7,150,"There is substantial variation in the curves for the individual annotators; however, the curve based on the union of all annotations at each time step is smooth and is better than any individual past the three hour mark.",POS
7,151,"One way to consider this is in terms of building an accurate parser quickly with multiple, diverse annotators, where wall clock time matters.",NC
7,152,Another way is to consider robustness with respect to possibly bad annotators.,NC
7,153,The next obvious steps would be to use active learning and to detect disagreement in annotators to either drop some or intervene improve their quality.,PROSP
7,155,"Comparison to Full Annotation To this point, all performance comparisons have been between different parse feature sets; we have demonstrated that the GFL features are complimentary to the UG features, and that when standing alone the GFL features are stronger than the UG features.",POS
7,156,The question of whether it might be more effective to simply have annotators produce full annotations is not addressed by these comparisons.,NEG
7,157,"To answer this question, we had our most experienced annotator fully annotate the same section that the other annotators did partially.",NC
7,158,Producing these full annotations required roughly 13 hours of time from the single expert annotator.,NC
7,159,"In comparison, the other annotators were able to partially annotate the same section in roughly two hours each -a total of 24 hours.",NC
7,161,These different training sets were once again used to train ConvexMST models that were evaluated on a held out test set.,NC
7,162,"Table 6 contains the results of this experiment, demonstrating that the group of inexperienced annotators producing partial annotations was able to achieve similar performance levels to the single annotator producing full annotations.",POS
7,163,It should be noted that this comparison does not weight the results using the extrinsic costs associated with the production of the training data.,NEG
7,166,We also evaluated ConvexMST with longer sentences: those with 20 words or less.,NC
7,168,"When using all the annotations on the common set for all annotators, the scores for ConvexMST with UG, GFL, and GFL+UG are 47.6%, 54.4%, and 55.3%, respectively.",POS
7,169,"The values are worse than for shorter sentences, as expected, but the pattern observed in Table 5 still holds: GFL annotations best UG alone, and their combination is the best of all.",POS
7,171,"Assuming the availability of gold-standard POS tags is antithetical to this idea, and is one way in which direct supervision can show up in otherwise unsupervised (or indirectly supervised) systems.",NC
7,172,"Many tagger errors are not likely to cause major problems during parsing; for instance mislabeling pronouns as nouns, or adverbs as adjectives, is unlikely to lead to major structural issues.",POS
7,174,"Here, the phrase 'beating politically' (gold tags 'NOUN ADV') is mistagged as 'ADJ VERB', leading to the attachment of 'politically' to the root word and the reorganization of a substantial chunk of the sentence.",NC
7,177,"This result is not entirely unexpected given the relative performances of the constraints on their own, but it provides more evidence that direct supervision even in small amounts can beat indirect supervision.",POS
7,178,We have shown that human-sourced partial annotations can be exploited to learn effective dependency parsers in short period of time.,POS
7,179,"The ConvexMST method we adapt from Grave and Elhadad easily combines constraints from both language universals and partial annotations, providing greater robustness from starting annotation until one runs out of budget or time.",POS
7,182,"We believe that overreliance on creeping supervision of this type may lead to an inaccurate picture of the cross-lingual and low-resource applicability of various models, and are encouraged by recent work on character-based models by Gillick et al.",POS
7,183,"(2015) and Ballesteros et al (2015), among others.",POS
7,184,"Their work shows viable models can be produced without relying on having annotations a priori, but rather learning representations on the fly that need not conform to any one set of standards.",NC
8,0,"  In this paper, we explore the use of convolutional networks (ConvNets) for the purpose of cognate identification.",FACT
8,1,We compare our architecture with binary classifiers based on string similarity measures on different language families.,FACT
8,2,Our experiments show that convolutional networks achieve competitive results across concepts and across language families at the task of cognate identification.,POS
8,3,Cognates are words that are known to have descended from a common ancestral language.,NC
8,4,"In historical linguistics, identification of cognates is an important step for positing relationships between languages.",NC
8,5,"Historical linguists apply the comparative method (Trask, 1996) for positing relationships between languages.",NC
8,6,"In NLP, automatic identification of cognates is associated with the task of determining if two words are descended from a common ancestor or not.",NC
8,7,There are at least two ways to achieve automatic identification of cognates.,NC
8,8,"One way is to modify a well-known string alignment technique such as Longest Common Subsequence or Needleman-Wunsch algorithm (Needleman and Wunsch, 1970) to weigh the alignments differentially (Kondrak, 2001;List, 2012).",NC
8,9,The weights are determined through the linguistic knowledge of the sound changes that occurred in the language family.,NC
8,10,The second approach employs a machine learning perspective that is widely employed in NLP.,NC
8,11,The cognate identification is achieved by training a linear classifier or a sequence labeler on a set of labeled positive and negative examples; and then employ the trained classifier to classify new word pairs.,NC
8,12,"The features for a classifier consist of word similarity measures based on number of shared bigrams, edit distance, and longest common subsequence (Hauer and Kondrak, 2011;Inkpen et al., 2005).",NC
8,13,The above procedures provide an estimate of the similarity between a pair of words and cannot directly be used to infer a phylogeny based on models of trait evolution.,NC
8,14,The pairwise judgments have to be converted into multiple cognate judgments so that the multiple judgments can be supplied to a automatic tree building program for inferring a phylogeny for the languages under study.,NC
8,15,"It has to be noted that the Indo-European dating studies (Bouckaert et al., 2012;Chang et al., 2015) employ human expert cognacy judgments for inferring phylogeny and dates of a very well-studied language family.",NC
8,16,"Hence, there is a need for developing automated cognate identification methods that can be applied to under-studied languages of the world.",NC
8,39,This article is the first to apply convolutional networks (ConvNets) to phonemes by treating each phoneme as a vector of binary valued phonetic features.,FACT
8,42,The cognacy statements can be obtained from etymological dictionaries and the quality of the phonemes can be obtained from Ladefoged and Maddieson (1998).,NC
8,43,Collobert et al.,NC
8,44,"(2011) proposed ConvNets for NLP tasks in 2011 and were since applied for sentence classification (Kim, 2014;Johnson and Zhang, 2015;Kalchbrenner et al., 2014;Zhang et al., 2015), part-of-speech tagging (Santos and Zadrozny, 2014), and information retrieval (Shen et al., 2014).",NC
8,45,Kim (2014) applied convolutional networks to pre-trained word embeddings in a sentence for the task of sentence classification.,NC
8,46,Johnson and Zhang (2015) train their convolutional network from scratch by using a one-hot vector for each word.,NC
8,47,The authors show that their convolutional network performs better than a SVM classifier trained on bag-of-words features.,NC
8,48,Santos and Zadrozny (2014) use character embeddings to train their POS-tagger.,NC
8,49,"The authors find that the POS-tagger performs better than the accuracies reported in (Manning, 2011).",NC
8,50,"In a recent work, Zhang et al.",NC
8,51,(2015) treat documents as a sequence of characters and transform each document into a sequence of one-hot character vectors.,NC
8,52,The authors designed and trained two 9-layer convolutional networks for the purpose of sentiment classification.,NC
8,53,The authors report competitive or state-of-the art performance on a wide range of benchmark sentiment classification datasets.,NC
8,54,Chopra et al.,NC
8,55,( 2005) extended the traditional Con-vNets to classify if two images belong to the same person.,NC
8,56,These ConvNets are known as Siamese Networks (inspired from Siamese twins) and share weights for independent but identical layers of convolutional networks.,NC
8,57,"Siamese networks and their variants have been employed for identifying if two images are from the same person or different persons (Zagoruyko and Komodakis, 2015); and for recognizing if two speech segments belong to the same word class (Kamper et al., 2015).",NC
8,58,Historical linguists perform cognate identification based on regular correspondences which are described as changes in phonetic features of phonemes.,NC
8,59,"For instance, Grimm's law b h ∼ b is described as loss of aspiration; p ∼ f is described as change from plosives to fricatives; and devoicing d ∼ t in English ten ∼ Latin decem.",NC
8,60,Learning criteria for cognacy through phonetic features from a set of training examples implies that there is no need for explicit alignment and design/learning of sound scoring matrices.,NC
8,61,"In this article, we represent each phoneme as a binaryvalued vector of phonetic features and then perform convolution on the two-dimensional matrix.",NC
8,62,"Intuitively, a network should learn a similarity function such that words that diverged due to accountable sound shifts are placed close to one another than two words that are not cognates.",NC
8,63,"And, Siamese networks are suitable for this task since, they learn a similarity function that has a higher similarity between cognates as compared to noncognates.",NC
8,64,The weight tying ensures that two cognate words sharing similar phonetic features in a local context tend to be get higher weights than words that are not cognate.,NC
8,65,"In this article, we work with the ASJP alphabet (Brown et al., 2013).",NC
8,66,The ASJP alphabet is coarser than IPA but is designed with the aim to capture highly frequent sounds in the world's languages.,NC
8,67,"The ASJP database has word lists for 60% of the world's languages but only has cognate judgments for some selected families (Wichmann and Holman, 2013).",NC
8,68,We composed a binary vector for each phoneme based on the description given in table 1.,NC
8,69,"In total, there are 16 binary valued features.",NC
8,70,We also reduced all vowels to a single vowel that has a value of 1 for voicing feature and 0 for the rest of the features.,NC
8,71,"The main motivation for such decision is that vowels are diachronically unstable than consonants (Kessler, 2007).",NC
8,72,"A word such as ""fat"" would be represented as 3×16 matrix where each column provides a binary value for the phonetic feature (cf.",NC
8,73,Table 1: ASJP consonants.,NC
8,74,ASJP has 6 vowels which we collapsed to a single vowel V.,NC
8,82,"Until now, each word is treated as a separate input.",NC
8,83,Zagoruyko and Komodakis (2015) introduced a 2-channel architecture which treats a pair of image patches as a 2-channel image.,NC
8,84,This can also be applied to words.,NC
8,85,"The 2-channel ConvNet has two convolutional layers, a maxpooling layer, and a fully connected layer with 8 units.",NC
8,86,The number of feature maps in each convolutional layer is fixed at 10 with a kernel size of 2 × 3.,NC
8,87,The max-pooling layer halves the output of the previous convolutional layer.,NC
8,88,"We also inserted a dropout layer with 0.5 probability (Srivastava et al., 2014) after a fully-connected layer to avoid over-fitting.",NC
8,89,The convolutional layers were trained with ReLU non-linearity.,NC
8,90,We zero-padded each word to obtain a length of 10 for all the words to apply the filter equally about a word.,NC
8,91,"We used adadelta optimizer (Zeiler, 2012) with learning rate of 1.0, ρ = 0.95, and = 10 -6 .",NC
8,92,We fixed the mini-batch size to 128 in all our experiments.,NC
8,93,"We experimented with different batch sizes ([32, 64, 128, 256]) and did not observe any significant deviation in the validation loss.",NC
8,94,"Both, Manhattan and 2-stream ConvNets were trained using the log-loss function.",NC
8,95,Both our architectures are relatively shallow (3) as compared to the text classification architecture of Zhang et al.,NC
8,96,"We trained all our networks using Keras (Chollet, 2015) and Theano (Bergstra et al., 2010).",NC
8,97,We compare the ConvNet architectures with SVM classifiers trained with different string similarities as features.,NC
8,98,"Other sound classes/alphabets Apart from ASJP alphabet, there are two other alphabets that have been designed by historical linguists for the purpose of modeling sound change.",NC
8,99,"As mentioned before, the main idea behind the design of sound classes is to discourage transitions between partic-ular classes of sounds but allow transitions within a sound class.",NC
8,100,Dolgopolsky (1986) proposed a ten sound class system based on the empirical data of 140 languages.,NC
8,101,"SCA alphabet (List, 2012) has a size of 25 and attempts to address some issues with the ASJP alphabet (lack of tones) and also extend Dolgopolsky's sound classes based on evidence from more number of languages.",NC
8,102,Orthographic measures as features We converted all the datasets into all the three sound classes and computed the following string similarity scores: • Edit distance.,NC
8,103,• Common number of bigrams.,NC
8,104,• Length of the longest common subsequence.,NC
8,105,• Length of longest common prefix.,NC
8,106,• Common number of trigrams.,NC
8,107,"• Global alignment based on Needlman-Wunch algorithm (Needleman and Wunsch, 1970).",NC
8,108,"• Local alignment score based on Smith-Waterman algorithm (Smith and Waterman, 1981).",NC
8,109,"• Semi-global alignment score is a compromise between global and local alignments (Durbin et al., 2002).2 • Common number of skipped bigrams (XDICE).",NC
8,110,"• A positional extension of XDICE known as XXDICE (Brew and McKelvie, 1996).",NC
8,111,Pair-wise Mutual Information (PMI) We also computed a PMI score for a pair of ASJP transcribed words using the PMI scoring matrix developed by Jäger (2013).,NC
8,112,This system is referred to as PMI system.,NC
8,113,We included length of each word and the absolute difference in length between the words as features for both the Orthographic and PMI systems.,NC
8,114,"The sound class orthographic scores system attempts to combine the previous cognate identification systems developed by (Inkpen et al., 2005;Hauer and Kondrak, 2011) and the insights from applying string similarities to sound classes for language comparison (Kessler, 2007).",NC
8,143,"In terms of averaged F-scores, Manhattan ConvNet performs slightly better than orthographic model and only performs worse than the other models at Austronesian language family.",POS
8,144,The Manhattan ConvNet shows mixed performance at the task of cross-family cognate identification.,POS
8,145,The Manhattan ConvNet does not turn up as the best system across all the evaluation metrics in a single language family.,POS
8,146,The ConvNet performs better than PMI but is not as good as Orthographic measures at Indo-European language family.,POS
8,147,"In terms of accuracies, the ConvNet comes closer to PMI than the orthographic system.",POS
8,148,These experiments suggest that ConvNets can compete with a classifier trained on different orthographic measures and different sound classes.,POS
8,149,ConvNets can also compete with a data driven method like PMI which was trained in an EM-like fashion on millions of word pairs.,POS
8,150,ConvNets can certainly perform better than a classifier trained on word similarity scores at cross-concept experiments.,POS
8,151,The Orthographic system and PMI system show similar performance at the Austronesian crossconcept task.,POS
8,152,"However, ConvNets do not perform as well as orthographic and PMI systems.",POS
8,153,The reason for this could be due to the differential transcriptions in the database.,POS
8,154,"In this article, we explored the use of phonetic feature convolutional networks for the task of pairwise cognate identification.",FACT
8,155,Our experiments with convolutional networks show that phonetic features can be directly used for classifying if two words are related or not.,POS
8,156,"In the future, we intend to work directly with speech recordings and include language relatedness information into ConvNets to improve the performance.",PROSP
8,157,We are currently working towards building a larger database of word lists in IPA transcription.,PROSP
9,0,"  The task of information retrieval is an important component of many natural language processing systems, such as open domain question answering.",NC
9,1,"While traditional methods were based on hand-crafted features, continuous representations based on neural networks recently obtained competitive results.",NC
9,2,"A challenge of using such methods is to obtain supervised data to train the retriever model, corresponding to pairs of query and support documents.",NC
9,3,"In this paper, we propose a technique to learn retriever models for downstream tasks, inspired by knowledge distillation, and which does not require annotated pairs of query and documents.",FACT
9,6,"Information retrieval is an important component for many natural language processing tasks, such as question answering (Voorhees et al., 1999) or fact checking (Thorne et al., 2018).",NC
9,7,"For example, many real world question answering systems start by retrieving a set of support documents from a large source of knowledge such as Wikipedia.",NC
9,8,"Then, a finer-grained model processes these documents to extract the answer.",NC
9,9,"Traditionally, information retrieval systems were based on hand-crafted sparse representations of text documents, such as TF-IDF or BM25 (Jones, 1972;Robertson et al., 1995).",NC
9,10,"Recently, methods based on dense vectors and machine learning have shown promising results (Karpukhin et al., 2020;Khattab et al., 2020).",NC
9,11,"Deep neural networks based on pre-training, such as BERT (Devlin et al., 2019), have been used to encode documents into fixed-size representations.",NC
9,12,"These representations are then queried using approximate nearest neighbors (Johnson et al., 2019).",NC
9,13,These techniques have lead to improved performance on various question answering tasks.,NC
9,14,A challenge of applying machine learning to information retrieval is to obtain training data for the retriever.,NC
9,15,"To train such models, one needs pairs of queries and the corresponding list of documents that contains the information corresponding to the queries.",NC
9,16,"Unfortunately, hand-labeling data to that end is time consuming, and many datasets and applications lack such annotations.",NC
9,17,"An alternative approach is to resort to heuristics, or weakly supervised learning, for example by considering that all documents containing the answer are positive examples.",NC
9,18,"However, these approaches suffer from the following limitations.",NC
9,19,"First, frequent answers or entities might lead to false positive examples.",NC
9,20,"As an example, consider the question ""where was Ada Lovelace born?"".",NC
9,21,"The sentence ""Ada Lovelace died in 1852 in London"" would be considered as a positive example, because it contains the answer ""London"".",NC
9,22,"A second limitation is that for some tasks, such as fact checking or long form question answering, such heuristics might not be applicable directly.",NC
9,23,"In this paper, we propose a procedure to learn retriever systems without strong supervision in the form of pairs of queries and documents.",FACT
9,24,"Following previous work (Chen et al., 2017), our approach uses two models: the first one retrieves documents from a large source of knowledge (the retriever), the second one processes the support documents to solve the task (the reader).",NC
9,25,"Our method is inspired by knowledge distillation (Hinton et al., 2015), and uses the reader model to obtain synthetic labels to train the retriever model.",NC
9,26,"More precisely, we use a sequence-to-sequence model as the reader, and use the attention activations over the input documents as synthetic labels to train the retriever.",NC
9,28,We then train the retriever to reproduce the ranking of documents corresponding to that metric.,NC
9,30,"3.2) ; • Second, inspired by knowledge distillation, we propose to iteratively train the retriever from these activations, and compare different loss functions (Sec.",FACT
9,199,"In Table 1, we report the performance of our approach for different number of self-training iterations.",NC
9,200,"Generally, we observe that the accuracy of our system increases with the number of iterations, obtaining strong performance after a few iterations.",POS
9,201,"Interestingly, while the initial performance with documents retrieved with BERT is very poor, our method still reach competitive scores on TriviaQA, and to a lesser extent, NaturalQuestions.",POS
9,202,"However, a second observation is that the quality of the initial document sets plays an important role on the performance of the end system.",POS
9,203,"Indeed, we observe that starting the procedure from BM25 documents, which are higher quality as indicated by the performance of the system at iteration 0, leads to stronger results than using BERT documents.",POS
9,204,"An interesting research question would be to explore pre-training of the initial BERT model for retrieval, for example by using the inverse cloze task.",PROSP
9,205,"In Table 2, we report the performance of our approach, as well as existing state-of-the-art systems on TriviaQA and NaturalQuestions.",NC
9,207,"First, we observe that our method improve the performance over the state-of-the-art, even when starting from BM25 documents.",POS
9,208,This validates our assumption that it is possible to obtain strong retrievers without the need of supervision for the documents.,POS
9,209,"Second, when starting from DPR passages, our method leads to a +4.5 EM improvement on TriviaQA and +2.3 EM improvement on NaturalQuestions when the final evaluation is carried out with a large reader.",POS
9,210,In Table 3 we report retrieval results on the test set depending on the initial passages and compare to the state-of-the-art.,NC
9,211,Published as a conference paper at ICLR 2021,NC
9,212,"TriviaQA R@20 R@100 R@20 R@100 DPR (Karpukhin et al., 2020) 79.4 86.0 79.4 85.0 ANCE (Xiong et al.)",NC
9,213,"82 In Table 4, we report the performance of our method on the NarrativeQA dataset.",NC
9,214,"We use the setting where the knowledge source corresponds to the whole document, and in particular, we do not use the summary.",NC
9,215,We compare our results to the best ones reported in the original paper for this setting.,NC
9,216,"Similar to results obtained on NaturalQuestions and TriviaQA, we observe that training the retriever by using the attention scores of the reader leads to improvements, compared to the BM25 baseline.",POS
9,217,"In this section, we investigate design choices regarding two key elements of our approach: the training objective and the aggregation of cross-attention scores.",NC
9,218,"For all experiments, we consider a simplified experimental setting: a single training iteration is performed on NaturalQuestions, starting from BM25 passages.",NC
9,222,"In Section 4 the cross-attention scores α are aggregated in a specific way, in order to obtain a single scalar used to train the retriever.",NC
9,223,"Formally let us denote by α i,j,k,h the cross-attention scores between token i of the output and token j of the input, for the k-th layer and h-th head.",NC
9,224,"Then, the scores G q,p for p ∈ D q used in Section 4 are computed as follows: G q,p = mean j,k,h α 0,j,k,h , where j describes the input tokens corresponding to p. In Table 6 we explore alternatives to this choice by considering different aggregation schemes.",NC
9,225,"In particular, we consider (1) taking the max over the input tokens corresponding to passage p instead of the average, (2) taking the average over the output tokens instead of taking the score of the first token, (3) taking the mean over the last six layers instead of all the layers, (4) taking the max over the layers instead of the average, (5) taking the max over the heads instead of the average.",NC
9,226,"We observe that the performance of our approach is relatively stable to the choice of aggregation, and that the best result is obtained by averaging, except over the output tokens where it is best to only consider the first token.",POS
9,227,"Method R@5 R@20 R@100 Dev EM (0) mean The index i corresponds to output tokens, j corresponds to input tokens of a given passage, h to heads and k to layers of the decoder.",NC
9,228,We report all metrics on the validation set.,NC
9,229,"In this paper, we introduce a method to train an information retrieval module for downstream tasks, without using pairs of queries and documents as annotations.",FACT
9,230,"Our approach is inspired by knowledge distillation, where the retriever module corresponds to the student model and the reader module corresponds to the teacher model.",NC
9,231,"In particular, we use the cross-attention scores, from a sequenceto-sequence reader, to obtain synthetic targets for the retriever.",NC
9,232,"We compare different ways to aggregate the scores, as well as different training objectives to learn the retriever.",NC
9,233,"We show that iteratively training the reader and the retriever leads to better performance, and obtain state-of-the-art performance on competitive question answering benchmarks.",POS
9,234,"In the future, we would like to explore better pre-training strategies for the retriever module, as well as better scoring functions for the retriever.",PROSP
