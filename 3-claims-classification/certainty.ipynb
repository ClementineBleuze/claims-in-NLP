{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a06c249-dd2e-4ab1-b6ff-5f32fa7bfb24",
   "metadata": {},
   "source": [
    "# Certainty annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69686bcd-d5cd-4e82-855c-586ec5134064",
   "metadata": {},
   "source": [
    "In this Notebook: certainty classifiers from [Jiaxin Pei](https://github.com/Jiaxin-Pei/certainty-estimator/) are applied to a corpus of claims. The model can be easily installed using `pip install certainty-estimator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdb535b9-b767-46f9-b8e8-aa814b39eb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds\n",
    "import pickle\n",
    "\n",
    "from certainty_estimator.predict_certainty import CertaintyEstimator\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.ClaimDB import ClaimDB\n",
    "from utils.Paper import Paper\n",
    "import json\n",
    "from utils.Corpus import Corpus\n",
    "from utils.utils import load_corpus_object, CustomEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b964cf-6090-4ae4-b9ad-d3b4ddae4daa",
   "metadata": {},
   "source": [
    "## Load the certainty estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2028dfe-8508-4b85-9708-128ffc5dec8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clbleuze/myenv/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:769: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/clbleuze/myenv/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/clbleuze/myenv/lib/python3.9/site-packages/transformers/modeling_utils.py:3027: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentence_estimator = CertaintyEstimator('sentence-level', cuda = True)\n",
    "aspect_estimator = CertaintyEstimator('aspect-level', cuda = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb4fc7aa-06ff-4861-8cea-8400da44b7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 18.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "4.944007\n",
      "4.6444902\n",
      "4.6428776\n",
      "4.1955776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sents = [\"We have proven that our model compares similarly to BERT\",\n",
    "         \"We leave this issue to future research.\",\n",
    "        \"We obtain F1 score of more than 0.85.\",\n",
    "        \"Maybe this is due to small dataset size\"]\n",
    "\n",
    "res_sentence = sentence_estimator.predict(sents, tqdm = tqdm)\n",
    "print(type(res_sentence))\n",
    "for res in res_sentence:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9494ace-483f-402b-9e77-428188deb2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/clbleuze/myenv/lib/python3.9/site-packages/transformers/modeling_utils.py:1052: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "1it [00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Probability', 'Certain'), ('Framing', 'Certain')]\n",
      "[('Suggestion', 'Certain'), ('Framing', 'Certain')]\n",
      "[('Number', 'Certain'), ('Framing', 'Certain')]\n",
      "[('Probability', 'Uncertain')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res_aspect = aspect_estimator.predict(sents, tqdm = tqdm)\n",
    "for res in res_aspect:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf52fec-3d29-4211-a65c-0f1c173f1f15",
   "metadata": {},
   "source": [
    "## Load data to annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02d2bfb1-f820-4017-a62e-df1a24d49d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 6930/42759 [1:33:11<6:51:43,  1.45it/s] IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 34%|███▍      | 14735/42759 [3:14:43<6:10:20,  1.26it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     paper\u001b[38;5;241m.\u001b[39mcontent[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_certainty\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sent_certainty\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maspect_certainty\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m paper\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m---> 16\u001b[0m     aspect_certainty \u001b[38;5;241m=\u001b[39m \u001b[43maspect_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     paper\u001b[38;5;241m.\u001b[39mcontent[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maspect_certainty\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m aspect_certainty\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/certainty_estimator/predict_certainty.py:170\u001b[0m, in \u001b[0;36mCertaintyEstimator.predict\u001b[0;34m(self, text, get_processed_output, batch_size, tqdm)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_sentence_level(text, batch_size, tqdm)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_aspect_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_processed_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/certainty_estimator/predict_certainty.py:146\u001b[0m, in \u001b[0;36mCertaintyEstimator.predict_aspect_level\u001b[0;34m(self, text, get_processed_output, batch_size, tqdm)\u001b[0m\n\u001b[1;32m    143\u001b[0m             input_ids \u001b[38;5;241m=\u001b[39m Tensor(ids)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m    144\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(input_ids)\n\u001b[0;32m--> 146\u001b[0m     predicted \u001b[38;5;241m=\u001b[39m [y_pred\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m y_pred \u001b[38;5;129;01min\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    147\u001b[0m     all_preds\u001b[38;5;241m.\u001b[39mextend(np\u001b[38;5;241m.\u001b[39mtranspose(predicted,(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m    149\u001b[0m all_res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(all_preds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/certainty_estimator/predict_certainty.py:146\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    143\u001b[0m             input_ids \u001b[38;5;241m=\u001b[39m Tensor(ids)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m    144\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(input_ids)\n\u001b[0;32m--> 146\u001b[0m     predicted \u001b[38;5;241m=\u001b[39m [\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m y_pred \u001b[38;5;129;01min\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    147\u001b[0m     all_preds\u001b[38;5;241m.\u001b[39mextend(np\u001b[38;5;241m.\u001b[39mtranspose(predicted,(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m    149\u001b[0m all_res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(all_preds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    for paper in tqdm(corpus_ACL.papers):\n",
    "    # collect the list of sentences to annotate in certainty\n",
    "        sents = paper.content.sentence.values.tolist()\n",
    "    \n",
    "        # use the certainty models\n",
    "        if \"sentence_certainty\" not in paper.content.columns:\n",
    "            sent_certainty = sentence_estimator.predict(sents)\n",
    "            paper.content[\"sentence_certainty\"] = sent_certainty\n",
    "        \n",
    "        if \"aspect_certainty\" not in paper.content.columns:\n",
    "            aspect_certainty = aspect_estimator.predict(sents)\n",
    "            paper.content[\"aspect_certainty\"] = aspect_certainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cdb8857-fdab-4f7c-a35d-2f121da9f17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    305.000000\n",
       "mean       4.831699\n",
       "std        0.285639\n",
       "min        2.867607\n",
       "25%        4.819613\n",
       "50%        4.937650\n",
       "75%        4.978834\n",
       "max        5.322650\n",
       "Name: sentence_certainty, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_ACL.papers[14001].content.sentence_certainty.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fabec4d8-04e2-4985-8500-152c0b87f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper in corpus_ACL.papers:\n",
    "    paper.corpus = corpus_ACL\n",
    "\n",
    "for paper in corpus_ACL.papers_with_errors:\n",
    "    paper.corpus = corpus_ACL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d982111-13b3-4bd9-a7ca-dd1911db0082",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_ACL_dict = corpus_ACL.to_dict()\n",
    "corpus_ACL_s = json.dumps(corpus_ACL_dict, cls = CustomEncoder)\n",
    "with open(\"data/test_drop_corpus_ACL.json\", \"w\") as f:\n",
    "    json.dump(corpus_ACL_s, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02e69c85-3b0a-42f7-95c1-855939ab9b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_ACL_reloaded = load_corpus_object(\"data/test_drop_corpus_ACL.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dee4d94a-757c-4722-84f7-8dcc3a816c66",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Corpus' object has no attribute 'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcorpus_ACL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Corpus' object has no attribute 'path'"
     ]
    }
   ],
   "source": [
    "corpus_ACL."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
