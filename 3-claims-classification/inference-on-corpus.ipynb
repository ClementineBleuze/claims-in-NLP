{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d9de67c-55b2-42df-8a99-9e25c82e19e1",
   "metadata": {},
   "source": [
    "# Model inference on corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a6aa78-28ed-4235-af56-edbb188439ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3993fe9c-88d3-4c89-9940-b0259e7c6c5b",
   "metadata": {},
   "source": [
    "## Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56fb94dc-7229-4c5f-ad09-c907003c5cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_870856/1616858793.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data/sentences.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12519965, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sent_id_in_paper</th>\n",
       "      <th>sentence</th>\n",
       "      <th>section</th>\n",
       "      <th>-2</th>\n",
       "      <th>-1</th>\n",
       "      <th>candidate</th>\n",
       "      <th>sentence_certainty</th>\n",
       "      <th>aspect_certainty</th>\n",
       "      <th>label_anno</th>\n",
       "      <th>label_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There is a need to measure word similarity whe...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4.546492</td>\n",
       "      <td>[['Condition', 'Certain'], ['Suggestion', 'Cer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Usually, measures of similarity between two wo...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.729261</td>\n",
       "      <td>[['Extent', 'Uncertain'], ['Probability', 'Cer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>The taxonomy approaches are more or less seman...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.835920</td>\n",
       "      <td>[['Probability', 'Certain']]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>However, in real applications, both semantic a...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.872213</td>\n",
       "      <td>[['Probability', 'Certain'], ['Suggestion', 'C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Word similarity based on context vectors is a ...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.952981</td>\n",
       "      <td>[['Probability', 'Certain']]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  paper_id  sent_id_in_paper  \\\n",
       "0            0         0                 0   \n",
       "1            1         0                 1   \n",
       "2            2         0                 2   \n",
       "3            3         0                 3   \n",
       "4            4         0                 4   \n",
       "\n",
       "                                            sentence   section   -2   -1  \\\n",
       "0  There is a need to measure word similarity whe...  abstract  NaN  NaN   \n",
       "1  Usually, measures of similarity between two wo...  abstract  NaN  0.0   \n",
       "2  The taxonomy approaches are more or less seman...  abstract  0.0  1.0   \n",
       "3  However, in real applications, both semantic a...  abstract  1.0  2.0   \n",
       "4  Word similarity based on context vectors is a ...  abstract  2.0  3.0   \n",
       "\n",
       "   candidate  sentence_certainty  \\\n",
       "0       True            4.546492   \n",
       "1       True            4.729261   \n",
       "2       True            4.835920   \n",
       "3       True            4.872213   \n",
       "4       True            4.952981   \n",
       "\n",
       "                                    aspect_certainty label_anno label_pred  \n",
       "0  [['Condition', 'Certain'], ['Suggestion', 'Cer...        NaN        nan  \n",
       "1  [['Extent', 'Uncertain'], ['Probability', 'Cer...        NaN        nan  \n",
       "2                       [['Probability', 'Certain']]        NaN        nan  \n",
       "3  [['Probability', 'Certain'], ['Suggestion', 'C...        NaN        nan  \n",
       "4                       [['Probability', 'Certain']]        NaN        nan  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset containing all of the sentences\n",
    "df = pd.read_csv(\"data/sentences.csv\")\n",
    "df[\"label_pred\"] = df[\"label_pred\"].astype(str)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fec0f10f-7077-4d84-8f6a-e32a533bd3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[0, \"label_pred\"] = str([1, 0, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f98f6bc5-d7cf-4168-bfc2-8862d4e0af13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sent_id_in_paper</th>\n",
       "      <th>sentence</th>\n",
       "      <th>section</th>\n",
       "      <th>-2</th>\n",
       "      <th>-1</th>\n",
       "      <th>candidate</th>\n",
       "      <th>sentence_certainty</th>\n",
       "      <th>aspect_certainty</th>\n",
       "      <th>label_anno</th>\n",
       "      <th>label_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Usually, measures of similarity between two wo...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.729261</td>\n",
       "      <td>[['Extent', 'Uncertain'], ['Probability', 'Cer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>However, in real applications, both semantic a...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.872213</td>\n",
       "      <td>[['Probability', 'Certain'], ['Suggestion', 'C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>In this paper, we propose using only syntactic...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.658012</td>\n",
       "      <td>[['Framing', 'Certain']]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  paper_id  sent_id_in_paper  \\\n",
       "1            1         0                 1   \n",
       "3            3         0                 3   \n",
       "5            5         0                 5   \n",
       "\n",
       "                                            sentence   section   -2   -1  \\\n",
       "1  Usually, measures of similarity between two wo...  abstract  NaN  0.0   \n",
       "3  However, in real applications, both semantic a...  abstract  1.0  2.0   \n",
       "5  In this paper, we propose using only syntactic...  abstract  3.0  4.0   \n",
       "\n",
       "   candidate  sentence_certainty  \\\n",
       "1       True            4.729261   \n",
       "3       True            4.872213   \n",
       "5       True            4.658012   \n",
       "\n",
       "                                    aspect_certainty label_anno label_pred  \n",
       "1  [['Extent', 'Uncertain'], ['Probability', 'Cer...        NaN        nan  \n",
       "3  [['Probability', 'Certain'], ['Suggestion', 'C...        NaN        nan  \n",
       "5                           [['Framing', 'Certain']]        NaN        nan  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t = df.loc[[1,3,5]]\n",
    "df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef3b7d1-88fa-40ee-b252-eee898a05070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sent_id_in_paper</th>\n",
       "      <th>sentence</th>\n",
       "      <th>section</th>\n",
       "      <th>-2</th>\n",
       "      <th>-1</th>\n",
       "      <th>candidate</th>\n",
       "      <th>sentence_certainty</th>\n",
       "      <th>aspect_certainty</th>\n",
       "      <th>label_anno</th>\n",
       "      <th>label_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There is a need to measure word similarity whe...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4.546492</td>\n",
       "      <td>[['Condition', 'Certain'], ['Suggestion', 'Cer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Usually, measures of similarity between two wo...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.729261</td>\n",
       "      <td>[['Extent', 'Uncertain'], ['Probability', 'Cer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>The taxonomy approaches are more or less seman...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.835920</td>\n",
       "      <td>[['Probability', 'Certain']]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>However, in real applications, both semantic a...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.872213</td>\n",
       "      <td>[['Probability', 'Certain'], ['Suggestion', 'C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Word similarity based on context vectors is a ...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.952981</td>\n",
       "      <td>[['Probability', 'Certain']]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  paper_id  sent_id_in_paper  \\\n",
       "0            0         0                 0   \n",
       "1            1         0                 1   \n",
       "2            2         0                 2   \n",
       "3            3         0                 3   \n",
       "4            4         0                 4   \n",
       "\n",
       "                                            sentence   section   -2   -1  \\\n",
       "0  There is a need to measure word similarity whe...  abstract  NaN  NaN   \n",
       "1  Usually, measures of similarity between two wo...  abstract  NaN  0.0   \n",
       "2  The taxonomy approaches are more or less seman...  abstract  0.0  1.0   \n",
       "3  However, in real applications, both semantic a...  abstract  1.0  2.0   \n",
       "4  Word similarity based on context vectors is a ...  abstract  2.0  3.0   \n",
       "\n",
       "   candidate  sentence_certainty  \\\n",
       "0       True            4.546492   \n",
       "1       True            4.729261   \n",
       "2       True            4.835920   \n",
       "3       True            4.872213   \n",
       "4       True            4.952981   \n",
       "\n",
       "                                    aspect_certainty label_anno  \\\n",
       "0  [['Condition', 'Certain'], ['Suggestion', 'Cer...        NaN   \n",
       "1  [['Extent', 'Uncertain'], ['Probability', 'Cer...        NaN   \n",
       "2                       [['Probability', 'Certain']]        NaN   \n",
       "3  [['Probability', 'Certain'], ['Suggestion', 'C...        NaN   \n",
       "4                       [['Probability', 'Certain']]        NaN   \n",
       "\n",
       "              label_pred  \n",
       "0  [1, 0, 0, 0, 0, 0, 0]  \n",
       "1                    nan  \n",
       "2                    nan  \n",
       "3                    nan  \n",
       "4                    nan  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0884a2d0-5cec-4ed1-899a-49f4ea805ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sent_id_in_paper</th>\n",
       "      <th>sentence</th>\n",
       "      <th>section</th>\n",
       "      <th>-2</th>\n",
       "      <th>-1</th>\n",
       "      <th>candidate</th>\n",
       "      <th>sentence_certainty</th>\n",
       "      <th>aspect_certainty</th>\n",
       "      <th>label_anno</th>\n",
       "      <th>label_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There is a need to measure word similarity whe...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4.546492</td>\n",
       "      <td>[['Condition', 'Certain'], ['Suggestion', 'Cer...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Usually, measures of similarity between two wo...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.729261</td>\n",
       "      <td>[['Extent', 'Uncertain'], ['Probability', 'Cer...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>The taxonomy approaches are more or less seman...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.835920</td>\n",
       "      <td>[['Probability', 'Certain']]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>However, in real applications, both semantic a...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.872213</td>\n",
       "      <td>[['Probability', 'Certain'], ['Suggestion', 'C...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Word similarity based on context vectors is a ...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.952981</td>\n",
       "      <td>[['Probability', 'Certain']]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  paper_id  sent_id_in_paper  \\\n",
       "0            0         0                 0   \n",
       "1            1         0                 1   \n",
       "2            2         0                 2   \n",
       "3            3         0                 3   \n",
       "4            4         0                 4   \n",
       "\n",
       "                                            sentence   section   -2   -1  \\\n",
       "0  There is a need to measure word similarity whe...  abstract  NaN  NaN   \n",
       "1  Usually, measures of similarity between two wo...  abstract  NaN  0.0   \n",
       "2  The taxonomy approaches are more or less seman...  abstract  0.0  1.0   \n",
       "3  However, in real applications, both semantic a...  abstract  1.0  2.0   \n",
       "4  Word similarity based on context vectors is a ...  abstract  2.0  3.0   \n",
       "\n",
       "   candidate  sentence_certainty  \\\n",
       "0       True            4.546492   \n",
       "1       True            4.729261   \n",
       "2       True            4.835920   \n",
       "3       True            4.872213   \n",
       "4       True            4.952981   \n",
       "\n",
       "                                    aspect_certainty label_anno label_pred  \n",
       "0  [['Condition', 'Certain'], ['Suggestion', 'Cer...       None       None  \n",
       "1  [['Extent', 'Uncertain'], ['Probability', 'Cer...       None       None  \n",
       "2                       [['Probability', 'Certain']]       None       None  \n",
       "3  [['Probability', 'Certain'], ['Suggestion', 'C...       None       None  \n",
       "4                       [['Probability', 'Certain']]       None       None  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label_anno\"] = [None] * df.shape[0]\n",
    "df[\"label_pred\"] = [None] * df.shape[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a229fa41-4915-4ba7-aa04-2a93fddd2395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105101, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>category</th>\n",
       "      <th>num_cited_by</th>\n",
       "      <th>xml_path</th>\n",
       "      <th>nb_ref</th>\n",
       "      <th>annotated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>O02-2002</td>\n",
       "      <td>ACL</td>\n",
       "      <td>A Study on Word Similarity using Context Vecto...</td>\n",
       "      <td>[['Chen', 'Keh-Jiann'], ['You', 'Jia-Ming']]</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>O02-2002.tei.xml</td>\n",
       "      <td>13.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>R13-1042</td>\n",
       "      <td>ACL</td>\n",
       "      <td>Headerless, Quoteless, but not Hopeless? Using...</td>\n",
       "      <td>[['Jamison', 'Emily'], ['Gurevych', 'Iryna']]</td>\n",
       "      <td>2013</td>\n",
       "      <td>INCOMA Ltd. Shoumen, BULGARIA</td>\n",
       "      <td>Computational Social Science and Social Media</td>\n",
       "      <td>10.0</td>\n",
       "      <td>R13-1042.tei.xml</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>R13-1044</td>\n",
       "      <td>ACL</td>\n",
       "      <td>Recognizing semantic relations within {P}olish...</td>\n",
       "      <td>[['K{\\\\k{e}}dzia', 'Pawe{\\\\l}'], ['Maziarz', '...</td>\n",
       "      <td>2013</td>\n",
       "      <td>INCOMA Ltd. Shoumen, BULGARIA</td>\n",
       "      <td>Semantics: Sentence-level Semantics, Textual I...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>R13-1044.tei.xml</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>W05-0818</td>\n",
       "      <td>ACL</td>\n",
       "      <td>{LIHLA}: Shared Task System Description</td>\n",
       "      <td>[['Caseli', 'Helena M.'], ['Nunes', 'Maria G. ...</td>\n",
       "      <td>2005</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>W05-0818.tei.xml</td>\n",
       "      <td>12.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>R13-1045</td>\n",
       "      <td>ACL</td>\n",
       "      <td>Unsupervised Induction of {A}rabic Root and Pa...</td>\n",
       "      <td>[['Khaliq', 'Bilal'], ['Carroll', 'John']]</td>\n",
       "      <td>2013</td>\n",
       "      <td>INCOMA Ltd. Shoumen, BULGARIA</td>\n",
       "      <td>Phonology, Morphology and Word Segmentation</td>\n",
       "      <td>2.0</td>\n",
       "      <td>R13-1045.tei.xml</td>\n",
       "      <td>17.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id        id source  \\\n",
       "0         0  O02-2002    ACL   \n",
       "1         1  R13-1042    ACL   \n",
       "2         2  R13-1044    ACL   \n",
       "3         3  W05-0818    ACL   \n",
       "4         4  R13-1045    ACL   \n",
       "\n",
       "                                               title  \\\n",
       "0  A Study on Word Similarity using Context Vecto...   \n",
       "1  Headerless, Quoteless, but not Hopeless? Using...   \n",
       "2  Recognizing semantic relations within {P}olish...   \n",
       "3            {LIHLA}: Shared Task System Description   \n",
       "4  Unsupervised Induction of {A}rabic Root and Pa...   \n",
       "\n",
       "                                             authors  year  \\\n",
       "0       [['Chen', 'Keh-Jiann'], ['You', 'Jia-Ming']]  2002   \n",
       "1      [['Jamison', 'Emily'], ['Gurevych', 'Iryna']]  2013   \n",
       "2  [['K{\\\\k{e}}dzia', 'Pawe{\\\\l}'], ['Maziarz', '...  2013   \n",
       "3  [['Caseli', 'Helena M.'], ['Nunes', 'Maria G. ...  2005   \n",
       "4         [['Khaliq', 'Bilal'], ['Carroll', 'John']]  2013   \n",
       "\n",
       "                                   publisher  \\\n",
       "0                                        NaN   \n",
       "1              INCOMA Ltd. Shoumen, BULGARIA   \n",
       "2              INCOMA Ltd. Shoumen, BULGARIA   \n",
       "3  Association for Computational Linguistics   \n",
       "4              INCOMA Ltd. Shoumen, BULGARIA   \n",
       "\n",
       "                                            category  num_cited_by  \\\n",
       "0                                                NaN          14.0   \n",
       "1      Computational Social Science and Social Media          10.0   \n",
       "2  Semantics: Sentence-level Semantics, Textual I...           2.0   \n",
       "3                                                NaN           5.0   \n",
       "4        Phonology, Morphology and Word Segmentation           2.0   \n",
       "\n",
       "           xml_path  nb_ref  annotated  \n",
       "0  O02-2002.tei.xml    13.0      False  \n",
       "1  R13-1042.tei.xml    32.0      False  \n",
       "2  R13-1044.tei.xml    33.0      False  \n",
       "3  W05-0818.tei.xml    12.0      False  \n",
       "4  R13-1045.tei.xml    17.0      False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset containing all of the papers\n",
    "df_papers = pd.read_csv(\"data/papers.csv\")\n",
    "print(df_papers.shape)\n",
    "df_papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98d4df08-a52c-4286-97db-f2a68e493706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14792, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_structure</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>section</th>\n",
       "      <th>label</th>\n",
       "      <th>rw</th>\n",
       "      <th>error</th>\n",
       "      <th>Comments</th>\n",
       "      <th>split</th>\n",
       "      <th>label_as_int</th>\n",
       "      <th>label_as_one_hot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59852</td>\n",
       "      <td>3435904</td>\n",
       "      <td>Multi-Task Active Learning for Neural Semantic...</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Related Work\\...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Most Semantic Role Labeling (SRL) approaches a...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>context-AIC</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59853</td>\n",
       "      <td>3435905</td>\n",
       "      <td>Multi-Task Active Learning for Neural Semantic...</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Related Work\\...</td>\n",
       "      <td>2018</td>\n",
       "      <td>In this paper, we propose a Multi-Task Active ...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>contribution-AIC</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59854</td>\n",
       "      <td>3435906</td>\n",
       "      <td>Multi-Task Active Learning for Neural Semantic...</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Related Work\\...</td>\n",
       "      <td>2018</td>\n",
       "      <td>We evaluate our approach on Indonesian convers...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>contribution-AIC</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>3435907</td>\n",
       "      <td>Multi-Task Active Learning for Neural Semantic...</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Related Work\\...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Our experiments show that multi-task active le...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>result</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>3435908</td>\n",
       "      <td>Multi-Task Active Learning for Neural Semantic...</td>\n",
       "      <td>0. abstract\\n1. Introduction\\n2. Related Work\\...</td>\n",
       "      <td>2018</td>\n",
       "      <td>According to our results, active learning is m...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>result</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eval</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   doc_id                                        paper_title  \\\n",
       "0  59852  3435904  Multi-Task Active Learning for Neural Semantic...   \n",
       "1  59853  3435905  Multi-Task Active Learning for Neural Semantic...   \n",
       "2  59854  3435906  Multi-Task Active Learning for Neural Semantic...   \n",
       "3  59855  3435907  Multi-Task Active Learning for Neural Semantic...   \n",
       "4  59856  3435908  Multi-Task Active Learning for Neural Semantic...   \n",
       "\n",
       "                                     paper_structure  year  \\\n",
       "0  0. abstract\\n1. Introduction\\n2. Related Work\\...  2018   \n",
       "1  0. abstract\\n1. Introduction\\n2. Related Work\\...  2018   \n",
       "2  0. abstract\\n1. Introduction\\n2. Related Work\\...  2018   \n",
       "3  0. abstract\\n1. Introduction\\n2. Related Work\\...  2018   \n",
       "4  0. abstract\\n1. Introduction\\n2. Related Work\\...  2018   \n",
       "\n",
       "                                                text   section  \\\n",
       "0  Most Semantic Role Labeling (SRL) approaches a...  abstract   \n",
       "1  In this paper, we propose a Multi-Task Active ...  abstract   \n",
       "2  We evaluate our approach on Indonesian convers...  abstract   \n",
       "3  Our experiments show that multi-task active le...  abstract   \n",
       "4  According to our results, active learning is m...  abstract   \n",
       "\n",
       "              label     rw  error Comments  split label_as_int  \\\n",
       "0       context-AIC  False  False      NaN  train          [0]   \n",
       "1  contribution-AIC  False  False      NaN  train          [1]   \n",
       "2  contribution-AIC  False  False      NaN  train          [1]   \n",
       "3            result  False  False      NaN  train          [2]   \n",
       "4            result  False  False      NaN   eval          [2]   \n",
       "\n",
       "           label_as_one_hot  \n",
       "0  [1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1  [0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "3  [0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "4  [0, 0, 1, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno = pd.read_csv(\"data/processed-annotations-11-06-full.csv\")\n",
    "print(anno.shape)\n",
    "anno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "daef8c41-16a7-481f-b520-725a015d01d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [03:19<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "# store the annotations in the global sentences file\n",
    "anno_titles = list(anno[\"paper_title\"].unique())\n",
    "\n",
    "for title in tqdm(anno_titles):\n",
    "    \n",
    "    # annotations for the given title\n",
    "    df_t = anno[anno[\"paper_title\"] == title]\n",
    "    \n",
    "    # candidate papers with the same titles\n",
    "    cand_paper_ids = df_papers[df_papers[\"title\"] == title].paper_id.values.tolist()\n",
    "    assert len(cand_paper_ids) != 0\n",
    "    \n",
    "    # candidate sentences\n",
    "    cand_sentences = df[df[\"paper_id\"].isin(cand_paper_ids)]\n",
    "    assert len(cand_sentences) != 0\n",
    "\n",
    "    for i, row in df_t.iterrows():\n",
    "        sent = row[\"text\"]\n",
    "        label = row[\"label_as_one_hot\"]\n",
    "\n",
    "        for j, row in cand_sentences.iterrows():\n",
    "            if row[\"sentence\"] == sent: # check if it is the correct sentence\n",
    "                sent_id = row[\"sentence_id\"]\n",
    "                df.at[sent_id, \"label_anno\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3117c353-8f91-4618-969e-4dfda30da67c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15357, 12)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df[\"label_anno\"].isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "708d6b3e-be11-4f19-9e8f-6c1840cb6db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "df.to_csv(\"data/sentences.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a2fef2-7485-4dae-8363-0687dbef7eca",
   "metadata": {},
   "source": [
    "## Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57115576-5456-46c4-a327-51cf91181540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38002/3896265683.py:2: DtypeWarning: Columns (9,13,14,15,16,17,18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data/sentences-corr.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15850807, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sent_id_in_paper</th>\n",
       "      <th>sentence</th>\n",
       "      <th>section</th>\n",
       "      <th>-2</th>\n",
       "      <th>-1</th>\n",
       "      <th>candidate</th>\n",
       "      <th>sentence_certainty</th>\n",
       "      <th>aspect_certainty</th>\n",
       "      <th>label_anno</th>\n",
       "      <th>label_pred</th>\n",
       "      <th>rel_pos_in_paper</th>\n",
       "      <th>unique_label</th>\n",
       "      <th>Number</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Framing</th>\n",
       "      <th>Suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There is a need to measure word similarity whe...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>4.546492</td>\n",
       "      <td>[['Condition', 'Certain'], ['Suggestion', 'Cer...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['context-AIC']</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>mixed</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td>Certain</td>\n",
       "      <td>Certain</td>\n",
       "      <td>Certain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Usually, measures of similarity between two wo...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.729261</td>\n",
       "      <td>[['Extent', 'Uncertain'], ['Probability', 'Cer...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['context-AIC']</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>mixed</td>\n",
       "      <td>absent</td>\n",
       "      <td>Uncertain</td>\n",
       "      <td>Certain</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>The taxonomy approaches are more or less seman...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4.835920</td>\n",
       "      <td>[['Probability', 'Certain']]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['context-AIC']</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>mixed</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td>Certain</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>However, in real applications, both semantic a...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4.872213</td>\n",
       "      <td>[['Probability', 'Certain'], ['Suggestion', 'C...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['context-AIC']</td>\n",
       "      <td>0.021164</td>\n",
       "      <td>mixed</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td>Certain</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td>Certain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Word similarity based on context vectors is a ...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>4.952981</td>\n",
       "      <td>[['Probability', 'Certain']]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['context-AIC']</td>\n",
       "      <td>0.026455</td>\n",
       "      <td>mixed</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td>Certain</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  paper_id  sent_id_in_paper  \\\n",
       "0            0         0                 0   \n",
       "1            1         0                 1   \n",
       "2            2         0                 2   \n",
       "3            3         0                 3   \n",
       "4            4         0                 4   \n",
       "\n",
       "                                            sentence   section  -2  -1  \\\n",
       "0  There is a need to measure word similarity whe...  abstract  -1  -1   \n",
       "1  Usually, measures of similarity between two wo...  abstract  -1   0   \n",
       "2  The taxonomy approaches are more or less seman...  abstract   0   1   \n",
       "3  However, in real applications, both semantic a...  abstract   1   2   \n",
       "4  Word similarity based on context vectors is a ...  abstract   2   3   \n",
       "\n",
       "   candidate  sentence_certainty  \\\n",
       "0       True            4.546492   \n",
       "1       True            4.729261   \n",
       "2       True            4.835920   \n",
       "3       True            4.872213   \n",
       "4       True            4.952981   \n",
       "\n",
       "                                    aspect_certainty label_anno  \\\n",
       "0  [['Condition', 'Certain'], ['Suggestion', 'Cer...         []   \n",
       "1  [['Extent', 'Uncertain'], ['Probability', 'Cer...         []   \n",
       "2                       [['Probability', 'Certain']]         []   \n",
       "3  [['Probability', 'Certain'], ['Suggestion', 'C...         []   \n",
       "4                       [['Probability', 'Certain']]         []   \n",
       "\n",
       "        label_pred  rel_pos_in_paper unique_label  Number     Extent  \\\n",
       "0  ['context-AIC']          0.005291        mixed  absent     absent   \n",
       "1  ['context-AIC']          0.010582        mixed  absent  Uncertain   \n",
       "2  ['context-AIC']          0.015873        mixed  absent     absent   \n",
       "3  ['context-AIC']          0.021164        mixed  absent     absent   \n",
       "4  ['context-AIC']          0.026455        mixed  absent     absent   \n",
       "\n",
       "  Probability Condition  Framing Suggestion  \n",
       "0      absent   Certain  Certain    Certain  \n",
       "1     Certain    absent   absent     absent  \n",
       "2     Certain    absent   absent     absent  \n",
       "3     Certain    absent   absent    Certain  \n",
       "4     Certain    absent   absent     absent  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset containing all of the sentences\n",
    "df = pd.read_csv(\"data/sentences-corr.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d717c30e-0772-4043-86a2-d52918f3562a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sent_id_in_paper</th>\n",
       "      <th>sentence</th>\n",
       "      <th>section</th>\n",
       "      <th>-2</th>\n",
       "      <th>-1</th>\n",
       "      <th>candidate</th>\n",
       "      <th>sentence_certainty</th>\n",
       "      <th>aspect_certainty</th>\n",
       "      <th>label_anno</th>\n",
       "      <th>label_pred</th>\n",
       "      <th>rel_pos_in_paper</th>\n",
       "      <th>unique_label</th>\n",
       "      <th>Number</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Framing</th>\n",
       "      <th>Suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15850802</th>\n",
       "      <td>15850802</td>\n",
       "      <td>104542</td>\n",
       "      <td>907</td>\n",
       "      <td>This approach then promises to adress the stor...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>15850800</td>\n",
       "      <td>15850801</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15850803</th>\n",
       "      <td>15850803</td>\n",
       "      <td>104542</td>\n",
       "      <td>908</td>\n",
       "      <td>Finally, annotations could simply be output st...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>15850801</td>\n",
       "      <td>15850802</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15850804</th>\n",
       "      <td>15850804</td>\n",
       "      <td>104542</td>\n",
       "      <td>909</td>\n",
       "      <td>Mohri (1994) has described an algorithm to mak...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>15850802</td>\n",
       "      <td>15850803</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15850805</th>\n",
       "      <td>15850805</td>\n",
       "      <td>104542</td>\n",
       "      <td>910</td>\n",
       "      <td>Advantages and disadvantages of this approach ...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>15850803</td>\n",
       "      <td>15850804</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15850806</th>\n",
       "      <td>15850806</td>\n",
       "      <td>104542</td>\n",
       "      <td>911</td>\n",
       "      <td>Of course, application of underlying and surfa...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>15850804</td>\n",
       "      <td>15850805</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentence_id  paper_id  sent_id_in_paper  \\\n",
       "15850802     15850802    104542               907   \n",
       "15850803     15850803    104542               908   \n",
       "15850804     15850804    104542               909   \n",
       "15850805     15850805    104542               910   \n",
       "15850806     15850806    104542               911   \n",
       "\n",
       "                                                   sentence     section  \\\n",
       "15850802  This approach then promises to adress the stor...  Discussion   \n",
       "15850803  Finally, annotations could simply be output st...  Discussion   \n",
       "15850804  Mohri (1994) has described an algorithm to mak...  Discussion   \n",
       "15850805  Advantages and disadvantages of this approach ...  Discussion   \n",
       "15850806  Of course, application of underlying and surfa...  Discussion   \n",
       "\n",
       "                -2        -1  candidate  sentence_certainty aspect_certainty  \\\n",
       "15850802  15850800  15850801      False                -1.0              NaN   \n",
       "15850803  15850801  15850802      False                -1.0              NaN   \n",
       "15850804  15850802  15850803      False                -1.0              NaN   \n",
       "15850805  15850803  15850804      False                -1.0              NaN   \n",
       "15850806  15850804  15850805      False                -1.0              NaN   \n",
       "\n",
       "         label_anno label_pred  rel_pos_in_paper unique_label Number Extent  \\\n",
       "15850802         []         []              -1.0          NaN    NaN    NaN   \n",
       "15850803         []         []              -1.0          NaN    NaN    NaN   \n",
       "15850804         []         []              -1.0          NaN    NaN    NaN   \n",
       "15850805         []         []              -1.0          NaN    NaN    NaN   \n",
       "15850806         []         []              -1.0          NaN    NaN    NaN   \n",
       "\n",
       "         Probability Condition Framing Suggestion  \n",
       "15850802         NaN       NaN     NaN        NaN  \n",
       "15850803         NaN       NaN     NaN        NaN  \n",
       "15850804         NaN       NaN     NaN        NaN  \n",
       "15850805         NaN       NaN     NaN        NaN  \n",
       "15850806         NaN       NaN     NaN        NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a46e63d-8268-4213-830f-d6287619db3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3330842, 20)\n"
     ]
    }
   ],
   "source": [
    "# we focus on the part that has not been annotated yet\n",
    "df_inf = df[(df[\"label_pred\"].apply(lambda x: x == \"[]\")) & (df[\"label_anno\"].apply(lambda x: x == \"[]\"))]\n",
    "print(df_inf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a55b186-b4e8-4e36-a8e9-a5d90ac9f9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3330842/3330842 [05:53<00:00, 9427.76it/s] \n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "inputs = []\n",
    "\n",
    "for i, row in tqdm(df_inf.iterrows(), total = df_inf.shape[0]):\n",
    "    \n",
    "    ll = int(row[\"-2\"])\n",
    "    l = int(row[\"-1\"])\n",
    "\n",
    "    lls = df_inf.at[ll, \"sentence\"] if ll != -1 else \"\"\n",
    "    ls = df_inf.at[l, \"sentence\"]if l != -1 else \"\"\n",
    "    \n",
    "    input = f\"{row['section']}[SEC]{lls}[SEP]{ls}[SEP]{row['sentence']}\"\n",
    "    inputs.append((row[\"sentence_id\"], input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3261e532-88a1-44bd-bc68-ac414c818a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12520018,\n",
       " 'The Role of the Information Handler[SEC]When XSEL is ready to accept input, the information handler is passed a message indicating the case frame or class of case frames expected as a response.[SEP]For our example, assume that a command or query is expected, the parser is notified, and the user enters >[SEP]What is the price of the 2/argest dual port fixed media disks? ')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a0c24c0-78c0-4e85-b25d-5c666ec7413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/inference-inputs-for-left-out-sents.json\", \"w\") as f:\n",
    "    json.dump(inputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48943117-5b2c-4c63-8fde-e80b7efc04ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/inference-inputs-for-left-out-sents.json\", \"r\") as f:\n",
    "    inputs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d93d4ad5-0c8c-48d9-bd37-3a67f8f6b032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /home/clbleuze/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clbleuze/myenv/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from utils.utils import get_predictions_from_logits\n",
    "\n",
    "# connect to Huggingface\n",
    "login(token = \"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\", add_to_git_credential = True)\n",
    "\n",
    "# load labels\n",
    "with open(\"data/labels.json\", \"r\") as f:\n",
    "    LABELS = json.load(f)\n",
    "    \n",
    "# load the model\n",
    "model_checkpoint = \"ClementineBleuze/scibert_prefix_cont_ll_SEP\"\n",
    "tokenizer_checkpoint = \"allenai/scibert_scivocab_uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint,\n",
    "                                                           num_labels = len(LABELS),\n",
    "                                                           problem_type = \"multi_label_classification\")\n",
    "\n",
    "# load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_checkpoint)\n",
    "# add new special token separator for section\n",
    "special_tokens_dict = {'additional_special_tokens': ['[SEC]']}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "# resize model embeddings\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# create a trainer\n",
    "args = TrainingArguments(output_dir = \"results\", per_device_eval_batch_size = 16)\n",
    "trainer = Trainer(model = model, args = args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a8dedfc-1b7f-4ece-a7fd-2e4361512d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "832710\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# define tokenization function\n",
    "def tokenize_function(tokenizer):\n",
    "    def tokenize(examples):\n",
    "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    return tokenize\n",
    "\n",
    "batch_size = len(inputs) // 4\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b46c8d2-ca82-4975-a8be-0459abd2c5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbed08291f734094aa3731fff7344436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/832710 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 0\n",
    "test_ds = Dataset.from_dict({\"text\": [ip[1] for ip in inputs[n * batch_size : (n+1) * batch_size]]})\n",
    "tokenized_test_ds = test_ds.map(tokenize_function(tokenizer), batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fca35dfd-cf56-47dd-b37b-59ef00738b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='92' max='104089' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    92/104089 00:30 < 9:42:43, 2.97 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# data inference\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_test_ds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpredictions\n\u001b[1;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m get_predictions_from_logits(logits, strategy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstraints\u001b[39m\u001b[38;5;124m\"\u001b[39m, threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m, use_sigmoid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/transformers/trainer.py:3648\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3645\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3647\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3648\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[1;32m   3650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3651\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/transformers/trainer.py:3774\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3772\u001b[0m         all_inputs\u001b[38;5;241m.\u001b[39madd(inputs_decode)\n\u001b[1;32m   3773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3774\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3775\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3776\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics(logits, labels)\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/accelerate/accelerator.py:2482\u001b[0m, in \u001b[0;36mAccelerator.pad_across_processes\u001b[0;34m(self, tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m   2449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpad_across_processes\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pad_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2451\u001b[0m \u001b[38;5;124;03m    Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so\u001b[39;00m\n\u001b[1;32m   2452\u001b[0m \u001b[38;5;124;03m    they can safely be gathered.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_first\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/accelerate/utils/operations.py:414\u001b[0m, in \u001b[0;36mchained_operation.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 414\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DistributedOperationException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    416\u001b[0m         operation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/accelerate/utils/operations.py:681\u001b[0m, in \u001b[0;36mpad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    678\u001b[0m     new_tensor[indices] \u001b[38;5;241m=\u001b[39m tensor\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_tensor\n\u001b[0;32m--> 681\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_pad_across_processes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_first\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/accelerate/utils/operations.py:126\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    118\u001b[0m         {\n\u001b[1;32m    119\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m         }\n\u001b[1;32m    124\u001b[0m     )\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_on_other_type:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported types (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) passed to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. Only nested list/tuple/dicts of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects that are valid for `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` should be passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/accelerate/utils/operations.py:661\u001b[0m, in \u001b[0;36mpad_across_processes.<locals>._pad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n\u001b[1;32m    660\u001b[0m \u001b[38;5;66;03m# Gather all sizes\u001b[39;00m\n\u001b[0;32m--> 661\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    662\u001b[0m sizes \u001b[38;5;241m=\u001b[39m gather(size)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    663\u001b[0m \u001b[38;5;66;03m# Then pad to the maximum size\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# data inference\n",
    "logits = trainer.predict(tokenized_test_ds).predictions\n",
    "predictions = get_predictions_from_logits(logits, strategy = \"constraints\", threshold = 0.5, use_sigmoid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f7c8cd-d571-4293-b57b-00fef48dcd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [ip[0] for ip in inputs[n * batch_size : (n+1) * batch_size]]\n",
    "\n",
    "for sentence_id, prediction in zip(idx, predictions):\n",
    "    df.at[sentence_id, \"label_pred\"] = prediction\n",
    "\n",
    "df.to_csv(\"data/sentences-corr.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "20858950-12fc-4427-a9e1-d09e5a879312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ebb1db-62d6-4239-a847-30e86ea2d681",
   "metadata": {},
   "source": [
    "## Certainty validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "823acd91-c4a6-4262-a0b6-ebdfcdf742b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sent_id_in_paper</th>\n",
       "      <th>sentence</th>\n",
       "      <th>section</th>\n",
       "      <th>-2</th>\n",
       "      <th>-1</th>\n",
       "      <th>candidate</th>\n",
       "      <th>sentence_certainty</th>\n",
       "      <th>aspect_certainty</th>\n",
       "      <th>label_anno</th>\n",
       "      <th>label_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There is a need to measure word similarity whe...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4.546492</td>\n",
       "      <td>[['Condition', 'Certain'], ['Suggestion', 'Cer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Usually, measures of similarity between two wo...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.729261</td>\n",
       "      <td>[['Extent', 'Uncertain'], ['Probability', 'Cer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>The taxonomy approaches are more or less seman...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.835920</td>\n",
       "      <td>[['Probability', 'Certain']]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>However, in real applications, both semantic a...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.872213</td>\n",
       "      <td>[['Probability', 'Certain'], ['Suggestion', 'C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Word similarity based on context vectors is a ...</td>\n",
       "      <td>abstract</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.952981</td>\n",
       "      <td>[['Probability', 'Certain']]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  paper_id  sent_id_in_paper  \\\n",
       "0            0         0                 0   \n",
       "1            1         0                 1   \n",
       "2            2         0                 2   \n",
       "3            3         0                 3   \n",
       "4            4         0                 4   \n",
       "\n",
       "                                            sentence   section   -2   -1  \\\n",
       "0  There is a need to measure word similarity whe...  abstract  NaN  NaN   \n",
       "1  Usually, measures of similarity between two wo...  abstract  NaN  0.0   \n",
       "2  The taxonomy approaches are more or less seman...  abstract  0.0  1.0   \n",
       "3  However, in real applications, both semantic a...  abstract  1.0  2.0   \n",
       "4  Word similarity based on context vectors is a ...  abstract  2.0  3.0   \n",
       "\n",
       "   candidate  sentence_certainty  \\\n",
       "0       True            4.546492   \n",
       "1       True            4.729261   \n",
       "2       True            4.835920   \n",
       "3       True            4.872213   \n",
       "4       True            4.952981   \n",
       "\n",
       "                                    aspect_certainty label_anno  label_pred  \n",
       "0  [['Condition', 'Certain'], ['Suggestion', 'Cer...        NaN         NaN  \n",
       "1  [['Extent', 'Uncertain'], ['Probability', 'Cer...        NaN         NaN  \n",
       "2                       [['Probability', 'Certain']]        NaN         NaN  \n",
       "3  [['Probability', 'Certain'], ['Suggestion', 'C...        NaN         NaN  \n",
       "4                       [['Probability', 'Certain']]        NaN         NaN  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "52c4bf3e-678b-4ecd-acb2-ede16f2839c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"sentence_certainty\"].hist(bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "17996375-a263-440c-be08-511a7a0dbf45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['They might be slightly related, but grouping them together seems inappropriate according to the following table : Word set Average similarity Stand deviation 數量,多少 人數 0.379825 0.253895 c) Different uses: Differences in their usage cause synonyms to behave differently .',\n",
       " 'Average similarity Stand deviation 十分,非常, 特別 0.45054 0.305209 Although the three words, 十分 \"very/ten points\", 非常 \"very\" and 特 別\"special, extraordinary\" might seem to be very close in meaning to \"very\", the polysemous word 特別 \"special, extraordinary\" is different in its major sense.',\n",
       " 'Words that are similar in terms of their context s might not be similar in meaning.',\n",
       " 'We propose that sturctural features, as well as style features below, may help in classification by means of communication accommodation theory (Giles and Ogay, 2007). ',\n",
       " \"Attribute is a property of an individual or an event, such as colour, size, weigth, intensity, duration etc., which might be expressed with a qualitative adjective: czerwony samochód 'red car', głośna muzyka 'loud music'. \",\n",
       " 'The poor performance in the English-Inuktikut task may be partly due to the fact that Inuktikut is a polysynthetic language, that is, one in which, unlike in English, words are formed by long strings of concatenated morphemes.',\n",
       " 'The advantage of this approach to gauge relatedness of words over other approaches, such as minimum edit distance, is the ability to better capture morpheme dependencies between words with common roots which may be orthographically quite different due to substantial affixing.',\n",
       " 'In Arabic, sometimes alterations in root radicals take place; for example, in hollow roots, when moving from a root containing a long vowel to the surface word, the long vowel might change its form to another type or get dropped.',\n",
       " 'On the other hand, some corpus-attested word combinations may appear semantically deviant when considered out of context (for example, when they are used metaphorically).',\n",
       " 'Vecchi et al. (2011) have focused on unattested adjective-noun (AN) combinations and noted that if a combination does not occur in a corpus, it may be due to various reasons including data sparsity as well as nonsensicality.',\n",
       " \"Learners may lack robust intuitions about words' selectional preferences and subtle differences in meaning, so they may confuse near-synonyms, overuse words with broad meaning, and otherwise choose words inappropriately.\",\n",
       " \"When a word combination appears to be nonsensical as in 2c, the words chosen might still be related to the appropriate ones in the learner's mental lexicon.\",\n",
       " \"We recognise that although error detection in learners' content word combinations is a natural extension to semantic anomaly detection, it also poses additional difficulties that semantic models might not be able to deal with.\",\n",
       " 'However, semantic models might still be able to capture some of these conventions.',\n",
       " 'We estimate the word cooccurrence statistics using the BNC only, and leave it for future research to explore the impact of estimating them from larger corpora, for example, the ukWaC or the concatenated corpus mentioned above.',\n",
       " 'We hypothesise that some cues alternative to the ones already proposed may also be effective: The models can be assessed by their ability to place the AN vector in the neighbourhood populated by similar words and combinations.',\n",
       " 'We assume that there might be a difference between the corpus-attested and corpus-unattested  Vecchi et al. (2011).',\n",
       " 'Some other models such as the ones by Erk and Padó (2008) and Thater et al. (2010) which take selectional preferences and context into account may yield better results on this task, and we plan to test this experimentally in the future.',\n",
       " 'Thus, the semantic role tags in the Japanese corpus of CoNLL 2009 might be different from those for English SRL. between main and subordinate clauses, e.g., Cooccurrence and Sequence; however, these similar semantic role tags are not connected to predicate concepts, such as frames, as defined in PropBank or FrameNet.',\n",
       " 'In the present experiment we only used the sum of Japanese and English hits; we may be able to obtain more efficient information by taking into account the balance between the hits in the two languages. ',\n",
       " 'Combined with the fact that labeled data nowadays is inexpensive to come by, the \"kitchen sink\" approach, while technically nonglamorous, might be perfectly adequate in practice.',\n",
       " 'Combined with the fact that labeled sentiment data tends to be cheap to come by through either the collection of product reviews from the web or inexpensive crowd-sourced labeling, this indicates that in practice, domain-adaptation for sentiment detection might be of less importance than previously claimed. ',\n",
       " 'We also show that the often anecdotally observed \"polarity-flip\" of sentiment terms from one domain to another in practice is a rather rare occurrence and might not be as detrimental to sentiment domain adaptation as assumed in much of the literature.',\n",
       " 'Depending on the specifics of how idf is calculated, this may yield different results from indexing ngrams directly, but it is advantageous in terms of space consumed and scalability to different ngram sizes without reindexing.',\n",
       " 'This may often lead to false matching as some idioms require the strict use of either definite or indefinite articles, but we found we can gain more than we lose by applying this processing, from the point of view of system requirements. ',\n",
       " 'The remaining variations may well be ones that are more context dependent, creative, and/or related to constructions larger than those that can be conveniently described by POS-based patterns.',\n",
       " 'The low interest in developing rule-based systems might be caused by a lack of robust and accessible tools for rule construction and execution.',\n",
       " 'The task is not as simple as it may seem, because both decisions depend not only on the syntactic and semantic attributes of the light-verb, but also on those of the nominalized verb (Muraki, 1991). ',\n",
       " 'The important point is that for languages that are distant, some algorithms may not perform too well, if they rely on some closeness between languages.',\n",
       " 'In future, we might extend the evaluation to all kinds of alignments, since the manual alignment currently being done on ERDC corpus includes partial and 1-to-2 or 2-to-1 alignments.',\n",
       " 'Perhaps with better tuning for English-Hindi, it might perform better.',\n",
       " 'Leaving aside the tuning aspect, the low performance of Mmd may be due to the fact that it relies on cognate matching, and there are fewer cognates between Hindi and English.',\n",
       " 'It might also be due to the syntactic differences (word order) between Hindi and English.',\n",
       " 'It could be because of the fact that the EMILLE has a lot of very short (1-3 words) sentences, and word correspondence (in the second pass) may not be that effective for such sentences.',\n",
       " 'For example, on sentiment classification, different types of negative expressions may be preferred to a positive expression which ap-pears several times.',\n",
       " 'As a result, it may happen that a positive text using the same positive expression several times with some types of negative expressions is classified as a negative text because consideration of frequency is lacking. ',\n",
       " 'In addition to being a key step in discourse analysis (Joty et al., 2019), discourse segmentation has been shown to improve a number of downstream tasks, such as text summarization, by helping to identify fine-grained sub-sentence units that may have different levels of importance when creating a summary (Li et al., 2016). ',\n",
       " 'The main motivation for this model is its simplicity; however, using only local contexts might be sub-optimal, as longer distance linguistic artifacts are likely to help locating breaks.',\n",
       " 'Moreover, RNNs in general may also be useful for very long documents as they are able to deal with very long input sequences. ',\n",
       " 'In future work, we plan to further investigate how different techniques apply to the problem of text segmentation, including data augmentation (Wei and Zou, 2019;Lukasik et al., 2020b) and methods for regularization and mitigating labeling noise (Jiang et al., 2020;Lukasik et al., 2020a).',\n",
       " 'This might be due to the low number of documents compared to the other languages (Steinberger et al., 2012), but also because, in the case of the BERT variant, we use a multilingual model instead of a monolingual one.',\n",
       " 'It has practical implications for social networking and social media, where it may be desirable to organize comments and other user-generated content by language.',\n",
       " 'This may reveal some insight into the design of CLD, which is likely to have been tuned for language identification of web pages.',\n",
       " 'Multilingual animacy detection (Jahan et al., 2018) might help with this challenge; co-reference information might additionally help. ',\n",
       " 'Furthermore, traditional entities tend to occur as noun phrases, while the newly proposed entities (for the purposes of the task) may be linguistically complex (complex noun phrases, gerunds, infinitives or full clauses).',\n",
       " 'Older texts have been corrected to the current orthography using an internally developed tool that uses a 1.5 million word lexicon of the Romanian language backing-off a rule-based word corrector in case the lexicon might not contain some words. ',\n",
       " 'Given that I criticize existing WSD algorithms for using too much data, it might seem hypocritical to employ a data source with 10 12 words.',\n",
       " 'Substitutes that are not synonyms, on the other hand, may be very useful such as \"hot\" vs. \"cold\" or \"car\" vs. \"truck\".',\n",
       " 'A more intuitive way to look at the result may be the following: Human annotators assigned 4.04 distinct substitutes for each instance on average, and my system was able to guess one of these as the best in 33.73% of the cases. ',\n",
       " 'Investigation reveals that different types of events defined in TimeML may or may not have specific semantic or syntactic roles (e.g. THM or OBJECT) in a particular context, therefore having an impact on their ways to convey temporal meanings.',\n",
       " 'For real-world data, documents W are observed, while the corresponding topic assignments Z are unobserved and may be inferred using either variational methods (Blei et al., 2003;Teh et al., 2006) or MCMC methods (Griffiths and Steyvers, 2004).',\n",
       " 'If the topic is not coherent, there may be words in the topic that are also not semantically related to any other word, thus causing users to select \"correct\" words instead of the real intruder. ',\n",
       " 'We also found that Gibbs sampling mixes faster for models that use word cooccurrence information, suggesting that such methods may also be useful in guiding online stochastic variational inference (Hoffman et al., 2010).',\n",
       " 'Once the seed segmenter is developed on the basis of a manually segmented corpus, the performance may be improved by iteratively expanding the stem vocabulary and retraining the language model on a large automatically segmented Arabic corpus.',\n",
       " 'It is likely that the various conversational phases are subject to different norms of turntaking and that phenomena such as laughter or disfluency may appear in different distributions in different phases.',\n",
       " 'Comparing the production by all participants in all conversations, where a participant may produce either laughter or speech, laughter accounts for ap-proximately 9.5% of total duration of speech and laughter production in chat phases and 4.9% of total duration of speech and laughter production in chunk phases.',\n",
       " \"As chunks are generic (narrative, gossip..), it may be fruitful to consider modelling extended casual talk as a series of 'mini-dialogs' of different types modelled on different corpora -how to convincingly join these sections is an interesting research ques-tion. \",\n",
       " 'First, given an existing conversation history, there may be a large number of valid responses (Vinyals and Le, 2015).',\n",
       " 'How-ever, we hypothesize that this additional diversity may lead to lower engagingness scores. ',\n",
       " 'Finally, we observe in Figure 8 (left) that the memory attention is most heavily weighted on coffee, which may explain why the coffee persona begins with such high weights.   ',\n",
       " 'We believe that the reason for this is that we used a dependency parser, and that the rules that we used to convert dependency nodes into spans may have produced some errors.',\n",
       " 'For example, we might expect that the adjective Baltimorean attaches to man roughly the same number of times as it attaches to woman, controlling for the frequency of man and woman.',\n",
       " 'However, differences in the use of other adjectives (or verbs) may be more pernicious.',\n",
       " 'For example, in (Sorg and Cimiano, 2008) when the whole Wikipedia collection is adopted to build the space, one document is mapped to ten thousand dimensions, in which it may only have very few truly semantically related dimensions.',\n",
       " 'Depending on the IE setting, one might, for example, judge that statements (1)-( 3) justify the extraction of an (NE 1 , NE 2 ) relation, while (4) and (5) do not.',\n",
       " 'This difference in distribution suggests that it may be beneficial to give the two cases different treatment in extraction.',\n",
       " 'Here the NLI task is treated as a textual sequence classification problem, where the premise and hypothesis sentences are concatenated as [CLS], premise, [SEP ], hypothesis, [SEP ] (depending on the tokenizer, the concatenated text might be slightly different) and fed into the model.',\n",
       " 'Augmentation, and NLI pre-training We use the SGD dataset to further study how relevant factors like labeling technique, data augmentation, and NLI pre-training on general corpus might impact USLP-T performance in different few-shot settings.',\n",
       " 'We tend to think that the effect of data augmentation is task-dependent, it might work well on some datasets but fail on other datasets.',\n",
       " 'NLI pre-training can boost performance in low-shot setting, but might have adverse effect when more training data is available.',\n",
       " 'Since the training data we use is highly imbalanced, data augmentation might lead to disturbance in the original intent distribution.',\n",
       " 'The language detection score varies across languages, which may be due to the vocabulary overlap between languages, e.g., San Francisco appears in both English and German utterances.',\n",
       " 'The lower slot F1 scores using the MT approach in few and zero shot setups indicate that the fast align method to align slots in source and translation might result in noisy training data affecting the SL model.',\n",
       " 'Sufficient performance for statistical models may therefore only come when we have access to many millions of aligned sentences. ',\n",
       " 'The use of multiple learners increases the chance that useful information will be added; an example which is easily labeled by one learner may be difficult for the other and therefore adding the confidently labeled example will provide information in the next round of training. ',\n",
       " \"Because languages vary in how they use morphology (some languages have grammatical gender whereas others don't) one language's translation model might have the translation of a particular word form whereas another's would not.\",\n",
       " 'The accuracy gains from co-training might extend for additional rounds if the size of the candidate pool were increased, or if some method were employed to reduce the amount of noise being introduced.',\n",
       " 'One can imagine that sizable parallel corpora might be available between Turkish and a few EU languages like Greek and Italian.',\n",
       " 'For example, creators of a media assistant may want to add new commands specialized towards new media types like podcasts, or those of a navigation assistant might like to add a new feature to allow users to specify roads to avoid.',\n",
       " 'For example, when introducing a new intent for podcasts, the original dataset may have included podcast examples labeled with a more generic media intent or a label indicating that the feature is unsupported.',\n",
       " \"When introducing a new argument, say 'roads to avoid', there may be instances in the original dataset that should have this argument labeled but do not because they were annotated before the argument was introduced.\",\n",
       " 'By taking advantage of this information, we may be able to avoid some unwanted side effects of our model updates.',\n",
       " 'Since LEN CH is more appropriate for multilingual processing due to variations in the rules of tokenization between languages (e.g., English vs. German), it may be considered a preferable multilingual metric. ',\n",
       " 'We continue to investigate why this might be the case, but believe it may be due to the fact that the training data we randomly selected for the Hansards may not have been representative of the gold standard data. ',\n",
       " 'Second, we believe that the relatively small amount of training data might account for the somewhat unpredictable nature of these results.',\n",
       " 'Readers use a variety of clues to distinguish temporality from the clinical narrative, and we wanted to identify features from other tem-poral models that may be useful for determining whether a condition is historical or recent. ',\n",
       " 'We used TimeML Specification 1.2.1 for standardization of tense and aspect where examples of tense include Past or Present and aspect may be Perfective, Progressive, Both or None as found in Saur´ı, et al. (2006).',\n",
       " 'The primary verb may be a predicate adjective integral to interpretation of the condition (Left ventricle is enlarged), a verb preceding the condition (has hypertension), or a verb following a condition (Chest pain has resolved).',\n",
       " \"Emergency Department reports and Discharge Summaries contain similar proportions of historical conditions (17% and 19% respectively), which might be explained by the fact that both reports describe a patient's temporal progression throughout the stay in the Emergency Department or the hospital. \",\n",
       " 'This may seem counterintuitive; however, in the statement \"We are treating this as chronic musculoskeletal pain with oxycodone\", the condition is being referenced in the context of the reason for the current visit.',\n",
       " 'By incorporating additional section headers that may strongly predict historical, ConText could potentially predict a condition as historical when a trigger term is absent and the header title is the only predictor as in the case of \"ALLERGIES: peanut allergy\".',\n",
       " 'Although our results are preliminary, we believe our study has provided a few new insights that may help improve the state of the art for historical categorization of a condition.',\n",
       " 'Both JRip and RL produced high performance, suggesting a broader set of features may improve historical classification; however, because these features do not result in perfect performance, there are surely other features necessary for improving historical classification.',\n",
       " 'However, identifying which parts of an utterance trigger a considerable reduction in the set of plausible intent interpretations may be helpful when evaluating the performance of such a module.',\n",
       " 'Popular NLU intent benchmarks with notably fewer classes, such as ATIS and SNIPS (Hemphill et al., 1990;Coucke et al., 2018), may contain more such artefacts, which would speak against the generalisability of the results obtained on them.',\n",
       " 'Rather, they represent subtle differences in formulation of utterances that humans, but not the classifier, might associate with a certain intent class, which results in a considerable amount of (but not all) participants predicting the final intent. ',\n",
       " 'People are probably more likely to buy perishable items such as milk at a store in-person: a failure to \"understand\" this real-world knowledge might have caused the classifier to miss this prediction.',\n",
       " 'Inspection of the training data reveals that some features may be more important than others in establishing word sense assignment for each choice of word lemma.',\n",
       " 'Although these results are promising, there is still much work to be done.',\n",
       " 'For instance, ONYX may produce two interpretations for \"mesial amalgam\"-one referring to the mesial surface of an amalgam filling, and one referring to an amalgam filling on the mesial surface of some unspecified tooth.',\n",
       " 'As can be seen in these examples, the tokens in the query q and answers r q (S) and r q (T ) may or may not be contiguous (examples 2 and 3), and the TL answer may possibly be empty (example 4) when there is no satisfying way of linking TL tokens to the query. ',\n",
       " 'This suggests that it might be a good idea to integrate a \"contiguity constraint\" right into the alignment search procedure. ',\n",
       " 'Although the other two data sets may have popular people with many web pages, their web presence are usually created by others and often scatter across many domains with little hyperlinkage between them.',\n",
       " 'While this might be sufficient for the BioNLP community, it is certainly insufficient for bioinformaticians and molecular biologists since they require large-scale data with high coverage and reliability.',\n",
       " 'As, however, every manually curated database is likely to be incomplete and might contain some errors, we supplement our evaluation against REGULONDB with a manual analysis of false positives errors caused by our system (cf. Section 5.4).',\n",
       " 'Confounded agents and patients (21% on the abstracts, 14% on full texts) and information not contained in REGULONDB (24% on the abstracts, 21% on full texts) might be useful from a heuristic perspective to focus on interesting data during the curation process.',\n",
       " 'Given that different clustering results may have different labels for the same cluster, the Hungarian algorithm (Kuhn, 1955) is employed in the process of calculating ACC to map labels from one clustering to those from the other.',\n",
       " 'E.g. part of sentence one in the source might be translated as part of the second sentence in the target; • 2:1, 1:2, and 3:1 -these cases are similar to the case before: they handle differences in how a text is split into sentences.',\n",
       " 'In addition, using either a language-dependent penalty function to measure the similarity between bilingual word pairs, or handcrafted heuristic mapping rules for transliteration may lead to problems when porting to other language pairs.',\n",
       " 'This article reports on mass experiments supporting the idea that data extracted from strongly comparable corpora may successfully be used to build statistical machine translation systems of reasonable translation quality for in-domain new texts.',\n",
       " 'However, depending on the comparability level of the extraction corpus, the quantity of parallel data extracted may range from 0.1% (weakly comparable corpora) to 29% (strongly comparable corpora) of the entire corpus (Ion et al., 2011).',\n",
       " 'A similar variation may be noticed for En-Es pair: from 24.42 to 12.28 (En) and from 25.49 to 12.63 (Es).',\n",
       " 'The almost eight BLEU points difference between our results and those in (Dumitrescu et al., 2013) may be explained by: 1) our language model was entirely in-domain for the test data and much larger: our language model was built from entire Romanian Wikipedia (more than 220,000 documents) while the language model in (Dumitrescu et al., 2013) was built only from the Romanian doc-ument paired to English documents (less than 100,000 documents); 2) different Moses filtering parameters (e.g. the length filtering parameters), 3) different test sets.',\n",
       " 'The astute reader may have noticed that the dictionaries used by LEXACC for mining MT useful data were extracted by GIZA++ from out-ofdomain corpora (JRC-Acquis and Europarl).',\n",
       " 'Comparing different translation models containing MT useful data ranging from comparable, through strongly comparable, to parallel, we concluded that there is sufficient empirical evidence not to dismiss sentence pairs that are not fully parallel on the suspicion that because of the inherent noise they might be detrimental to the translation quality.',\n",
       " 'Although it can significantly slow down the extraction process, it might still be useful in cases where the potential user wants to improve the quality of the output.',\n",
       " 'As Polish is an inflectional language, this approach allows a lot of grammatically incorrect phrases to be filtered out while, at the same time, it is not limited to the sequences recognized properly by a deep parser for Polish, which for a specific domain might not have enough coverage. ',\n",
       " 'Although in some approaches the ranking procedure may be very complex, the idea of an additional phase of filtering improperly built pre-selected phrases, as suggested in our paper, is not very popular.',\n",
       " \"The phrase Ustawa o Funduszu Kolejowym 'Act on the Railway Fund' may not be shortened to the phrase Ustawa o Funduszu 'Act on the Fund', although it is still acceptable at the syntactic level.\",\n",
       " 'Once our candidate terms are extracted, we processed to the second step, and we assign to each one of them linguistic, stylistic, statistic, and distributional descriptors that might help us get insights as to the nature of terms (Table 1).',\n",
       " 'We suspect that in this case uniformity of the training data and lack of diversity in the n-best list may have damaged MBR; the resulting translations appear similar in structure, but many have extraneous articles and determiners, which hurts BLEU.',\n",
       " 'Since the absence of capitalisation in Arabic, Arabic POS taggers might mistake some organisations and locations for nouns (NN) or adjectives (JJ), especially meaningful names.',\n",
       " \"For example, (alwlaayaat almutHdah alamrykyh 'United States of America') might be tagged as alwlaayaat/NNS almutHdah/JJ alamrykyh/JJ.\",\n",
       " 'While evaluating ontologies for the particular application is a relatively straightforward method, evaluations may be sensitive to the test dataset, and it may also be expensive to perform evaluations for many ontologies. ',\n",
       " 'Conversely, features that count the number distinct actors mentioned in text may be good indicators of lower relevance-such as an article mentioning many different diseases or companies is less likely to be of high relevance.',\n",
       " 'This may be due to the fact that the probability models in the Berkeley and Bikel parsers are more finely tuned to the PTB and thus more brittle to noisy data, whereas LoPar uses a simpler model and is more robust. ',\n",
       " 'This might suggest that the other parser combinations may not have resulted in this critical mass; in other words, that the HCRC corpus may be too small as a target domain data set given a parser combination setting.',\n",
       " 'In the best case, correctness may be correlated with utility, in the worst case it is independent of utility (e.g., if the system happens to achieve high correctness on events from the past, which have low relevance).',\n",
       " 'The system may provide some support for determining reliability, e.g., by tracking the performance of different information sources over time, since the reliability of the facts extracted from an article is related to the reliability of the source.',\n",
       " 'It may be possible to classify Web-based sources according to their credibility; some sources may habitually withhold informa-tion (for fear of impact to tourism, trade, etc.); other sites may try to attract readership by exaggerated claims (e.g., tabloids).',\n",
       " \"User's interest is individual, e.g., a user may have specific geographic, or medical focus (e.g., only viral or tropical illnesses), and given the structured database, s/he can filter the content according to specific criteria.\",\n",
       " 'This is done because it may be beneficial for various sounds to have a higher frame rate, while for some other that may not be the case.',\n",
       " 'Note that, the Merge( 1)+( 2) G2P may result in one or two pronunciations per word, while other techniques only result in one pronunciation per word.',\n",
       " 'Also, since Chinese and English may use punctuation (especially for the usage of comma) in different places of parallel sentences, the sub-sentence splitting method for the HIT corpus that we described in Section 4.2 can lead to non-parallel sentences.',\n",
       " 'Since the development data of this task also has the sub-sentence problem (described in Section 4.3), our system may use examples across punctuation boundaries which can generate translations with unnatural word order.',\n",
       " 'In Latvian only half of the word endings are unambiguous, while for the rest, multiple base forms may be derived from the inflected form (Skadin ¸a et al., 2012). ',\n",
       " 'They argue that, although \"NMT shows significant improvements for some language pairs and specific domains, there is still much room for research and improvement before broad generalizations can be made.',\n",
       " 'This hypothesis can motivate us to explore more types of features (lexical, syntactic, semantic...) in the future work ; (2) the whole combination of features without any selection strategy might be an unskilful option weakening our classifier capability.',\n",
       " 'The amount of context-dependent user utterances, as Dahlbäck and Jönsson (1989) already pointed out, as well as the distribution of the different relations among questions and answers explained above, may be dependent on the nature of the task attempted in the dialogue. ',\n",
       " 'Yet, there may be cases of ambiguity, where only inferences about the goals of the user may help to resolve the reference, as in ( 13): (13) US: How is the contact for that project? LT: daelem@uia.ua.ac.be US: What is the institute?',\n",
       " 'However, for open domain systems not having a knowledge-base with structured data it may be much more difficult to keep track of the focus of attention beyond the strictly local context.',\n",
       " \"For other kinds of interactions which don't have such a structured nature as our tasks, this may also be the case.\",\n",
       " \"In such cases it may be difficult to determine how long frames are active if the nesting goes very far, as well as making any inferences about the user's plans.\",\n",
       " 'However, it might also be the case, that in that kind of interactions no implicit referring expressions are used beyond the segmental level, because there is no such an extended context.',\n",
       " 'In further work, it will be necessary to integrate the lexicon we obtained into a sentiment analysis system to check whether or not taking modifiers into may improve the performance. ',\n",
       " 'A survey of currently available NLPaaS services suggests that it may be possible to identify a minimal application layer protocol that can be shared by NLPaaS services without sacrificing functionality or convenience, while at the same time simplifying the development of clients for these services.',\n",
       " 'To that end, we survey and compare protocols used by NLPaaS services and suggest how these protocols may be further aligned to reduce variation.',\n",
       " 'Therefore, when requests are expected to take an extended amount of time, e.g. in order to process a large amount of text or to execute a heavy task, the use of a synchronous protocol may be inappropriate. ',\n",
       " 'In a GET request, the (short) text to be processed is given as the value of a parameter, whose name may differ among servers; text is commonly used, but more abstract names such as content may be used for services that can process multiple content types (e.g., HTML, XML).',\n",
       " 'To illustrate how the proposed protocol might be used, we consider both a client-server communication environment and a server-server communication environment using PUSH notifications.',\n",
       " 'When a value of a key is a structured value (e.g., an array of NLP processes to make up a pipeline), it may be difficult or impossible to send them as key-value pairs.',\n",
       " 'In contrast to allomorphs, some morphemes might sound the same phonetically; however, they might function differently.',\n",
       " 'Some examples of homophonous morphemes in Turkish are given below: • kalemi: -i might correspond to either an accusative form (e.g. his/her pen) or a possessive form (e.g. give me the pen) which can be determined from the context. ',\n",
       " 'As already mentioned, prepositional semantics is language-specific: The semantic classes a preposition might express do vary between languages, the semantic contributions given by a preposition in one language are often realized by different prepositions in different languages.',\n",
       " 'Even if such a correlation turns out not to be a strong one, it might nevertheless help as a feature in a machine learning model.',\n",
       " \"In English, the corresponding verb construction is 'to listen to', es\\\\en with 0 by to of in on about as from  The second examples illustrates that the same semantic class, LOC (local), might be realized by two different prepositions in German and in English.\",\n",
       " 'Finally, contextual features might profit from synonym expansion or synonym set classification, a technique also used by Kiss et al. (2010).',\n",
       " 'The authors state that a major challenge in building text classification models may be the change which occurs in the characteristics of the documents and their classes over time (Mourão et al., 2008).',\n",
       " 'the authors raise the problem of access to historical collections of doc-uments, which may be difficult due to the different historical and modern variants of the text, the less standardized spelling, words ambiguities and other language changes.',\n",
       " 'In ISO Standard 25964 of 2013, when it comes to discuss about the interoperability of the systems, the associative mapping is described as a connection that \"[...] may be established between concepts when they do not qualify for equivalence or hierarchical mappings, but are semantically associated to such an extent that documents indexed with the one are likely to be relevant in a search for the other.\"',\n",
       " 'The Princeton WordNet specifies 14 types of morphosemantic relations between verbs and nouns many of which may be related to semantic roles such as agent, instrument, location, etc., though the correspondence is not always straightforward (e.g., By-means-of).',\n",
       " 'We think that it is important to start doing this kind of application-driven evaluations, which might shed light to the intricacies in the interaction between WSD and IR strategies.',\n",
       " 'This might have the disadvantage of having been produced by pooling the results of CLEF participants, and might bias the results towards systems not using WSD, specially for monolingual English retrieval.',\n",
       " 'Note that due to the limitation of the search engine, long queries were truncated at 50 words, which might explain the very low results of the full expansion.',\n",
       " 'These high results can be explained by the fact that many senses get the same translation, and thus for many words with few translation, the random translation might be valid.',\n",
       " '(Yang et al., 2019) introduced the permuted language model task, although it is not clear whether the success of the model is due to the innovative pre-training or larger quantity of pre-training. ',\n",
       " 'To explore how frequent this case might be we select 100 thousand new SSPT instances with a relevant passage and for each select an alternative, random, answer-bearing, passage.',\n",
       " 'In addition, the linguistic generalisations behind the existing MSRs have been made on the basis of English derivational morphology, hence the proposed set of MSR instances may be extended based on evidence from the derivational morphology of other languages, including Bulgarian. ',\n",
       " 'The relation Body-part may be an inanimate cause that is an inalienable part of an actor and is expressed by nouns with noun.body primes (rarely noun.animal or noun.plant).',\n",
       " \"The relation Material denotes a subclass of inanimate causes -substances that may bring about a certain effect (e.g. inhibitor:1 ('a substance that retards or stops an activity').\",\n",
       " 'Results also show that for certain MSRs the OneR algorithm performs slightly better than the RandomTree (usually RandomTree outperforms OneR by more than 25%), which suggests that a more complex approach combining case-specific classifiers may prove more reliable. ',\n",
       " 'The lower accuracy on CC-DBP and NYT-FB might be caused by the different style of the corpora (Wikipedia vs. Web pages).',\n",
       " 'For instance, InferSent is trained using a natural language inference dataset, which might be not suitable to learn representations which represent relations in text.',\n",
       " 'Recently, pre-trained language models have been used for slot filling (Petroni et al., 2020), opening a new research direction that might provide an effective solution to the aforementioned problems.',\n",
       " 'Regarding our second hypothesis, we might expect that more frequent entities have better representations in the parameters of a pre-trained language model, and that therefore the gain in performance due to use of explicit knowledge will show a strong dependence on the corpus frequency of the head or tail entity. ',\n",
       " 'The context aggregation approaches of state-of-the-art neural models, max-pooling (Zeng et al., 2015) and attention (Lin et al., 2016), do not consider that different contexts may contribute to the prediction in different ways.',\n",
       " 'Furthermore, even cases where there is a relevant binary context set, the contexts may not provide enough or any textual support for the relation, while the unary context sets might. Woolworths, Coles owner Wesfarmers, JB Hi-Fi and Harvey Norman were also trading higher.',\n",
       " 'For example, a prediction that a city is in France might depend on the conjunction of several facets of textual evidence linking the city to the French language, the Euro, and Norman history. ',\n",
       " 'However, this is not the case for under-resourced languages in which reliable language resources such as machine-readable bilingual dictionaries with broad word coverage or word lemmatizers might be not publicly available.',\n",
       " 'Weg in die Vereinten Nationen offensteht -0.397418711927629 Even though some of the extracted phrases are not exact translation equivalents, they may still be useful resources both for SMT and RBMT if these phrases are passed through an extra preprocessing stage, of if the engines are modified specifically to work with semi-parallel translation equivalents extracted from comparable texts.',\n",
       " 'The dataset for supervised lexical substitution consists of sentences, containing an annotated target word t. Considering the sentence being the context for the target word, the target word might have different meanings.',\n",
       " 'However, it shows promise that subjectivity may be reduced by casting lexical substitution into a task of maintaining entailment.',\n",
       " 'Incorporating fine-grained senses B+gold senses yields only a slightly higher gain, showing that a coarsegrained subjective/objective classification might be sufficient for subjectivity-ambiguous words for aiding translation.',\n",
       " 'In addition, the small gain using fine-grained senses might disappear in practice as automatic WSD is a more challenging task than SWSD: in our experiment, B+auto sense performs worse than B+auto subj.',\n",
       " 'In this case, word sense subjectivity might help to distinguish List-S from List-O, but not among the candidate translations within a single list.',\n",
       " 'While linguistic theories may identify only one or two prepositions associated with an argument of a verb, frame semantic analyses bring in the possibility of a greater variety of prepositions introducing the same type of frame element.',\n",
       " 'However, Kim and Hovy (2004) and Andreevskaia and Bergler (2006) show that subjectivity recognition might be the harder problem with lower human agreement and automatic performance.',\n",
       " 'More importantly, as the unlabeled data can be chosen to be related to the labeled and test data, they might help pull test data to the right cuts (categories).',\n",
       " 'Selection of unlabeled data: Random selection of unlabeled data might hurt the performance of Mincuts, as they might not be related to any sense in our training/test data (denoted by A).',\n",
       " 'However, in our graph-based Mincut framework, the vertex \"religious\" might link to other vertices (for example, it links to the vertex \"scrupulous\" in the unlabeled data by the relation \"similar-to\").',\n",
       " 'Moreover, the prevalence of different word senses in different domains also means that a subjective or an objective sense of a word might be dominant in different domains; thus, in a science text positive is likely not to have a subjective reading.',\n",
       " 'However, our mapping from its phrase annotation to sentence annotation might be too coarse-grained as many sentences in the corpus span several clauses containing both opinions and factual description.',\n",
       " 'However, this word-based approach does not take different senses of a word into account, which might differ in whether and what kind of sentiment they evoke.',\n",
       " 'We hypothesize that annotation at the sense level might eliminate one possible source of disagreement for subjectivity/polarity annotation and will therefore hopefully lead to higher agreement than at the word level. ',\n",
       " 'A potential disadvantage for annotation at the sense level is that it is dependent on a lexical resource for sense distinctions and that an annotation scheme might have to take idiosyncracies of specific resources into account or, ideally, abstract away from them. ',\n",
       " 'Overall, the experimental results show high agreement, confirming our hypothesis that agreement at sense level might be higher than at the word level.',\n",
       " 'In contrast, a sense like the one of alarm clock in Example 11 might have negative connotations for late risers but it would be annotated as O:NoPol in our scheme.',\n",
       " 'Thus, a researcher might want to mainly focus on explicitly expressed opinions as exemplified by subjectivity, whereas another can also focus on opinion bias in a text as expressed by loaded words of positive or negative polarity.',\n",
       " 'Objects may be functional aggregates, such as the oil burner, which is a system component that includes other components; linguistic aggregates, which include plurals and conjunctions; or a summary over several unspecified indicators or RUs.',\n",
       " 'Since not all interested participants may have access to the LDC corpus described in the previous subsection, the second track of this task makes use of English-Chinese documents gathered from the URL pairs given by the STRAND Bilingual Databases.',\n",
       " 'A common criticism of LSA is that its \"bag of words\" approach ignores any other linguistic information that may be available, e.g. order and syntactic information: to LSA, man bites dog is identical to dog bites man.',\n",
       " 'This has made the task particularly challenging for participants, because naive learning strategies (such as empirical adjustment of distance thresholds to optimize standard clustering algorithms) might be misleaded by the training set.',\n",
       " 'More complex patterns might be involved.',\n",
       " 'Beyond these simple heuristics, more sophisticated approaches might take advantage of the work in anaphora resolution, such as (Baldwin, 2001). ',\n",
       " \"It should be pointed out, however, that the term annotated corpus is still small enough to be representative of the word frequency and is a sample of translated texts that might manifest different tendencies for a term's distribution from those in the original texts.\",\n",
       " 'The adjective-noun agreement in Bulgarian noun phrases is partially exploited in the presented piece of work, but it might be extensively considered in further improvements of the method. ',\n",
       " 'Although, some parameters are common in many languages, some others may be language specific.',\n",
       " 'Recognition involves term identification in its surface form, which for morphologically complex languages may be hindered by many surface forms a single word can take or by the level of form ambiguity in the case of morphologically impoverished languages (Bergmanis and Goldwater, 2018).',\n",
       " 'The outcome might be unintended downplaying of the role of translation for technical domains, could lead to diminishing interest in terminology translation from the MT research community.',\n",
       " 'A typical result of an evaluation may be that out of twelve measures ten favor B and two favor A, but only two show statistical significance and those two point to opposite conclusions.',\n",
       " 'To understand how a human tutor may verbalize a collection of facts, we collected 23 tutoring dialogues (for a total of 270 tutor turns) between a student interacting with the DIAG application on home heating and a human tutor.',\n",
       " 'While useful for animate nouns, such annotations might seem otherwise redundant because the majority of nouns in training data can be expected to be inanimate.',\n",
       " 'However, this might just be owing to this particular test sample having more verbs with higher perplexities, and maybe even ones that are indeed difficult to disambiguate -in spite of high human agreement.',\n",
       " 'Given high enough ITA rates we can can hope to build sense disambiguation systems that perform at a level that might be of use to a consuming natural language processing application.',\n",
       " 'Although easier items usually require less time than difficult items, the interaction between these two item properties is not strictly linear -examinees may spend very little time responding to certain difficult items and, likewise, examinees may spend a great deal of time on items that are relatively easy.',\n",
       " 'In such cases, one item may require the formation of a complex cognitive model of the problem and thus take a long time, while another item with a similar level of difficulty may require factual knowledge that few examinees recall (or that many recall incorrectly) and thus take a short time on average.',\n",
       " 'Studying the linguistic characteristics of these two categories may help test developers gain a more nuanced understanding of how cognitively complex items differ from those with a straightforward solution.',\n",
       " 'For example, medical terms can be expected to have lower absolute frequencies and familiarity ratings, among other characteristics, and combinations of these features may suggest a higher density of medical terms and specialized language in some items compared to others.',\n",
       " 'The words contained in the high-complexity items also have slightly higher concreteness levels, providing another indication that they may contain more terms, as terms tend to be more concrete than common words.',\n",
       " 'While the approach taken in this paper has a higher ecological validity, studying such cases in the future may lead to a greater understanding of various aspects of response process complexity and their relationship to item text.',\n",
       " 'In the future we may consider splitting this into two tasks, where one subtask focuses on those anchorings that are very local, like \"...White House spokesman Marlin Fitzwater [said] [late yesterday] that...\".',\n",
       " 'Meta information, like scene settings and description, was only available for a small minority of the films and has thus not been utilised in the current paper although we believe it may be useful for our future research.',\n",
       " 'If Compliance Officers are in any doubt, if a film is on the borderline between two categories, or if important policy issues are involved, it may be seen by other members of the BBFC, up to and including the Chief Executive, the President and Vice Presidents.',\n",
       " 'As a consequence, a Romanian synset may have one of the following structures: (i) list of words; (ii) list of free word combinations; (iii) empty list.',\n",
       " 'The same type of analysis applies not only to events but also to relations and states; the frame-evoking expressions may be single words or multi-word expressions, which may be of any syntactic category.',\n",
       " 'In other words, these models may be useful to partially solve the problem of effort associated with SAQ scoring but do not help with solving the problem of rater accuracy.',\n",
       " 'While the exploration of the effects on training and test set sizes is not the focus of this paper (see (Heilman and Madnani, 2015) for a study on this topic), it is conceivable that model performance would improve as the year progresses and more training data becomes available. ',\n",
       " 'While there is no clear explanation for this lack of an effect, it may possibly be related to the size of the corpora or it could mean that most of the variations found in the answers were everyday variations, rather than medicine-specific ones (e.g., \"drug side effects\" and \"effect of medication\").',\n",
       " 'While acknowledging that such subtle differences may exist, it is not far-fetched to assume that both formats measure the generic construct of clinical skills knowledge.',\n",
       " 'As a result, it is sometimes not possible to pretest as many new items as needed and some exam programs may not be able to afford pretesting at all.',\n",
       " 'In spite of the limitations of current QA systems, it is conceivable that since humans and machines need to perform similar processes in order to answer a question, these processes might be challenged by the same types of questions.',\n",
       " 'Even if such parallels are not found, testing this working hypothesis is a useful by-product of the current research, as it may inform better strategies for approaching automatic QA tasks.',\n",
       " '• Item length in words: This baseline is applied to rule out the possibility that item survival is simply a function of item length (e.g., that longer items may be more difficult).',\n",
       " 'In terms of task definition, the results from the classification approach were better than those from modeling P-value and Rb individually, suggesting that there may be value in learning the two parameters simultaneously. ',\n",
       " 'While such data sets are typically not freely available because of test security (exam questions become unusable if there is a chance that examinees might have seen them in advance), they exist in most high-stakes exams that test subject knowledge using the multiple-choice format.',\n",
       " 'Further research might lie in finding efficient representations of Bayes Risk loss functions within the decoding process (rather than just using MBR to rescore n-best lists), as well as analyses on different language pairs from the available Europarl data.',\n",
       " 'The goal of the analysis was to determine what the methodology might reveal regarding the difficulty level of either the machinetranslation (MT) task or the text-alignment (TA) task.',\n",
       " 'The results of this analysis show that even in a perfectly aligned corpus, the word distributions between the two languages deviate and because they do, LSA may contribute much to our understanding of the difficulty of the MT and TA tasks.',\n",
       " 'Because of the way LSA represents word-usage associations and patterns among documents and terms, it may have much to offer in understanding the difficulty levels of these tasks.',\n",
       " 'This paper presents a first look at the alignment patterns found in a parallel corpus and how LSA may offer some insights into the MA and TA tasks.',\n",
       " 'This paper presented a brief discussion on the possibility that the LSA methodology may have something to contribute with respect to identifying the difficulty level of the MT and TA tasks.',\n",
       " 'It may be that a much smaller number of input texts is needed than formerly believed, in order to \"train\" an LSA-based system to correlate the appropriate cross-language word pairs.',\n",
       " 'The cause of such errors may depend not only on the translation paradigm adopted, but also on the language pairs, the availability of enough linguistic resources and the performance of the linguistic processors, among others.',\n",
       " 'Additionally, the graphical interface of the toolkit may help developers to better understand the strengths and weaknesses of the existing evaluation measures and to support the development of further improvements or even totally new evaluation metrics.',\n",
       " 'As we are combining different word embeddings, some of them may be more beneficial for certain words than others, e.g., domain-specific embeddings for in-domain words.',\n",
       " 'Sentence alignments typically involve one English sentence matching one Inuktitut sentence (a 1-to-1 bead), but may also involve 2-to-1, 1-to-2, 0-to-1, 1-to-0 and 2-to-2 sentence matching patterns, or beads.',\n",
       " 'Under such conditions, there may not be sufficient information available for an unsupervised clustering algorithm to make fine grained distinctions, and so discovering one cluster for a word may be a better course of action that making divisions that are not well supported by the data.',\n",
       " 'Another factor that attributes to the weak performance of KnowledGPT might be the pre-training models used for initialization 6 .',\n",
       " 'While the values on Distinct-1/2 (Li et al., 2016) indicate the PLATO-KAG and supervised TMN might have better capacity on lexical diversity.',\n",
       " 'While some knowledge details might be obscured with this fusion.',\n",
       " \"SUPPORT verbs (Gross, 1981;Gross, 1982;Mel'ĉuk, 1988;Mel'ĉuk, 1996;Fontenelle, 1997) are verbs which 5 When a noun fits into multiple categories, those categories may predict multiple senses, but not necessarily.\",\n",
       " 'Finally, there are cases where argument sharing may ¥ Support verb/noun pairs can be idiosyncratically connected to the point that some researchers would call them idioms or phrasal verbs, e.g., take a walk, keep tabs on. ¥',\n",
       " 'The \"verb/noun\" combination may take a different set of arguments than either does alone, e.g., take advantage of. ',\n",
       " 'This is because in general, for the reordering purpose the POS tags are good class representations for content words whereas different prepositions may have different word order patterns so that mapping them all to a single POS P masks the difference.',\n",
       " 'Given the fact that some slots co-occur more often than others, modeling the slot types jointly may be helpful when making this kind of prediction.',\n",
       " 'The slot value S (t) s of the s-th slot type at time step t might be a span in the previous conversation of simply none.',\n",
       " '2) On the other hand, improving other classes may be less effective, since the number of mistakes is much smaller.',\n",
       " 'It may be because TripPy+LSTM models all the assignment {C s } N s=1 of the classes jointly, while TripPy+MRF only models {C s } N s=1 jointly.',\n",
       " 'Again, we can blame this on the bad selection of reference, but there could be also something else: selection strategies that synthesize input datasets based on what is easiest to translate might not be as useful as we have assumed.',\n",
       " 'On the other hand, it might also indicate a problem with BLEU as an evaluation measure. ',\n",
       " 'Features from quality estimation (Specia et al., 2010) might be also helpful to determine the best input to tune on. ',\n",
       " \"The hotel reservation data could have parts that might be useful to learn from, e.g., greeting and obtaining a user's name/contact information.\",\n",
       " \"The data could also have parts that are inconsistent with the needs of the restaurant reservation system, e.g., hotel reservation might require the dialog system to ask for the user's duration of stay while the restaurant reservation might require the dialog system to ask for the particular day and time of table reservation.\",\n",
       " 'For example, some data points of the related task which are quite different from the primary task might still be useful to learn from at the early stages of training to help with learning better representations for the vocabulary, and some data points that the dialog system has already learned from might get lower weights at later stages of learning so as to avoid overfitting and thereby helping with the prediction of other data points.',\n",
       " \"For instance, after linking the German 'Fledermaus' to the animal sense of 'bat', we may be able to infer the same for the Turkish translation 'yarasa'.\",\n",
       " 'In some cases, there is overwhelming evidence indicating that two slightly different articles should be grouped together, while in other cases there might be little evidence for the correctness of an edge and so it can easily be deleted with low cost. ',\n",
       " \"These are all integrated into WordNet's hypernym hierarchy, i.e. from language families like the Sinitic languages one may move down to macrolanguages like Chinese, and then to more specific forms like Mandarin Chinese, dialect groups like Ji-Lu Mandarin, or even dialects of particular cities. \",\n",
       " \"For example, a user wishing to find a Spanish word for the concept of persuading someone not to believe something might look up the word 'persuasion' and then navigate to its antonym 'dissuasion' to find the Spanish translation.\",\n",
       " 'For further improvements, there may be two directions: (1) using joint learning methods for task 1 and task 2.',\n",
       " \"Second, finetuning on small datasets may reduce response diversity and fluency due to neural networks' known propensity for catastrophic forgetting (Greco et al., 2019)\",\n",
       " 'But note the conceptual difference: the \"parse projection\" approach departs from a given monolingual parser, with a particular style of analysis, whereas our project will explore to what extent it may help to design the grammar topology specifically for the parallel corpus case.',\n",
       " 'For large-scale learning experiments this may be problematic, especially when one moves to lexicalized grammars, which involve an additional factor of n 4 .',\n",
       " 'As a further issue, we observe that the inference rules are insufficient for multiply branching rules, in which partial constituents may be discontinuous in one dimension (only complete constituents need to be continuous in both dimensions).',\n",
       " 'Condition (iii) excludes discontinuity in passive chart items, i.e., complete constituents; active items (i.e., partial constituents) may well contain discontinuities.',\n",
       " 'Continuity assumptions make it possible to constrain the search space significantly, to the point that synchronous parsing for sentence pairs with few \"NULL words\" (which lack correspondents) may be faster than standard monolingual parsing.',\n",
       " 'A more sophisticated statistical model might take into account dependencies between discourse markers and referential patterns and from them posit hidden states which correspond to different discourse relations.',\n",
       " 'Even in the case of ample training data, the tool may fail to generate correct annotation if the model implemented in it is not capable to capture some relevant generalization, e.g. a second-order HMM model may not capture long-distance agreement constraints, which results in random noise.',\n",
       " 'While the usage of morphological information might seem at first sight to be simple, there are several corner cases that need to be handled.',\n",
       " 'For the BERT model the difference between exact and overlap results is slightly larger, which might be caused by the additional retokenization to subword units and detokenization back to the original CoNLL format.',\n",
       " 'The usefulness of complex linguistic features (especially syntactic and semantic tags) is questionable: they may be hard to compute, errorprone and their contribution is not clear.',\n",
       " 'If we adopt this theory, we can explain why it may be difficult to tag some examples, since both readings may co-exist.',\n",
       " 'Language generation systems that use corpora and methods without awareness of emotions may generate callous, generic or even biased responses (Bender et al., 2021;Sheng et al., 2019).',\n",
       " 'Depending on the use case or type of system, it may be useful to stylistically vary responses, e.g., using shorter responses for spoken dialogue systems, longer responses if the system includes visual modality through a screen, or emotion-specific responses that appropriately address user sentiment. ',\n",
       " 'Our analysis shows that, in general, styles that encapsulate abstract ideas are naturally harder to generate (e.g., empathy), and methods that require careful hyper-parameters tuning may run into the problems of instability and degeneration (e.g., PPLM) while under-performing in style accuracy. ',\n",
       " 'Additionally, since abstract styles may be characterized by multiple features (e.g., a combination of sentiment and descriptiveness), we are interested in studying how these underlying features can be represented and incorporated more accurately to improve overall semantic and stylistic control.  ',\n",
       " 'Secondly, by ordering the remaining sentences by their relative original position, we maintain positional information about the emotional content of the most subjective sentences in the document and thus may be able to extract useful positional patterns.',\n",
       " 'These systems have proven successful, but relying wholly on text means that some analyses may be inaccurate (Nygaard et al., 2009), since acoustic signals may be needed to arrive at the right intent.',\n",
       " 'This disambiguating function of pause information is well known, but the potential role of pause information in signalling different types of constituents, as described in Seifart et al. (2018), has not, to our knowledge, been investigated in this setting. ',\n",
       " 'Knowledge describing lexico-semantic relations that is extracted from it is always partial (not all word senses occur, most senses are infrequent) and may suggest erroneously accidental semantic associations between words.',\n",
       " 'Although Glove is trained on a very large corpus, it may still lack domain coverage when processing medical texts.  ',\n",
       " 'In addition, as NER-A, NER-B and NER-C can also produce outputs for Task 1, we can combine their prediction result in a simple ensemble manner, which may lead to better performance.',\n",
       " 'Second, there are different structure candidates to engage different subtasks in an HMTL setting, and we simply made an empirical design for the current DeepGeneMD system, which may have limited the potential of mutual benefits of multiple learning tasks.',\n",
       " 'Third, when merging results from different components, we assume that decomposed subtasks may have learned better knowledge regarding the corresponding subset of entities, but that assumption may not hold. ',\n",
       " 'Moreover, the comparison with other supervised and knowledge-based systems may be also done, since the test corpus was borrowed from the well known \"English lexicalsample\" task in SemEval-2007, with the usual training + test split. ',\n",
       " 'This may be done by calculating the ratio between the number of times that both terms appear together (in the same context and not necessarily in the same order) and the product of the number of times that each term ocurrs alone.',\n",
       " 'However, given the similar values with the \"Baseline1\", we may assume that that team presented one cluster per ambiguous word as its result as the Baseline1 did; whereas we obtained 9.03 senses per ambiguous word in average.',\n",
       " 'We will further investigate whether an improvement may be obtained by applying term selection methods to the expanded corpus.',\n",
       " 'In molecular biology for example class cross-over of terms may arise because many DNA and RNA are named after the protein with which they transcribe.',\n",
       " \"An additional obstacle to re-use is that the classification scheme used within an existing thesaurus or database may not be the same as the one in the users' ontology which may change from time to time as the consensus view of the structure of knowledge is refined. \",\n",
       " 'This may be an effect of the small sample of training data that we used and we could not find any consistent explanation why this occurred. ',\n",
       " 'One possible explanation for this is that all of these classes have very small numbers of samples and the effect of adding features may be to blur the distinction between these and other more numerous classes in the model.',\n",
       " 'This may possibly be due to either overlapping knowledge or more likely subtle inconsistencies between POS features and say, orthographic features.',\n",
       " 'At the same time, relying only on out-of-domain data might be risky as CDL accuracy largely depends on the properties of in-domain and out-ofdomain data sets, e.g., domain similarity and complexity (Ponomareva and Thelwall, 2012a;Ponomareva and Thelwall, 2012b).',\n",
       " 'However, in some cases it might be beneficial to give them different impacts.',\n",
       " 'In contrast, for CDL highly reliable labels do not help much when source and target data are very different and it might be better to prioritise unlabeled examples.',\n",
       " 'While participants were allowed to choose the tasks they would participate, due to the dependency between the tasks, it was expected that participating all the three tasks might maximize the chance of high performance: Task 2 requires the result of Task 1, and Task 3 may be benefited from the result of Task 1 and 3.',\n",
       " 'To extract the triples of a gene, a function change, pendent from Task 1 and 2, syntactically, it may be benefited from the results of the two tasks, semantically. ',\n",
       " 'On the other side, investigations on this language may be quite useful since the majority of principles can be extended to the wider group of Slavic languages (e.g. Czech, Polish, Russian, etc.). ',\n",
       " 'All these characteristics indicate that morphosyntactic knowledge might be very useful for statistical machine translation involving Serbian language, especially when only scarce amounts of parallel text are available.',\n",
       " 'These percentages are indicating that this parallel text, although very scarce, might be an useful additional training material. ',\n",
       " 'The motivation for choosing the approach of the MSTParser is that two of the tasks that we handle can be non-local, and the algorithm may require information from distant nodes in or-der to find an appropriate solution.',\n",
       " 'Since the co-reference might be dependant mainly on morphological features (in morphologically rich languages) and/or syntactic positions and dependencies (both -in morphologically rich and morphologically poor languages), the difference would be rather explicated in the degrees of mutual interaction.',\n",
       " 'Moreover, this technique may help capture all possible variations in languages that present a flexible word order, such as Romance languages, Hungarian, etc.',\n",
       " 'We lemmatize all terms in an attempt to reduce the variability that morphologically rich languages (that commonly also have a rather flexible word order) might bring, which is often a source of problems for unsupervised bilingual dictionary induction methods, as per Søgaard et al. (2018b).',\n",
       " 'This process will yield a score per document, which may have a different representation depending on the specific analysis criteria, be it mentions of a certain topic or the frequency of the terms with which it is related (i.e. combined incidences for all the terms that belong to a certain topic in a text). ',\n",
       " 'Further refinements in such processes and integration of the CLE-generated phrase-table into statistical or neural machine translation models may mitigate the issue, among other possibilities that we will briefly explore at the end of this section.',\n",
       " 'Term matching overlap can be tuned in order to maximise performance, although it would mean that the logic behind some of the terms of the original thesaurus might be compromised, which in some cases might be a better fit for the target language.',\n",
       " 'We include some possible heuristics that may help build sensible expressions from a unigram translation dictionary, which is itself induced from the aforementioned CLE procedure, and compare their performance against each other and a commercial machine translation system.',\n",
       " 'Although this simplifying assumption is reasonable for calculating the difference in probability of the data given the augmented model, it might not be such a good assumption during decoding.',\n",
       " 'This boost in performance might be due to the model understanding code-mixed language after the first finetune and, as a result, adapting better over the code-mixed dialogs in the second finetune.',\n",
       " 'There are, however, cases where self-training may be beneficial performance-wise, namely as a way to adapt systems to new domains (Steedman et al., 2003;Bacchiani et al., 2006), when using a re-ranker (Charniak and Johnson, 2005) or when considering the confidence score of the parser (Schneider, 2012). ',\n",
       " 'However, this difference may be partially due to a second effect, namely that the TüBa-D/Z training corpus is in-domain in respect to the TüBa-D/Z test set, but Europarl is not.',\n",
       " 'Church et al. (1994) show that Pointwise Mutual Information (PMI) is a suitable measure to capture the degree to which a given word may substitute for another; we have adopted PMI as the quantified measure of substitutability in the systems used for these tasks. ',\n",
       " 'Features were also created that harnessed the idea that it is not only the level of substitutability for each candidate word that is useful, but also that it may be informative to recognise that some words are better substitutes than others.',\n",
       " 'It is also possible that the current highly supervised and lexicalised approach employed is not well-suited to the all-words task, and may require extension to achieve broad coverage. ',\n",
       " 'Although these results may seem discouraging, we believe this challenge can be overcome in the future by using algorithms which reduce variance in the policy gradient and by initializing EX with a model pre-trained in span extraction.',\n",
       " 'This study focuses on relations and entities found in multi-party conversations, and while there are similarities between the dialogue domain, medical literature, and wikipedia (e.g., multi-entity, multi-relation), it is not clear whether the methods from this paper can transfer to other such domains.',\n",
       " 'For the same reasons that language models may have ethical and social risks, so may our algorithm which is built on top of such language models.',\n",
       " 'While we test only on TV show dialogues, were this technology to be put to use in non-scripted, real life conversations, there would need to be very thorough analysis of any ethical risks that the proposed explanations may have.  ',\n",
       " 'A revised European copyright law may, for example, accommodate an exception for the \"decompilation of languages\" for the purposes of developing language resources for machine translation, i.e. a provision transposed mutatis mutandis from the \"reverse engineering/decompilation\" exception presently available in the EC Software Directiveart. 6).',\n",
       " 'It should be noted that it may happen that some of the resources collected this way are actually not available for commercial or any other use because of IPR problems. ',\n",
       " 'Further research is dedicated toward the question of whether expensive human relevance judgments are necessary or whether the constructed document pool of the most highly ranked documents from all runs may serve as a valid approximation of the human judgments.',\n",
       " 'Consequently, this technique may also be beneficial for lower-ranked runs.',\n",
       " 'For our pattern detection system, we used the patterns from Hearst (1992), complemented with those from Mititelu (2008) Some of the patterns were not as likely to occur in their Dutch translation as they might be in English (e.g. in common with other), but we decided to test all the patterns to get an idea which patterns would yield the correct noun pairs and which would more often result in false positives.',\n",
       " 'Conventional word-alignment methods have been successful at treating many language pairs, but may be limited in their ability to generalize beyond the Western European language pairs for which they were originally developed, to pairs which exhibit more complex divergences in word order, morphology and lexical granularity.',\n",
       " 'However, because the network is directed, the lowest cost from w 1 to w 2 , P min (w 1 , w 2 ), may be different than from w 2 to w 1 , P min (w 2 , w 1 ).',\n",
       " 'As mentioned previously, there is still much room for improvement in addressing cross-sentence relation extraction. ',\n",
       " 'Although the resulting set of links may still be relatively accurate, we can symmetrize by combining it with the set produced by applying the complementary model P(e|f) to the same data (Och and Ney, 2000b).',\n",
       " 'If we allow NULL alignments, we may be able produce a high-precision, low-recall asymmetric alignment, but symmetrization by intersection will not improve recall.',\n",
       " 'We consider training an intent classifier, where an intent is a type of request that the conversational agent supports; e.g. the user may want to change the language of the conversation, play a song, transfer money between accounts, etc.',\n",
       " 'Although focusing mainly on the POS tagging problem, we believe that this work may be the foundation for a new paradigm to solve other NLP tasks.',\n",
       " 'These texts usually contain information related to drugs, medications, chemicals, reactions, interactions, etc. Named Entity Recognition (NER) of chemical compounds is receiving increased attention from researchers, as it may facilitate the application of information extraction to the pharmaceutical treatment of diseases.',\n",
       " 'Looking forward, possible improvements might be pursued by combining the two approaches into a more robust system.',\n",
       " 'Contrary to generic simple words, terminological word compounds are mono-referential, i.e. they are unambiguous and refer only to one specific concept in one special language, even if they may occur in more than one domain.',\n",
       " 'This choice allows us to demonstrate that the modularity of our architecture may be applied to a domain which is variable by type and properties and is semantically interlinked. ',\n",
       " 'Various attributes (preference, quality, and profit) are initially hidden from one agent with respect to its role; during the conversation, both sides may reveal, fake, or retain the information uncovered to come to a final decision through natural language.',\n",
       " 'In the FruitStand task, the seller might claim that one type of fruit is the best in quality when it really is not, attempting to attract a buyer to choose a more profitable item, and vice versa, to keep a buyer away from a less lucrative one. ',\n",
       " 'A more detailed examination of this resource and approaches on how to optimally merge/combine multiple annotations and in turn train new systems using this silver standard dataset might give new insights on how to speed up the creation of new NER tools/annotated datasets. ',\n",
       " 'Another possibility might be to integrate our method with another preprocess-splitting method, for example, by giving higher priorities to splitting positions as the latter method implies, which can be also used to improve the efficiency discussed below.',\n",
       " 'Compared to generation-based methods, which may provide enhanced flexibility and diversity of the rewrites, this provides an advantage for system stability, especially for a task like QR which is strongly relevant with runtime production setup. ',\n",
       " 'For example, for a same-goal request, certain users may say \"In my kitchen put John Lennon\\'s song Imagine\" while others may say \"play Imagine by John Lennon on my kitchen device\".',\n",
       " 'For example, for a query (ASR 1-best) \"turn on prayer lights\", considering its ASR n-best such as \"turn on foyer lights\" in addition might be helpful to retrieve the correct rewrite \"turn on party lights\". ',\n",
       " 'For example, given an input query \"play shooting the sheriff\", personalized index may have one strong rewrite candidate \"play I shot the sheriff by Eric Clapton\", reflecting user\\'s previously shown preferences.',\n",
       " 'Thus, embedding CCG categories in the semantic space might be useful to give better representation of the meaning of verbs. ',\n",
       " 'Since often for a technical term there might be many naïve terms, and Freebase is far from being complete, we asked two physicians (one is a coauthor) to manually evaluate the extracted terms according to their expertise.',\n",
       " 'e.g. Google Flu Trends, since it may help estimating the seriousness of any disease outbreak, the incidence of individual symptoms (e.g. cephalgia was a predominant flu symptom this year), to classify an illness in sub-cases (ILI vrs common cold), to detect frequently -and possibly unexpected-co-occurring symptoms, etc.',\n",
       " 'For instance, a noun ending in the -nak/-nek suffix may be in the genitive or in the dative case, thus the MSD codes Nc-sd (a singular noun in the dative) and Nc-sg (a singular noun in the genitive) will be reduced in a different way.',\n",
       " 'The form of nouns with a third person singular possessor may coincide with the non-possessive form of the noun, e.g. Ajkán Ajka-SUP (a town in Hungary) or lip-SUP \"in Ajka\" or \"on his lip\" and here the reduced codes also differ from each other.',\n",
       " 'An inflected form of a third person singular possessive form of a noun with front vowels may coincide with the inflected possessed form of the same noun, e.g. énekét song-3SGPOSS-ACC or song-POSS-ACC \"his song\" or \"that of his song\"',\n",
       " 'It may be the case that sublanguages exist at the level of patents in general, or only at the lowest levels of the hierarchy, or at some level of abstraction between the lowest levels and the general category of \"patent.\"',\n",
       " 'Studies of closure properties have previously failed to consider the possibility that closure properties might be observed with small samples, but that there might be a \"spikiness\" to the distribution of lexical and other linguistic types that would reveal a lack of closure if larger samples were considered.',\n",
       " 'In addition, when a PC is a standalone character, it might not indicate its own or similar pronunciation when it serves as a PC in the hosting character, e.g., \"賣\" and \"讀\" are pronounced as /mai4/ and /du2/, respectively.',\n",
       " 'Without considering the characters in In-list for the game, we might believe that \"甲\" (jia3) and \"呈\" (cheng2) look equally similar to \"里\", so both are good distracters.',\n",
       " 'By contrast, if we have \"裡\" in the In-list, we may prefer to having \"程\" (cheng2) than having \"玾\" in the Out-list. ',\n",
       " 'For the example problem that we showed in Figures 1 and 2, we may apply an extended procedure of (Liu et al., 2011) to find an In-list for \"里\": \"鋰裡浬狸埋理娌哩俚\".',\n",
       " 'This error analysis indicates that our system might benefit from including other modules besides machine translation.',\n",
       " 'The orthographic issues might probably be resolved using a spell checker, whereas the phonetic ones, especially the equivalents, might benefit from grapheme-to-phoneme conversion. ',\n",
       " 'Considering the error analysis, we feel that a combination of the three metaphors (machine translation, spell checking and speech recognition) might produce an optimal combination of various features.',\n",
       " 'This proves that, in the case of very small sub-languages, statistical translation may be of sufficient quality, starting from a corpus 100 to 500 smaller than for the general language.',\n",
       " 'For example, the concept young might be defined over the universe U of possible (integer) ages U = [0, 120] by the discrete fuzzy set A = ((10 1), (20 0.8), (30 0.6), (40 0.2), (50, 0.1), (60 0), (70 0), (80 0)).',\n",
       " 'The problem with CERAE suggests that it might be necessary to consider separately organisms in their roles as sources of the interactor proteins and as hosts for the experiments.',\n",
       " 'This may be due to either missing names in the termbase (the organisms are mentioned, but by different names) or because they are identified by human readers through other contextual hints which may consist of any sort of information, 9 and may presuppose massive amounts of background knowledge.',\n",
       " 'The second problem might be adressed by using a machine learning approach, which however brings with it a whole set of new problems, such as selection and representation of the features relevant for training, as well as the fact that a sufficiently large training corpus needs to be available. ',\n",
       " 'Through this reorganisation, several problems with the system from (Dinu et al., 2012) can be alleviated: • Class sparsity: Certain cooccurrences of variable letters are very rare in the dataset, but the individual variable letters may appear more frequently.',\n",
       " 'As indicated above, there might be multiple (correct) classes per instance.',\n",
       " 'This might be due to the low number of senses of these words: stand has 4 senses, and top has 5, where the average number of senses is 9.4.',\n",
       " 'Clusters: Experiment 5 was motivated by the hypothesis that the best synset embeddings from former experiments might work as seeds for the clustering of more example sentence data, where the cluster centroids could function as a new synset embedding.',\n",
       " 'For example, in Information Extraction (IE), a system may be given a template with variables (e.g., \"X is employed by Y\") and has to find text fragments from which this template, with variables replaced by proper entities, can be inferred.',\n",
       " 'Such research efforts might include developing knowledge resources, developing inference components for specific phenomena such as temporal inference, or extending RTE to different languages. ',\n",
       " 'There might be some well-known domain knowledge and rules that every medical person knows.',\n",
       " 'It might therefore be useful to produce lists of such SFs and to filter them additionally, e.g. by combining the recognition patterns with a named entity recognition tool or by training classifiers to get rid of unwanted LFs.',\n",
       " 'It might also be possible to exploit the fact that these SFs occur with unusually high numbers of different LFs, but care must be taken not to also exclude the good LFs.',\n",
       " 'For instance, we only identify acronym pairs of the form LF (SF), while some languages may more frequently use the inverse order SF (LF) or other alternatives such as LF, SF (i.e. the short form is shown inside the text, separated by a comma) or SF, acronym for LF (i.e. explicitly mentioning in the text that SF is the acronym for LF).',\n",
       " 'From these observations, one may conclude that we need to collect large sets of (sense-tagged) domain-and probably genre-specific corpora to determine predominant senses.',\n",
       " 'Thus, important syntactic or semantic information to decide on metonymy might be missing in the features.',\n",
       " 'Also, in the semantic extension, we might have structural links anomaly such as LE1 is synonym with LE2, LE2 is synonym with LE3 and LE3 is antonym with LE1.',\n",
       " 'According the standard LMF-ISO 24613, the stem is a sequence of morphs that is smaller than or equal to the form of a single lexeme and that may be affected by an inflectional, agglutinative, compositional or derivative process. ',\n",
       " 'First, aligning a rare (low frequency) term may encounter the garbage collection effect (Moore, 2004;Liang et al., 2006) that cause the term to align to many unrelated words.',\n",
       " 'In some cases, especially in long sequences, RNN architectures, such as LSTM, might not be able to hold all the important information in its final hidden state.',\n",
       " 'Thus, TOCs might be used as a short document summary that provides more information about search results in a search engine.',\n",
       " 'Keyphrase extraction methods (Frank et al., 1999;Turney, 2000) may also be used for segment title generation if a reader prefers even shorter headlines.',\n",
       " 'Besides, a user might be interested in a specialized table-ofcontents, such as one consisting only of named entities.',\n",
       " 'For example, in a document about US presidential elections, a TOC consisting only of the names of presidents might be more informative than one consisting of the dates of the fouryear periods.',\n",
       " 'Of course, we are also using lexicalized features, so this conclusion might be false.',\n",
       " 'We show that constraint factors in similarity measuring such as word overlap and word order may have a major impact on the quality of selected data as well as the translation quality.',\n",
       " 'We also analyzed the provided reference data and found that the data seems to diverge quite distinctly from the training data, suggesting that there may be a need to look for more robust methods of evaluation for future editions of this task.',\n",
       " 'Poor retention is evident at the level of individual modules or course units, where completion rates may be as low as 60-70%, or even lower for particular groups of students, such as those from ethnic minorities (Richardson,  2012).',\n",
       " 'We first noted this promotion in the ranking of a word by its adjacent word in an essay about model, cholera, One might think these observations suggest that PageRank would be a better algorithm for identifying key n-grams, whereas betweenness might be better for identifying individual key words.',\n",
       " 'This experiment, therefore, illustrated by a different method the influence of neighbouring nodes in the PageRank algorithm, and it also raised further suspicions that PageRank might not be the most appropriate centrality algorithm for key word and key phrase extraction.',\n",
       " 'It may be that a different method of key phrase extraction, such as RAKE (Rose et al., 2010), would produce more appropriate results for key ngrams.',\n",
       " \"We intend to add a second dimension to the linguistic engine's capabilities: to train a classifier to recognise each place in an essay where feedback that falls into a particular category (as proposed by (Nelson and Schunn, 2009)) might be helpful for the student.\",\n",
       " 'If a term A is a kind of B and A holds a relation R with C , then we might expect that B could hold the same type of relation with C .',\n",
       " 'If the term A is presenting two distinct meanings which hold respectively the premises (as shown in Figure ??), then the inference done from that term may be probably wrong.',\n",
       " 'Indeed, some classes like concrete objects or living beings may be substantially more productive for certain relation types than abstract nouns of processes or events.',\n",
       " 'Without normalization, longer definitions might tend to have higher number of matching lemma.',\n",
       " 'Also our sampling strategies to deal with imbalanced data may have caused the models to overfit certain patterns of definitions pairs having some kind of relations(BROADER, NARROWER, EXACT, RELATED) and classified some of NONE-related pairs as being related, which could explain high recall and low precision.',\n",
       " 'However, the pre-trained German language model is pretrained on smaller dataset ( 16GB of data) than English (RoBERTa: 160GB), thus it is to assume there might be room for improvement of both approaches.',\n",
       " 'For this reason, we think that building language models based on multiple dictionaries might help to further increase accuracy of the models. ',\n",
       " 'Considering that the pre-trained models were trained on more general corpora, further studies involving pre-training on dictionary data and further fine-tuning different aspects described in (Sun et al., 2020) might lead to improvements of the models.',\n",
       " 'As demonstrating the IlluMe system by our original model house may be difficult in transportation and it may need a large space for demonstration, we will demonstrate the lightings by several table lamps, in which the LED lighting board resides.',\n",
       " 'λ 2 1 +1 term Z s (λ) may require much more efforts.',\n",
       " 'However the problem is that there may be multiple sequences of preceding words t i−n+1 t i−n+2 . . .',\n",
       " 'Part of the low recall for English may be due to the fact that the training set is restricted in size, which is detrimental for English since there the task is more difficult because of the mixed directionality in NPs. ',\n",
       " 'The best results are thus achieved if a full utterance is presented to the component initially, which is used for computation of prosody, and of which then elements may be changed (e. g., adjectives are replaced by different ones) on the fly.',\n",
       " 'In a multi-threaded, real-time system, the crawling vocoder may reach the end of synthesis before the NLG component (in its own thread) has been able to add a continuation to the ongoing utterance.',\n",
       " 'While iSS can show its full strengths in systems that also generate output incrementally (a strategy which is currently seeing some renewed attention), we discussed how even otherwise unchanged systems may profit from its capabilities, e. g., in the presence of intermittent noise.',\n",
       " 'About GI alone, it is possible that other algorithms would give better results than k-RI, such as those of Garcia and Vidal (1990;Denis et al. (2002).',\n",
       " 'Nevertheless, despite the advantages that the automatic translation inference across dictionaries might have, this task is still challenging (Gracia et al., 2019).',\n",
       " 'The hypothesis of this work is that graph-based heuristics may still have potential for improving results.',\n",
       " '⇒ ∃T = a ↔ b (8) where p k anf p l might be synonymous words in lexicon P, as reported also in (Torregrosa et al., 2019).',\n",
       " 'This may be because some of the pivot lexicons used for the shared task might be related to each other and might share polysemous cases. ',\n",
       " 'Nevertheless, the second setting of Strategy IV (see Figure 4) might have similar drawbacks as Strategy I. It would have been interesting to test a Multi-StrategyII+III+IV in the TIAD shared task, as the results in the validation phase were promising.',\n",
       " 'This set of features encoding some syntactic-level information may improve the overall classification performance like the same features facilitated a shallow discourse parsing task by Ghosh et al. (2011); in addition to the feature bundle, the named entities might reflect some information about distribution of discourse entities.',\n",
       " 'Our goal is to investigate possible improvements using discourse features or some other features that may encode discourse information via shallow parsing. ',\n",
       " 'We observe that the exact macro-average scores obtained with shallow discourse structure feature classification outperforms our own baseline; NEs and syntax based feature fails to outperform that baseline, this is may be due to the fact that at this level the discourse structure provide more information than the NEs. ',\n",
       " 'While one might consider that training independent models for each morphological attribute would provide better results, decision trees, Linear Classifier and DNN performed significantly better, when trained to output all the morphological features at once (softmax one-of-n encoded, not multitask learning).',\n",
       " 'Our features are calculated from tokenization of the tweets that attempts to preserve punctuation that may signify sentiment (e.g., emoticons and exclamation points) as well as twitter specific phenomena (e.g., extracting intact URLs).',\n",
       " 'We think that the values in the example are plausible ones, but it is not clear how much weaker they may get -for example, a threshold of around 0.6 may build a transition between an obligatory and an optional element.',\n",
       " 'In addition to that, we have enhanced the representation of situations by several attributes that we thought might be driving forces in the selection of attributes for the referring expression.',\n",
       " 'Moreover, the role of hair color, which might be considered as ontologically related to color in the furniture domain, is much less prominent than color: even in cases where it is distinguishing by itself, it is only alternative to location.',\n",
       " 'However, this result may be an impact of the pictures used in the experiments: they all showed scientists, and one might suspect that the role of hair color would be more prominent in other kinds of situations, e.g., for identifying attractive women. ',\n",
       " 'For example, a significantly increased examination of the role of attributes and their combinations might then be possible, which is inhibited by data sparseness in the TUNA corpus and also by the fact that the corpus appears to be biased in some ways.',\n",
       " 'Finally, we expect that these directions of extensions will suggest refinements in the description of regularities, e.g., more than two exclusive alternatives, and some more complex dependencies may need to be modeled, especially more fine-grained situational contexts for optionals.',\n",
       " 'Given that humans apparently use different strategies in making sense of words, it might be beneficial to have such cognitive aspects, including the type and strength of various kinds of semantic association, realised in NLP systems explicitly.',\n",
       " 'In other words, some target words happen to be more \"topical\" than others and might therefore be more susceptible to topical contextual features during disambiguation.',\n",
       " 'Others, however, might only be optimally disambiguated with other types of information.',\n",
       " 'One possibility is that Naïve Bayes classifiers favour aggregative features, so it might not be most appropriate to do the fine-tuning with a separate classifier.',\n",
       " 'For example, shooting and several shots can refer to the same event and people may have different or vague intuitions about their identity (for a discussion of full and partial coreference see also Hovy et al. 2013).',\n",
       " 'Because this word does not have Italian etymology, we assume it might have a cognate pair in Italian.',\n",
       " 'There may be other comparative questions that might have been missed because of POS tagging errors.',\n",
       " 'There may also be problems with \"Wh-\" or \"anything\" questions (e.g. \"What is better than X for treating Y?\" or \"Is there anything better than X for treating Y?\"), because \"Wh-words\" or \"anything\" do not have a type that can be mapped.',\n",
       " 'This way, different tasks might be applied to different RNN layers (i.e. there are layers shared by several tasks, and layers that are specific to some tasks).',\n",
       " 'One such group are adults with high-functioning autism, who are usually able to read long sentences and comprehend difficult words but whose comprehension may be impeded by other linguistic constructions.',\n",
       " 'In this paper we address this issue by providing insight into the needs of a specific subgroup, people with high-functioning autism, who are known to be able to read and comprehend complex texts, but may struggle with specific aspects of their comprehension.',\n",
       " 'These difficulties, together with the specific cognitive profile of individuals with autism (e.g., differences in the Theory of Mind (Baron-Cohen, 2000)) may lead to secondary issues such as challenges with identifying author intent and subtler nuances of meaning.',\n",
       " 'It is therefore possible that the results from evaluation studies of specific text adaptation strategies may point out to different outcomes.',\n",
       " 'Third, future competitions might consider using more fine-grained evaluation metrics because different cases of coreference have different difficulty levels.',\n",
       " 'We also showed that double back-translation may improve translation quality further than single back-translation.',\n",
       " 'For future work, we plan to integrate additional features into the algorithm, such as those based on novel neural network embeddings which may uncover additional hidden correlations between expressions in two different languages and may provide an alternative to large parallel corpora which are currently needed for the system for work.',\n",
       " 'While IR is a powerful method when answering questions where the correct answer is a string contained within a document, the systems fail when the sentences within the question do not individually hold a clue to what the correct answer might be (Clark et al., 2018).',\n",
       " 'When extracting data from, e.g., PDF or image files, it may happen that word boundaries are not captured correctly.',\n",
       " 'For future work, it may be beneficial to perform ablation experiments, to identify, which of the individual filtering methods contributes the most in order to acquire a higher quality parallel corpus.',\n",
       " 'This result might be due to the fact that the \"factotum\" domain is very frequent (much more frequent than any of the other domains).',\n",
       " 'A particularly difficult case for anaphora resolution systems is the pronoun it, as it may refer to a specific noun phrase or an entire clause, or it may even refer to nothing at all, as in sentences 1 -3 below 1 . ',\n",
       " 'While the full exploration of word embeddings for the classification of it remains outside of the scope of this work, it would be interesting to explore whether the embeddings add value to the models by encoding information that was not otherwise captured.',\n",
       " 'This suggests that further investigation may be required to find out whether a combination of the systems can lead to translations of even higher quality.',\n",
       " 'Those subjected to a red herring argument are led away from the issue that had been the focus of the discussion and urged to follow an observation or claim that may be associated with the original claim, but is not highly relevant to the issue in dispute (Teninbaum, 2009).',\n",
       " 'We hope that the corpus would raise interest outside of the community of researchers studying propaganda: the techniques related to fallacies and the ones relying on emotions might provide a novel setting for researchers interested in Argumentation and Sentiment Analysis. ',\n",
       " 'The model might not only benefit from this teleporting capability however; also the nature of the relations between words (i.e. dependency relation types and directionality) may be useful, and the GCN exploits this information.',\n",
       " 'Currently we use = =0.5, but it might be interesting to see, depending on different language pairs, how the performance of the aligner would be affected by a different settings of these parameters.',\n",
       " 'Again, we used = =0.5 but different values of these weights might be worthwhile investigating.',\n",
       " \"We used automatically translation lexicons (with or without a seed lexi-con), and the noise inherently present might have had a bad influence on YAWA's precision.\",\n",
       " 'Yet, this might be a harder to meet condition for some pairs of languages than using parallel corpora. ',\n",
       " 'Since this activity is pretty time consuming (human analysis plus re-training might take a couple of hours) we plan to extend MEBA with a supervised learning module, which would automatically determine the \"optimal\" parameters (thresholds and weights) values. ',\n",
       " 'Since Croatian and Slovene are related languages, the differences between the models are not as substantial as in (Tiedemann et al., 2014), but WORD models still turn out to be the most robust ones, even if word reordering might not be so frequent in this language pair as in the data from (McDonald et al., 2013).',\n",
       " 'Since this activity is pretty time consuming (human analysis plus re-training might take a couple of hours) we plan to extend MEBA with a supervised learning module, which would automatically determine the \"optimal\" parameters (thresholds and weights) values.',\n",
       " 'Therefore, some statistical indicators may be less meaningful.',\n",
       " 'This seems to suggest that indicators like document frequency (the number of documents containing a certain word/expression) may be more meaningful for certain sections and less meaningful for others. ',\n",
       " \"Obviously, such collections may contain term translations that are rated as unlikely (in certain contexts) by an SMT system's models or they may even be missing in the models at all if custom adaptation of the models using the customers' provided data is not performed.\",\n",
       " 'For instance, the first method may lack a term phrase pattern necessary for a specific term, whereas, when applying the second method, some inflected forms may be missing in the corpus or the stemming tool may not be able to identify all forms.',\n",
       " 'The set of rules is likely to be incomplete (some glued words might have survived in the training data) and also might produce wrong splitting in some cases (e.g. turnover being split always in turn over). ',\n",
       " 'This rule operates in several variants, one being that if the hypernym is a key term, then a \\'Which kind of\\' question may be generated (e.g. \\'Transitive verbs require objects\\' would trigger the question \"Which kind of verbs require objects?\").',\n",
       " 'However, it might be worthwhile to build content-specific models that predict item difficulty within-category (e.g., what are the relative item difficulties within the pool of psychiatric items).',\n",
       " 'In this sense, the extra words considered as errors by the EXTer measure may be actually beneficial for the overall performance of the system (see also the discussion in Section 5).',\n",
       " 'Further research (which may also be related to more informative features) to overcome this problem of uncertainty would have some potential.',\n",
       " 'To account for a broader spectrum of factors that may affect conversation quality, we conducted an additional evaluation that asks experts to judge pairs of interactions, where one interaction was assigned a low score by the model and one was assigned a high score.',\n",
       " 'In isolation, the instances of these dialogue patterns do not seem indicative of a problematic conversational interaction; however, when taken as an emergent pattern, they begin to illuminate types of interactions that may be subtly indicative of poor user experience.',\n",
       " 'A key problem for DSTs is that the values that fill a slot at inference may have never been encountered at training time (consider that the set of all possible restaurant names is bound only by the limits of language). ',\n",
       " 'We note that while we have achieved state-of-theart performance on the Sim-M and Sim-R datasets, there is certainly a possibility that a better choice of augmenting corpora could help the generality of the final model.',\n",
       " 'However, we cannot but admit the fact that many toponyms are at least meaningful etymologically, e.g, Cambridgebridge over the river Cam (Leidner, 2007), and, as Leidner pointed out, this etymology might or might not be apparent to a speaker.',\n",
       " 'Leidner (2007) describes three types of the toponymical ambiguity: morpho-syntactic ambiguity: a word itself may be a toponym or may be a common noun in a language, e.g. Hook as the populated place in the UK versus hook as a common noun; referential ambiguity: a toponym may refer to more than one place of the same type, e.g. Riga as the populated place and the capital of Latvia and Riga as the populated place in the USA, state Michigan; feature type ambiguity: a toponym may refer to more than one place of different type, e.g. Tanfield as the populated place and the castle in the UK, Gauja as the populated place and the river in Latvia. ',\n",
       " 'One of the reasons could be that it is not clear what the correct toponym translation is, since results may vary and more than one target toponymic unit is acceptable.',\n",
       " 'The high inflectional variation of target language increases data sparseness at the boundaries of translated phrases, where a language model over surface forms might be inadequate to estimate the probability of target sentence reliably.',\n",
       " 'As both the probabilistic dictionaries and the SMT-based transliteration systems provide confidence scores for each candidate, these scores are used as negative multipliers to filter out term pairs that may potentially result in invalid mappings. ',\n",
       " 'For a monolingual model in a language where codeswitching, orthographic variations, or rich morphological inflections are common, NLU models may not be able to perform well on all the variations, depending on the frequency of these variations in the training data.',\n",
       " 'This is done by following a set of simple steps which may include removing vowels, reducing character duplication, and mapping sets of characters to a single character, based on whether they 1) sound similar or 2) are used in similar environments in similar sounding words.',\n",
       " 'Leidner (2007) describes three types of toponymical ambiguity: morpho-syntactic ambiguity: a word itself may be a toponym or may be a nontoponym, e.g. Liepa as a populated place in Latvia versus liepa (lime-tree) as a common noun; referential ambiguity: a toponym may refer to more than one place of the same type, e.g. Riga as a populated place and the capital of Latvia and Riga as a populated place in the USA, state Michigan; feature type ambiguity: a toponym may refer to more than one place of a different type, e.g. Ogre as a populated place and a river in Latvia. ',\n",
       " 'The result of transliteration may vary, as there are several ways of rendering English letter combinations into Latvian, e.g., -c-stands for -k-before consonants (except -h-), and -a-, -o-, -u-, fors-before -i-, -e-, -y-, and for -č-in the combination with -h-. ',\n",
       " 'One of the reasons could be that it is not clear what the correct toponym translation is, since results may vary and more than one target toponymic unit is acceptable.',\n",
       " 'However, depending on the proficiency level of the learner, s/he may not be aware of these rules, and thus may try to derive compound readings in a more straightforward fashion, which is adequately modeled through our simplistic independence-based model.',\n",
       " 'This might be due to its pretraining LM objective: while both USE and ConveRT are forced to reason at the level of full sentences during the re- 9 We provide a colab script to reproduce these experiments.',\n",
       " 'This might be because the distribution of the language data used for pretraining is similar to the open-domain dataset but different from the closed-domain dataset.',\n",
       " 'Some frequent senses like NOUN.COMMUNICATION might benefit from extension. ',\n",
       " 'Model compatibility with on-device hardware is one of the most important considerations for practitioners as, even if a model works well on high throughput GPUs, its components may saturate valuable resources like memory and power (Lin et al., 2010). ',\n",
       " 'However, our system performed poorly on entities new in test, which might be caused by the lack of generalization of the method or over-fitting of the machine learning model.',\n",
       " 'Any evaluation technique must evaluate over many turns of a conversation in order to detect emergent faults such as repetitiveness or contradiction, while techniques that rely solely on a single evaluation at the end of a conversation may fail to take into account changes in model performance over its span.',\n",
       " 'Further, techniques that rate model performance on a Likert scale may suffer from inconsistencies in subjective numerical ratings across evaluations of different models (Li et al., 2019).',\n",
       " 'These findings, while highlighting the difficulty of human evaluation, also provide guidance on which method might be best to use in these different circumstances, as well as possible future work.',\n",
       " 'This work concerns itself with evaluation of opendomain dialogue, which, unlike more restricted domains such as question-answering and goaloriented conversations, may not have a precise goal, and no widely accepted evaluation technique for it currently exists (Deriu et al., 2021;Huang et al., 2020;Roller et al., 2020).',\n",
       " 'These latter techniques allow for efficient reuse of existing conversational data, and have shown to be useful experimentally (Li et al., 2019;Roller et al., 2021), but it may be harder for evaluators to rate conversations that they have not been involved in. ',\n",
       " 'We hypothesize that the juxtaposition of all three evaluation questions side-by-side in the UI of the SM-Turn and SM-Dialog crowdworker task (Figure 4) may aid workers in distinguishing among these three metrics and rating models differently on them. ',\n",
       " 'BlenderBot3B responses tend to contain many more words on average than those of BlenderBot3B-M0, and so we hypothesize that this difference in sensitivity among the techniques may be due to the fact that   1 and 2.',\n",
       " 'Thus, if crowdworkers tend to prefer longer responses on average, the side-by-side comparison of model responses might aid in their ability to choose BlenderBot3B responses over those of BlenderBot3B-M0.',\n",
       " 'We hypothesize that these more nonsensical responses may be very obvious to workers who are in the middle of having a conversation with the Bot Speaker during the PW-Turn evaluation.',\n",
       " 'However, these responses may be less obvious to workers reading whole conversations in the PW-Dialog evaluation who have not interacted with the models directly, as well as to workers in SM-Turn and SM-Dialog evaluations who cannot directly compare Reddit3B responses to those of a model that has been fine-tuned on dialogue. ',\n",
       " 'The results of these three model comparisons hint that perhaps a per-turn evaluation technique may be more suitable for pairs of models that differ in their ability to reply sensibly in a way that is easily detectable by their partner (i.e. BlenderBot3B vs. Reddit3B), but that a whole-conversation technique may be preferable when differences between models are more sensitive.',\n",
       " 'We also find that single-model techniques perform competitively to pairwise ones except for when model generations differ by average length: in this case, comparing the responses of both models side-byside may make the differences between them more apparent than just viewing them separately. ',\n",
       " 'Combining techniques Given how much the relative sensitivities of different evaluation techniques vary across different pairs of models, we also explore whether combining results from multiple techniques together may allow for a compromise technique that performs reasonably well in all cases.',\n",
       " 'Nevertheless, the results shown here demonstrate the difficulty in anointing one evaluation technique as superior to all others regardless of the models being compared, and they suggest that a combination of techniques, or else a different technique entirely, may be necessary for optimal measurement of differences among models.',\n",
       " 'Future improvements may also come from exploring other ways to amplify the weak signal from models with only slight performance differences such as BlenderBot3B and BlenderBot90M, perhaps by training workers to select responses based on general measures of conversational quality, as opposed to content that appeals to their personal interests.',\n",
       " 'Some issues are that they may not generalize as well to data beyond that which they are trained (overfit) and also may be biased and gameable (Wu et al., 2019;Albrecht and Hwa, 2007).',\n",
       " 'If it is possible to deploy a model to people who genuinely want to talk to it (e.g., without being paid), conversations may be more natural and evaluations will be in line with genuine interests.',\n",
       " 'First, user desires may not necessarily be aligned with the goals of the research itself, meaning researchers may have to develop features and improvements towards the goals of the product rather than towards long-term research.',\n",
       " 'On the other hand, it may be harder for evaluators to rate conversations that they have not been involved in (Finch and Choi, 2020).',\n",
       " \"Generally, we see a higher positive coefficient of the SM-Turn ratings in later turns in the conversation, which implies that the workers may have a recency bias: they may remember the most recent turns of the conversation more strongly when determining how to rate the model's performance overall.\",\n",
       " 'This suggests that calculating the per-conversation winner-takes-all win rate for the per-turn methods PW-Turn and SM-Turn may be disadvantageous if having a precise measurement of the win rate is more important than one that is statistically significant.  ',\n",
       " 'Well-known among these are conceptual synonymy, by which a given represented concept may be indicated by multiple unique textual mentions, and textual polysemy, by which a given text string may refer to multiple represented concepts.',\n",
       " 'Additionally, some ontologies employ standard patterns for concept labels, but some of these may result in long, complex labels that are infrequently seen in the literature (Ogren et al., 2005;Funk et al., 2014). ',\n",
       " 'While the main training is likely to override parts of the connections learnt during ontology pretraining, others may remain to form some kind of background knowledge.',\n",
       " \"Second, for certain target words, the two CSD senses may be different in terms of their syntactic behavior, yet semantically very close (for example, the 'be shocked' and 'shocked' senses of ).\",\n",
       " 'The increase in performance over the baselines were more noticeable in task 2 suggesting that information retrieval for RDoC task may be more challenging.',\n",
       " 'There was quite a lot of variation across the several RDoC constructs used for the tasks suggesting that the complexity of different constructs may hinder certain models and construct-specific methods or models may be a requirement in the future.',\n",
       " 'Sustained Threat being more challenging for IR may be explained by the fact that the annotators also found it to be the most challenging construct for task 1 annotation.',\n",
       " 'Regardless, this calls for more sophisticated methods for both tasks because any other sophisticated method (such as Lucene [17] or MetaMap [2]) used a baseline may have outperformed even more participating teams. ',\n",
       " 'Overall, this suggests that when a validation set of domain-specific annotated relevance data is not available, then L1 regularization may be helpful.',\n",
       " 'There may be a number of reasons for the limited effectiveness of our approach, potentially including sub-domain mismatch between our unlimited samples of PubMed and PMC documents and the comparatively narrow and focused domain of CRAFT texts.',\n",
       " 'We attribute some of this effect to the differences in the dimensionality of previously introduced vectors: although the parser can be configured to accept vectors of any size, some part of its development may have specifically optimized for the 100-dimensional CoNLL word vectors.',\n",
       " 'To avoid the model recommending the same movie that the user might have just mentioned, we only consider as a ground-truth recommendation the movie that is first time to be mentioned by the recommender in the conversation.',\n",
       " 'As the major \"language-independent\" tools are targeted to big and resourceful languages and industrial usage scenarios, they may not fit for the numerous less-and midresourced languages and the (linguistic) research-centric scenarios.',\n",
       " 'Beside that, it is not enough to test a module -or any part of the pipeline consisting of one or more modules -in itself, one may also test how robust the module is in the pipeline, i.e. whether the modules can work together or they need to be harmonised (e.g. the rules and the training data).',\n",
       " 'Deep learning models have shown great success in question answering (QA), however, biases in the training data may lead to them amplifying or reflecting inequity.',\n",
       " 'This may be through exacerbating empirically-observed inequality, e.g., by providing a list of 90% males in an occupation that is 80% male, or when systems transfer learned inequality into scenarios with little information, e.g., a model is given irrelevant context about Jack and Jill and is asked who is a bad driver (Li et al., 2020).',\n",
       " 'Additionally, we might be better able to probe QA systems by switching from straightforward questions (\"Who discovered the Biot-Savart law\") to more nuanced questions involving complex logic or paraphrasing (\"Who discovered the law describing the magnetic field generated by electric current\").',\n",
       " 'The inclusion of these types of questions might require more powerful QA models; we tried testing these types of questions but our QA models failed to answer them correctly with any regularity.',\n",
       " 'However, as the selected exemplars solely depend on the gold response, some of them may be irrelevant to the given context, which results in exemplar-based generative models still ignoring the retrieved exemplar.',\n",
       " 'In contrast, since both the AC and the RC are comparable from a text genre point of view, in (2) we want to capture the fact that some items that might be retrieved by the specificity carry meanings that do not contrast sharply with the ones they convey in general language corpora.',\n",
       " 'Some of the collected terms may not see widespread use before being supplanted by newer or better-known ones, but nonetheless linger on in the termbase, increasing the risk of ambiguity unbeknownst to the termbase editors.',\n",
       " 'Lastly, certain supplementary data, in the form of known terms and stop-words from that domain, might be available at times but could not be a prerequisite.',\n",
       " \"There are two primary ways in which the tagging and lemmatization may be done, decided on by the tool's administrator: Through the Reynir 8 Python package (Þorsteinsson et al., 2019), or through the tagger ABLTagger 9 (Steingrímsson et al., 2019) and lemmatizer Nefnir 10 (Ingólfsdóttir et al., 2019).\",\n",
       " 'Other future work may include using deep learning approaches, such as word embeddings and bilingual extraction where parallel data is available.',\n",
       " 'This type of corpora are usually small-sized (a few million words or less), which poses a challenge for distributional methods, and contain specific, highly technical vocabulary, meaning that adapting methods based on large generic corpora might be difficult.',\n",
       " 'We make the hypothesis, supported by the work of (Tanguy et al., 2015), that the small amount of data may be circumvented by a method based on syntactic contexts.',\n",
       " 'However, the benchmarks used in these studies, adopting the kind of diverse, generic corpora on which the tools have been trained, might not be the most relevant option for specialized corpus parsing.',\n",
       " 'To go beyond the limitation in (Tanguy et al., 2020), we have chosen, in the work we present in this article, to run a new evaluation on a small, specialized biomedical corpus, whose building is described in Section 3.1 and for which we may compare the relations implied by the extracted syntactic contexts against an external resource, the Unified Medical Language System (UMLS) (Bodenreider, 2004), which contains relations between medical and biomedical concepts (see Section 3.3).',\n",
       " 'One of the tokenizations may have split a token while the other may not, such as \"single-copy\" on one side and \"single\" followed by \"copy\" on the other side.',\n",
       " 'In practice, only the nearest 100 distributional neighbors are kept, which is a fairly large number compared to the average number of relations by concept -24.6 -but is justified by the fact that some concepts may have a much higher number of relations.',\n",
       " 'Finally, we have found that some patterns of proximity between parsers are stable across our evaluations, which means that some measures applied to the output of syntactic parsers may perhaps be used to anticipate the performance of a parser for building distributional models from a given corpus.',\n",
       " 'In practice, a vacancy title might not contain a job title (or could contain multiple), but this assumption holds for an overwhelming majority of online job postings, with exceptions typically being poorly composed titles.',\n",
       " 'For example, a system might have low title level accuracy due to a bias towards longer titles, which can be easily read from the token level precision and recall. ',\n",
       " 'For instance, if we simply searched for cells with a flat row header containing \"Revenue Passenger Miles\", we may mistakenly return value 226,346 appearing further down the table (which corresponds to the RPMs of total operations, instead of the requested mainline operations).',\n",
       " 'However, other domains may have their own peculiarities (e.g., different vocabulary or specific table templates).',\n",
       " 'In the domain of heart failure, for instance, ejection fraction might be a Specific Term: laypersons generally do not know what it means, and it is strongly related to the domain of heart failure, since it is an indication of the volume of blood the heart pumps on each contraction.',\n",
       " 'An example of an OOD term might be p-value, which is lexicon-specific since you need some knowledge of statistics to know the term, but it is not domain-specific to heart failure.',\n",
       " 'However, the large gap between precision and recall for the English model, which is much smaller for the French model, may be an indication of an often-cited downside of deep learning models: their unpredictability.',\n",
       " 'This may be partly due to their low recall, but since they did not extract a single Named Entity in any of the languages, it does appear that their system is most focused on terms.',\n",
       " 'This may be an indication that they are sensitive to frequency, as many of the Specific Terms are rarer (e.g., e-Terminology employs a frequency threshold of two).',\n",
       " \"may be part of the explanation for their high scores, and, in the case of TALN-LS2N's system, may be related to their reliance on the training data. \",\n",
       " 'For instance, translators may be more interested in a system that extracts mostly Specific Terms, since Common Terms may already be part of their general vocabulary. ',\n",
       " 'In many cases, it may therefore be desirable to combine multiple sentiment lexica into a single representation.',\n",
       " 'In computer science, the process of modifying natural language to reduce its complexity towards improving readability and comprehension is called text simplification (TS) (Shardlow, 2014), and it may involve modifications to the syntax, the lexicon or both. ',\n",
       " 'Further work on our proposal might explore different branches like working with syntactic issues, including abbreviation disambiguation to enhance lexical enrichment, or widening the scope of application to other medical reports besides rare diseases.',\n",
       " 'This might be due to the fact that the beam-width reported by the authors is not expressive enough to capture semantically relevant paths or entities.',\n",
       " 'In the second example, the relation traversed by KG-CRUSE is correct, however as the dialogue context is not specific, it decodes a path that might potentially fit the dialogue context but is different from the gold path.',\n",
       " 'The system performs best using the most frequent WordNet senses for those nominals, suggesting that the system may work usefully in deducing semantic relations between nominals without the need to deduce word senses.',\n",
       " 'Transformers may be applied as classifiers to each query and passage pair independently [Nogueira and Cho, 2019] or as generators to produce labels for passages in a sequence-tosequence model [Nogueira et al., 2020].',\n",
       " 'A further step might be to restrict the extraction and storage of personal attributes to only local devices using differential privacy and federated learning techniques.',\n",
       " 'However, this raises two significant challenges: (1) protected attributes may not be available or it may not be legal to use them, and (2) it is often desirable to simultaneously consider multiple protected attributes, as well as their intersections.',\n",
       " 'This approach is particularly useful if similar performance can be achieved by slightly different means-i.e., fairness constraints may aid in model selection if there are many near-optima. ',\n",
       " 'In practice, though, any approach that relies on protected attributes may stand at odds with antidiscrimination law, which limits the use of protected attributes in domains such as employment and education, even for the purpose of mitigating bias.',\n",
       " 'For example, a method that explicitly or implicitly infers protected attributes from names at deployment time may fail to correctly infer that an individual named Alex is female and, in turn, fail to mitigate gender bias for her.',\n",
       " 'We chose 22 high level concepts we believed may be good predictors of whether or not a nominal could be an argument of the semantic relations used in this task.',\n",
       " 'However, their applications might be limited due to the requirement of large amount of data.',\n",
       " 'For example, CNS, standing for the central nervous system, might often be used in research literature over topics of neuroscience, and would be annotated as entities to be linked.',\n",
       " 'We analyzed the result of the shallow CNN module and concluded that 3 possible reasons might be associated with the performance: 1) Missing context.',\n",
       " 'Further improvement might be achieved once more semantic clues are incorporated, as we briefly discussed at the end of Section 4.3.',\n",
       " 'Regarding this issue, syntactic parsers might be adopted for performance improvement.',\n",
       " 'If the results from the PJE version were not also available one might be inclined to conclude that there was not as much difference between systems in terms of Clarity as there was in terms of Fluency.',\n",
       " \"Part of the reason for this may be that in GREC-NEG PJE each system was only compared to one single other 'system', the (human-authored) original Wikipedia texts. \",\n",
       " 'If we see less effect of Clarity than of Fluency in an experiment (as in GREC-NEG RSE and TUNA RSE), then we might want to conclude that systems differed less in terms of Clarity than in terms of Fluency.',\n",
       " 'However, the real explanation may be that evaluators simply found it harder to apply the Clarity criterion than the Fluency criterion in a given evaluation set-up.',\n",
       " 'Their results might be improved by combining statistical techniques with linguistic information such as POS affinity or by combining several association scores. ',\n",
       " 'In cases where many unknown words are expected, for example when moving to a new domain, it may therefore be wise to choose a lower tag order to get better results, whereas a good compromise could be the 3.3.3.3 model (cf.',\n",
       " 'A possible reason for these poor results might be due to the difference in settings between our experiments and the ones in the PBA study.',\n",
       " 'In this section, we investigate whether the limited effect of automatic augmentation on the model performance may be caused by the stochasticity of the search.',\n",
       " 'As mentioned earlier, the limited impact of automatic data augmentation scheduling in our settings might be due to the small number of samples available for each experiment.',\n",
       " 'As a result of this discrepancy, the selected data augmentation might be relevant when only 250 data points are available for training but less effective when learning with 1500 samples as is ultimately the case.',\n",
       " 'This might be explained by the fact that both the train and the validation sets are too small to find optimal augmentation hyperparameters irrespective of the chosen split ratio.',\n",
       " 'First, the overall setup of the PBA approach (e.g., the need for large validation sets) might not be well suited for low-data regimes in NLP.',\n",
       " 'A second but more likely reason is that transformers are already pre-trained on huge datasets and their representations may already be invariant to many of the transformations that are encoded into the data augmentation.',\n",
       " 'A systematic investigation into the latter hypothesis is required, which, if proven, would show that data augmentation may be redundant when opting to use transformers to implement NLP solutions.',\n",
       " 'A final reason might be that the search space we consider only contains transformative data augmentation techniques and omits generative ones, even though the latter have started to show some promising results.  2019), we set the number of operations to 0, 1 and 2 with probabilities 0.2, 0.3 and 0.5 respectively.',\n",
       " 'It is worth noticing that to translate from German to English, the RFTagger is always used during the data pre-processing step, while a different POS tagger may be involved for the source reordering model training.',\n",
       " 'The reason why we use REG08-Type Recall and Precision for GREC-NEG rather than REG08-Type Accuracy as in GREC-MSR is that in GREC-NEG (unlike in GREC-MSR) there may be a different number of REFEXs in system outputs and the reference texts in the test set (because there are embedded references in GREC-People, and systems may select REFEXs with or without embedded references for any given REF). ',\n",
       " 'A contributing factor to this may be the fact that texts in Chefs tend to be much more colloquial.',\n",
       " 'SUC is compiled in a manner similar in spirit to that of the Brown (Francis and Kučera, 1979) corpus, and is meant to be representative of what a person might have read in a year in the early nineties.',\n",
       " 'They might also be possible to remedy in some respect by editing the model to include genitive forms for all baseforms in the model. ',\n",
       " 'Note that these two procedures are errorprone (especially as we have no information about the tokenization) and may introduce some noise in our analysis (cf. Section 4). ',\n",
       " 'For instance, suppose we want to generate (2b), repeated here as (3a), rather than 3 Given two TAG trees, there might also be several ways of combining them thereby inducing more non-determinism.',\n",
       " 'First, the paraphrase figures might seem low wrt to e.g., work by (Velldal and Oepen, 2006) which mentions several thousand outputs for one given input and an average number of realisations per input varying between 85.7 and 102.2.',\n",
       " 'Given a potentially unlimited number of domains as well as a dynamic nature of many domains (e.g. computer science) where new terms get introduced regularly, manual maintenance of one-to-one term bases for each pair of languages may become unmanageable.',\n",
       " 'In the worst case scenario, a MWT in one language (e.g. gofal iechyd) may be a singleton in the other language (e.g. healthcare), and as a single-word term it will fail to be identified as a term candidate. ',\n",
       " 'Using machine translation tools might be regarded as \"an overkill\" (Choudhury et al., 2007), considering the close relationships between source and target languages.',\n",
       " 'Furthermore, learning the kinds of many-to-many correspondences between source and target sentences that make up for the high translation accuracy of phrase-based systems might be seen as introducing an unnecessary complexity, as SMS tend to be shorter, in terms of words, than their normalized counterparts.',\n",
       " 'This suggests that looking for many (on the normalized side) to one (on the SMS side) might be good enough to capture most pairings.',\n",
       " 'There are a number of obvious improvements we might consider, such as using more accurate grapheme-to-phoneme rules, or plugging in a larger statistical language model, but we feel these would buy us only small increase in performance.',\n",
       " \"A hidden Markov model based on n-grams (assuming that a term's class may be induced from the previous n-1 lexical items and their classes) was used as a theoretical basis for their classification method.\",\n",
       " 'Alternatively, multiple classes may be suggested by setting a threshold for C(t, c i,j ). ',\n",
       " 'Term exctraction may have different applications in areas such as construction of ontologies, document indexing, validation of translation memories, and even classical terminology work.',\n",
       " 'However, in certain situations where more complex terms need to be captured, one might have to live with lower precision to actually bring all relevant term candidates into the validation stage.',\n",
       " 'Another obstacle might be the quality of syntactic tags for grammatical functions; if linguistic analysers can provide data for grammatical functions that are as good as for parts-of-speech, then the results may be improved. ',\n",
       " 'Since terms are semantic indicators used in scientific discourse, we hypothesised that they might be useful classification features. ',\n",
       " 'The C-value method extracts only multi-word terms, which may be enriched during the normalisation process with some single-word terms, sourcing from e.g. acronyms or orthographic variations.',\n",
       " 'The same document may have multiple, possibly interlaced tags, including POS, syntactic and domains-specific (i.e. semantic, e.g. protein, DNA, etc.) tags.',\n",
       " 'Usually, a tagging scheme includes additional structural complexities such as nesting and possible combinations of syntactic and semantic structures (e.g. a noun phrase which contains a DNA name), which may cause difficulties during document processing. ',\n",
       " 'Corpus mining systems may benefit from the use of a well-formed domain model, which reflects main concepts (linguistically represented by domain-specific terms) and relations between them.',\n",
       " 'More importantly, the hierarchical structure of a document may be lost if all tags are stored at the same level (i.e. in flat tables).',\n",
       " 'Also, systematic term normalisation may further improve precision and recall of the method (Nenadić et al., 2002).',\n",
       " 'Moreover, when applied to an initially POS tagged text 6 , this pattern may be too general even for description of NPs, as not all word sequences in a text that match this pattern are valid NPs.',\n",
       " '( 2 2 a a T b b f T a f a a a f a a value C yi and zi respectively), while these values may be different for each respective pair.',\n",
       " 'At this point, the usage of generic patterns in order to check the agreements in case, number and gender during the phase of filtering of term candidates might seem unnecessary, since all these features are subsequently normalised.',\n",
       " 'Further, the broader handling of term variants (e.g. dialectic variants, acronyms, derivational variants) may also improve both precision and recall.',\n",
       " 'There are several factors which might be responsible for this difference.',\n",
       " 'Further, if one of such terms has additional modifiers, this may indicate concept specialisation (e.g. nuclear receptor and orphan nuclear receptor).',\n",
       " 'Our evaluation results evidence that, in combination with a high-quality general-language sentiment lexicon, such as Lingmotif-lex, SentiEcon achieves very high performance levels that may encourage us to carry out further performance tests, different applications and the compilation of other domain-specific lexicons.',\n",
       " 'One disadvantage of relying solely on a sentiment lexicon is that different domains may greatly alter the valence of words, a fact well recognized in the literature (Aue and Gamon, 2005;Pang and Lee, 2008;Choi et al., 2009).',\n",
       " \"A shifters system may help accounting for contextual modification of sentiment, and is particularly interesting for finegrained sentiment analysis, such as aspect-based SA, where the text's overall classification/score is not enough (Yu et al., 2016).\",\n",
       " 'Sentiment items, after applying context rules, may be a single word form, a sequence of word forms matching a multiword expression, or a sequence of word forms matching a single or multiword item and the strings that make up the context rule.',\n",
       " 'For example, they may or may not include part of speech information, and, if this is present, different tagsets may be used.',\n",
       " 'Further testing, using other datasets, might be considered, but these results already offer enough evidence as to the high quality and usefulness of our resource.',\n",
       " 'For many features, it might result difficult to compute reliable probability values due to data sparseness.',\n",
       " 'Hence, finding a compromise between binary and real-valued features might help to develop ME models which better trade-off complexity vs. granularity of information.',\n",
       " 'Syntactic knowledge may also prove useful, since both Justin Trudeau and he are subjects (syntactic parallelism (Poesio et al., 2016;Ng, 2017)).',\n",
       " 'Finally, world knowledge may help to find the correct referent, since Justin Trudeau is the actual prime minister of Canada. Approaches that address this task automatically may be classified in different ways.',\n",
       " 'Another important evaluation parameter is the presence of singletons (82.9% of mentions from ANCOR, and 81.7% of mentions from Democrat), since they may impact the system performances.',\n",
       " \"This may be due to the fact that Kantor and Globerson's system cut the text into 30-sentence long segments for training: the model is almost never presented with related nouns distant by more than 64 mentions from each other. \",\n",
       " 'One disadvantage on relying solely on a sentiment lexicon is that different domains may greatly alter the valence of words, a fact well recognized in the literature (Aue and Gamon, 2005;Pang and Lee, 2008;Choi et al., 2009).',\n",
       " 'Moreover, when concurrent referents are present in the text, the pronoun resolution task is even more difficult (Givón, 1993;McMillan et al., 2012;Li et al., 2018): the pronouns may be ambiguous and their resolution depends on user knowledge about the main topic (Le Bouëdec and Martins, 1998).',\n",
       " \"In the following example, the substitution of hyène 'hyena' by animal 'animal' introduces an ambiguity in coreference resolution, since the animal might be le renard 'the fox' or la hyène 'the hyena'.\",\n",
       " 'It might address a specific language level (e.g. lexical or syntactic simplification), or it might be applied at different levels at the same time.',\n",
       " 'However, coreference and anaphora resolution may pose difficulty to dyslexic people (Vender, 2017;Jaffe et al., 2018).',\n",
       " 'Moreover, when concurrent referents are present in the text, the task of pronoun resolution is harder (Givón, 1993;McMillan et al., 2012;Li et al., 2018), considering that pro-nouns may be ambiguous and their resolution depends also on the main topic (Le Bouëdec and Martins, 1998).',\n",
       " 'Additionally, the referring expressions might be sorted according to its accessibility (Ariel, 1990), from low accessible to high accessible (e.g. personal and reflexive pronouns).',\n",
       " 'Thus, the first mention of a discourse entity might be a low accessible one (e.g. proper noun, indefinite noun phrases with a reference function), while the other mentions should be highly accessible expressions (e.g. demonstrative noun phrases, personal pronouns, or relative pronouns).',\n",
       " 'To avoid ambiguities, we replace referring expressions with high accessibility by those expressions with low accessibility (e.g. the personal pronoun is replaced with a referent, which might be a definite noun phrase or a proper noun).',\n",
       " 'The determiners might change the position in the accessibility scale, from high accessibility to less accessible referring expressions (e.g. the dog ⇒ a dog), or the other way around (for some contexts).',\n",
       " 'In other words, a demonstrative NP might be replaced by a more generic definite NP when a less accessible element replace both the determiners and the noun is replaced by a generic representation of the concept (e.g. hypernym).',\n",
       " 'Table 1 below shows a tendency toward low recall of negative segments, which we think may be caused by the \"positive bias\" effect mentioned in the previous section.',\n",
       " 'Each morphological tag is composed of different data fields, depending on which morphosyntactic category it belongs to; some categories, like interjections, have just one field, while others have up to seven fields (e.g., verb phrases), some of which may be instantiated at runtime.',\n",
       " 'This is not only a question of neutral words acquiring a certain polarity when they appear in a MWE: as we have shown, some words may also reverse their polarity from positive to negative or the other way around. ',\n",
       " 'The relations between the WD processes and inflectional morphology have been extensively studied in Czech linguistic literature, see e. g. (Dokulil, 1962;Karlík et al., 1995;Petr, 1986) where one may find informal descriptions of the WD processes using terms like \"fundace\" (basic derivation), as well as mutation, transposition, modification, adaptation, and others. ',\n",
       " 'Compound formants are also possible, and may consist either of a prefix combined with suffix, e. g. in pří-ruč-ní (reference) or prefix combined with an ending před-měst-í (suburb).',\n",
       " 'Todirascu et al. (2013) argued that these mixed results might be due to approximations of the NLP systems, since automatically annotating co-reference chains remains a challenge.',\n",
       " 'This feature means that the distance between two consecutive mentions of the same chain is larger than one sentence, a phenomenon that often occurs in informative texts where the same referent may be repeated across the text, even after several sentences.',\n",
       " 'First, we have experimented on an L2 corpus, while the cohesive aspects might be more relevant for L1 texts.',\n",
       " 'Moreover, the study was performed on French and the results might vary from one language to another (although our findings are mostly in line with results on English).',\n",
       " 'Using their word representations as-is for specialised and low-resource domains might be less efficient.',\n",
       " 'However, in the case of specialised domains, the corpora are generally relatively modest in size, and these methods might be less efficient.',\n",
       " \"Nonetheless, this particular feature of BERT may make it more challenging for it to consider the more global place a word occupies within a corpus's vocabulary, especially for these words. \",\n",
       " 'In the case of specialised domains, these methods might be less efficient due to the usually modest size of the corpora.',\n",
       " 'It may be possible to integrate syntactic parsing with semantic analysis by taking advantage of LFG (Kaplan et al. 1982) and HPSG (Pollard et al. 1994).',\n",
       " 'Our main hypothesis, developed in § 2, is that automatic text understanding systems (machine reading) having made remarkable progress (Hermann et al., 2015;Dhin-gra et al., 2017;Yu et al., 2018), 1 it might become possible to use them to assess the readability of texts.',\n",
       " 'We can conclude that our set of models is quite diverse, even though we would have expected to get more diversity across training corpora from our RNNs, suggesting that we may have to move away from the Wikipedia domain in future experiments. ',\n",
       " 'Complementary experiments show that better controlling for POS distribution across corpora is likely to improve, albeit by a small margin our results: and that testing with other genre of texts might yield similar conclusions. ',\n",
       " 'This suggests that standard recipes for BT might be sub-optimal. ',\n",
       " 'The experimental setup we proposed may also benefit from a refining of the data selection strategies to focus on the most useful monolingual sentences.',\n",
       " 'This additional information can be useful, since we can employ different strategies for a word with one single tag with a probability of 1, versus a word with multiple tags, the most probable of which might only have a probability of 0.3 for example.',\n",
       " 'While much information exists within the textual content of Wikipedia that may assist in WSD, the approach presented here instead uses the article names and link structure within Wikipedia to find articles which are most related to a WordNet sense or context.',\n",
       " 'In addition, many of these SCFs unseen in the data are also very low in frequency, and some may even be true negatives (recall that the gold standard was supplemented with additional SCFs from dictionaries, which may not necessarily appear in the test data). ',\n",
       " 'For a translation system, the ability to model the context may notably improve certain translation decisions, e.g. a better or most consistent lexical choice (Kuang et al., 2018) or a better translation of anaphoric pronouns (Voita et al., 2018;Bawden et al., 2019).',\n",
       " 'One possible reason is that similar sentences retrieved with low similarity scores may be too noisy, and therefore decrease the overall performance.',\n",
       " 'We first see that using back-translated data is detrimental to the BLEU score of the baseline system, an effect that might be due to the difference between News texts and ECB domain.',\n",
       " 'This type of content may be used for business intelligence, targeted marketing, prediction of political election results, analysis of sociolinguistic phenomena, among many other possibilities.',\n",
       " 'Some examples that might be seen as deviations from standard language and that should be normalized include spelling errors, abbreviations, mixed case words, acronyms, internet slang, hashtags, and emoticons.',\n",
       " '(Yang and Eisenstein, 2013) proposed a model in which the relationship between standard and nonstandard words may be characterized by a log-linear model with arbitrary features.',\n",
       " 'It may also be possible to inspect and prune existing Eflomal links using MPWA to get better results in this scenario.',\n",
       " 'Digital tools based on automatic speech recognition (ASR) may be really useful to support teachers in this task, currently very time consuming and prone to human errors.',\n",
       " 'For some test domains, there may even be no data at all (Farajian et al., 2017a).',\n",
       " 'If the motivation is primarily computational, then a drop in MT quality with respect to multiple individual domains might be acceptable if compensated by the computational savings.',\n",
       " 'This might be due to the fact that domains are well separated (cf. Section 4.1) and are hardly helping each other.',\n",
       " 'Fine-tuning with small domains is often outperformed by other MDMT techniques, an issue that a better regularization strategy might mitigate.',\n",
       " 'Also, as McEnery (1995) suggests, such quantitative data may be used to provide a more restricted search area for knowledge intensive anaphor resolution systems to work in.',\n",
       " 'This type of review is of interest because it shows the range of features that may be annotated in such a corpus, and consequently gives a sense of the type of quantitative data we may hope to extract from an appropriately annotated corpus. ',\n",
       " 'If we assume that with an increased search space accuracy declines, then quantitatively motivated limitations such as that suggested may boost the success rate of a knowledge intensive system which suffers from declining accuracy and speed with an open ended search space. ',\n",
       " 'But for the purpose of showing briefly and succinctly the reasons why we may want to do a more detailed analysis of our data, see  (I, my, me, myself, we, our, us, ourselves, you, yours) only ever occur within direct speech in this genre.',\n",
       " 'Although we are only reporting on one genre here, the work of Botley (1996) looking at determiners in three genres, suggest that genre is another dimension of variation where we may see significant differences in the pattern of distributions of pronouns across various distance measures.',\n",
       " 'The point of our investigations are to illuminate a variety of features that corpus based pronoun resolution systems may benefit by, and which they must certainly be aware of: 1.',\n",
       " 'Different normalization purposes may require the use of substantially different normalization procedures For example, converting text-tospeech requires the expansion of acronyms and abbreviations, as well as the conversion of numeric or mathematical expressions into words (Boros et al., 2012, Schlippe et al. 2012); conversely, normalization for purpose of storing data may perform the reduction of word forms into their stems.',\n",
       " 'Approaches to text normalization may be roughly divided into two groups: those that \"translate\" non-standard language into standard language using contextual information (based on language models), and those that replace OOV words (lexical-based) by suitable forms in the standard language.',\n",
       " 'General Opinion usually is a plain text, but Pros and Cons may present single words (Pros: inexpensive), noun phrases (Pros: battery life), bulleted lists of words and noun phrases, or complete sentences.',\n",
       " 'This difference may be due to the small size of both samples and the number of misspellings (in Mercado Livre there are almost twice as many misspellings as in Buscapé).',\n",
       " 'It is not clear whether the ranking produced from the gold standard evaluation is representative: there may be corpus effects for parsers not trained on Susanne, and real life applications may not reflect this ranking.',\n",
       " 'This choice of evaluation method may be having an impact on our overall accuracy.  ',\n",
       " 'Note that these three possibilities are not mutually exclusive, and gender may well be transferred through a combination of the three influences, and also through the representations computed for the other words in the sentence. ',\n",
       " 'Although the comparison with alternative splitting methods might lead to different results, this is not the main focus of the paper and is left as future work.',\n",
       " 'As outlined by Bulte and Tezcan (2019) and Xu et al. (2020) the accuracy of networks implementing priming may slightly drop in performance when no similar translations are integrated.',\n",
       " 'We might be wondering whether the letter-ngram size limit of 3 is large enough, or whether a higher amount of training data could solve this issue.',\n",
       " 'This may seem to be a regression with respect to current state-ofthe-art SMT systems, as the shift from the wordbased model of (Brown et al., 1993) to the phrasebased models of (Zens et al., 2002) is usually considered as a major breakthrough of the recent years.',\n",
       " \"If the underlying machine translation technology is good enough, TransType2's contributions may reduce the need to consult conventional tools such as a bilingual dictionary, term bank, or translation memory. \",\n",
       " 'The agreement features (left half of Table 13) show a somewhat different picture, with the NICT system clearly leading the board, suggesting that good data selection strategies may be more important for these types of features than explicit modeling of morphology.',\n",
       " 'There may indeed be several sources of inconsistencies in the gold annotations : in addition to the divergences in the theoretical linguistic principles that governed the design of the original annotation guidelines, inconsistencies may also result from automatic (pre-)processing, human post-editing, or human annotation.',\n",
       " 'The annotation variation principle (Boyd et al., 2008) states that if two identical sequences appear with different annotations, one of these two label sequences may be inconsistently annotated.',\n",
       " 'This observation suggests that there may be systematic differences in the annotations of different treebanks which could make the domain adaptation setting artificially more difficult.',\n",
       " 'These results open perspectives for further improving these models, especially for German, Czech and Romanian, for which the 16K-16K setting might be suboptimal.',\n",
       " 'For example, a person might pose a question that concerns all the participants; and once everybody has replied, that same person might reply to all of them with a single comment (e.g. thanking them) or with a single acknowledgment.',\n",
       " 'Since, though, what is being written is publicly available to all involved parties, it can be the case that participants of one thread might reply or comment to something said to another thread.',\n",
       " 'From an engineering perspective, if our goal is to extract any positive inference from negated clauses, such distinctions may be academic.',\n",
       " 'WSD is usually approached as an independent task, however, it has been argued that different applications may have specific requirements (Resnik and Yarowsky, 1997).',\n",
       " 'In terms of multi-document summarization, there is room to explore more advanced summarization models, quality and performance metrics as well as better explainability assessment.',\n",
       " 'It might be worth trying other pooling strategies as well, like last-pooling or subword self-attention pooling.',\n",
       " 'For example, the specialized terminology and financial date errors may be alleviated by adopting hierarchical classifiers (Chalkidis et al., 2020a;Manginas et al., 2020), which would first detect entities in coarse classes (e.g., expenses, dates) and would then try to classify the identified entities into finer classes (e.g., lease vs. rent expenses, instrument maturity dates vs. other types of dates).',\n",
       " 'Second, it opens new alleys to also incorporate monolingual data during training, which might especially prove useful in low-resource scenarios. ',\n",
       " 'Given the combinatorial nature of language and specifically the interchangeability of lexical items yielding hosts of possible valid solutions to one same instance lexicalization task, disjunction may well become a major source of (combinatorial) complexity.',\n",
       " 'For example, \"woman\" might be said to contribute λx.f emale(x)∧human(x), while \"female\", only λx.',\n",
       " 'In fact, even verbs might be treated analogously if Infl constituents were modelled, constituting the concentrators of verb base forms.',\n",
       " 'Apart from overhead reasons, it might as well be imposed between every pair of nodes.',\n",
       " 'Such robust similarity methods may be useful for a lot of generic tasks, in which maximum accuracy is not the main criterion, or simply where the required resources are not available. ',\n",
       " 'The underlying idea is simply that most measures may be viewed as a process following different steps: representation as a sequence of features 13 (e.g. tokenization), alignment and a way to compute the final score.',\n",
       " 'Below we do not detail the representation step, because there is no difficulty with it, and also because it is interesting to consider that any measure may be used with different kinds of features, as we will show in the next section.',\n",
       " 'Our viewpoint is that traditional measures may be seen not only in their original context, but also as modular parameterized functions.',\n",
       " 'But we will show that modularity is also useful at a lower level: measures concerning words may rely on similarity between (for example) n-grams, and even at this restricted level numerous possible kinds of similarity may be used. ',\n",
       " 'As we have explained in section 2.2, the Soft-TFIDF measure (Cohen et al., 2003) may suffer from normalization problems.',\n",
       " 'However, this problem may be solved by choosing a more adequate sub-measure: experiments show that using the CosTFIDF measure with bigrams or trigrams outperforms standard CosT-FIDF.',\n",
       " 'In conclusion, we have proposed a generic model to show that similarity measures may be combined in numerous ways.',\n",
       " 'The suffix structure tends to consist of a single vowel V (e.g. -a or -i) whereas the prefix structure may be both CV and V. Most common syllable structures are V and CV, although CCV may arise due to the presence of affricates and prenasalized plosives mentioned above.',\n",
       " 'We present below the evaluation metrics used as well as a monolingual baseline system which does not take advantage yet of the French translations aligned to the speech utterances (bilingual approaches may be also evaluated with this dataset but we leave that for future work).',\n",
       " 'We are now looking at whether the item meta-data might allow filtering uninteresting items, as they seem unlikely to be appropriate.',\n",
       " 'Additionally the approach taken by (Zhu et al., 2007), where multiple images are shown per paragraph, is also being investigated, as this might reduce the impact of non-appropriate items.',\n",
       " 'While studies assessing the quality of individual scales and comparing different types of rating scales are common in psychology and related fields, such studies hardly exist in NLP, and so at present little is known about whether discrete scales are a suitable rating tool for NLP evaluation tasks, or whether continuous scales might provide a better alternative. ',\n",
       " 'This paper presents an efficient unsupervised algorithm to detect all substrings occurring less than k times in the input string, based on the assumption that such rare sequences are likely to contain sensitive information such as names of people and rare diseases that may identify individuals.',\n",
       " 'IDs such as social security numbers in the United States are obvious means to aggregate data sources, but full names, residential addresses, and other attributes about individuals and their combinations may also work as pseudo identifiers from which one may be able to identify persons, or to raise the probability of successful identification (Sweeney, 2002)',\n",
       " 'On the other hand, our approach may be prone to false positives, because rare sequences do not necessarily express private information, especially when the given source of the text statistics is small. ',\n",
       " 'For example, an address line such as Pine street may serve as an informative clue to identify a specific location, while each of constituents of the expression is a common word that is unlikely to be suppressed by simple word frequency threshold.',\n",
       " 'Nevertheless, for massive text data, which may be larger than the typical RAM size, our method may still need to introduce a way to reduce the memory footprint.',\n",
       " 'Following other work dealing with massive data using suffix arrays, solutions to memory constraints may include distributed processing (Kulla and Sanders, 2007), external memory algorithms (Bingmann et al., 2012) and succinct data structures.',\n",
       " 'In the absence of multiple reference sentences or human evaluation results for the n-best list though, it is unclear to what extent the outputs in the n-best list might represent valid paraphrases versus clearly less acceptable outputs.',\n",
       " 'These resources may be close specialized corpora (e.g. a breast cancer corpus may benefit from contexts derived from a more general oncology corpus), corpora of different types of discourse and gender (e.g. a corpus of popular science discourse supplementing a corpus of scientific discourse), corpora of general language or out-of-domain data.',\n",
       " 'This statement lend support the idea that enriching small specialized comparable corpora may be beneficial to bilingual terminology extraction task.',\n",
       " 'It might seem surprising that we found more terms outside the first rank with CC corpus than BC+CC (80 versus 75) since the MAP is lower with CC than BC+CC (57.4 versus 73.9).',\n",
       " 'On the other hand, the phrasal verb \"brush down\" may fall under either B4 category with the sense of cleaning or G2.2 category {ETHICS} with the sense of reprimand.',\n",
       " 'Most noun-noun compounds are rare, and statistics based on such infrequent events may lead to an unreliable estimation of the acceptability of particular modifier-head pairs. ',\n",
       " 'However, there is always the possibility that these systems might encounter modifier-head pairs in testing which never occurred in training, forcing the system to \"back off\" to some default strategy.',\n",
       " 'Therefore, it would be preferable to have a method of measuring conceptual associations which is less domaindependent and which does not rely on the presence of unambiguous subconstituents in training; we investigated whether Latent Semantic Indexing might satisfy these requirements.',\n",
       " 'It is this compression step which is said to capture important regularities in the patterns of word co-occurrences while ignoring smaller variations that may be due to idiosyncrasies in the word usage of individual documents.',\n",
       " 'Whereas highly compositional MWEs may pose a trivial challenge to human speakers for interpretation, they present a tough challenge for fully automatic MT systems to produce even remotely fluent translations.',\n",
       " 'Indeed, due to the open-ended nature of such MWEs, any manually compiled lexicons, however large they may be, are unlikely to cover them exhaustively.',\n",
       " 'However, pivot hypotheses may contain better lexical predictions, that the additional model helps transfer into the baseline system, yielding translations with a higher quality, as shown in many cases the +auxLM systems results.',\n",
       " 'This could be explained, in addition to the lower Bleu3 and Bleu4 precision, by the fact that the quality of the translation of grammatical words may have decreased.',\n",
       " 'Existing Welsh part-of-speech (sections 2.1) and semantic (section 2.2) taggers produce good results, but their heavy dependence on handcrafted rules and hard-coded resources may pose a maintenance challenge in future.',\n",
       " 'Although it was not built aiming to the MWE extraction, we thought it might be very well suited for this purpose.',\n",
       " 'Here, there may need to be a compromise between levels of accuracy and domainspecific explainability.',\n",
       " 'We also intend to carry out a corpusbased investigation into variability of GO terms which may not be replicated exactly in the corpora, for example inflectional or derivational suffixes such as \"processes\" instead of \"process\", and the potential for intervening items within multiword expressions.',\n",
       " 'These differences between the results obtained with our dev/test configuration and the official ones may be due to the lack of tuning data when performing the 3-fold cross-validation, leaving only 1,000 sentences for tuning.',\n",
       " 'The fact that its entropy is lower even compared with the \"most frequent\" baseline, which is also a single-pronunciation baseline, may be explained by the fact that the most frequent pronunciations represent better the spoken terms that can be often easily confused.',\n",
       " 'We believe that the size might be influential to people who like to eat a lot, but people who might not be interested in them. ',\n",
       " \"Given that this system is overall less reli-able than Moore's approach, it might be safe to filter these alignments and keep only the surer ones (here, keeping only links having a score greater than 0.5).\",\n",
       " 'However, this approach may give too much weight on the length ratio feature and it remains to be seen whether alternative approaches are more suitable. ',\n",
       " 'Worse, as the complexity of language permits for one relation to be expressed in a multitude of ways, we may expect the distribution of patterns observed for each relation to be heavy-tailed, with a few patterns observed in high numbers and a large number of very rare patterns. ',\n",
       " 'At the same time, these patterns may also express other relations at varying degrees; the pattern \"X divorced from Y\", for example, explicitly expresses the DIVORCEDFROM relation, while also entailing the MARRIEDTO relation.',\n",
       " 'Other examples are appositions, which may be connected to an entity but are not themselves part of the shortest path (indicated by \"nn\" or \"appos\"), and light verb constructions in which only the verb, but not the typically more important noun is part of the shortest path.',\n",
       " 'The second intuition is that patterns that occur in more than one cluster may be ambiguous and lend different amounts of evidence to different relations.',\n",
       " 'For example, if the student gives a contradictory answer, accepting it as correct may lead to student misconceptions; on the other hand, calling an irrelevant answer \"partially correct but incomplete\" may be less of a problem.',\n",
       " 'If the predictions made by the original interpreter and the classifier differ, and in particular when the classifier assigns the \"contradictory\" label to an answer, BEETLE II may choose to use a generic strategy for contradictory utterances, e.g. telling the student that their answer is incorrect without specifying the exact problem, or asking them to re-read portions of the material. ',\n",
       " 'Instead of the linear model, we may consider using a model based on F β score, F β = (1 + β 2 ) P R β 2 P +R , and fitting it to the data to derive the β weight rather than using the standard F 1 score.',\n",
       " 'A task for future work is to investigate, whether it is possible to build larger clusters, which are still meaningful.',\n",
       " 'Since the semantic restrictions of JCVs are similar to those of phrasal verbs in English (Villavicencio and Copestake 2002), there might be a possibility of applying our method to machine translation. ',\n",
       " 'We do not differentiate these two types in advance, because our method may be also useful for identifying them.',\n",
       " 'A similar issue applies to other languages such as Arabic, which may affect the coverage as well as the accuracy of part-of-speech taggers chosen to embed within the semantic taggers.',\n",
       " 'More advanced tools are meant to identify inconsistencies in terminological translations and might prove useful in controlledlanguage situations (Itagaki et al., 2007). ',\n",
       " 'One might argue that domain-specific comparable (or perhaps unrelated) corpora are easier to acquire, in which case context-vector techniques (Rapp, 1995;Fung and McKeown, 1997) can be used to identify the translation of terms.',\n",
       " 'As a consequence, one of the difficulties with comparable corpora is that the translation of a source term may not be present in its \"normalized\" or \"canonical\" form but rather in the form of a morphological or paraphrastic variant (e.g. postmenopausal translates to après la ménopause \\'after the menopause\\' instead of postménopausique).',\n",
       " \"For instance, postoophorectomy may be translated to postovariectomie 'postoophorectomy' or après l'ovariectomie 'after the oophorectomy' or après l'ablation des ovaires 'after the removal of the ovaries'. \",\n",
       " 'This might be due to the fact that context-based methods need the source and target words to be very frequent in the corpora to work properly.',\n",
       " 'Furthermore, some work needs to be done on lexical variation: we used a dictionary of synonyms, but a thesaurus, which contains a large variety of semantic relations, may help us better in tackling lexical variation.',\n",
       " 'It also allows us to use extra operations such as word deletion, a transformation that may be difficult to control in the approach described in § 3.2. ',\n",
       " 'First, parameters updates reinforce only gold derivations; at test time, the model might find itself, after an error, in a part of the search space where it was not trained to take good decisions, thus propagating errors (Goldberg and Nivre, 2012).',\n",
       " 'As they are directly derived from the number of hypotheses in the search space that contains this n-gram, these probabilities might be more reliable than the ones estimated from the decoder scores. ',\n",
       " 'From a performance point of view, it might also be interesting to combine the use of large-scale feature sets with other recent improvements such as the use of semi-supervised learning techniques (Suzuki and Isozaki, 2008) or variable-length dependencies (Qian et al., 2009).',\n",
       " 'Consequently, for lack of investing enough energy working on the same problems with the same tools and towards the same goals, we might not achieve the efficiency that is needed, as time is running out for many languages.',\n",
       " 'To induce word segmentation from parse trees, we will consider that each span covered by the non-terminal symbol Word defines a linguistic word, even though in a fully unsupervised setting, this non-terminal might actually correspond to larger or smaller linguistic units.',\n",
       " 'The suffix structure mostly consists of a single vowel V (e.g. -a or -i) whereas the prefix structure may be both CV or V (or CVV in Mboshi).',\n",
       " 'The token/type ratio (5.75 tokens for one type in Mboshi, and 4.30 in Myene) indicates a higher lexical diversity in Myene, which might explain weaker results on types.',\n",
       " 'When two equally useful ranking methods are compared, method A might just happen to perform better in a particular experiment, with B taking the lead in a repetition of the experiexperiment, the corpus was annotated with the partial parser YAC (Kermes, 2003).',\n",
       " 'Statistical significance tests are designed to account for a small fraction of this variation that is due to random effects, assuming that all parameters that may have a systematic influence on the evaluation results are kept constant.',\n",
       " 'Some elements will be entirely new candidates, sometimes the same candidate appears with a different feature vector (and thus represented by a different point x ∈ Ω), and sometimes a candidate that was annotated as a TP in one experiment may be annotated as a FP in the next.',\n",
       " 'In order to encapsulate all three kinds of variation, let us assume that C + and C − are randomly selected from a large set of hypothetical possibilities (where each candidate corresponds to many different possibilities with different feature vectors, some of which may be TPs and some FPs). ',\n",
       " 'In the definition of the n-best precision Πg,n, i.e. for A = Cg(γg(n)), the number of candidates in A is constant: NA = n. At first sight, this may seem to be inconsistent with the interpretation of NA as a random variable.',\n",
       " 'It is obvious that a repetition of the evaluation experiment may lead to quite different precision values, especially for n < 1 000.',\n",
       " 'The number of candidates in the difference regions, N D 1 and N D 2 , may be small, especially for acceptance regions with large overlap (this was one of the reasons for using conditional inference rather than a normal approximation in Section 3.1).',\n",
       " \"However, there might be some morphological or paraphrastic variants in the French texts like post-ménopause 'post-menopause' or après la ménopause 'after the menopause'.\",\n",
       " 'These components may be either free (i.e. they can occur in texts as autonomous lexical items like toxicity in cardiotoxicity) or bound (i.e. they cannot occur as autonomous lexical items, in that case they correspond to bound morphemes likecardioin cardiotoxicity). ',\n",
       " \"For instance, postoophorectomy may be translated as postovariectomie 'postoophorectomy', après l'ovariectomie 'after the oophorectomy' or après l'ablation des ovaires 'after the removal of the ovaries'.\",\n",
       " 'This might be partly due to the low comparability of the corpus but we think that the main reason lies in the morphological type of the languages involved in the translation.',\n",
       " 'Even though some of those might be true positives per se (i.e. they are accepted as collocations by a human annotator), they are not a part of the source corpus and thus should not be included in the list of candidates. ',\n",
       " 'Given the difference in size between the two corpus, this approach may introduce a bias in the translation model in favor of out-of-domain. ',\n",
       " 'This might be due to the difficulty of computing valid alignments between phonemes and words in very limited data conditions, which remains very challenging, as also demonstrated by the results of Pisa.',\n",
       " 'Consequently, results achieved by individual measures may very well be due to chance (cf. sections 4.1 and 4.2), and evaluation with respect to frequency strata is not possible (cf. section 4.3).',\n",
       " 'For instance, if we just look at the first © ¨ § & of the SLs for the PNV data, we might conclude that the t-test and frequency measures are equally well suited for the extraction of PNV collocations.',\n",
       " 'If a given candidate has a high frequency in the corpus, it may be similar not only to the selected nearest lexical units (k), but also to other lexical units of the dictionary.',\n",
       " 'Apart from exhibiting differences in field, tenor and mode, scientific texts are associated with particular discourse \"styles\" such as technicality, abstractness or informational density, which may again be linguistically realized in different ways and to different degrees across disciplines.',\n",
       " 'Relating this back to the notion of comparability, the concept of register may thus provide the basis for a fine-grained description of comparability, as it acknowledges the multi-dimensional nature of linguistic variation. ',\n",
       " 'Standard corpus methods are employed for the quantification of instances of linguistic features that are considered to be relevant indicators of variation across scientific disciplines and may be expected to significantly contribute to differences in language use across disciplines.',\n",
       " 'As another feature, we analyze n-grams on the basis of PoS combinations (rather than words), since we have seen in a previous study that they may be involved in processes of conventionalization (Kermes and Teich, 2012). ',\n",
       " \"The insight to be gained from our study for multilingually comparable corpora is that more elaborate definitions of 'comparability' might be re-quired.\",\n",
       " 'French-English), there is still much room for improving automatic alignments produced by standard tools such as Giza++ [2] or Fastalign [6].',\n",
       " 'At test time, one may need to produce on output a word form that has not been seen in the training data, which is challenging and may require extra processing or enriched representations (e.g. factored models). ',\n",
       " 'Number is an attribute that is common to English, and gender is an intrinsic part of Czech nouns, meaning that it may serve to disambiguate two identical lemmas that have a different lexical meaning.',\n",
       " 'Number is an attribute that is common to English, and gender is an intrinsic part of Czech nouns, meaning that it may serve to disambiguate two identical lemmas that have a different lexical meaning.',\n",
       " 'The same holds for the rich use of non-manual articulators in sentences and the limited role of facial expressions in the lexicon: these too make sign languages across the world very similar in appearance, even though the meaning of specific articulations may differ (Crasborn, 2006).',\n",
       " 'The variability between signers either in terms of physical properties (hand sizes, colors, etc) or in terms of articulation (movements) is such that it does not affect the understanding of the sign language by humans, but that it may be difficult for machines to generalize over multiple individuals.',\n",
       " 'Likewise, analyzing performance in agreement tests with respect to the distance between two coordinated nouns or verbs might also be revealing. ',\n",
       " 'Without distinction of these last two levels, we privileged documents written by specialists, assuming that they may be richer in content and vocabulary (for example advices from a doctor would be richer and longer than forum discussions). ',\n",
       " 'Since it appears the pre-processor is the cause of most of the errors, in-processing with a state-ofthe-art lexicalized parser might outperform the preprocessing approach.',\n",
       " '(ii) we must include combinations of EEs as nonterminals may dominate more than one unbound EE (i.e. S § ¤© ¥ ¨ § ¤© ¦ ¨¢ ¤£ ¦¥ ¨ § ¤© ¡ and (iii) a single nonterminal may be repeated in the presence of co-ordination (i.e. S § ¤© ¥ ¨ § ¤© § ¤',\n",
       " 'Indeed, by taking advantage of the insights that make the finite-state and lexicalized parsing models successful, it may be possible to generalize the results to other strategies as well.',\n",
       " 'We conjecture that a parser that takes advantage of these features might be more accurate in detecting EEs while parsing than the parsers presented here.',\n",
       " 'Doing an exhaustive search might help in principle, but it is infeasible in practice.',\n",
       " 'The benefit would be two-fold: EEs might be found more reliably with a different module, and the parser would be fast and accurate in recovering antecedents.',\n",
       " 'Given this combination method, there still are two interesting variations: we may use only the EEs proposed by the tagger (henceforth the NOINSERT model), or we may allow the parser to insert even more EEs (henceforth the INSERT model).',\n",
       " 'LM rescoring Our results to date with target side language models have proven inconclusive, which might explain why our best results remain between one and two BLEU points behind the n-gram based system using comparable information.',\n",
       " 'However, recent research also suggests further pretraining of already existing models with texts that are close to the texts of the downstream task may improve results (domain-specific fine-tuning) (Gururangan et al., 2020;Rietzler et al., 2020).',\n",
       " 'A reason might be that, while research argues that further pretraining with even low amount of texts can show improvements, the amount of text used in our setting (300 MB) is below the amounts reported in similar research (Kameswara Sarma et al., 2018;Gururangan et al., 2020;Rietzler et al., 2020).',\n",
       " 'The usage of solely dramatic texts instead of varied forms of texts for training might also lead to problems in generalizing the specific language of the annotated material.',\n",
       " 'Because these association scores may sometimes be unreliable and poor indicators of a translation relationship, the best-first segmentation algorithm may produce incorrect results, especially on long sentence pairs.',\n",
       " 'We will furthermore consider the compactness of the produced phrase tables, as it can be regarded as a desirable quality of phrase tables licencing works on phrase table pruning (see e.g. [19]), and anormally large phrase table may in fact only artificially inflate oracle results. ',\n",
       " 'Chinese words may in fact be very difficult to align to English words, partly for ambiguity reasons, and many noisy translation candidates may be extracted.',\n",
       " 'The EBMT systems mentioned above both convert translation examples into templates using manually-created information, such as from a machine-readable dictionary with part-of-speech information, to replace words with tokens indicating the class of word which may occur in a particular location.',\n",
       " 'D S 2 where S 1 and S 2 are the same in both instances (at most one of these may be the empty string) and D di ers between the two training instances, but may contain common subsequences.',\n",
       " 'If more than the target numberof clusters remain when the rst clustering pass terminates, clusters with frequency values (the sum of term frequencies for all word pairs included in the cluster) of ve or less may merge regardless of the selected threshold.',\n",
       " 'During development i t w as found that the process has largely converged after six iterations, even though total convergence may require fteen or more iterations, with the last several iterations each adding only a few new equivalence classes with a handfull of members. ',\n",
       " 'This result is counter-intuitive; we assume that the specific selection of a larger window size and position (see chapter 3.2.6) might be a reason for this.',\n",
       " 'In order to provide some insights about what went wrong in the systems and whether the dataset might have to be blamed for their relatively low performance in subtask 2, we investigated how many and which pairs were misclassified by the top three systems, separately for each subtask. ',\n",
       " 'As can be seen from Table 4, many of the false positives carry some kinds of association (e.g. cold -bad, combine -create, eye -lens, etc.), which in very few cases might be due to an accidental semantic relationship not filtered out by the annotators (e.g. desert -landscape as hypernymy).',\n",
       " 'With respect to these ones, hypernyms were most often confused with synonyms (even native speakers may have a hard time discriminating them: e.g. dessert -sweet) and antonyms (as they might share similar distributional properties, cf.',\n",
       " 'As the filtering reduced the initial corpus by only 19%, we might be inclined to completely skip the filtering step for future studies, and rather rely on the crowd for tagging the most frequent words as being dialect or non-dialect.',\n",
       " 'Alternatively, more robust variants of Delta such as ∆ ∠ might be used, although there is still a gradual decline, especially for the French data in Fig. 1(c).',\n",
       " 'This observation suggests that other Delta measures such as ∆ B might also benefit from vector normalization.',\n",
       " '∆ B is also improved substantially by vector normalization (contrast the black curve with the red and blue ones), resulting in clustering quality equal to ∆ ∠ , although ∆ B might be slightly less robust for n w > 5 000.',\n",
       " 'However, content words may be more prone to overfitting than function words.',\n",
       " 'Also, in the English and French collections, a small number of roman numerals are included (such as \"XL\" or \"XXXVVII\"), which may be characteristic of novels with an unusually high number of chapters.',\n",
       " 'In Sec. 4 we showed that supervised feature selection may be a viable approach to further improve authorship attribution and determine a suitable value for n w in a principled manner. ',\n",
       " 'For example, regarding the former, it might be expected that summaries on ASR transcripts would be rated lower than summaries on manual transcripts, due to speech recognition errors.',\n",
       " 'Two drawbacks of this method are that dimensionality is tied to summary length and that good sentence candidates may not be chosen if they do not \"win\" in any dimension (Steinberger and Ježek, 2004).',\n",
       " 'It may be di cult, time-consuming, and expensive to obtain that much parallel text, particularly for lesser-used language pairs.',\n",
       " 'Because word order is important, counts are accumulated separately for each position within the context, i.e. for N = 3 , a particular context word may contribute to any of six di erent counts, depending on its location relative to the occurrence.',\n",
       " 'More sophisticated clustering algorithms such as k-means and deterministic annealing may provide better-quality clusters for better performance, at the expense of increased processing time. ',\n",
       " 'Similarly, this work aims to detect important utterances that may not be detectable according to lexical features or prosodic prominence, but are nonetheless linked to high speaker activity, decision-making, or meeting structure.',\n",
       " 'For a given dialogue act, it may be that one annotator links it 0 times, one annotator links it 1 time, and the third annotator links it two times, resulting in an average score of 1 for that dialogue act.',\n",
       " \"The reason for the random summarizaton system not suffering a sharp decline when applied to ASR may be due to the fact that its scores were already so low that it couldn't deteriorate any further.\",\n",
       " 'A zero co-occurrence count might be due to insufficient evidence or might reflect the fact that the adjective-noun pair is inherently implausible.',\n",
       " \"The best second-order and first-order models from the evaluation reported in this paper are likely to focus on different types of relations between response and stimulus words: this leads us to believe that an integration of the two sources may produce improvements in NaDiR's performance. \",\n",
       " '(2017) (NMT of curated hotel descriptions), who point out that automatic metrics like BLEU tend to neglect semantic differences that have a small textual footprint, but may be seriously misleading in practice, for instance by interpreting available parking as if it meant free parking.',\n",
       " 'However, when doing so, some information may be lost (e.g., named entities, acronyms, emphasis) which may result in lower translation quality.',\n",
       " \"For example, if a blogger writes his/her journey to Norway in multiple blog entries, it might state 'We traveled to Norway' in the first entry, while only writing 'We ate wild sheep!'\",\n",
       " '(2013) and references therein), we believe that such applications may benefit from our detailed analyses on the effects of DSM parameters. ',\n",
       " 'For this reason, a pre-tokenization step may be useful (as a way to enforce some linguistic bias and consistency in the BPE segmentation). ',\n",
       " 'Once all of the sentence pairs in the corpus have been processed, the correspondence table is filtered using a symmetric co-occurrence ratio and an asymmetric co-occurrence ratio, both of which may vary as a function of the total co-occurrence count.',\n",
       " 'By setting the thresholds used in filtering to different values, a tradeoff between yield and accuracy may be tuned (see Table 2); note that the error rate is based on total definitions, and that a far lower percentage of words have only incorrect definitions.',\n",
       " 'Due to the nature of this task, performance in it might be especially useful as an indicator for the usefulness of a system in the area of summarization. ',\n",
       " 'However, we thought that a translation model for patents might be useful for our task, because translation results using the patent translation model tend to contain more patent terms than those obtained using the model for research papers.',\n",
       " 'However, as it is assumed that the translation model translates documents in genre G2, the translation results might contain more mistranslations than the results obtained by a model for genre G1.',\n",
       " 'A tagger that works particularly well for many irrelevant tokens (punctuation, verbs, etc.), correctly marking them ATX, may achieve high accuracy even if it has low recall on tokens belonging to aspect terms.',\n",
       " 'Since this would effectively be cutting out a number of the pauses, a smaller pause duration might be preferable as the higher coverage would compensate for the more concentrated search area.',\n",
       " 'However, as stated in the previous section, with multiple document summarization, there may be more than one sentence with the same content, and thus we may have more than one set of sentences in the original document that corresponds to a given sentence in the abstract; that is to say, there may be more than one key datum for a given sentence in the abstract 5 . ',\n",
       " \"If we don't impose these restrictions, however, much erroneous script knowledge might be obtained.\",\n",
       " 'Finally, classification techniques such as those described in Gyawali et al. (2013) may be used to discard translations when building monolingual, vernacular corpora. ',\n",
       " 'An analysis of mis-classified positive messages further suggests that certain punctuation marks, especially multiple exclamation marks, might be useful as additional features.',\n",
       " 'In fact, the learning curve for our system (Fig. 1) suggests that even as few as 3 000-3 500 labelled messages might be sufficient.',\n",
       " 'Determining the nearest neighbors of a message based on Latent Semantic Analysis might be a useful addition, as might be the use of part-of-speech tags created by an in-domain POS tagger (Gimpel et al., 2011) 14 .',\n",
       " 'But a very similar-looking sentence can play a completely different argumentative role in a scientific text: when it occurs in the section \"Future Work\", it might refer to a minor weakness in the work presented in the source paper (i.e. of the author\\'s own solution).',\n",
       " 'This might have to do with the location of those types of sentences in the paper: AIM and TEXTUAL are usually found at the beginning or end of the introduction section, whereas CON-TRAST, and even more so BASIS, are usually interspersed within longer stretches of OWN.',\n",
       " 'Student session papers are easiest to annotate, which might be due to the fact that they are shorter and have a simpler structure, with less mentions of previous research.',\n",
       " 'At the second round-table discussion, it was pointed out that we might need to examine more closely the results of evaluation, especially the one by ranking. ',\n",
       " 'To counteract this effect, we experimented different pre-processing schemes for Turkish, and we also evaluated the use of continuous space language models which might lessen the sparsity issues. ',\n",
       " 'As a result, due to the random initialization of the parameters and to data sparsity, many vectors of R might be blocked in some local maxima, meaning that similar vectors cannot be grouped in a consistent way and that the induced similarity is more \"loose\".',\n",
       " 'As discussed above, this strategy may explain why the neighborhoods in the induced context space for the less frequent types were difficult to interpret.',\n",
       " 'The reason that there is a larger overlap in CRIS † might be from higher contextual consistency between CRIS † and BioWord2Vec. ',\n",
       " 'With the same settings, the F1-score is also higher than that of CRIS (0.63) with lower deviation, which might be the outcome of a more balanced dataset.',\n",
       " 'This result might be inherited from the fact that there is a significant increase in the overlap between CRIS † and CRATE datasets (see Table 3). ',\n",
       " 'These might be the reasoning behind higher deviation and instability of F1-scores observed in some predictions (see Table 4). ',\n",
       " 'However, using those embeddings might be hindered by excessive noise (concatenation of words and punctuation, misspellings) in data and hence poor vocabulary overlap.',\n",
       " 'There may be room for improvement for the bilateral and internal configurations by taking into account the relative position of the pattern (e.g. if the pattern has been found on the left side, right side or both sides of the candidate) and not only its number of occurences. 7 60% precision and probably a recall close to 100% Finally, among the classifiers we tested, SVM with linear kernels offers the best results.',\n",
       " \"If the models' estimates for 3 times the size of the training set have acceptable errors of around 5%, for many applications we might want to extrapolate to 100N 0 or more (recall the example of estimating type counts for the entire Web).\",\n",
       " 'Finally, future work should systematically explore to what extent different textual typologies are affected by the non-randomness problem (notice, e.g., that non-randomness seems to be a greater problem for the BNC than for the more uniform la Repubblica corpus).',\n",
       " 'The considerable improvement (in particular in precision) brought about by the interruption points, and the comparatively small impact of sentence boundary information, might be explainable in several ways.',\n",
       " 'units (as delimited by interruption points) may be beneficial for precision as they give rise to fewer spurious matches.',\n",
       " 'We compare rated plausibility with the corpus frequency of the head noun, the motivation being that highly frequent nouns are more familiar than less frequent ones, and consequently may affect the judged plausibility of the whole noun phrase. ',\n",
       " 'However, though machine learning algorithms may deduce to make best use of a given set of features for a given problem, it is a linguistic question and a non-trivial task to identify a set of features which describe the data sufficiently. ',\n",
       " 'The major reason may be that the resolution algorithm relies on surface features and does not have access to world or domain knowledge, which we did not want to depend upon since we were mainly interested in cheap features.',\n",
       " 'For instance, clusters (Koo et al., 2008) may be used to reduce lexical sparseness, which is particularly appropriate in the case of dependency parser transfer since parallel data are generally not from the same domain as the corpus used to train and evaluate the parser.',\n",
       " \"In this section, we aim at assessing, first, how parsing performance of the source language impacts the quality of the transferred parser, and second, how using more 'advanced' parsing techniques may boost parsing in the target language. \",\n",
       " 'This observation has already been reported several times (e.g. by Mc-Donald et al. (2013)), but Figure 2 suggests that the increase in performance may mainly result from a good alignment between the source and the target languages.',\n",
       " 'This might be caused by the increase of the number of feature functions, from 14 to 26, due to the duplication of the phrase table and the lexicalized reordering model.',\n",
       " 'These results may be explained by the use of automatic tools (POS tagger and lemmatizer) that are not entirely error free, and also, to a lesser extend, by the noise in the test data.',\n",
       " 'Although quantitative results were unsatisfactory, it is finally worth mentioning that a manual examination of the output revealed that the explicit usage of gender and number in our models (via POS tags) may actually be helpful when translating to French.',\n",
       " 'Unsupervised learning might be an alternative, since it does not need any annotation at all.',\n",
       " 'However, the cost is the decrease in performance to about 53% F-measure on the same data (Cardie and Wagstaff, 1999) which may be unsuitable for a lot of tasks.',\n",
       " 'To cope with this lack of syntactic information that a speech synthesis developer may face currently, e.g. in the absence of a reliable parser, several strategies have been applied to allocate phrase boundaries.',\n",
       " 'Cooccurrence strength values may provide additional clues to informational ties among words; when we investigate the cooccurrences of nouns and prepositions, and of verbs and prepositions, the cooccurrence strength value could also indicate whether the prepositional phrase is attached to the noun or to the verb in the syntactic tree. ',\n",
       " 'First, the noun of the preceding NP or PP that the focus PP might be attached to (Ni); second, the preposition (P) of the PP to be attached; third, the verbal head (V) of the clause that the PP is in; and fourth, the noun head of the PP to be attached.',\n",
       " 'To estimate appropriate settings, a big search space needs to be sought through in some way, after which one can only hope that the estimated best parameter setting is also good for the test material -it might be overfitted on the training material. ',\n",
       " 'While using higher-order models or more sophisticated models of the same family (Teh, 2006b;Mochihashi et al., 2009) may improve the performance (see (Godard et al., 2016) for an experimental comparison), we believe that in our low-resource conditions, these variations would be small 2 and would not change our main conclusions. ',\n",
       " \"This may be because both words 'bana' and 'ba' often occur together, a cooccurrence that can not be captured by our unigram model (Goldwater et al., 2009).\",\n",
       " 'Using AGs comes, however, with a high computational price, as the Gibbs sampling process typically requires repeated parses of the corpus, even though cheaper estimation techniques may also be considered (Cohen et al., 2010).',\n",
       " 'Finally, improving the performance of the MT system in one domain will often hurt that of another (van der Wees et al., 2017;Britz et al., 2017) and improving model generalization across all domains (Koehn et al., 2018) may not achieve optimally for any particular domain. ',\n",
       " 'This strategy is potentially suboptimal as some out-of-domain samples may contribute to the final performance due to e.g. domain similarity.',\n",
       " 'Optimizing the learning distribution in multidomain settings is even more challenging as the learner needs to take advantage of possible domains overlaps and also of the fact that some domains might be easier to learn than others. ',\n",
       " 'As a result, feature selection may only choose only few higherorder features, motivating the need for an effective variable-order CRF (voCRF) training procedure (Ye et al., 2009).',\n",
       " 'In some cases, apparently simpler inflectional markers may take more time to be acquired than formally more complex and articulated ones.',\n",
       " 'In addition, understanding more of the real cognitive hurdles a human learner has to face in the process of effectively acquiring an inflectional system of average complexity may also shed some light on optimal practices for language teaching.',\n",
       " 'Although practical significance of this study may be limited at the moment since it does not demonstrate a dramatic increase in retrieval performance in large test collections, we believe our findings have important theoretical contributions since they indicate that the power of discriminative approach is comparable to the best known analytical or heuristic apporaches.',\n",
       " \"We believe that our work and the ones referred in this paper may bring many of the achievements made in a more general area of classification and machine learning closer to the task of rank ordered information retrieval, thus making retrieval engines more helpful in reducing the information overload and meeting people's needs.\",\n",
       " 'Captions, which are often meant for viewers with hearing difficulties, and subtitles, which are produced for viewers with an imperfect command of the source language, may have slightly different traits, that we ignore here. ',\n",
       " 'Finally, even in scenarios where only subtitles would be needed, generating captions at the same time may still help to better check the correctness of subtitles. ',\n",
       " 'This approach might also be limited by the lack of appropriate training resources (Sperber and Paulik, 2020).',\n",
       " 'Since more informed units may yield more accurate predictions, more informed units may also force the model to fall to lower n-grams.',\n",
       " 'However, each tuple may be tagged differently, as words with same surface form may have different POS tags. ',\n",
       " 'When translating into the embedded language, we observe a larger number of word order changes: in this case, inserted target segments may not appear in their correct order in the CSW sentence, an issue that the model tries to fix.',\n",
       " 'While it is quite easy to handle local context through suitable representations and learning techniques, complexity may increase significantly when a broader context is required, especially when relations exist among various parts of a document. ',\n",
       " 'In general, the assumptions behind these approaches are the following: (1) If a source language word is translated differently into a second language, it might be ambiguous and the different translations can indicate the senses in the source language. ',\n",
       " 'The main idea behind this filtering of public opinion as found on the social Web, is that citizens that try to justify their opinion with arguments may be more important or influential than the less justified ones. ',\n",
       " 'These segments may sometimes start with cue words such as \"διότι\" (\"because\"), \"για να\" (\"in order to\"), \"αλλά\" (\"but\"), or may just follow the usual sentence structure.',\n",
       " 'However, the resulting acceptor might still contain a large number of duplicated paths, corresponding to identical hypotheses produced for different values of t, even after λ update.',\n",
       " 'It may finally be noted that better stopping criteria are needed to detect convergence, as lattice MERT sometimes operates in regions where small changes in λ do not produce visible improvement of dev-BLEU (e.g., for n r = 20 for the small set).',\n",
       " 'While some domain distinctions are clearly undebatable, such as when opposing e.g. News commentaries and parliamentary speeches, other distinctions may in fact be more difficult to draw when one considers arbitrary text inputs, as may be submitted to online translation services. ',\n",
       " 'Given some word alignment between a source and target parallel corpora, the absence of an aligned target phrase for a given source phrase may suggest that the corresponding failure of the extraction process should be accounted for in the translation model.',\n",
       " 'As the synthesis of all test documents shows significant improvement, we may question whether this result would be due to the length of the document, with the intuition that longer documents would allow for better adaptation 14 , or to the similarity of documents, with the intuition that documents that have close matches in the training corpus should be translated better.',\n",
       " '• It may also be the case that English as an original language, resulting in a more complex language as opposed to when English is the result of translation (i.e. translationese), is less present in our training data.',\n",
       " 'Experimenting with other corpora in which original language is known may help us to confirm this hypothesis. ',\n",
       " 'Our adapted systems have recourse to sampling, and consequently do not use a reverse translation model [9], thus resulting in systems that may be built very efficiently, even for large data set conditions.',\n",
       " 'Some of our observations and hypotheses may pave the way to future experiments to determine under what conditions adaptation techniques can improve translation results.',\n",
       " 'Third, the number of chunks may better match across languages than the number of words, which may yield better alignment at the chunk level.',\n",
       " 'But considering that chunk alignment alleviates some structural mismatch problems in a language pair, we think the method may still have improvements with a larger data set.',\n",
       " 'In many applications, unlabeled instances may be abundant but obtaining labels for these instances could be expensive and time-consuming.',\n",
       " 'For rare words, knowing that the translation of the rare word may not be correct (due to poor alignment statistics), the target translation of the replacement is replaced by the translation of the rare word obtained from the dictionary.',\n",
       " \"Each entity is comprised of a title, a type (which may allow the user to add additional fields, such as first, middle and last name) and some optional fields such as their social media information and URLs for the entity's web, Wikipedia and Wikidata pages.\",\n",
       " 'While there may be various explanations to these accuracy differences, what is surprising here is that the best treebank does not seem consistent with common factors of high accuracy (treebank size, domain similarity, treebank consistency).',\n",
       " 'Concluding on this hypothesis would require, however, further analysis of the treebank domains: the scores may still be partially explained by actual domain adaptation issues, e.g. the relative size of each domain in multi-domain treebanks, or details of the domains (style, author, date...) that do not appear in the coarse domain categories (news, Wikipedia, fiction...). ',\n",
       " 'This may seem to be a step backwards, since the transition from word (Brown et al., 1993) to phrase-based models (Zens et al., 2002) is considered as one of the main recent improvement in MT.',\n",
       " 'This is to cope with situations in which, since tasks are not related, negative transfer of information across tasks might occur, thus harming the generalization of the model.',\n",
       " 'The distance between News and the other domains indicates that, when it is used as target, knowledge transfer from the other domains might be problematic.',\n",
       " 'Let us suppose that our answer segment is (human) answer may be non-contiguous, but the combination of SPA and EBMT to date is only capable of using the best contiguous target mgram alignment it can find.',\n",
       " 'Further improvements may result from the generalized use of phrases and tighter integration with the dictionary generation process, as well as from updates to the EBMT code to permit exploitation of non-contiguous alignments.',\n",
       " 'In this setting, finding better ways to score phrases might prove necessary.',\n",
       " 'Similarly, multi-engine MT (MEMT) systems may be forced to select a poorer translation for one portion of the input after selecting the best translation for another portion. ',\n",
       " \"The limit on target-language overlap may be specified as either an absolute difference in length between source and target overlaps, or as the minimum ratio between the shorter and the longer of the two values (i.e. a value of 0.5 means that a source-overlap of 2 words yields allowable target overlaps between one word [& ¨' ( 0) 21 43 65 ] and four words [( 7' 98 @)\",\n",
       " 'Given a pair of sentences from an unknown source, the algorithm employs a model trained on all data combined (i.e., omits the corpus information), which may resemble the input (On-WN) or it may not (SMT-news). ',\n",
       " 'The overall performance on the MSRvid data is higher than for the other corpora, which may be due to the small number of adjectives and the simpler structure of the shorter sentences within the corpus. ',\n",
       " 'For example, words like \"orange\", \"lemon\", \"apple\" and \"pear\" may often appear together in documents: aggregating them into a new correlated group \"fruits\", creates a new feature.',\n",
       " 'If enough evidence exists in a document from the target domain (i.e. some of the features of the correlated group appear in the document), the feature that corresponds to the correlated group may help the task in the target domain.',\n",
       " 'An electronic dictionary may be an easier resource to find than an ontology or hierarchy, thus our approach may have a small advantage in initial requirements when compared to (Gabrilovich and Markovitch, 2005).',\n",
       " 'In addition, mining correlated groups may be computationally intensive if the feature set from the source domain is large enough (a problem tackled by limiting the source domain feature set to 2000 features, selected through mutual information, as reported in (Zhang and Shakya, 2009)).',\n",
       " 'Trying to match such a test vector to a training one that has the augmented, but also their original related features set to 1, may be misclassified in favour of a vector with less magnitude, and possibly with no related features (both original and augmented) set to one.',\n",
       " 'This result may outline the benefit of using criteria based on multiples hypotheses from different parts of the N -best list, rather than only on the best hypothesis and the most critical one as does the max-margin loss.',\n",
       " 'The lack of specialized data may partially explain these lower results as well as the multiple tuning parameters of CBOW and Skip-gram models.',\n",
       " 'However, our findings may suggest a starting point of applying word embeddings and the multiple proposed variants to specialized domains as well as to other tasks.',\n",
       " 'On the other hand, even if a form has been seen at training time, it might be hard to use it in a relevant way if its frequency is low, which is a common phenomena, since the number of singletons in Romanian and Russian corpora is a lot higher than in English corpora.',\n",
       " 'The reason may be due to the fact that we did not only expect that the CRF would make a better choice than the baseline system regarding word inflection, we also assumed that these morphological predictions would help to make right decisions regarding lexical choices and word order.',\n",
       " 'Thus, in languages with little resources we may be unable to obtain a gold standard and in the case one is available, there is a potentially strong risk of over fitting.',\n",
       " 'As we have seen from the other systems, graph based local measures may be the appropriate answer to reach the level of the best systems on this task, however it is important not to dismiss the potential of other approaches.',\n",
       " \"When re-using the template in a different context it might be necessary to re-generate the word's plural form. \",\n",
       " 'Furthermore, since most automatic systems rely on co-occurrence, rare correspondences go unnoticed, even though they may be relevant for applications such as terminology or lexicography.',\n",
       " 'The text had originally been segmented by the Punkt sentence tokeniser (cf. §3.1.), but this produced some sentences that were very short, which the person acting as the voice talent thought might result in unnatural prosody.',\n",
       " 'The lemma may be \"öl\" (die) for all of these whereas some Turkish dictionaries would contain different entries for them but may be not for another verb which could take similar inflections.',\n",
       " 'When more than one company were mentioned in an article, we sorted the stock return rates of those companies in descending order, then removed those whose absolute value was less than the mean plus one standard deviation, because the stock return rates of such companies may have not been affected by the article.',\n",
       " \"For example, a negative view for some voting event may be expressed using 'flaw', while a negative view for some politician may be expressed using 'reckless'.\",\n",
       " \"For example, the adjective 'unpredictable' may have a negative orientation in an automotive review, in a phrase such as 'unpredictable steering', but it could have a positive orientation in a movie review, in a phrase such as 'unpredictable plot', as mentioned in (Turney, 2002) in the context of his sentiment word detection. \",\n",
       " 'This sort of expression may effectively function as degrading sentences only conveying facts, but may function harmfully by catching sentences conveying opinions without sentiments in the task of sentiment retrieval.',\n",
       " 'If individual processing steps may be greatly accelerated, including e.g. word alignment [1] or system tuning [2], the requirement to process the entire parallel data significantly delays the availability of a trained system.',\n",
       " 'And even though a careful pre-selection of bilingual sentences may greatly reduce the size of the training material [3], this selection is itself time-consuming and is not justified when one only needs to translate a handful of documents or documents from multiple domains. ',\n",
       " 'This result may be related to overfitting issues and suggests to use more sophisticated online adaptation strategies. ',\n",
       " 'However they are far more expensive to compute and rely on the existence of external resources, which may be problematic for some languages.',\n",
       " 'Moreover, objects in S may be unequally relevant, and we might expect the search procedure to treat them accordingly. ',\n",
       " 'We finally believe that this approach might also prove useful in other application domains involving structured data and are willing to experiment with other kinds of data.',\n",
       " \"Even with carefully chosen distractors, models may just be picking up contingent features of the experimental items: Levy et al. (2015b) observe that many hypernym classifiers merely learn to recognize words that are 'typical' hypernyms, independently of the stimulus items (i.e. corresponding hyponyms).\",\n",
       " 'For the lexical access task, the combined model with a mixed span consistenly outperforms both the 2word and 10-word combinations, even though the improvement over the 10-word span is small, showing that our assumptions regarding the complementarity of the two models may not entirely be justified. ',\n",
       " 'Another highly speculative explanation for the better performance of FastText is its use of subword embeddings, which may be sensitive to some rhyming effects that are are known to be present in free associations (Nelson et al., 2004).',\n",
       " 'It is not clear yet whether the better results in this setting are a feature of the embeddings (because the uninflected form might not reflect the typical usage of the lemma in corpora) or of the free association task (because human subjects may have different associations for different inflected forms).',\n",
       " 'Besides the integration of more recent datasets (De Deyne et al., 2018), future work should target more sophisticated methods for the combination of different models, e.g., using machine learning techniques rather than just taking the harmonic mean as in our baseline experiments, and should also explore type-level representations derived from contextualized embeddings. ',\n",
       " 'Some keyphrases may be contained within larger ones, e.g. giant tortoise and Pinta Island giant tortoise.',\n",
       " 'One reason for that may be that the manual score assignments are arbitrary (i.e. 0, 1, 2), and that a score of one is in fact closer to two than to zero.',\n",
       " 'Fig. 8 also suggests that the differences observed in the shortening experiments may well be due to the selection of authors and texts.',\n",
       " 'Furthermore, its success will depend on the density and quality of the alignments (Lacroix et al., 2016b), meaning that it might be more suited to situations in which large bitexts are available.',\n",
       " 'Even though the resulting it:ro bitext is noisier and smaller than the fr:ro one, which could also be used for transferring PoS labels, transfer to Romanian may still be more accurate when using Italian as an additional source, or even as a better source than French. ',\n",
       " 'It may be that word alignments obtained by transfer are less accurate but focus more on general cross-lingual structures which, in turn, enables a better annotation projection, or that these score differences are simply not significant.',\n",
       " 'In future work, we intend to further explore the benefits of language similarity in the RELATED, DI-RECTED BRIDGE and DIALECT scenarios, along two tracks: weighting based on linguistic similarity during the EM training and selective transfer at the sub-model level.',\n",
       " 'At first sight, it might be surprising that neither of the two taggers is able to beat the lookup-based baseline strategy. ',\n",
       " 'Projecting POS information across languages relies on a rather strong assumption that morphosyntactic categories in the source language can be directly related to the categories in the target language, which might not always be warranted (Evans and Levinson, 2009;Broschart, 2009).',\n",
       " 'Our analysis of these results also suggests that, for this task, additional gains might be more easily obtained by fixing systematic biases introduced by conflicting mappings between tags or by train/test domain mismatch than by designing more sophisticated weakly supervised learners.',\n",
       " 'This view might be interpreted at its simplest level as a virtual representation of the guided tours routinely offered in physical CH spaces, and indeed there is a small strand of research into the creation of systems for generating and exploring online exhibitions and tours from items held within digital collections.',\n",
       " 'Guided tours or pathways are essentially more structured, purposeful forms of trails, taking the user through a specific sequence of information nodes and may also be automatically generated, rather than manually curated as in the examples above.',\n",
       " 'Besides being used by our approach to re-rank translations, comparable sentences that contain a term and its translation in corpora are promising, as they may be useful examples to a user or a human translator that needs to verify a translation pair. ',\n",
       " 'In the German language, many compound nouns may be written as single units (e.g. German term \"Produktionsstandort\" is translated into French by \"site de production\").',\n",
       " 'While performing experiments, we have noticed that re-ranking the first 5 translation candidates for each term may increase the top 1 precision more than if we, for example, re-ranked the first 20 translation candidates for each term.',\n",
       " 'Previous work on RBM-based language models do not use a shared word representation and therefore, they might suffer of a lack of generalization for larger contexts.',\n",
       " 'It is our hope that the present work may provide a starting point to cooccurrence prediction on comparable corpora as an alternative to unreliable counts.',\n",
       " 'Using very large input/output vocabularies partially mitigates these issues, yet may cause serious instability (when computing embeddings of rare or unseen words) and complexity issues (when dealing with large softmax layers). ',\n",
       " 'The domain labels group together words from different syntactic categories (e.g. nouns and verbs), and also may group together different senses of the same word and thus reduce polysemy. ',\n",
       " 'This might be explained by considering that items grouped together under the same node will share a number of keywords which link to the same Wikipedia articles which would ensure that the items are very similar.',\n",
       " 'This difference might be explained due to DBpedia containing article entities as well as categories.',\n",
       " \"This may be due to the domain concepts being sometimes quite general and possibly harder for general users to understand (for example one pair of concepts was 'color' and 'factotum').\",\n",
       " ...]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"sentence_certainty\"] <= 3].sentence.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "951c68b1-0b73-4b15-b3f0-2f8af97d19c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First of all, the information in the context vectors is vague.',\n",
       " 'All co-occurrence words are collected without distinguishing whether they are syntactically or semantically related.',\n",
       " 'For the context features, the Cilin semantic classes (a Chinese thesaurus) are adopted.',\n",
       " 'The weight for each level is equal to the information-content of that level [Shannon, 1948;Manning and Schutze 1999]. ',\n",
       " 'We have compared the clustering results to the Cilin classifications.',\n",
       " 'However, such an ideal corpus does not exist.',\n",
       " 'Since the similarity measure based on the vector space model is a rough estimation, minor errors made at the stage of context vector extraction are acceptable.',\n",
       " 'However, the semantic label is not provided for each word in the parsed trees.',\n",
       " 'There are five levels in the Cilin semantic hierarchy, denoted in the format L 1',\n",
       " 'In level 1, \"A\", denotes the semantic class of human; in level 2, \"a\", indicates a group of general terms; level 3, \"02\", means pronouns in the first person, and in level 4, \"2\" represents the plural property.',\n",
       " 'In level 5, \"01\" represents the order rank in the level 4 group.',\n",
       " 'This means that \"01\" in level 5 is the first prototypical concept representation of \"A-a-02-2\".',\n",
       " 'The sense tagging algorithm is based on the facts that the syntactic categories of each word in the tree bank are assigned uniquely, and that each Cilin class has its own major syntactic category.',\n",
       " \"<Cilin> <word1>), (<Thematic role> <Cilin> <word2>) (agent B -i-07-2 狗'dog'), (Head(S) H-h-04-2 跳舞'dance' )\",\n",
       " \"(property E -a-03-3 小'small'), (Head(NP) B -i-07-2 狗'dog') \",\n",
       " 'The context data of the word 1 狗 \"dog\" consists of its thematic role \"agent\" and the Cilin class \"B-i-07-2\" ; the word 2 跳舞 \\'dance\\' consists the thematic role \"Head(S)\" and the Cilin class \"H-h-04-2\" and so on.',\n",
       " 'The word 小 \"small\" and 跳舞 \"dance\" are not syntactically related even though they co-occur.',\n",
       " 'Therefore , they will not be extracted.',\n",
       " 'The role vector is a fixed 48-dimension vector, and each dimension value is equal to the probabilistic distribution of its thematic roles.',\n",
       " 'The cosine distance between their context vectors is a measure of the similarity of the two words.',\n",
       " 'The role vector of \"dog\" is {127, 207, 169… , 0} 48 , which represents the values of \"agent\", \"goal\", \"theme\"… and \"topic\" respectively, generated by Equation (1).',\n",
       " 'The role vector of \"cat\" is {28, 73, 56… , 0} 48 , which is also acquired by Equation (1).',\n",
       " 'Frequency (R i ):',\n",
       " 'The frequency of R i played by word W in the corpus. ',\n",
       " 'P i : = Total frequency of R i in the corpus / Total frequency of all roles in the corpus. log(1/P i ):',\n",
       " 'IDF(word j ) if word X has the same neighbor word j with word Y TF(word j ) if word X does not have the same neighbor word j with word Y } ; for every left co-occurrence word j with the ith Cilin semantic class. ',\n",
       " '(2) TF(word j ): the frequency of pair ( word j , Cilin(word j ) )',\n",
       " 'IDF(word j ): -log(the number of the documents that contains the word j /total document number of the corpus) ',\n",
       " \"IDF(養'raise') 2 , … , TF(La064) } L4 1 IDF(養'raise')\",\n",
       " 'The four left context vectors and their dimensions are shown below and the right context vectors are similarly derived.',\n",
       " '<LeftCilin1>',\n",
       " '<LeftCilin3>',\n",
       " '<LeftCilin4>',\n",
       " 'LeftCilin4 < x, > LeftCilin4 (< cos w41 { w4 y)} > 3 RightCilin < x, > 3 RightCilin (< cos w32 + y) >',\n",
       " 'LeftCilin3 <',\n",
       " 'LeftCilin2 <',\n",
       " 'LeftCilin1 <',\n",
       " ', x > LeftCilin1 (< cos w11 { 1 y) >',\n",
       " 'First of all, we produced a 1000 × 1000 symmetric similarity matrix called SMatrix, where SMatrix (x, y) = similarity   4 3 2 1 4 , 3 , 2 , 1 K RightCilin K n RighttCili K LeftCilin x K LeftCilin K RightCilin x K RightCilin K RightCilin K n RighttCili K LeftCilin x K LeftCilin K LeftCilin x K LeftCilin 2 1 > < = + + + + = > <',\n",
       " '= = p n m m p n n q 1 word contains ) wordj ( Group m 1 word )contains wordx ( Group x j 0 ) word , (word similarity [x] SMatrix[j] , q , p 1 q p 1 q ≤ ≤ ≤ ≤ < < ×',\n",
       " 'With the threshold=0.7, our method clustered 830 words, and only 167 words of them were clustered in the correct Cilin class.',\n",
       " 'The results are shown in Figure 3 to Figure 6 in the Appendix.',\n",
       " 'We discovered that the best F-score of level1 was that 0.7648 located at a threshold equal to 0.65, the best F-score of level2 was that 0.5178 located at a threshold equal to 0.7, the best F-score of level3 was that 0.3165 located at a threshold equal to 0.8, and that the best F-score of level4 was that 0.2476 located at a the threshold equal to 0.8.',\n",
       " 'We list the detailed F-socre data for various parameters in appendix.',\n",
       " 'For each semantic class, the average similarity between words in the class and their standard deviation was comp uted.',\n",
       " 'The results are listed in Table1 in the Appendix.',\n",
       " 'As a result, the average similarity value was quite low, and the standard deviation was very high.',\n",
       " 'For example, when we measured the similarity of 美國 \"America\" to 日本 \"Japan\" and to 中國 \"China\", the results we obtained were 0.86 and 0.62,respectively, for each pair.',\n",
       " 'As a result, the usage of 中國 \"China\" is different from that of 美國 \"America\" and 日本 \"Japan\". d)',\n",
       " 'The word senses that Cilin adopted were not those frequently used in the corpus.',\n",
       " 'For example, the similarity value of 結婚 \"marry\" and 長大 \"grow\" is 0.8139.',\n",
       " 'Although the two words have similar contexts, they are not alike in meaning.',\n",
       " 'c) Syntactic and semantic similarity is balanced by using related syntactic contexts only. ',\n",
       " 'However, our experimental results are encouraging.',\n",
       " 'Thread disentanglement is the task of separating out conversations whose thread structure is implicit, distorted, or lost.',\n",
       " 'We show that i) content text similarity metrics outperform style and structure text similarity metrics in both a class-balanced and class-imbalanced setting, and ii) although feature performance is dependent on the semantic similarity of the corpus, content features are still effective even when controlling for semantic similarity.',\n",
       " 'We have found that content-based text similarity metrics outperform a Dice baseline, and that structural and style text similarity features do not; adding these latter feature groups does not significantly improve total performance.',\n",
       " 'However, to the best of our knowledge, no work has investigated reassembling email threads without the help of MIME headers or quoted previous emails. ',\n",
       " 'However, the precise definition of an email thread actually depends on the implementation that we, or any other researchers, used to identify the thread.',\n",
       " '(2005) auto-threaded all messages with identical, non-trivial, Fwd: and Re:-stripped Subject headers.',\n",
       " 'Klimt and Yang (2004) auto-threaded messages that had stripped Subject headers and were among the same users (addresses).',\n",
       " 'As the emails in the EEC do not contain any inherent thread structure, it was necessary for us to create email threads.',\n",
       " 'To determine whether emails were among the same users, we split a Subject-created email proto-thread apart into any necessary threads, such that the split threads had no senders or recipients (including To, CC, and BCC) in common. ',\n",
       " 'Such clusters of \"broadcast\" emails do not satisfy our goal of identifying email discussions between users. ',\n",
       " 'A singleannotator hand-investigation of 465 previously quoted emails from 20 threads showed that none of them had interspersed comments or had otherwise been altered by more recent thread contributors.',\n",
       " 'Threads in the EEC are quoted multiple times at various points in the conversation in multiple surviving emails.',\n",
       " 'Our pairwise classification experiments, described in Section 4, are unaffected by this reduced recall, because each experimental instance includes only a pair of emails, and not the entire thread. ',\n",
       " 'The sizes of email threads in the Enron Threads Corpus is shown in Table 2.',\n",
       " 'Emails have an average of 80.0±201.2 tokens, and an average count of 4.4±9.3 sentences.',\n",
       " 'In our experiments, all features are derived from the body of the email, while all headers such as Recipients, Subject, and Timestamp are ignored. ',\n",
       " 'A pair of emails with a high content overlap is shown below. ',\n",
       " \"Sets of ngrams from the two emails are compared using the Jaccard coefficient (from Lyon et al. (2004)) and Broder's (1997) Containment measure. \",\n",
       " \"We measured the stopword n-gram overlap with Broder's (1997) Containment measure and four different stopword lists.\",\n",
       " 'Token Pair Order (Hatzivassiloglou et al. 1999) uses pairs of words occurring in the same order for the two emails; Token Pair Distance (Hatzivassiloglou et al., 1999) measures the distance between pairs of words.',\n",
       " 'However, as this measure is sensitive to differences in document length between the pair of documents (documents become less lexically diverse as length and token count increases but type count levels off), and fluctuating lexical diversity as rhetorical strategies shift within a single document, we also used Sequential TTR (McCarthy and Jarvis, 2010), which corrects for these problems.',\n",
       " \"Function Word Frequencies is a Pearson's correlation between feature vectors of the frequencies of 70 pre-identified function words from Mosteller and Wallace (1964) across the two emails.\",\n",
       " 'We also compute Case Combined Ratio, showing the percentage of UPPERCASE characters in both emails combined ( U P P ERCASE e1 +U P P ERCASE e2 ALLCHARS e1 +ALLCHARS e2 ), and Case Document similarity, showing the similarity between the percentage of UPPERCASE characters in one email versus the other email.',\n",
       " 'The 10 folds contained carefully distributed email pairs such that email pairs with emails from the same thread were never used in pairs of training, development, and testing sets, to avoid information leakage.',\n",
       " 'Although we had 413,814 positive instances available in the Enron Threads Corpus, we found that classifier performance was unaffected by the amount of training data, down to very low levels (see Figure 1).',\n",
       " 'For every positive instance we used, we created a negative email pair by taking the first email from the positive pair and pseudo-randomly pairing it with another email from a different thread that was assigned to the same training, development, or test set. ',\n",
       " 'However, the probability of semantic similarity between two emails in a positive instance is much greater than the probability of semantic similarity between two emails in a randomly-created negative instance.',\n",
       " 'For each positive instance, we measured the semantic similarity within the email pair using Cosine Similarity and then created a negative instance with the same (±.005) similarity.',\n",
       " 'Emails had an average of 96±287 tokens and 5±11sentences, and a similar token size distribution as SB. ',\n",
       " 'No minimum email length was used, similar to a more natural distribution.',\n",
       " 'Our results are shown in Table 3.',\n",
       " 'Feature groups are shown in isolation as well as the complete set of features minus one group.',\n",
       " 'The benefit of content features is confirmed by the reductions in complete feature set performance when they are left out.',\n",
       " 'The content features group was the only group to perform significantly above the Dice baseline.',\n",
       " 'Adding the other feature groups does not significantly improve the overall results.',\n",
       " 'Further leave-one-out experiments revealed no single high performing feature within the content features group. ',\n",
       " 'The low results on structural features show that we are not relying on such artifacts for classification. ',\n",
       " 'Style features were also unhelpful, failing to significantly beat the Dice baseline.',\n",
       " 'The features failed to identify communication accomodation within the thread. ',\n",
       " 'Results on the SB dataset show that there is a noticeable drop in classification for all feature groups when negative instances have a similar semantic similarity as positive instances.',\n",
       " 'However, content features continues to be the best performing feature group with semantically similar negative instances, as with random negative instances, and outperformed the Dice baseline.',\n",
       " 'Adding the additional feature groups does not significantly improve overall performance. ',\n",
       " 'Some email thread relations cannot be detected with text similarity metrics, and require extensive discourse knowledge, such as the emails below. ',\n",
       " 'Several other problems in email thread disentanglement cannot be solved with any discourse knowledge.',\n",
       " 'One problem is that some emails are identical or near-identical; there is no way to choose between textually identical emails.',\n",
       " 'Finally, our classifier cannot out-perform humans on the same task, so it is important to note human limitations in email disentanglement.',\n",
       " 'Our human upper bound is shown in Table 3.',\n",
       " 'Linguistic features included an appearance of consecutivity (emails appear in a Q/A relation, or one is informative and one is \\'please print\\', etc.), similarity of social style (\"Language vocab level, professionalism, and social address are a reasonable match\"), and the annotator\\'s perception that the emails could be from the same thread. ',\n",
       " 'Large text errors (such as 2 emails labelled as one) occurred in only 1% of emails and were too rare to correlate with results. ',\n",
       " 'Email1: i do',\n",
       " 'The level of professionalism (\"Language vocab level, professionalism, and social address are a reasonable match\") was also notable between class categories.',\n",
       " 'A set of semantic relations, including some thematic relations, has been determined for the need of experiments.',\n",
       " 'The method consists in two steps: first the system recognizes word pairs and triples, and then it classifies the relations.',\n",
       " 'The authors used Support Vector Machines classifier and a very rich set of features (i.e., part of speech for all constituents of a semantic relation pair, number of words between the nominals, features based on paths in the dependency tree from Stanford dependency parser).',\n",
       " \"przez Jana θ '(man) educated by John θ ', wyj ący wilk θ 'howling wolf θ '.\",\n",
       " \"Proto-Patient θ is the second macrorole -it is an entity undergoing action, event or change of state caused by another participant; for predicates denoting relations -it is the second element of a given relation: wykształcenie kogoś θ 'educating someone θ ', (Jan) posiadaj ący maj ątek θ '(John) possessing an estate θ '.\",\n",
       " 'According to (Dowty, 1991) 2',\n",
       " \"'speared with a spear', lina θ cumownicza adjective 'a hawser, lit.\",\n",
       " \"Material θ is an entity that is used by someone to produce something from it, material undergoes change of state resulting in its disappearance and emerging of a result: zrobiony z mosi ądzu θ 'made out of brass θ ', mosiężna θ figurka 'brass θ statuette'. \",\n",
       " \"Purpose θ -an entity or a situation toward which the event is directed or an individual which benefits from the event (purpose combines goal, beneficiary and recipient roles): wręczenie (medali) olimpijczykom 'giving (medals) to Olympians θ , sala koncertowa θ\",\n",
       " \"Location is a physical place at which a given event is localised, a place being destination of an event, a path or a source of motion, or simply a place at which a particular individual is situated: wręczenie (medali) w auli 'giving (medals) at the lecture theatre ', przedzieranie się przez moczary 'struggling through the swamp '. \",\n",
       " 'Time is a particular moment or a duration of an event -it localises a situation within the flow of events or gives its duration: przedzieranie się przez godzinę /w',\n",
       " \"Temporal/spatial meronymy -these relations point onto a spatial or temporal part of a place/location/time/period): poniedziałkowy poranek 'Monday morning ', środek zimy 'middle of the winter', koniec drogi 'end of the road', stolica kraju 'capital of the country'. \",\n",
       " \"Family (member) is a relative or an in-law to someone, the relation is bidirectional and reflexive: syn króla 'king's son ', moja żona 'my wife ' (I am a relative to my wife). \",\n",
       " \"Order gives a position of an entity or an event in an ordered sequence/chain: druga odpowiedź '2nd answer', lata 80 .\",\n",
       " \"Quantity is an amount of something or a cardinality of a given set: pięciu panów 'five men', kieliszek wina 'glass of wine'.\",\n",
       " 'Since we consider relations within noun phrases, we must identify them correctly.',\n",
       " 'We made use of a CRF shallow parser (Radziszewski and Pawlaczek, 2012) trained on an annotated corpus of Polish (KPWr) (Broda et al., 2012) which comprises shallow syntactic annotation level (Radziszewski et al., 2012).',\n",
       " 'KPWr contains 326 annotated text samples representing different genres and styles: blogs, press articles, official and legal texts and Polish Wikipedia articles, it comprises 106358 annotations (phrases and phrase heads, and predicateargument relations). ',\n",
       " 'Here is an example NP from the corpus (a head of the phrase is boldfaced, AgP heads are underlined): [[samolot wyprodukowany] AgP',\n",
       " '[przez PZL] AgP',\n",
       " '[w Łodzi] AgP ] N P',\n",
       " 'one superordinate token, the triples comprise one superordinate token and a subordinate preposition phrase (preposition + governed nominal head of a subordinate noun phrase). ',\n",
       " 'We start from the first AgP 0 head to the left, then we proceed to the right, jumping from AgP',\n",
       " 'i head to the closest AgP i+1 head to the right.',\n",
       " 'The algorithm in pseudocode was shown in Algorithm 1 The algorithm gives following description for just analysed phrase, \"R + number\" denotes the number of a rule in the Algorithm 1 activated on the word pair or triple (for instance, R3 means that the rule number 3 was activated):',\n",
       " 'Having identified pairs and triples we run on them operators written in a constraint language WCCL (Radziszewski et al., 2011).',\n",
       " 'If an operator is successfully applied to a pair (or a For example, our Proto-Patient relation was described by the 6 WCCL operators.',\n",
       " 'One of them is presented in Listing 1.',\n",
       " 'This operator uses two dictionaries with valence frames (acc -a list of verbs possessing any accusative frame, frames -a list of verbs described in the Polish valence dictionary (Dębowski, 2013)) and morphosyntactic information about part of speech (class) and case. ',\n",
       " \"This operator PROTO-PATIENT-acc captures pairs like dręcz ący pact Janka noun.acc−θ 'tormenting John θ ' with a noun playing a Proto-Patient role of the predicate dręcz ący.\",\n",
       " 'The operator first checks whether a predicate (active participle) has an accusative frame or is outside the dictionary of Dębowski (\"frames\").',\n",
       " \"The PROTO-AGENT-ger-przez-acc operator is written for triples, i.e., for a triple wydanie pact przez pron wydawcę noun.acc−θ 'publishing by the publisher θ '.\",\n",
       " \"The first element in the triple is a gerund form of verb wydać 'to publish'.\",\n",
       " \"The operator checks whether the verb wydać has in its frame accusative/genetive or whether it cannot be found in Dębowski's dictionary (position 0 in the triple, frames). \",\n",
       " 'Listing 1: One of the WCCL operators describing Proto-Patient relation.',\n",
       " \"Next the operator seeks for the preposition przez 'by' at position 1.\",\n",
       " \"Then it tests if the first meaning of the lemma wydawca 'publisher' does not belong to the domain 'time' (= Polish czas) in Polish WordNet (position 2).\",\n",
       " \"Indeed, the first meaning of wydawca is in the domain 'person' (that iformation is avaiable in the dictionary noun_domain).\",\n",
       " 'In Listing 3 one operator for family ralation was shown.',\n",
       " \"The operator, inter alia, uses semantic dictionary of kinship names built on the basis of Polish WordNet (the dictionary kinship), lammas of possessive pronouns (e.g., mój 'my', twój 'yours'). \",\n",
       " 'Listing 3: Two WCCL operators describing Family relation @b:\"FAMILY-agpp\" ( and( // agreement agrpp(0,1, {nmb, gen, cas}), // position 0 in(base[0], [\"moj\", \"twoj\", \"swoj\", \"nasz\", \"wasz\"]) // position 1 equal(lex(base[1], \"kinship\"), [\"1\"]), equal(lex( base[1], \"noun_domain\"), [\"os\"]), in(class[1], {ger, subst, depr}), ) )',\n",
       " 'Evaluation of the presented semantic relation recognition algorithm was performed in three steps.',\n",
       " 'Evaluation in the experiments was done by a professional linguist. ',\n",
       " 'Percentile bootstrap methods (DiCiccio and Efron, 1996), (DiCiccio and Romano, 1988) were applied to statistical significance and confidence interval (CI) analysis of the data.',\n",
       " 'We took 10000 bootstrap resamplings for each measure (P, R, F1), α was equal to 0.05 for each one-tailed test and CI (a percentile CI need not be symmetrical). ',\n",
       " 'Our system is thus comparable in this aspect to the systems described in Sec.',\n",
       " 'not avaiable. ',\n",
       " 'Given two sentence-aligned corpus files, the NA-Tools word aligner -based on the Twenty-One system (Hiemstra, 1998)-counts the co-occurrences of words in all aligned sentence pairs and builds a sparse matrix of word-to-word probabilities (Model A) using an iterative expectation-maximization algorithm (5 iterations by default).',\n",
       " 'Exact match LIHLA creates a 1 : 1 alignment between s j and t',\n",
       " 'j -the best candidate word according to B S among those in a position which is favorably situated in relation to s j -and looks for multiword units involving s j and t',\n",
       " 'The LCSR of two words is computed by dividing the length of their longest common subsequence by the length of the longer word.',\n",
       " 'For example, the LCSR of Portuguese word alinhamento and Spanish word alineamiento is 10 12 0.83 as their longest common subsequence is a-l-i-n-a-m-e-n-t-o. t',\n",
       " 'i (for target multiword units) and are not possible translations for other words in T and S, respectively.',\n",
       " 'If no possible translation for s j is found in the bilingual lexicon and the target sentence (T ) at the same time, LIHLA uses the LCSR to look for cognates for s j in T and sets a 1 : 1 alignment between s j and its best cognate or a 1 : 0 alignment if there is no cognate available. ',\n",
       " 'In its last step (which is optional and has not been performed in the experiments described in this paper), LIHLA aligns the remaining unaligned source and target tokens between two pairs of already aligned tokens establishing several 1 : 1 alignments when there are the same number of source and target tokens, or just one alignment involving all source and target tokens if they exist in different quantities.',\n",
       " 'The training sets -composed of 338,343 English-Inuktitut aligned sentences (omission cases were excluded from the whole set of 340,526 pairs) and 48,478 Romanian-English aligned ones-were used to build the bilingual lexicons. ',\n",
       " 'Then, without changing any default parameter (threshold for LCSR, maximum number of iterations, etc.), LIHLA aligned the 75 English-Inuktitut and the 203 Romanian-English parallel sentences on test sets.',\n",
       " 'The whole alignment process (bilingual lexicon generation and alignment itself) did not take more than 17 minutes for English-Inuktitut (3 iterations per sentence, on average) and 7 minutes for Romanian-English (4 iterations per sentence, on average). ',\n",
       " 'The evaluation was run with respect to precision, recall, F -measure, and alignment error rate (AER) considering sure and probable alignments but not NULL ones (Mihalcea and Pedersen, 2003).',\n",
       " 'Tables 1 and 2 present metric values for English-Inuktitut and Romanian-English alignments, respectively, as provided by the organization of the shared task.',\n",
       " 'This indicates that evaluating alignment systems is not a simple task since their performance depends not only on the language pairs and the quality of parallel corpora (constant criteria in this shared task) but also the way the reference corpus is built. ',\n",
       " 'Then, the only conclusion that can be taken at this moment is that LIHLA, with its heuristics and/or default parameters, can not be indistinctly applied to any pair of languages. ',\n",
       " 'Despite of its performance, LIHLA has some advantages when compared to other lexical alignment methods found in the literature, such as: it does not need to be trained for a new pair of languages (as in Och and Ney (2000)) and neither does it require pre-processing steps to handle texts (as in Gómez Guinovart and Sacau Fontenla ( 2004)).',\n",
       " 'Final root extraction accuracy of 87.2% is achieved.',\n",
       " 'In contrast to previous work on unsupervised learning of Arabic morphology, our approach is applicable to naturally-written, unvowelled Arabic text.',\n",
       " 'However, another type of word formation consists of the interdigitation of a root morpheme with an affix or pattern template; in this case there is no boundary between morphemes, since they are rather intercalated with each other.',\n",
       " \"Their work shows comparable performance to Goldsmith's (2000) Linguistica system.\",\n",
       " 'The second (ii) is affixation, by means of prefixes, suffixes or infixes, including inflectional morphemes marking gender, plurality and/or tense, resulting in a stem.',\n",
       " \"The 'y' and 't' in the respective words are clitic/inflectional markers, which are part of the affix template.\",\n",
       " \"'A' is the derivational infix marker for nouns.\",\n",
       " 'Unlike for supervised learning, no annotated text is used.',\n",
       " \"The final set of these features for the word 'yErf' is shown in the first column of Table 2. \",\n",
       " 'These inverse features are shown in the second column of Table 2.',\n",
       " 'Table 3 shows an example of the closest neighbours in a cluster, along with their headword.',\n",
       " 'Each pattern is scored with a function ܵ( \\u202b\\u202c ௫ ) (equation 2) which aggregates the Logarithmically Scaled ( \\u202bܵܮ\\u202c ) probability value, ܲ of words k j (j = 1,2,…500 words in each cluster), such that \\u202bݎ\\u202c ௫ matches any of the roots in word k, \\u202bݎ\\u202c ௬ (y=1,2,…m root combinations in k).',\n",
       " 'This aggregation is not only local to each cluster but covers all occurrences of the pattern in each of the N clusters.',\n",
       " '௫ ) = ቀ\\u202bܵܮ\\u202c൫ܲ ൯× \\u202b|(ܣܮ\\u202c ௫ |)ቚ \\u202bݎ\\u202c ௫ = \\u202bݎ\\u202c ௬ ቁ ହ ୀଵ ே ୀଵ (Eq. 2) Logarithmic scaling is necessary since the probability drops too rapidly and too low in order to provide a feasible ratio between words.',\n",
       " 'The score is also exponentially Length Adjusted \\u202b)ܣܮ(\\u202c for each pattern, \\u202b,\\u202c according to the length of the pattern, \\u202b,||\\u202c in terms of the number of affix charaters in \\u202b.\\u202c',\n",
       " 'Thus the pattern is scored according to the score of words containing plausible roots.',\n",
       " \"Table 4 shows how each pattern for the headword 'yErf' is scored, aggregating the logarithmic score over words (in column 4 of Similarly, we score the root, ܵ( \\u202bݎ\\u202c ௫ ), with respect to the pattern occurrence in each word k of cluster\",\n",
       " 'There is no need for length adjustment to these ratios since we are considering only three letter roots.',\n",
       " 'Word Table 6 shows the top lexicon entries for roots and patterns along with their respective scores.',\n",
       " 'Such words with hollow roots or reduplicated radicals, whose characters do not match every radical of the root, were removed from the evaluation as they are beyond the scope of the learning algorithm to identify.',\n",
       " 'Likewise, the root score was obtained by counting the number of words with corresponding patterns. ',\n",
       " 'In the baseline we do not have the ME based word clusters with proximities to the target word; only one cluster exist: the vocabulary set with unit promitiy of 1.',\n",
       " 'The accuracy is measured in terms of percentage of the roots that are correctly identified. ',\n",
       " 'The results for the different configuration evaluations is given in table 7.',\n",
       " 'The finalized procedure offers significant boost in performance. ',\n",
       " 'In contrast to single words, the distribution of phrases cannot be used as a reliable approximation of their meaning, as phrase vectors are much sparser.',\n",
       " 'Another challenge is that some expressions cannot be unambiguously classified as either correct or incorrect, as their interpretation depends on the context of use: best moment (2d) is appropriate when used to denote a short period of time, but it is often incorrectly used by learners instead of best time. ',\n",
       " 'In the former case error detection, which is a difficult task in itself, is not addressed, while in the latter case it is integrated into that of suggesting alternatives according to some metric (for example, frequency or mutual information).',\n",
       " \"If c is a word combination vector and a and b are word vectors, then c's i-th component is the sum of the i-th components of a and b for the add model: \",\n",
       " 'b i (1) and the product of the corresponding components for the mult model: ',\n",
       " 'In addition, the add model does not take \"incompatibility\" of constituent vectors along individual dimensions into account.',\n",
       " 'This problem does not arise with the mult model.',\n",
       " 'The meaning of the adjective new is defined through its application to the denotations of the nouns.',\n",
       " 'The composition is defined by matrix-by-vector multiplication as follows: f (noun) = def F × a = b (3) where F is the matrix representing an adjective and encoding function f, which maps the input noun vector a to the output AN vector b.',\n",
       " 'The ij-th cell of the matrix contains the weight determining how much the component corresponding to the jth context element in the noun vector contributes to the value assigned to the i-th context element in the AN vector (Baroni et al., 2012).',\n",
       " '3 Experimental Setup',\n",
       " 'It also includes ANs occurring in the BNC 4 -3294 of the correct test ANs and 256 of the incorrect ones are corpus-attested.',\n",
       " 'The semantic space is represented by a matrix encoding word co-occurrences, with the rows representing the target elements and the columns representing a set of 10K context words consisting of 6,590 nouns, 1,550 adjectives and 1,860 verbs most frequent in the combined corpus.',\n",
       " 'The ijth cell of the original matrix contains a sentenceinternal co-occurrence count of the i-th target element with the j-th context word.',\n",
       " 'but We perform all operations on vectors in the full semantic space, using a 76,053 × 10K matrix.',\n",
       " 'For the add and mult models, the AN vectors are obtained by component-wise addition and multiplication without normalisation.',\n",
       " 'This model is computationally expensive since a separate weight matrix must be learned for each adjective and since we use the non-reduced semantic space.',\n",
       " 'We have gradually changed this number from 3 to 20 depending on the adjective and the number of available training pairs with the aim of keeping the independentvariable-to-training-item ratio stable.',\n",
       " 'In Tables 1 to 3 we report p values estimating statistical significance at the 0.05 level, and statistical significance is marked with an asterisk ( * ). ',\n",
       " 'We report the results on the full set of test ANs, as well as on each of the two subgroups separately. ',\n",
       " 'Of the three composition models, the mult model (Table 2) shows the best results overall. ',\n",
       " 'The alm model (Table 3) shows statistically significant difference between the model-generated vectors for the correct and incorrect combinations with the cosines and component overlap, but it does not detect the difference on the corpusunattested subset with any of the metrics. ',\n",
       " 'The add model (Table 1) shows statistically significant differences only with the cosine measures on the corpus-unattested subset.',\n",
       " 'In contrast to the results reported by Vecchi et al. (2011) With COver, the alm model, followed by the mult model, produce sensible results.',\n",
       " 'Table 4 shows the top 3 nearest neighbours found by the models for the correct AN bad intention and the incorrect * bad information.',\n",
       " 'Note that only the alm model is able to discriminate between the correct and the incorrect word combinations suggesting sensible nearest neighbours for bad intention and less sensible ones for *bad information.',\n",
       " 'All results presented were generated by using a statistical machine translation system which implements a log-linear combination of feature functions along with a bilingual n-gram translation model.',\n",
       " 'This translation model was developed by de Gispert and Mariño (2002), and it differs from the well known phrase-based translation model in two basic issues: first, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies.',\n",
       " 'Two important issues regarding this translation model must be mentioned.',\n",
       " 'First, when extracting tuples, some words always appear embedded into tuples containing two or more words, so no translation probability for an independent occurrence of such words exists.',\n",
       " 'This cannot be allowed since no NULL is expected to occur in a translation input.',\n",
       " 'This section describes the procedure followed for preprocessing the data, training the models and optimizing the translation system parameters.',\n",
       " 'However, no significant reduction was produced. ',\n",
       " 'In the case of French, a re-tokenizing procedure was performed in which all apostrophes appearing alone were attached to their corresponding words.',\n",
       " 'Once the training data was preprocessed, a wordto-word alignment was performed in both directions, source-to-target and target-to-source, by using GIZA++ (Och and Ney, 2000).',\n",
       " 'The same pruning parameter, which was actually estimated for Spanish-English, was used for the other three language pairs.',\n",
       " 'Table 1 presents the total number of running words, distinct tokens and tuples, for each of the four training data sets.',\n",
       " 'This feature actually consisted of a word 3-gram model, which was trained from the target side of the bilingual corpus by using the SRI Language Modeling toolkit. ',\n",
       " 'More specifically, the penalization factor was given by the total number of words contained in the translation hypothesis. ',\n",
       " \"For all the results presented in this work the decoder's monotonic search modality was used. \",\n",
       " 'Table 2 presents the BLEU scores obtained for the shared task test data.',\n",
       " 'es -en fr -en de -en fi -en',\n",
       " 'A big difference is observed between the best and the worst results. ',\n",
       " 'It is evident from these translation outputs that translation quality decreases when moving from Spanish and French to German and Finnish.',\n",
       " 'Table 3 presents the results for both the full system and the baseline.',\n",
       " '1   Table 3: Baseline-and full-system BLEU scores (computed over development sets).',\n",
       " 'language pair baseline full es -en 0.2588 0.3004 fr -en 0.2547 0.2938 de -en 0.1844 0.2350 fi -en 0.1526 0.1989 From Table 3, it is evident that the four additional feature functions produce important improvements in translation quality.',\n",
       " 'As can be concluded from the presented results, performance of the translation system used is much better for French and Spanish than for German and Finnish.',\n",
       " 'It is also evident that the bilingual n-gram model used requires the additional feature functions to produce better translations.',\n",
       " 'Dependency parsing assigns every word to another word or NIL as its regent and the resulting edges are annotated with a label.',\n",
       " 'Tn this case, the analysis includes the information that the regent of \"red\" is the object of \"drives\", which is missing in the analysis using minimal prediction.',\n",
       " 'The key difference between non-incremental and incremental parsing is the uncertainty about the continuation of the sentence.',\n",
       " 'If a prediction about upcoming structure is being made, there is no guarantee that this prediction will be accurate.',\n",
       " 'In contrast to beam search, only a single analysis is generated for each prefix and there is no guarantee that the analysis of a prefix p n is a monotonic extension of p n−1 .',\n",
       " 'Because the analysis of p n−1 is only used to initialize the transformation process, the search space is not restricted by the results that were obtained in former prefixes although they still guide the analysis.',\n",
       " 'In the WCDG formalism, the best analysis of a sentence is defined by ba = arg max a∈Analyses c∈Conflicts(a)',\n",
       " 'where the conflicts are the parts of an analysis that stand in conflict with the grammar and penalty(c) is the penalty that the grammar assigns to the conflict c.',\n",
       " 'Frobbing consists of two phases: first, the problem is initialized.',\n",
       " 'In this phase, all possible edges are constructed and the constraints defined for a single edge are evaluated on them.',\n",
       " 'The new word is added to the previous analysis using the best edge.',\n",
       " 'The frobbing algorithm is then run until no better result can be found or the parser is interrupted.',\n",
       " 'This way, all changes regarding incrementality are completely transparent to the frobbing algorithm, only the constraints in the grammar need to be aware of virtual nodes and nonspec.',\n",
       " 'However, since the PoS tags are needed and a PoS tagger needs lookahead as well to achieve good accuracy, a lookahead of at least three words is needed for the whole taggerparser pipeline to achieve a high accuracy.',\n",
       " 'In addition, MaltParser is not capable of producing structural predictions.',\n",
       " 'Table 1 shows the time needed to construct new edges and judge them while parsing a subset of the NEGRA corpus (Brants et al., 2003).',\n",
       " 'More than sixteen cores yield no further improvement. ',\n",
       " 'Since these transformations all work independently, they have been parallelized in the same manner as the initialization.',\n",
       " 'While the introduction of parallelized code causes a small overhead, using two cores already provides a noticeable benefit.',\n",
       " 'These optimizations have a noticeable impact on parsing performance under time pressure: With a time limit of two seconds per word, jwcdg base scores an unlabeled accuracy of 72.54% for the final analyses, while jwcdg parallel scores 76.29%.',\n",
       " 'Unless otherwise noted, all evaluations have been carried out on sentences 18602 to 19601 of the NEGRA corpus.',\n",
       " 'The parser works monotonically since edges are only added to but never removed from the set of edges.',\n",
       " \"Each time a new word w is pushed to jwcdg, MaltPredictor forwards w together with its PoS-tag onto MaltParsers input queue and runs MaltParser's algorithm until a shift operations occurs.\",\n",
       " 'With this shift operation, w is consumed from the input queue.',\n",
       " 'MaltPredictor then reads the state of MaltParser and stores for each word the regent it has been assigned to by Malt-Parser.',\n",
       " 'If Maltparser did not assign a regent to a word, this fact is also stored.',\n",
       " 'Since -as already mentioned -MaltParser works eagerly (i. e. constructs every edge as soon as possible), the regent of such a word must either lie in the future or be the root node. ',\n",
       " \"The three constraints that are used for accessing MaltParser's analyses are depicted as pseudocode in Figure 3.\",\n",
       " 'The first two constraints are only applicable if MaltPredictor has made a prediction for the word in question.',\n",
       " \"The first constraint checks whether prediction_exists(word) -> regent_of(word) = predicted_regent(word) prediction_exists(word) -> label_of(word) = predicted_label(word) not prediction_exists(word) -> (regent(word) is virtual or regent(word) is nonspec or regent(word) is NIL or word is virtual) Figure 3: Constraints for incorporating Malt-Parser's results into jwcdg the regent of a word is the one that has been selected by MaltParser.\",\n",
       " 'The second constraint checks that the predicted label matches the label of the edge in the analysis given that a label has been predicted.',\n",
       " 'When the input sentence is going to be extended, the new word is attached using the edge that violates the least unary, non context-sensitive constraints.',\n",
       " 'To compare MaltParser and jwcdg, the richer prediction of jwcdg has to be transformed into minimal prediction.',\n",
       " 'The two accuracies that are used for evaluation are initial attachment accuracy (how often is the newest word attached correctly?)',\n",
       " 'and the final accuracy (how many attachments are correct in the parse trees for the whole sentences?). ',\n",
       " 'Figure 4 shows the accuracy for initial attachment and final accuracy as a function of a given time limit.',\n",
       " 'Since MaltParser does not use an anytime algorithm, its results are the same for all time limits 4 .',\n",
       " \"When ignoring labels, Maltparser's initial attachment accuracy is higher than its final accuracy since it does not change edges it has created (therefore the accuracy cannot rise) and words can be counted as correct initially but wrong in the final analysis: If the correct regent of a word lies somewhere in the future, the initial decision to not attach it is counted as correct.\",\n",
       " 'The only exception is the unlabeled attachment score for the initial attachment.',\n",
       " 'Figure 6 shows the accuracy of the different parser versions on this corpus.',\n",
       " 'In addition to that, the result does not improve much with a time limit of more than two seconds.',\n",
       " \"Of the language pairs in the shared task, French-English is particularly interesting to us in light of Canada's demographics and policy of official bilingualism.\",\n",
       " 'Section 2 describes the architecture of the Portage system, including its hand-coded rules for French-English.',\n",
       " '(A fourth postprocessing phase was not needed for the shared task.)',\n",
       " 'Preprocessing is a necessary first step in order to convert raw texts in both source and target languages into a format suitable for both model training and decoding (Foster et al., 2003).',\n",
       " 'Segmentation is a crucial step in preprocessing languages such as German and Finnish texts. ',\n",
       " 'Decoding is the central phase in SMT, involving a search for the hypotheses t that have highest probabilities of being translations of the current source sentence s according to a model for P(t|s).',\n",
       " 'The phrase-based translation model is similar to the one described in (Koehn, 2004), and relies on symmetrized IBM model 2 word-alignments for phrase pair induction.',\n",
       " \"The distortion model is also very similar to Koehn's, with the exception of a final cost to account for sentence endings.\",\n",
       " 'Canoe is input-output compatible with Pharaoh few extensions su back ards or forw',\n",
       " 'The second part, which includes 1,000 sentences in each language with referenc used in the evaluation of the performance of the translation models.',\n",
       " 'Our goal for this language pair was to conduct experiments on hniques:  1 indicates the method, the second column gives results for decoding with Canoe only, and the third column for decoding and rescoring with Canoe.',\n",
       " 'For comparison between the four methods, there was an improvement in terms of BLEU scores when using two language models and two translation models generated from Europarl and Hansard corpora; however, parsing numbers and dates had a negative impact on the ranslation els.',\n",
       " 'BLEU scores for the French-English test sentences A noteworthy feature of these results is that the improvement given by the out-of-domain Hansard corpus was very slight.',\n",
       " 'Our best result ranked third in the shared WPT05 French-English task , with a difference of 0.74 in terms of BLEU score from the first rank participant, and a difference of 0.67 in terms o BLEU score from the second ranked participant.',\n",
       " 'Translation between Spanish and English is also becoming more mportant as a result ble 2 BLEU scores for the Finnish-English, German-English and Spanish-English test sentences To establish our baseline, the only preprocessing we did was lowercasing (using the provided tokenization).',\n",
       " 'Canoe was run without any special settings, although weights for distortion, word penalty, language model, and translation model were optimized using a grid search, as described above.',\n",
       " 'Our final results are shown in Table 2.',\n",
       " 'Our results distinguished the NRC team at the third, second, third and fourth ranks with slight differences with the first ranked participants. ',\n",
       " 'We first reveal that the final morphemes in each argument, which have not been discussed in previous work on English SRL are effective features in determining semantic role labels in Japanese.',\n",
       " '1',\n",
       " 'In Japanese syntax, the case markers located in the final part of each phrase, play important roles in determining the semantic relations (i.e., semantic roles) to the predicate.',\n",
       " 'Not only the case markers but also certain functional multi-morphemes, attached to the final part of each phrase have an effect on determining the semantic relations to the predicate.',\n",
       " 'Unfortunately, there is no standard dictionary of functional morphemes 6 nor morphological analyzers that can detect these functional morphemes 7 .',\n",
       " 'There was a study on the collection of Japanese suffixes (Matsuyoshi et al., 2007); however, there are still no registered functional morphemes such as to-issyoni (with). ',\n",
       " 'For example, the Japanese morphological analyzer MeCab (http://taku910.github.io/mecab/) with the IPA dictionary does not extract the functional suffix no-tame-ni. 8',\n",
       " 'The functional morphemes are annotated in CoNLL2009 not as features but as semantic role tags (i.e., target of disambiguations).',\n",
       " 'Thus, we do not use EDR as the target SRL corpus. ',\n",
       " 'Unlike the EDR corpus, the JFN (Ohara et al., 2003) was constructed in the same structure of English FrameNet, however, JFN is a closed corpus, and several essential information such as total amount of the annotated sentences and number of lexicons are not revealed.',\n",
       " 'The semantic role labels are also connected to frames defined in the PT, which is freely published on the Web.',\n",
       " 'This framework of tags and frames is the same as PropBank and FrameNet.',\n",
       " 'The BCCWJ-PT corpus has not only semantic role labels but also annotated tags of morphemes, the target predicate, and its arguments; thus, we convert the tagged texts into the target data, which are separated into target semantic role labels and their features.',\n",
       " 'In the example features in Figure 3, basic forms as well as surface forms of the verbs are stored for normalization as the predicate features.',\n",
       " 'In the following sections, we give details of the three proposed models, their input features, and the methods of transfer learning.',\n",
       " '(3) Feature vector (2) with a BOW of the last two morphemes in an argument.',\n",
       " 'For example, feature vector (1) for the first data in Figure 3 is a BOW vector of granturisumo, 4, o, and kau.',\n",
       " 'In feature vector (3), a BOW vector of the two morphemes 4 and o is added to feature vector (2). ',\n",
       " 'Regarding the network structure and tuning methods, ReLU (Nair and Hinton, 2010) is applied to the non-linear function of the intermediate units, and softmax is used as the function of the units at the final layer. ',\n",
       " 'The input of the CNN is a sequence of feature morphemes in verb-argument order.',\n",
       " 'After the convolution layer, a pooling layer with max pooling is applied, then a fully connected layer is applied to the connection to the final output layer.',\n",
       " 'The slash in the examples denotes a delimiter of morphemes.',\n",
       " 'Feature vectors v3 and v4 have a surface form of the verb.',\n",
       " 'The basic procedure of transfer learning is as follows: 1) a neural network is trained using an annotated corpus of different semantic tags from the target corpus; 2) the units at the final layer of the neural network are replaced with new units for the target semantic tags; and 3) all the weights in the neural work are trained using the target corpus 11 .',\n",
       " 'The input feature is the BOW, which is the same as case (1) used in the 3-LNN model.',\n",
       " 'The BCCWJ-PT corpus was the target corpus containing 5069 sentences, 64 semantic role labels for 548 verb types 12 .',\n",
       " 'We extracted 82,892 instances whose format is the same as that in Figure 3.',\n",
       " 'Table 2 shows the details of the data sets used in the experiments. ',\n",
       " 'The top five most frequent semantic role labels contained in the BCCWJ-PT data are listed in Table 3.',\n",
       " 'The SRL accuracies of our models and the SVM model were evaluated based on the instances of the test data using the following accuracy formula: accuracy = #instances correctly estimated labels #total instances (1) In the SVM model, evaluation on test data in one hold was conducted with the above accuracy formula.',\n",
       " 'The final accuracy of the SVM model was then an average evaluated based on all the test data in 5-fold cross validation. ',\n",
       " 'Table 4 lists that experimental results of the SRL accuracies of the proposed and baseline models using only the BCCWJ-PT data.',\n",
       " 'All three neural-network-based models outperformed the SVM model regarding SLR accuracy.',\n",
       " 'When we look at the effectiveness of the features in the SVM and 3-LNN models, the skip-gram vectors significantly improved the accuracies of the both models.',\n",
       " 'For the GRU results, v2 showed the best performance among the other feature sets.',\n",
       " 'The SRL accuracy of the GRU model, however, was inferior to that of the 3-LNN model.',\n",
       " 'The best SRL accuracy of all the models was that of our CNN model.',\n",
       " 'The CNN model with only using the base feature vector conv did not perform as well as the 3-LNN model with the BOW + skip + two feature vector.',\n",
       " 'Table 5 shows the results of incorporating transfer learning, i.e., using the GDA data for training the initial values of the weights.',\n",
       " 'The 3-LNN model had the most improvement with transfer learning and showed the best accuracy among all the models.',\n",
       " 'The accuracy of the GRU model also increased 0.011 points within the maximum score, but the best accuracy of the GRU model was lower than those of the other models. ',\n",
       " 'The experimental results listed in Table 4 reveal that the multi-word functional suffix i.e., two feature vector, improves the accuracy of the GRU model as well as those of the SVM and 3-LNN models.',\n",
       " 'The three feature vectors v2, v3, v4 outperformed v1 in terms of SRL accuracy.',\n",
       " 'Since v1 is only the case in which a verb comes at the end, the other case markers come last.',\n",
       " 'In the GRU model, the final layer of the GRU loated at the final positions of a time sequence determines the label.',\n",
       " 'The accuracies of all the models show that the last morphemes have a positive effect on determining the semantic role labels in Japanese.',\n",
       " 'The dependency path is convenient, but He et al.',\n",
       " 'Thus, the effective grammatical features as well as approaches on neural-network-based models for Japanese SRL are required to be studied.',\n",
       " 'After pre-training the weights using the GDA data, the neural network models were trained on the BCCWJ-PT data.',\n",
       " 'Except these models, we do not need explicit word alignments for phrase extraction.',\n",
       " 'We presented the results and our experience in the shared tasks on French-English.',\n",
       " 'In our proposed algorithm, we do not need explicit word alignment for phrase extraction.',\n",
       " 'The paper is structured as follows: in section 2, The concept of blocks is explained; in section 3, a dynamic programming approach is model the width of the block; in section 4, a simple center distortion of the block; in section 5, the lexicon model; the complete algorithm is in section 6; in section 7, our experience and results using the proposed approach.',\n",
       " 'The y-axis is the source sentence, indexed word by word from bottom to top; the x-axis is the target sentence, indexed word by word from left to right.',\n",
       " 'The block is defined by the source phrase and its projection.',\n",
       " 'The source phrase is bounded by the start and the end positions in the source sentence.',\n",
       " 'The projection of the source phrase is defined as the left and right boundaries in the target sentence.',\n",
       " '− 3, i − 1] + log P φ (3|e i ) where P N U LL (0|e i ) is the probability of generating a NULL word from e i ; P φ (k = 1|e i ) is the usual word fertility model of generating one French word from the word e i ; φ[j, i] is the cost so far for generating j words from i English words',\n",
       " 'i is the position index, which is weighted by the word level translation probabilities; the term of I i=1 P (f j |e i ) provides a normalization so that the expected center is within the range of target sentence length.',\n",
       " 'The input parameters are essentially from IBM Model-4:',\n",
       " 'the word level lexicon P (f |e), the English word level fertility P φ (φ e = k|e), and the center based distortion P ( e i+k i | f j+l j ). ',\n",
       " 'The scores of the phrase length, center-based distortion, and a lexicon based score are computed for each candidate block A local greedy search is carried out for the best scored phrase pair (f j+l j , e i+k i ).',\n",
       " '+ 1 We compute phrase level relative frequency in both directions:',\n",
       " 'The maximum fertility for an English word is 3.',\n",
       " 'All the data is used as given, i.e. we do not have any preprocessing of the English-French data.',\n",
       " 'The word alignment provided in the workshop is not used in our evaluations.',\n",
       " 'The language model is provided by the workshop, and we do not use other language models.',\n",
       " 'Despite significant improvement, the performance is far from perfect.',\n",
       " 'Furthermore, to the best of our knowledge, there is no previous work in confidence estimation for the KBP slot filling task.',\n",
       " 'Each query consists of the name of the entity, its type (PER or ORG), a document (from the corpus) in which the name appears, its node ID if the entity appears in the provided KB, and the slots which need not be filled.',\n",
       " 'Since the overall goal is to augment an existing KB, the redundancy in list-valued slots must be detected and avoided, requiring a system to identify different but equivalent strings.',\n",
       " 'Like most SF systems, our system has three basic components: Document Retrieval, Answer Extraction, and Response Combination.',\n",
       " \"We have collected and merged the previous three years' KBP SF evaluation data, which consists of a total of 280 queries, and Table 1 lists the number of person and organization queries as well as the number of intermediate responses from each year.\",\n",
       " 'This voting system simply counts the frequencies of each response entity, which is a unique response tuple in the form <Query ID, Slot Name, Response Fill>.',\n",
       " 'For the list-valued slots, all non-redundant responses are returned as the final response fills.',\n",
       " \"In our experiment, voters are all of intermediate responses generated by all pipelines, and the voters' weights are their confidence values.\",\n",
       " 'We set a threshold τ in this weighted voting system, where those intermediate responses with',\n",
       " 'The slot name slot response length',\n",
       " 'The conjunction of the length of R and the slot name name response slot The slot requires a name as the response',\n",
       " 'The name of pipeline which generates R pipeline precision The Precision of the pipeline which generates R pipeline recall The Recall of the pipeline which generates R pipeline fmeasure The F-measure of the pipeline which generates R Local Features sent contain QR S contains both original Q and R sent contain ExQR S contains both co-referred Q or expanded Q and R dpath length ',\n",
       " 'The length of shortest dependency path between Q and R in S shortest dpath The shortest dependency path between Q and R in S NE boolean R is a person or organization name in S NE margin The difference between the log probabilities of this name R and the second most likely name n-gram Tri-gram context window associated with part-of-speech tags containing Q or R genre The supporting document is a newswire or web document',\n",
       " 'The number of documents retrieved by Q response doc num The number of documents retrieved by R co-occur doc num The number of documents retrieved by the co-occurrences of Q and R cond prob givenQ The conditional probability of R given Q cond prob givenR ',\n",
       " 'For each response entity, this weighted voting system simply sums all the weights of the intermediate responses that support this response entity as its weight.',\n",
       " 'Then for a single-valued slot of a query, it returns the response with the highest weight as the final slot fill, while it returns all nonredundant responses as the final slot fills for the list-valued slots.',\n",
       " 'The maximum confidence ψ of supporting intermediate responses is used as the final confidence for that slot fill.',\n",
       " 'Table 3 compares the results of this weighted voting system (with τ = 0, η = 0.17) and the baseline voting system, where the responses were judged based only on the answer string, ignoring the document ID.',\n",
       " 'As we can see, the weighted voting system achieves 2.3% absolute improvement in F-measure over the baseline, at a 99.8% confi- Figure 1 summarizes the results of this weighted voting system with different threshold τ settings.',\n",
       " 'Applying the features separately, we find that slot response length and response doc num are the best predictors of correctness.',\n",
       " 'dpath length (the length of the shortest dependency path between query and response) is also a significant contributor.',\n",
       " 'Among the features, only NE margin seeks to directly estimate the confidence of a pipeline component, and it makes only a minimal contribution to the result.',\n",
       " \"A strong correlation between the confidence estimates in KBP slot fills and the correctness has also been proved by obtaining an average precision of 83.5% and Pearson's r of 54.2%.\",\n",
       " 'The LDV-COMBO system follows the SMT architecture suggested by the workshop organizers. ',\n",
       " 'Notice that it is not necessary that the two parallel counterparts of a bitext share the same data view, as long as they share the same granularity.',\n",
       " 'See token descriptions: (W) word, (WL) word and lemma, (WP) word and PoS, (WC) word and chunk label, (WPC) word, PoS and chunk label, (Cw) chunk of words (Cwl), chunk of words and lemmas, (Cwp) chunk of words and PoS (Cwc) chunk of words and chunk labels (Cwpc) chunk of words, PoS and chunk labels.',\n",
       " 'V P (the session)',\n",
       " 'N P (of) P P (the European Parliament)',\n",
       " 'Combo-models must be then postprocessed in order to remove the additional linguistic annotation and split chunks back into words, so they fit the format required by Pharaoh. ',\n",
       " 'The Freeling 2 package (Carreras et al., 2004) has been used for lemmatizing.',\n",
       " 'Finally, the Phreco software by (Carreras et al., 2005) has been used for shallow parsing. ',\n",
       " 'No additional tokenization or pre-processing steps other than case lowering have been performed.',\n",
       " 'Special treatment of named entities, dates, numbers, 1',\n",
       " 'In any case, phrase extraction 3 is performed as depicted by (Och, 2002).',\n",
       " 'These are scored by relative frequency according to the number of senses that lexicalized in the same manner.',\n",
       " 'No extra training or development data were used in our experiments. ',\n",
       " 'Table 2 presents MT results for the 10 elementary data views devised in Section 2.',\n",
       " 'No tuning has been performed.',\n",
       " 'In this view, only words are used.',\n",
       " 'The 10-GPHEX/MRG system uses the 5 word based views combined as in GPHEX, the 5 chunk based views combined as in GPHEX, and then a combination of these two combo-models as in MRG.  ',\n",
       " 'Table 4 shows MT results after optimizing λ tm , λ',\n",
       " 'lm , λ w , and the weights for the MRG operation, by means of the Downhill Simplex Method in Multidimensions (William H. Press and Flannery, 2002).',\n",
       " 'The λ w parameter is particularly sensitive to tuning. ',\n",
       " 'The 10-MRGsub W N system is this same system at the time of submission.',\n",
       " 'However, numbered semantic roles have not been annotated for Japanese texts.',\n",
       " 'Also, none of the annotated corpora that are reported in the literature are web accessible because of licensing restrictions 2 . ',\n",
       " 'Thus, the annotated sentences are not available on the website: http://sato.fm.senshu-u.ac.jp/frameSQL/jfn23/notes/index2.html (accessed 2019/11/22). ',\n",
       " 'The semantic roles and frames are annotated based on a freely available web-accessible thesaurus of predicateargument structure for Japanese (PT) 4 .',\n",
       " 'Frame-based Semantic Roles Are Needed in an Agglutinative Language Such as Japanese With semantic role annotation, the aim is to fix the semantic relations between arguments and predicates in a manner that is abstracted away from differences between case markers and syntactic alternations.',\n",
       " 'Each verb meaning of polysemous verbs is fixed by adding example sentences.',\n",
       " \"The meaning of 'hirak-u' in ( 7) is assigned to the development frame to which verbs such as 'kaitaku-su-ru' (cultivate) and 'kaihatsu-su-ru' (develop) are also assigned.\",\n",
       " 'PT is composed of hierarchical frames for predicates and each frame indicates a shared meaning of predicates whose sense is designated with semantic-role-annotated example sentences.',\n",
       " 'The semantic roles in PT have conventional role names (e.g., Agent, Theme, Goal) 7 .',\n",
       " \"As a polysemous verb, 'hirak-u' has open, develop, and start meanings.\",\n",
       " 'The semantic roles are Arg1 and Theme in all of the example sentences 8 in Figure 1. !',\n",
       " 'Then each example sentence is linked to a frame in the thesaurus.',\n",
       " \"The start frame also contains 'kigyoosu-ru' (start new venture) and 'kaiten-su-ru' (open a shop).\",\n",
       " 'The structure of frames is a thesaurus.',\n",
       " 'There is no multiple inheritance in the thesaurus of frames.',\n",
       " 'In the moving from frame, the mover of the moving event is annotated as Arg0 and Agent.',\n",
       " \"case, 'chichi' is annoated with the Experiencer named semantic role because 'chichi' is moved without intending to be moved.\",\n",
       " 'On the other hand, named semantic roles are helpful for understanding the meanings of arguments.',\n",
       " \"In ( 10) and ( 11), even though the frames are different, 'kangoshi' (nurse) and 'asshoo' (big win) are a complement of the argument with the accusative case marker.\",\n",
       " 'For the arguments, the named semantic role is Complement (ACC) that indicates a complement of the argument with accusative case.',\n",
       " 'The annotation task is carried out by annotators under the guidance of a supervisor.',\n",
       " 'The procedure of annotation of semantic roles and frames on the NPCMJ is as follows: 1.',\n",
       " 'Target predicates and their arguments are extracted by a program (Treebank Semantics) (Butler, 2019).',\n",
       " 'The named semantic roles are annotated according to syntactic expressions of arguments for verbs, while the numbered semantic roles are annotated based on frames. ',\n",
       " 'Adding new words or example sentences to PT is limited to the supervisor only so as to maintain the consistency of the dictionary.',\n",
       " 'In PT numbered arguments and named roles are assigned on the basis of active voice.',\n",
       " 'The first one is the adversative passive (Wierzbicka, 1979), that is, the passive form for an intransitive verb.  ',\n",
       " 'For this construction, there is an argument that works as the predicate, and so this argument that provides the predicate content is withdrawn from being assigned a semantic role.',\n",
       " \"( 18 In ( 18), the target verb 'shi-ma-su' (do) is a light verb.\",\n",
       " \"The content of the action is expressed by the deverbal noun 'oshaberi' (chatting).\",\n",
       " \"For this light verb case, the Arg PRX tag is assigned to the content argument 'oshaberi o'.\",\n",
       " 'This follows the treatment proposed in the PropBank guidelines (Bonial et al., 2010).',\n",
       " \"However, the composed meaning of the light verb construction, i.e., the chat frame and the verb 'oshaberi-sur-u' (chat-do-PRS) are assigned to the light verb 'shi-ma-su'.\",\n",
       " \"Thus the role sets of the chat frame are applied to the arguments and adjuncts except for 'oshaberi o' (ArgM PRX).\",\n",
       " 'First, we show the statistics of annotated numbers of sentences, target predicates, types of predicates, and semantic roles.',\n",
       " 'The target data is BCCWJ-PT, where data is annotated with the semantic roles defined in PT.',\n",
       " 'The input of the semantic role labeling system is the target predicate and morpheme sequence of its argument (or adjunct), and then the output is a semantic role label of the argument.',\n",
       " ', Sem) is the jth semantic role label.',\n",
       " 'Let y j be an output of the jth unit at the final output layer of the neural network model.',\n",
       " 'Figure 5 shows the 13 http://nwjc-data.ninjal.ac.jp/  !\"',\n",
       " '$C B%\"# DDC@6E)@$C)=%\"&516)C2(<6))DC@6E)F$C)$)!2\\'E -\"%0@6#6C)2()=@6)$%3&#6(=G$\\'H&(<= 8$%36=) 0%6\\'2<$=6 Figure 5: Bi-directional GRU with max-pooling model architecture of the bi-GRU model.',\n",
       " 'An input vector sequence X is applied to the input of bi-directional GRU, and then the max-pooling is applied to outputs of the GRU with time sequence direction.',\n",
       " ', y Sem ] is obtained after applying a fullyconnected layer to the results of max-pooling.',\n",
       " 'The settings of the optimizer are set the same as in Okamura et al. (2019).',\n",
       " 'The performance is evaluated by the accuracy of the test data.',\n",
       " 'Table 4 shows the total accuracies of numbered and named semantic role labels.',\n",
       " 'The accuracy of the third column shows the results for BCCWJ-PT (Okamura et al., 2019). ',\n",
       " 'According to the accuracies of named semantic roles in Ta-NPCMJ BCCWJ-PT Numbered semantic roles 0.716 N/A Named semantic roles 0.667 0.702 Table 4: Total accuracy of semantic roles ble 4, the accuracy of the model using NPCMJ is near to that of BCCWJ-PT.',\n",
       " 'Arguments are the essential factors for the defined frame, while adjuncts are not core elements for a frame.',\n",
       " \"( The recipient 'imooto-ni' (sister DAT) must be part of a construction (Goldberg, 1995).\",\n",
       " 'In the frameset write.01 of PropBank, the corresponding roles are defined as A2 (benefactive), that is an essential argument.',\n",
       " \"The meaning of the above case, i.e., 'write' in English, is assigned to the Contacting frame.\",\n",
       " 'In the Contacting frame, the recipient role is defined as the Addressee role that indicates a core role (i.e., an essential argument).',\n",
       " 'Frame: create \\'(They) write it as \"Shomyo\" in the old kanji style\\' (5 wikipedia KYOTO 11)',\n",
       " 'Such comparisons are only possible because there are web-accessible frame data sets, notably, PropBank and FrameNet.',\n",
       " 'The annotation task is coupled with the expansion of PT, that is, the repository of semantic roles and frames.',\n",
       " 'Both the numbered semantic roles and the named semantic roles are defined consistently with respect to frames.',\n",
       " 'What is currently annotated is the first part of a planned annotation cycle, and so all is due for review as we also continue to annotate new texts from the NPCMJ.',\n",
       " 'With the constant introduction of new terms in many domains, timely augmentation and update of terminologies is critical for proper terminology management, and automatic assistance for this process is greatly needed (Kockaert and Steurs, 2015).',\n",
       " 'The steps for this process are as follows: ',\n",
       " 'However, we considered only head-modifier pairs by minimum unit in this time.',\n",
       " 'We set English as source language for convenience of processing; there is no inherent technical reason for us to make the process directional in terms of languages. ',\n",
       " '4 Experimental setup',\n",
       " 'These are two of the five terminological dictionaries used in Sato et al. (2013).',\n",
       " 'Table 1 shows the number and ratio of terms by length in each terminology, i.e. single terms, terms with two constituents, terms with three constituents and terms with four or more constituents.',\n",
       " 'Table 2 shows the quantitative nature of the terminological networks, in which N stands for the number of constituent elements, V the number of vertices, E the numbers of edges, and S the number of isolated terms.',\n",
       " 'The number of candidates generated from these clusters is given in Table 3, which also provides the number of candidates generated from the method by Sato et al. (2013).',\n",
       " 'Table 4 shows the basic quantities of the collected documents.',\n",
       " 'We extracted 200 pages randomly from the English data and manually checked the number of technical documents.',\n",
       " 'The result is shown in Table 5.',\n",
       " 'Note that we do not make comparison between our approach and the approach of extracting terms from corpora, because their experimental setups are very different to each other.',\n",
       " 'Table 6: The result of validation (filtering)',\n",
       " 'Table 6 shows the result.',\n",
       " 'The first line in each domain shows the number of validated candidates.',\n",
       " 'The second line shows their percentage against the number of candidate pairs given in Table 3.',\n",
       " 'The first point indicates that our method successfully captures the conceptual subsystems/terminological subgroups within the dynamics of which new terms are formed.',\n",
       " 'In order to keep the comparison with Sato et al.',\n",
       " 'Jacard coefficient is defined as: Jaccard(L1, L2) = H(L1) ∧ H(L2) H(L1) ∨',\n",
       " 'H(L2) = H(L1) ∧ H(L2) H(L1) + H(L2) − H(L1 ∧ L2) , where L1 and L2 indicate English and Japanese parts (or vice versa) of a candidate pair in our case, and H(x) is the number of documents in which they occur.',\n",
       " 'The evaluation was carried out by one of the authors.',\n",
       " 'Table 8 shows the result, together with the corresponding results given in Sato et al. (2013) (in bracket).',\n",
       " 'Table 8 shows that except for \"pairing\" by Jaccard in computer science, our method is consistently better than Sato et al.',\n",
       " 'The breakfast room is just not big enough to cope with the Sunday-morning crowds. ',\n",
       " \"Much attention is paid to the customer's (or reader's) perspective in studies in the area of business and social science.\",\n",
       " 'However, none of these studies focus on the relationship between reviewer rating and review text. ',\n",
       " '( 2011) is the only study which mentions the mismatch between rating and text.',\n",
       " 'The corpus consists of 1,171 reviews extracted from four different booking sites during the period 2010-2012.',\n",
       " 'They include reviews on hotels from all over the world (although the majority is Dutch).',\n",
       " \"\\uf0b7 They include reviewer's ratings ranging from strong negative to strong positive Each review contains the following information: \\uf0b7\",\n",
       " 'Reviewer rating: a user rating given by the reviewer translated to a scale ranging from 0 to 10 (very negative to very positive) describing the overall opinion of the hotel customer.',\n",
       " \"\\uf0b7 Review text: a brief text describing the reviewer's opinion of the hotel.\",\n",
       " 'We measured the Pearson Correlation Coefficient (r) between the 10-point numerical rating scales of each annotator pair (R1, R2 and reviewer), regarding the reviewer (REV) also as an annotator.',\n",
       " \"A 2-class evaluation was performed by translating 1 to 5 ratings to 'positive' and 6 to10 ratings to 'negative'; a 4class evaluation is performed by translating 1-3 ratings to 'strong negative', 4 to 5 ratings to 'weak negative', 6 to 7 ratings to 'weak positive' and 8 to 10 to 'strong positive'.\",\n",
       " 'Agreement was measured between each annotator pair in terms of percentage of agreement (%) and kappa agreement (κ).',\n",
       " 'raters 1/10 2-class 4-class REV-R1 0.82 r 0.81 κ 0.90% 0.51 κ 0.63% REV-R2 0.83 r 0.82 κ 0.91% 0.53 κ 0.65% R1-R2 0.92 r 0.92 κ 0.96% 0.71 κ',\n",
       " 'Table (1) shows that inter-annotator agreement is quite high between all raters, both when correlation is measured on the 10-point-scale (r >= 0.82) and when agreement is measured with the 2-class annotation sets (κ >= 0.81).',\n",
       " 'However, given the purpose of this study, we are not interested in agreement as such.',\n",
       " 'From that perspective it is interesting to note that, according to all measures, the reviewer is an outlier.',\n",
       " 'Agreement between each individual reader and the reviewer (REV-R1 and REV-R2, respectively) is consistently lower than agreement between both readers (R1-R2).',\n",
       " 'All observed differences ranging from 5 up to 15%, are statistically significant (p < 0.01). ',\n",
       " '37% (cf. table 1, row 1, column 6) of the reviews (when reviews are categorized in more fine-grained categories) readers do not agree with the reviewer.',\n",
       " 'Classifier accuracy is measured against the three sets of ratings (R1, R2 and REV) we described in the previous section.',\n",
       " 'If polar words are preceded by a negator, their polarity is flipped; if polar words are preceded by an intensifier, their polarity is doubled.',\n",
       " 'We then assign the majority polarity to the review.',\n",
       " \"Results are evaluated against the whole set of 1,172 reviews (cf. table 2 'all').\",\n",
       " 'Table (2) shows the classification results in terms of accuracy, obtained by the lexicon-based approach (LBA, row 1, 2, 3) and the machinelearning approach (NBM,row 4,5,6).',\n",
       " 'This alignment matrix is the starting point for the phrase based extraction. ',\n",
       " 'I, which is identical to the alignment criterion described in [11]. BP (f J 1 , e I 1 , A) = {(f j2 j1 , e i2 i1 ) :',\n",
       " 'The set of BP is consistent with the alignment and consists of all BP pairs where all words within the foreign language phrase are only aligned to the words of the English language phrase and viceversa.',\n",
       " 'The length of a M P is defined as its number of words.',\n",
       " 'The length of a BP is the greatest of the lengths of its M P . ',\n",
       " 'Moreover, the huge increase in computational and storage cost of including longer phrases does not provide a significant improve in quality [8]. X-length In our system we considered two length limits.',\n",
       " \"NULL ( ) When ( 1 ) the ( 2 ) European ( 4) Parliament ( 3 4 ) , ( 5) that ( 6) so ( 7) frequently ( 8) insists ( 9) on ( 10) workers ( 11 15 ) '\",\n",
       " '( 14) rights ( 12) and ( 16) proper ( 19) social ( 21) protection ( 20 ) , ( 22 ) (...) where the number inside the clauses is the aligned word(s).',\n",
       " 'And the phrase that we are looking for is the following one.',\n",
       " '= N (f, e) N (e) where N(f,e) means the number of times the phrase f is translated by e.',\n",
       " 'This is specially harmful given a BP where the source part has a big frecuency of appearence but the target part appears rarely.',\n",
       " 'On the other, note that \"la que no\" cannot be considered an unusual trigram in Spanish.',\n",
       " 'Hence, the language model does not penalise this target sequence either.',\n",
       " \"= N (f, e) N (f ) where N'(f,e) means the number of times the phrase e is translated by f.\",\n",
       " 'This results in an important improvement in translation quality.',\n",
       " '(6) The p(f j |e i ) are the source-target IBM Model 1 word probabilities trained by GIZA++.',\n",
       " 'The English language model plays an important role in the source channel model, see equation (2), and also in its modification, see equation (3).',\n",
       " 'The phrase penalty is a constant cost per produced phrase.',\n",
       " 'The training material covers the transcriptions from April 1996 to September 2004.',\n",
       " 'This material has been distributed by the European Parlament.',\n",
       " 'In our experiments, we have used the distribution of RWTH of Aachen under the project of TC-STAR 1 .',\n",
       " 'The test material was used in the first evaluation of the project in March 2005.',\n",
       " 'This material corresponds to the transcriptions of the sessions from October the 21st to October the 28th.',\n",
       " 'The decoder used for the presented translation system is reported in [2].',\n",
       " 'We report the results of the baseline.',\n",
       " 'We do the same as in the paragraph above, we do not consider the IBM Model 1 and the IBM1 −1 .',\n",
       " \"Finally, we made an experiment without modification of the phrases' length.\",\n",
       " 'We observe that there is no much difference between the number of phrases, so this approach does not require more resources.',\n",
       " 'Notice that the language model has been trained with the training provided in the shared task.',\n",
       " 'However, the optimization in the parameters has not been repeated, and we used the parameters obtained in the subsection above.',\n",
       " 'We also reported several features as P (e|f ) which in combination with the functions of the source-channel model provides significant improvement.',\n",
       " 'Finally, we have optimized the parameters, and we provided the final results which have been presented in the Shared Task: Exploiting Parallel',\n",
       " 'We focus on the verb conjugation as the most important and problematic phenomenon in the context of morphology in Persian.',\n",
       " 'Therefore, morphological analysis is an important phase in the translation from or into such languages, because it reduces the sparseness of model.',\n",
       " 'Simple form is broken into two categories according to the stem used in its formation.',\n",
       " 'We cannot derive the two stems from each other due to different surface forms they usually have.',\n",
       " 'More details about this corpus, which is used by Mansouri and Faili (2012) to build an SMT, are presented in Table 2.',\n",
       " 'Giza++ (Och and Ney, 2003) is used to word alignment.',\n",
       " 'However, as we have the verb, we only use their proposed method to determine VOC, MOD, NUM, TEN, NEG and PER for a given verb as our class labels.',\n",
       " 'Table 3 shows Correct Classification Ratio (CCR) of each DTC learned on our train data containing 178782 entries and evaluated on a test set containing more than 20k verbs.',\n",
       " 'Table 4 shows detailed n-gram BLEU (Papineni et al., 2002) precision (for n=1,2,3,4), BLEU and TER (Snover et al., 2006) scores for morphology generation using gold lemma with the most common feature values (LEM) as a baseline and other gold morphological features and their combinations as our reference experiments. ',\n",
       " 'As another baseline we have used a rule-based morphological analyzer which determines morphological features of the verb grammatically and generates inflected verb form (this rule-based morphological analyzer uses syntactic parse, POS tags and dependency relationships of English sentence).',\n",
       " 'Note that, these results are obtained from our reference experiments in which a reference is duplicated and modified by our approach.',\n",
       " 'In fact, there is no translation task here and a reference is evaluated by its modified version. ',\n",
       " 'Table 5 reports the results of detailed n-gram BLEU precision, BLUE and TER scores.',\n",
       " 'According to the results, our approach outperforms the baselines in all configurations.',\n",
       " 'In these approaches, the model of morphol-ogy prediction is an independent process of the SMT system. ',\n",
       " 'Experiments using Japanese-English terminologies of five domains show that the method is highly promising.',\n",
       " 'Section 3 explains the system arrangement and the methods and algorithms adopted in the modules of the system.',\n",
       " 'Except for section 2, Japanese-English language pairs are assumed,',\n",
       " 'This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND.',\n",
       " '\" These corpus-based approaches have shown steady technical advancement and improvement, but the results are essentially restricted by available corpora and not anchored to existing terminologies.',\n",
       " 'From the point of view of augmenting terminologies for terminological management, more \"terminology-driven\" methods, i.e. those that make use of existing terminologies, are required.',\n",
       " 'Figure 2: Main modules of the system Figure 2 shows the main modules of the system.',\n",
       " 'Validating (and ranking) candidate pairs generated in module (a) constitutes an essential part for our method.',\n",
       " 'We did not take this approach for reasons related to search engine api and in order to controlling evaluation and diagnosis.',\n",
       " 'For step 1, MeCab 1 and Stanford POS Tagger (Toutanova et al., 2003) 2 are used for decomposing terms and POS-tagging CUs for Japanese and English, respectively.',\n",
       " 'Algorithm 1 shows the procedure in pseudo-code.',\n",
       " 'Table 2 lists the number of terms by length (by the number of constituent units).',\n",
       " 'The number of Japanese-English term pairs of which the number of constituent units is the same for Japanese and English is also listed (CP).',\n",
       " 'In collecting the web documents, the following domain keywords were used: -‰;J ¶ (keisanki kagaku) and \"computer science\" for COM, &A ¶ (keizaigaku) and \"economics\" for ECN, O ¶ (hougaku) and \"law\" for LAW, úg ¶ (butsurigaku) and \"physics\" for PHY, and úg ¶ (shinrigaku) and \"psychology\" for PSY.',\n",
       " 'Table 3 shows the number of pages obtained from the web search.',\n",
       " 'The \"Japanese\" and \"English\" columns show the number of pages obtained by using Japanese and English terms, respectively.',\n",
       " 'Note that the number of Japanese web pages collected for COM is much smaller than its English counterpart, while in the other five domains they are more balanced. ',\n",
       " 'We randomly selected 200 web pages for each domain, without distinguishing between English and Japanese pages, and checked the relevance of the pages to the domain.',\n",
       " 'Table 4 shows the number of pages clearly relevant to the domain in ques-',\n",
       " 'Table 5 shows the basic statistics of the initial head-modifier bipartite graphs (created from steps 1-4 in section 3.2), in which \"mods\" stands for modifiers, \"# comp\" shows the number of connected components, \"maxcmp\" shows the number of vertices in the maximum component, \"2nd cmp\" shows the number of vertices of the second largest component (other headers should be obvious).',\n",
       " 'Table 6 shows the statistics of head-modifier graphs generated by removing bridges and applying the Kernighan-Lin algorithm.',\n",
       " 'Evaluation was carried out by two people; the results of the first evaluator were cross-checked by the other 10 . ',\n",
       " 'The results are listed in Table 8.',\n",
       " 'The Jaccard coefficient gave the highest performance both in terms of bilingual correspondence (pairing) and in terms of validity to the domain.',\n",
       " 'This indicates that the co-occurrence of SLT and TLT in the same document provides strong evidence for a pair being both a valid pair as well as valid terms.',\n",
       " 'For example, the meaning of lend and give in the above sentences is not categorized into the same Frame in FrameNet (Baker et al., 1998).',\n",
       " 'From the view of natural language processing, especially dealing the with propositional meaning of verbs, all of the above classes, i.e., the wider class of Giving Verbs containing lend and give as well as the narrower class of Giving Frame containing give and donate, are needed.',\n",
       " 'We constructed this thesaurus on Japanese verbs and the current status of the verb thesaurus is this: we have analyzed 7,473 verb meanings (4,425 verbs) and organized the semantic classes in a Àve-layer thesaurus with 71 semantic roles types.',\n",
       " \"EDR is a well-considered and wide coverage dictionary focusing on translation between Japanese and English, but EDR's semantic classes were not designed with linguistically-motivated lexical relations between verbs, e.g., alternations, causative, transitive, and detransitive relations between verbs.\",\n",
       " 'This must be high advantage to describe the different factors from the view of not only syntactic functions but also internal semantic relations.',\n",
       " 'A parent verb class includes concepts of subordinate verb class; thus a subordinate verb class is a concretization of the parent verb class.',\n",
       " \"As Figure 1 shows that all of the above verb senses are involved in the verb class Moving of One's Possession 5 .\",\n",
       " \"The semantic description, which expresses core meaning of the verb class Moving of One's Possession is ([Agent] CAUSE) BECOME [Theme] BE AT [Goal]. \",\n",
       " 'Verb class is essential for dealing with verb meanings as synsets in WordNet.',\n",
       " 'The sentence is simple, without adjunctive elements such as unessential time, location or method.',\n",
       " 'The principal function of the semantic role label name is to link arguments in a verb class.',\n",
       " 'As an example of entailment, Figure 5 shows that a verb class Move to Goal entails Theme to be Goal, and this corresponds to a verb class Exist.',\n",
       " 'The result shows that our thesaurus meaning covers 99.5% (199 verb meanings/200 verb meanings) of 200 7 Mainichi news article in 2003.',\n",
       " 'Table 1 and Table 2 show a comparison of statistical characteristics with existing resources.',\n",
       " 'Looking at number of concepts, our Thesaurus has 709 types of concepts (verb classes) which is similar to FrameNet and more than VerbNet.',\n",
       " 'While at the number of SRL, FrameNet has much more types than our thesaurus, and in the other resources VerbNet and EDR the number of SRL is less than our thesaurus.',\n",
       " \"VerbNet and EDR also deÀned abstracted SRL; The difference between their resources and our thesaurus is that our SRLs are deÀned taking into account what kind of roles in the core concept i.e., verb class; while SRLs in VerbNet and EDR are not dependent on verb's class. \",\n",
       " 'Table 2 shows that our thesaurus does not have large number in registered words and examples comparing to EDR and JWordNet.',\n",
       " 'Since we do not know all of the requirements of NLP applications currently, then it must be sufÀcient to provide an expandable descriptional framework of linguistically motivated lexical semantics.',\n",
       " 'This is similar to a camera, and we need to normalize the expressions as to their original meaning. ',\n",
       " 'Therefore, Ànding and describing these verb relations will be essential for dealing with propositional meanings of a sentence. ',\n",
       " 'Assuming that a user is confronted with the fact that wireless LAN in the user\\'s PC does not work, and the user wants to search for documents that provide a solution, the problem is that expressions of situations must be different from the views of individual writers, e.g., \"wireless LAN did not work\" or \"wireless LAN was disconnected\".',\n",
       " 'To solve this, a lexical database describing verb relations between \"go wrong\" and \"disconnect\" must be the base for estimating how the expressions can be similar.',\n",
       " 'One of the characteristics is that we describe verb relations on the basis of several semantic granularities using a thesaurus form with argument structure.',\n",
       " 'Semantic granularity is the basis for how we categorize (or recognize which semantic class relates to a verb meaning).',\n",
       " 'It is important to keep in mind, however, that our claims are strictly limited to the problem under investigation, namely polarity detection.',\n",
       " 'We do not make any claims whatsoever about domain adaptation for other sentiment-related problems or general problems in machine learning.',\n",
       " 'We also show on a previously released data set of four domains that the result is competitive with a state-of-theart domain adaptation approach using Structural Correspondence Learning.',\n",
       " 'Of direct importance to the discussion in this paper are results from domain adaptation in polarity detection.',\n",
       " 'Instead of using a single, general, feature set for source and target, three distinct feature sets are created: the general set of features, a source-domain specific version of the feature set, and a target-specific version of the feature set. ',\n",
       " '(2007) 4-domain data set and the larger Amazon review data set (25 domains) also made available in that release.',\n",
       " 'The average review length for the Amazon and hotel reviews is 437 characters and 97 words.',\n",
       " '25 Amazon domains, the hotel domain and the Twitter domain.',\n",
       " 'The Amazon reviews and the hotel reviews are rated between 1 and 5 on a 5 point scale where 1 is the most negative and 5 is the most positive.',\n",
       " 'Table 1 summarizes the 27 domains and their dataset sizes including the balanced datasets we used for training.',\n",
       " 'The in-domain classifier is trained with a dataset of that one domain and tested on the same domain (using cross-validation).',\n",
       " 'On average, the total number of features in each domain is 52,039.',\n",
       " 'Feature reduction was performed using LLR, retaining only the top 20,000 most predictive features as established on the training set. ',\n",
       " 'The all-in-one classifier is a maximum entropy classifier trained with the source domain datasets merged together.',\n",
       " 'The all-in-one classifier is trained with 26 domains datasets while being tested on the held-out 27 th domain.',\n",
       " 'The baseline in Blitzer et al. (2007) is a linear classifier trained without adaptation, while their ceiling reference is the same as ours, which is the in-domain classifier trained and tested on the same domain.',\n",
       " '(2007)  baseline and ceiling in-domain classifiers for the four domains.',\n",
       " 'This section summarizes the results of the experiments described in section 3.2 while further scrutinizing the comparison between the four domain adaptation sentiment analysis techniques. ',\n",
       " 'We also report the Transfer Ratio results of the all-in-one and ensemble classifiers.',\n",
       " 'Generally, the all-in-one classifier is closely comparable to the in-domain classifier of each domain',\n",
       " 'In the summary of each experiment results, we also plot the in-domain classifier results of each domain as the ceiling of comparison.',\n",
       " 'In the all-in-one classifier experiments, the sentiment classifier is trained with 26 domain datasets while testing it with the 27 th domain.',\n",
       " 'Table 3 summarizes the results.',\n",
       " 'The results of the allin-one classifier are very close to the in-domain classifiers in most domains except for the apparel, beauty, magazines, outdoor living, office products and software.',\n",
       " 'Table 3 summarizes the results of the three settings used in the ensemble. ',\n",
       " 'Table 3 shows that the ensembles with sum of weights and meta-training (SVM sigmoid kernel) are the most comparable to the in-domain classifier of each domain.',\n",
       " 'Table 2  Where is the transfer error defined as the test error obtained by a method trained on the source domain S and tested on the target domain T. is the test error obtained by the baseline method. ',\n",
       " 'The transfer ratio Q also characterizes the transfer but is defined by replacing the difference by a quotient in t:  Where n is the number of couples (S, T) with S≠T. The all-in-one classifier had a 1.12 transfer ratio across domains, which is very close to the best result of ~1.07 in Glorot et al.',\n",
       " 'Note that the transfer ratio of the indomain classifier, which is used a base-line for calculating the transfer ratio is 1.',\n",
       " '(2007) and that the all-in-one approach achieves comparable results in terms of transfer ratio to Glorot et al. (2011). ',\n",
       " 'They both are very close in some domains like When comparing the all-in-one and the ensemble approaches on the four datasets in Blitzer et al.',\n",
       " '(2007), the all-in-one exceeds the ensemble only in the DVD domain.',\n",
       " \"We have also employed NcNemar significance test between pairs of the all-in-one, the ensemble and Daumé's approaches on the 27 domains.\",\n",
       " \"Table 4 shows the significance difference between the approaches' combinations.\",\n",
       " 'Only 13 features are common among 20 domains while there are no common features from the highest 1000 likelihood ratio features among the 27 domains.',\n",
       " 'For example the word \"waste\" is common among 20 domains and maintains a negative polarity across the domains.',\n",
       " 'It maintains a positive polarity in all domains while it flips in Tools & Hardware.',\n",
       " 'Whilst human analysis remains essential to spot complex relationships, automated analysis has a key role to play in filtering the vast volume of data in real time and highlighting unusual trends using reliable predictor indicators. ',\n",
       " 'BioCaster (http://born.nii.ac.jp) (Collier et al., 2008) is a Web 2.0 monitoring station for the early detection of infectious disease events.',\n",
       " 'Compared to other similar systems BioCaster is characterized by its richly featured and publicly downloadable ontology and emphasizes critical evaluation of its text mining modules.',\n",
       " \"In the absence of a community gold standard, task performance was assessed on the best available 'silver' standard -the ProMED-mail network (Madoff and Woodall, 2005), achieving F-score of 0.63 on 14 disease-country pairs over a 365-day period (Collier, 2010). \",\n",
       " 'The central knowledge source for BioCaster is the multilingual ontology containing domain terms such as diseases, agents, symptoms, syndromes and species as well as domain sensitive relations such as a disease causing symptoms or an agent affecting particular host species.',\n",
       " 'To the best of our knowledge the BCO is unique as an application ontology, providing freely available multilingual support to system developers interested in outbreak surveillance in the language of the open media. ',\n",
       " \"The new version of the BCO now covers 12 languages including all the United Nation's official languages: Arabic (968 terms), English (4113), French (1281), Indonesian (1081), Japanese (2077), Korean (1176), Malaysian (1001), Russian (1187), Spanish (1171), Thai (1485), Vietnamese (1297) and Chinese (1142).\",\n",
       " 'Root terms themselves are fully defined instances that provide bridges to external classification schemes and nomenclatures such as ICD10, MeSH, SNOMED CT and Wikipedia.',\n",
       " 'To maintain consistency and computability we kept a single inheritance structure throughout.',\n",
       " 'It is the etiological agent of the eastern equine encephalitis. ',\n",
       " 'In such a large undertaking, the order of work was critical.',\n",
       " 'At regular stages we checked and validated terms against those appearing in the news media. ',\n",
       " 'As we expanded the number of conditions to include veterinary diseases we found a major structural reorganization was needed to support animal symptoms.',\n",
       " \"The MicroOrganism class contained bacterium, helminth, protozoan, fungus and virus, which then became the domain in a relation 'x causes y'.\",\n",
       " 'SP4: species(\"animal\") :-name(animal,A) words(,3) list(@cull verbs past)',\n",
       " 'Template rules contain a label, a head and a body, where the head specifies the template pattern to be output if the body expression matches.',\n",
       " 'Both are freely available to the research community under an open source license.',\n",
       " 'The rule book also contains specialised thesauri to recognize subclasses of entities such as locations of habitation, eateries and medical service centres.',\n",
       " 'Verb lists are maintained for lexical classes such as detection, mutation, investigation, causation, contamination, culling, blaming, and spreading.',\n",
       " \"Rule SP4 identifies the victim species as 'animal' in contexts like '250 geese were destroyed'. \",\n",
       " 'Version 3 of the ontology represents a significant expansion in the coverage of diseases, symptoms and pathogens on version 2.',\n",
       " 'Table 2 summarizes the number of root terms for diseases classified by animal familes. ',\n",
       " 'These too are freely available from the BCO site. ',\n",
       " 'For example, for French, within the subdomain of obesity in the domain of medicine, we find the term excès de poids (overweight) only inside texts sharing a popular science discourse, and the synonym excès pondéral (overweight) only in scientific discourse.',\n",
       " 'We found that taking discourse type into account resulted in candidate translations of a better quality even when the corpus size is reduced by half.',\n",
       " 'Thus, even using a state-of-the-art alignment method wellknown as data greedy, we reached the conclusion that the quantity of data is not sufficient to obtain a terminological list of high quality and that a real comparability of corpora is required.',\n",
       " 'Taking as input a comparable corpora, the multilingual terminology chain outputs a list of single-and multi-word candidate terms along with their candidate translations.',\n",
       " 'The terminology extraction programs are available for both French 1 (Daille, 2003) and Japanese 2 (Takeuchi et al., 2004).',\n",
       " 'For French, the main patterns are N N, N Prep N et N',\n",
       " 'Adj and for Japanese, N N, N Suff, Adj N and',\n",
       " 'At present, the Japanese term extraction program does not cluster terms.',\n",
       " 'Our implementation of the direct context-vector method consists of the following 4 steps: 1.',\n",
       " 'We collect all the lexical units in the context of each lexical unit $ and count their occurrence frequency in a window of % words around $ .',\n",
       " \"For each lexical unit $ of the source and the target language, we obtain a context vector & (' which gathers the set of co-occurrence units ) associated with the number of times that ) and $ occur together 0\",\n",
       " 'The candidate translations of a lexical unit are the target lexical units closest to the translated context vector according to vector distance.',\n",
       " 'For example, in the case of the MWT fatigue chronique (chronic fatigue), we have the following four translations for fatigue: ¢¡ , ¤£ , ¥ §¦ , © and the following two translations for chronique: , .',\n",
       " 'Here, only one term has been identified by the Japanese terminology extraction program: ! .',\n",
       " 'In this approach, when it is not possible to translate all parts of an MWT, or when the translated combinations are not identified by the term extraction program, the MWT is not taken into account in the translation process. ',\n",
       " 'They first decompose the French MWT into combinations of shorter multi-word units (MWU) elements.',\n",
       " 'The French and Japanese documents were harvested from the Web by native speakers of each language who are not domain specialists.',\n",
       " 'The texts are from the medical domain, within the sub-domain of diabetes and nutrition.',\n",
       " 'Then the documents were classified according to the type of discourse: scientific or popularized science.',\n",
       " \"Table 2 shows the main features of the harvested comparable corpora: the number of documents, and the number of words for each language and each type of discourse. '\",\n",
       " 'The French-Japanese bilingual dictionary required for the translation phase is composed of four dictionaries freely available from the Web 8 , and of the French-Japanese Scientific Dictionary (1989).',\n",
       " 'These lexicons contains terms that occur at least twice in the scientific corpus, have been identified monolingually by both the French and the Japanese term extraction programs, and are found in either the UMLS 9 thesaurus or in the French part of the Grand dictionnaire terminologique 10 in the domain of medicine.',\n",
       " 'For example, the French term diabète de type 1 (Diabetes mellitus type I) extracted by the French term extraction program and found in UMLS was not extracted by the Japanese term extraction program although it appears frequently in the Japanese corpus ( ¡ 2 3 4 ).',\n",
       " \"Since ' lexicon 1( is composed of SWTs, these terms are not more characteristic of popular discourse than scientific discourse.\",\n",
       " 'The frequency of the terms to be translated is an important factor in the vectorial approach.',\n",
       " 'Since we work with small-size corpora, this result is not surprising.',\n",
       " '4 ), facteur de risque (#occ. 267 -risk factor: ¦ ¨ § .',\n",
       " 'We carried out experiments using two corpora of the specialised domain concerning diabetes and nutrition:',\n",
       " 'Our alignment results are close to previous works involving the English language, and are of better quality for the scientific corpus despite a corpus size that was reduced by half.',\n",
       " 'Grammar is an essential tool in many applications of natural language processing (Feili and Ghassem-Sani, 2004).',\n",
       " 'Writing a natural language grammar by hand is not only a time-consuming and difficult task, but also it needs a large amount of skilled efforts.',\n",
       " 'But in the case of free word order languages such as Persian, its performance is inferior to that of fixed order languages like English. ',\n",
       " 'Unsupervised methods do not need to pars tree of sentences in training corpus. ',\n",
       " 'Increasing the dependencies on the context is the main feature of history based models.',\n",
       " 'He showed that, instead of P(A\\uf0e0B|A), which is used in ordinary PCFG based parsing, using P(A\\uf0e0B|A, parent(A)), where parent(A) is the nonterminal immediately dominating A, has a major positive impact on the accuracy of the parsing. ',\n",
       " 'Figure 1 shows t1 and t2 and the tree resulted from combining t1 and t2. ',\n",
       " 'UDOP takes the shortest derivation as the best derivation.',\n",
       " 'The probability of any construction C is calculated by dividing the number of times C appears in the corpus by the number of times that any tree t with the same root appears in the corpus. ',\n",
       " 'The probability of a parse tree T is calculated by the sum the probabilities of all the possible derivations of T. (3) \\uf0e5',\n",
       " 'Tj be a member in the set of all possible parse trees of a given sentence',\n",
       " 'The probability of each state is equal to the frequency of the subtree of that state.',\n",
       " 'This is due to the definition of the combination operator.',\n",
       " 'It means that if ti and tj cannot be combined, then P(ti\\uf0e0tij) and P(tj\\uf0e0tij), where ti\\uf0e0tij to presents the transition between statei and stateij, are set to zero.',\n",
       " 'In this case, there is a transition between tx and txy (i.e., tx\\uf0e0txy).',\n",
       " 'The probability of tx\\uf0e0txy is calculated as follows: \\uf0e5',\n",
       " '( t root t root t',\n",
       " 'i t t state P \\uf0e5',\n",
       " 'In HUDOP, the calculation of other probabilities, such as that of derivations and parse trees, is the same as UDOP. ',\n",
       " 'HUDOP was tested on both ATIS (Hemphill et al., 1990) and WSJ-10 (Schabes et al., 1993).',\n",
       " 'Part of speech tag sequences were used as the only lexical information of the training sets. ',\n",
       " 'Although, HUDOP is an unsupervised approach and does not require any bracketing data set, we need the tree style syntactic information of the test data set for the evaluation purpose.',\n",
       " 'The results of comparing HUDOP with other unsupervised methods, including EMILE (Adriaans and Haas, 1999), ABL (Van Zaanen, 2000), and CCM (Klein and Manning, 2005), on ATIS are shown in table 1.',\n",
       " 'LEFT and RIGHT are the left and the right-branching baselines applied to ATIS.',\n",
       " 'As table 1 shows, the performance of HUDOP is superior to all the mentioned work. ',\n",
       " 'The results are shown in Figure 2.',\n",
       " 'All sentences of these corpuses contain less than 11 words, and have been extracted from a Persian corpus named Peykareh (Bijankhan, 2003;Megerdoomian, 2000).',\n",
       " 'Table 2 shows main properties of the first corpus.',\n",
       " 'Table 3 shows main properties of the second corpus.',\n",
       " 'The results are shown in figure 3.',\n",
       " 'Figure 3 shows the impact of the free word orderness property on the performance of both UDOP and HUDOP.',\n",
       " 'This shows that the free word orderness property of the input language has a negative effect on these methods. ',\n",
       " 'The evaluation also sheds light on the evaluation metric and gives evidence showing that gaming translation with perfect fluency does not fool bleu the way it fools people.',\n",
       " \"Each Chinese character in the source sentence is tokenized individually, and we make use of the IR engine's phrase query feature, which matches documents in which all terms in the phrase appear in consecutive order, to create the ngrams.\",\n",
       " 'Unlike that work, we perform no second stage IR after query expansion.',\n",
       " 'We did not modify any Lucene defaults for these experiments. ',\n",
       " 'We Source TM output However , everything depended on the missions to be decided by the Security Council .',\n",
       " 'It is wrong to commit suicide or to use ones own body as a weapon of destruction .',\n",
       " 'There was practically full employment in all sectors .',\n",
       " 'He is elevating the intensity to test whether his body can adapt to it.',\n",
       " 'In the case of automated MT evaluation metrics, which are not necessarily symmetric, the source-language input string is treated as the reference and the source-language side of each pair returned by the IR engine as the hypothesis. ',\n",
       " 'Four contiguous source segments are presented, followed by TM output and finally one of the reference translations for those source segments.',\n",
       " 'The only indicator of the translation quality available to monolingual English speakers is the awkwardness of the segments as a group.',\n",
       " 'By design, the TM performs with perfect fluency at the segment level.',\n",
       " 'No duplication checks were performed.',\n",
       " 'The reference corpus consists of four independent human-generated reference English translations of the evaluation corpus.',\n",
       " \"All performance measurements were made using a fast reimplementation of NIST's bleu.\",\n",
       " 'bleu exhibits a high correlation with human judgments of translation quality when measuring on large sections of text (Papineni et al., 2001).',\n",
       " 'All of the calculations for this experiment are performed on the target language side of the parallel text. ',\n",
       " \"bleu produces a score of 0 for any hypothesis string that doesn't share at least one 4-gram with one reference string.\",\n",
       " \"Note that, for document scores, bleu's brevity penalty (BP) is applied globally to an entire document and not to individual segments. \",\n",
       " 'Thus, the document score does not necessarily increase monotonically with increases in scores of individual segments.',\n",
       " 'Also, the TM does not have much liberty to alter the length of the returned segments.',\n",
       " 'The hypothesis document was evaluated against the reference corpora by calculating a bleu score. ',\n",
       " 'TMs must attempt to match short sequences of stop words that indicate grammar as well as more traditional content words.',\n",
       " 'Note that our system performed neither stemming nor stop word (or ngram) removal on the input Chinese strings.',\n",
       " 'All of these were run on the tokens in the source language side of the IR result, comparing against the single pseudo-reference, the original source language segment.',\n",
       " 'The score that the IR engine associates with each segment is retained and marked as tf-idf in this experiment.',\n",
       " 'Naturally, bleu (Papineni et al., 2001) was the first choice metric, as it was well-matched to the target language evaluation function.',\n",
       " 'wer-g is a variation on traditional word error rate that was found to correlate very well with human judgments (Foster et al., 2003), and per is the traditional position-independent error rate that was also shown to correlate well with human judgments (Leusch et al., 2003).',\n",
       " 'Note the log-linear growth in the resulting   bleu score of the TM with increasing database size.',\n",
       " 'Note that the 4-gram result here (bleu of 5.87) provides the baseline system performance measure as well as the value when the segments are reranked according to tf-idf .',\n",
       " 'Of course, each of the segments produced by the TM exhibit perfect fluency.',\n",
       " 'Automatic look-up methods embodied in machine translation systems are not satisfactory, either.',\n",
       " 'Although many available machine translation systems successfully detect the idiomatic expression \"with one\\'s tongue in one\\'s cheek\" in (1), none among those we checked (e.g. Excite, 2005;Fujitsu, 2005;LogoVista, 2005;Sharp, 2004;Toshiba, 2005) 1 could properly translate (2).',\n",
       " 'The same is true for \"dumb down\". to develop enhanced look-up functions for idioms is of utmost importance from the point of view of aiding translators.',\n",
       " 'In relation to idiom look-up functions, two important features became clear. ',\n",
       " 'Firstly, translators do not want the system to provide a single idiom entry that matches textual occurrences.',\n",
       " 'In other words, from the point of view of translators, for the system to provide multiple possibilities of matching idioms is not a defect but a necessity if the system is to be useful for them.',\n",
       " \"What is important is reducing translators' burden as well as the quality of candidates the system proposes. \",\n",
       " 'Table 1 shows the basic quantities of the idiom variation data.',\n",
       " 'For instance, one of the informants provided the variation \"take the wild plunge\" of the idiom \"take the plunge,\" which only brings up four hits in a Google search.',\n",
       " 'Table 2 shows the basic variation patterns.',\n",
       " 'POS Each variation rule in Table 3 indicates the POS sequence of constituents of an idiom and the POS tag of the inserted word.',\n",
       " 'The input of the target system is an English text and the output is idiom candidates occurring in the text with their Japanese translations provided in the dictionary.',\n",
       " 'Figure 1 shows the overall flow of the system.',\n",
       " 'Table 4 shows the basic standardisation patterns of word forms.',\n",
       " 'Note that in the actual matching, we also retain the original forms.',\n",
       " \"an, the (4) my, his, etc. surface, one's (4) myself, herself, etc. surface, oneself\",\n",
       " \"O have one's eye on ...... had his ears on .....\",\n",
       " 'In this case, the surface matching module detected the three idiom candidates \"make a habit of doing\", \"wake up\", \"make after\" for the input text \"I make a habit of stretching after I wake up.\"',\n",
       " 'Figure 4 shows the system interface.',\n",
       " 'When the user inputs an English text, and clicks the \"search\" button, the system outputs the idiom candidates with their meaning (in Japanese).',\n",
       " 'By moving the mouse over an output idiom, the matched parts of the input text in the input area are emphasised.',\n",
       " 'Figure 4 shows that \"take the plunge\" and \"have one\\'s eye on\" were detected for the input: \"I decided to take the wild plunge and buy the car I had my eye on.\"',\n",
       " 'Figure 5 shows the interface in which automatic idiom lookup functions within the integrated environment.',\n",
       " 'The screen shot shows that the idiom entry \"(with) one\\'s tongue in one\\'s cheek\" matches the sentence \"He said that with his big fat tongue in his big fat cheek.\"',\n",
       " 'We manually identified and tagged the idioms for these articles.',\n",
       " 'For both the data (a) and (b), we compared the method of surface matching only with the method of surface matching and filtering with POS-based information. ',\n",
       " 'For instance, when \"come to the point\" is the idiom actually used in the text, \"come to a point\" is evaluated as correct output. ',\n",
       " 'These criteria were set on the basis of the consultation with eight online volunteer translators.',\n",
       " 'As mentioned, checking multiple candidates is not an optional, extraneous process that translators would like to omit if they can, but rather an essential process by which they make sure that their final decision is correct.',\n",
       " 'Figure 6 shows the range of the correct output defined here 5 .',\n",
       " 'From the viewpoint of translation support, it is important for our system to detect all the idioms that appear in the text.',\n",
       " 'Therefore, recall is the most important factor at this stage.',\n",
       " 'F-measure is irrelevant. ',\n",
       " 'Tables 5 and 6 show the results of the experiments.',\n",
       " 'The high recall is very promising, as the essential problem that prompted us to develop this system was the difficulty experienced by translators in looking up idioms, the improvement of which requires high performance in recall.',\n",
       " 'For most texts this will not be an excessive number.',\n",
       " 'For instance, \"She horribly damned him with faint praise\" is based on the idiom \"horribly damn with faint praise\".',\n",
       " 'However, our system could not detect this idiom because \"damned\" was recognised as an adverb rather than the verb \"damn\".',\n",
       " 'This was because, on the one hand, as we do not give structures to input texts, information about the proper construction of \"from (high school)\" is not provided, while on the other hand the dictionary entry \"from high\" was wrongly tagged as \"from:prep high:adj\" instead of \"from:prep high:nn\".',\n",
       " 'The dictionary we used does not give detailed information for the slot \"A\", \"B\" and \"...\".',\n",
       " 'For instance, the dictionary entry \"take apart\" was not detected for the input text: \"She takes (her daughter-inlaw) apart with stinging criticism.\"',\n",
       " 'The result of the experiment showed that the system performance is very promising.',\n",
       " 'As for the technical aspect, we used a morphological analyser but not a parser.',\n",
       " 'The toolset is built on the top of WCCL Match -a language for text annotation, which is a part of a WCCL framework (an open source, released under the GNU LGPL 3.0).',\n",
       " 'The list of possible relation categories is unbounded and it depends on the desired application, the scope of the named entities and the available resources.',\n",
       " 'For example, the well-known general framework GATE (Cunningham et al., 2011) does not support relation recognition within its rule formalism JAPE (Cunningham et al., 2000). ',\n",
       " 'The first one is the traceability and full control on decisions made by the system.',\n",
       " 'The last but not least it does not require annotated data. ',\n",
       " 'However, the main emphasis was put on the task definition and discussion of its difficulties.',\n",
       " 'Despite the formalism looks very promising the distribution and licensing is not clear and the XIP implementation is not freely available. ',\n",
       " 'Unfortunately, according to our best knowledge the system is not publicly accessible. ',\n",
       " 'It also does not support multilayered semantic annotations. ',\n",
       " 'The first section (match) contains a set of operators used to match a sequence of tokens and annotations (named entities, chunks, etc.).',\n",
       " 'The second section (cond) is optional and contains a set of additional conditions which must be satisfied by the matched elements.',\n",
       " 'The last section (actions) contains a set of operators to be performed on the matched elements.',\n",
       " 'Below is a sample rule which matches a sequence \"PERSON born in CITY\" and creates a connection between the PERSON and the CITY names of type origin. ',\n",
       " 'Below is a list of operators used in the examples presented in the article 3 : • is(type) -matches an annotation of given type, • equal(base[0], value) -matches a token with a base form equal to value, • inter(base[0], values) -matches a token with a base form present in the array of values, • repeat(op) -matches a sequence of elements matching the op operator, • not(op) -matches a token not matching the op operator, • isannpart(0, type) -matches a token that is a part of an annotation of given type, • and(op1,op2,..,opn) -matches a token if all operators are valid, • oneof(variant1,...,variant2)matches a sequence of elements for the first valid variant, • annsub(token, type) -test if given token is part of an annotation of given type, • agrpp(word1, word2) -test agreement of two given words, • outside(index) -test if given token index is inside sentence boundary, can be used to test if given token is the first or the last token in the sentence, The execution of a WCCL Relation rule consists of three steps (all of them are transparent to user).',\n",
       " 'In the first step, the WCCL Relation rule is transformed into a WCCL Match rule.',\n",
       " 'In the second step, the WCCL Match rule is run on a given text.',\n",
       " 'Below is the result of transformation the WCCL Relation rule to the WCCL Match rule.',\n",
       " 'Here, the link operator was replaced with a set of three match operators.',\n",
       " 'apply( match( // match annotation of type person_nam is(\"person_nam\"), // group 1 // match optional phrase in parentheses optional(is(\"parentheses\")) // group 2 // match word with base form \\'born\\' equal( base[0], \"urodzić\"), // group 3 equal( base[0], \"się\"), // group 4 // match word with base form \\'in\\' equal( base[0], \"w\"), // group 5 // match annotation of type city_nam is(\"city_nam\"), // group 6 ), actions( link(1, \"person_nam\", 6, \"city_nam\", \"origin\") ))',\n",
       " 'The following rule is a naïve rule for recognition of a location relation between a person name and a city name (i.e. a person is in a city). ',\n",
       " 'apply( match( is(\"person_nam\"), // group 1 // match word with base form \\'in\\' in(\"w\", base[0]), // group 2 is(\"city_nam\") //',\n",
       " 'For example when the person name is an possessive argument of an other subject then the relation does not occur between the person name and the city name but between the possessive phrase and the city name.',\n",
       " 'In the sentence it is stated that the monument is located in Kraków and it does not mean that Wojtyła is also in Kraków.',\n",
       " 'In order to handle properly such situations we must recognise the possessive nouns.',\n",
       " 'apply( match( in(subst, class[0]), is(\"person_nam\") ), cond( in(subst, class[first(:2)]), not(agrpp(first(:1), first(:2), {cas})) ), actions( mark(M, \"possessive\") )) ',\n",
       " 'Below is the original rule with the mentioned condition. ',\n",
       " '\"in\" is(\"city_nam\") // group 3 ), cond( not(annsub(:1, \"possessive\")) ), actions( link(1, \"person_nam\", 3, \"city_nam\", \"location\") ))',\n",
       " 'Below is a sample rule which matches the sequence \"COUNTRY ( CITY and CITY )\" and creates two links: both city names are connected with the country name as separate relations. ',\n",
       " 'apply( match( is(\"country_nam\"), // group 1 inter(base[0], \"(\"), // group 2 is(\"city_nam\"), // group 3 inter(base[0], \"i\"), // group 4 is(\"city_nam\"), // group 5 inter(base[0], \")\"), // group 6 ), actions( link(1,\"country_nam\",3,\"city_nam\",\"location\"), link(1,\"country_nam\",5,\"city_nam\",\"location\") ))',\n",
       " 'Below is an auxiliary rule that matches the text fragments not annotated with a road name nor a city name. ',\n",
       " 'apply( match( repeat( and( not(isannpart(0,\"road_nam\")), not(isannpart(0,\"city_nam\")) ) ) ), actions( mark(M, \"not_road_city\") )) ',\n",
       " 'group 6 ), cond( outside(first(M) -1), outside(last(M) + 1) ), actions( link(2, \"road_nam\", 4, \"city_nam\", \"location\") ))',\n",
       " 'The train and tune parts were used for the rule development and the test part for the final performance comparison. ',\n",
       " 'The recall is low but in terms of F-measure the results are comparable with the results obtained for the statistical methods presented by Marcińczuk and Ptak (2012).',\n",
       " 'Since the WCCL framework is language independent, also WCCL Relation is language independent.',\n",
       " 'Note, that the rules written for one language are not directly usable for other languages.',\n",
       " 'Below is a sample XML in the CCL format for a sentence \"Eiffel Tower is located in Paris\".',\n",
       " 'The file contains morphological tags for each word and semantic annotations (facility_nam for Eiffel Tower and city_nam for Paris).  ',\n",
       " 'Below is an XML output generated by the tool containing a single semantic relation of type location between Eiffel Tower and Paris. ',\n",
       " 'The API provides the following functions: • process_file(filepath) -process a single CCL file, • process_files(filepaths) -process a set of CCL files, • process_sentence(sentence) -process a single sentence represented as an object of class corpus2.AnnotatedSentence 6 , • process_document(document)process a single document represented as on object of class corpus2.DocumentPtr 6 . ',\n",
       " 'All the presented functions return a set of objects of class corpus2.Relation 6 representing the recognised relations.',\n",
       " 'WCCL Relation has a form of a Python script that is also released under the same license 8 . ',\n",
       " 'An LVC is a verb phrase (\"kandou-o ataeta (made an impression)\" in (1s)) that consists of a light-verb (\"ataeta (give-PAST)\") that grammatically governs a nomi-nalized verb (\"kandou (an impression)\") (also see Figure 1 in Section 2.2).',\n",
       " 'film-NOM him-DAT impression-ACC give-PAST',\n",
       " 'The film made an impression on him. ',\n",
       " 'In example (1), the causative voice is chosen, which is indicated by the auxiliary verb \"ase (causative)\".',\n",
       " 'In (1), the grammatical case of \"kare (him),\" which was originally assigned the dative case, is changed to accusative.',\n",
       " \"The paraphrasing associated with LVCs is not idiosyncratic to Japanese but also appears commonly in other languages such as English (Mel'čuk and Polguère, 1987;Iordanskaja et al., 1991;Dras, 1999, etc.)\",\n",
       " 'The first two operations are trivial in the field of text generation.',\n",
       " 'The most delicate operation is for the element (c) because it acts either as an adverb or as a case, relying on the con-',\n",
       " 'The school (Theme) locates near the river (Goal).',\n",
       " 'He (Agent) maintains a machine (Theme) in good condition (Goal). text.',\n",
       " 'In this paper, we take into account only the element (b), namely, the sibling cases of the nominalized verb.',\n",
       " 'Their model looks robust because of the availability of an ordinary dictionary.',\n",
       " 'party-GEN invitation-ACC receive-PAST',\n",
       " '(6) s. Kare-no hanashi-ni his-GEN talk-DAT kandou-o uketa. impression-ACC receive-PAST I was given a good impression by his talk.',\n",
       " 'his-GEN talk-DAT be impressed-ACT,',\n",
       " 'In (Kaji and Kurohashi, 2004), the target expression is restricted only to the LVC itself (also see Figure 1).',\n",
       " '.] denotes that the \"Agent\" causes the state change.',\n",
       " 'Its scale is considerably larger than any other existing collections of verb LCS entries.',\n",
       " 'In spite of these advantages, our preliminary examination of the dictionary revealed that further refinements were needed.',\n",
       " '4 A sahen-noun is a verbal noun in Japanese, which acts as a verb in the form of \"sahen-noun + suru\". ',\n",
       " 'Treatment of \"Partner\": The dative case of \"hankou-suru (resist)\" and \"eikyo-suru (affect)\" does not indicate the \"Goal\" of the action but the \"Partner.\"',\n",
       " 'In contrast with \"ataeru (give),\" the nominative case of \"ukeru (receive)\" and \"eru (acquire)\" is the \"Goal\" of the \"Theme,\" while the ablative case indicates \"Source.\"',\n",
       " 'The ascriptive part of the change has to be described.',\n",
       " 'The latest version of the LCSdic is available from http://cl.it.okayama-u.ac.jp/rsc/lcs/',\n",
       " 'Ken-NOM film-DAT inspiration-ACC receive-PAST Ken received inspiration from the film. ',\n",
       " 'Ken-NOM film-DAT inspire-PAS, PAST Ken was inspired by the film. ',\n",
       " 'The process consists of the following three steps: ',\n",
       " 'Semantic analysis: The model first analyzes a given input sentence including an LVC to obtain its semantic structure in terms of the LCS representation.',\n",
       " 'In our example, this step generates LCS N 1 together with the supplement [BECOME',\n",
       " 'In the example shown in Figure 2, the nominative \"Ken\" fills the leftmost argument z.',\n",
       " 'Ken-NOM film-DAT inspiration-ACC receive-PAST Ken received inspiration from the film. ',\n",
       " 'As a result, \"Ken\" comes to the y\\' slot and \"eiga (film)\" comes to the x\\' slot 8 .',\n",
       " 'This process is repeated until the leftmost predicate in LCS N 0 or that in LCS V 1 is matched.',\n",
       " 'In the case of Figure 3, [BECOME [[Ken]z BE WITH]]  in LCS V 1 remains non-transfered.',\n",
       " 'Therefore, the \"passive\" voice is selected and case alternation (passivization) is applied.',\n",
       " 'Otherwise, no modification is applied.',\n",
       " 'LCS N 1 [BECOME [[Ken]z BE WITH]] +',\n",
       " \"[[film]x' ACT ON [Ken]y'] t. Ken-ga eiga-ni shigeki-s-are-ta. Ken-NOM film-DAT inspire-PAS, PAST Ken was inspired by the film.\",\n",
       " 'The sentences used in the experiment were collected in the following way: Step 1.',\n",
       " 'The remaining 6 candidates were not classified.',\n",
       " 'The precision of the paraphrase generation was 75.8% (621 / 819).',\n",
       " 'Table 3 lists the error sources.',\n",
       " 'Errors in predicate matching: To paraphrase (10s) below, \"CONTROL\" in LCS V 1 must be matched with \"CONTROL\" in LCS N 0 , and x to x\\'.',\n",
       " 'The desired form of LCS N 1 is shown in (11).',\n",
       " '(10) s. kacho-ga buka-ni section-chief-NOM subordinate-DAT shiji-o dasu. order-ACC issue-PRES The section chief issues orders to his subordinates. ',\n",
       " 'The desired form of LCS N 1 is shown in ( 13).',\n",
       " 'time-DAT limitation-NOM exist-PRES There is a time limitation. ',\n",
       " 'In contrast to dative cases in English, in Japanese, the dative case has ambiguity.',\n",
       " 'However, the n, c, v in (15s) does not act as an LVC, while the same triplet in (16s) does.',\n",
       " 'meaning-NOM exist-PRES \"kennel\" has the meaning of doghouse.',\n",
       " '\"kennel\"-TOP doghouse-ACC mean-ACT, PRES \"kennel\" means doghouse. ',\n",
       " 'The above difference is caused by the polysemy of the nominalized verb \"imi\" that denotes \"worth\" in the context of (15s), but \"meaning\" in (16s).',\n",
       " 'Our model achieved an accuracy of 75.8% in selecting the voice and reassigning the cases. ',\n",
       " 'To make our paraphrasing model more accurate, further analysis is needed, especially for the LCS transformation stage described in Section 4.2.',\n",
       " 'earthquake-NOM building-DAT destroy-PAST The earthquake destroyed the building. ',\n",
       " 't. Jishin-de building-ga kowareta. earthquake-LOC building-NOM be destroyed-PAST The building was destroyed in the earthquake. ',\n",
       " '(18) s. Kare-wa kikai he-TOP machinesousa-ga jouzu-da. operation-NOM good-COPULA He is good at operating the machine. ',\n",
       " 'While previous work (Teufel et al., 2009;Athar, 2011;Athar and Teufel, 2012) record positive and negative sentiment about cited work, we record information about how cited documents are compared to each other.',\n",
       " 'In contrast to [1], we found clear detrimental effects of prophylaxis. ',\n",
       " 'This study corroborates a study [2] finding no evidence of cross-hemisphere invasions.  ',\n",
       " 'In the first case, the citation is an argument of some predicate (Figure 1, citation 1).',\n",
       " 'In the second case, the citation is parenthetically linked to a constituent (Figure 1, ci-tations 2, 3 and 4) ((Abu Jbara and Radev, 2012) refers to this case as non-syntactic).',\n",
       " 'These self-citations participate in the same citation relations as conventional citations.',\n",
       " 'In Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) and related approaches (Marcu, 2000), the discourse structure of a document forms a tree, with the root representing the document; internal nodes representing sections, paragraphs and multi-clause sentences, and leaves representing single clauses.',\n",
       " 'As in Figure 2, substituting the leaves of a discourse tree with predicate argument representations (or parses) results in a rooted graph for a document with words as leaves.',\n",
       " 'We recognize a third DISCOURSE relation, EX-PAND, which does not directly link to either of our citation relations.',\n",
       " 'Each file in our corpus of PubMed scientific articles has the citations premarked.',\n",
       " 'For each sentence, we find: (a) lexical signals; (b) sentence dividers (semi-colons, coordinate/subordinate conjunctions); and (c) citations (conventional and self-citations).',\n",
       " 'We maintain a dictionary of lexical signals, which includes: surface forms, local disambiguating information, part of speech (POS) and CITA-TION relation (EXPAND, CORROBORATE or CONTRAST).',\n",
       " 'When an SCONJ occurs at the beginning of a clause, the clause must be divided at a centrally-located comma.',\n",
       " 'The 2 cases of SCONJ are: For Case 1, ARG1 is 20 and ARG2 is 21; for case 2, both 23 and 24 are ARG1s and 22 is ARG2.',\n",
       " 'Our approach to SCONJ is essentially the same as that of (Marcu, 2000) among others. ',\n",
       " 'However, as there is not an EXPAND relation between sentences B and C, these potential ARG1s are not stored for connectives in subsequent sentences. ',\n",
       " 'Cross-sentence CONTRAST and CORROBO-RATE signals (St SLink in Figure 1) are stored in addition to previous ARG1s up to that point.',\n",
       " 'Figure 3 is one such example: the citations in the the sentence preceding In contrast are ARG1s and the citations following the signal are ARG2s: both citations in the sentence and in subsequent sentences.',\n",
       " 'Storage of these elements is emptied in the absence of EXPAND. ',\n",
       " 'This creates separate multi-sentence units for CONTRAST and CORROBORATE relations, since all storage is emptied in the absence of cross-sentence EX-PAND relations; (2) the sets of citations for proposed ARG1 and ARG2 cannot have a member in common -this rules out relations that do not make sense (a document contrasting with itself) or that are uninformative (a document corroborating with itself).',\n",
       " 'The CORROBORATE and CONTRAST entries are signals which license citation relations, the entries being based on their roles in syntax and discourse structure.',\n",
       " 'We evaluated (CORROBORATE, CONTRAST) relations between citations, but not discourse relations between sentences (CAUSE, CONTRAST, EXPAND) or predicate argument relations.',\n",
       " 'We achieve the highest accuracy for relations linking citations across adjacent sentences.',\n",
       " 'The main contribution of this paper is the working out of the details of how to identify citation relations.',\n",
       " 'A novel feature of this model is that the alignments it produces are hierarchically arranged.',\n",
       " 'Each of the parts is translated by a recursive application of the model and the resulting translation are then concatenated.',\n",
       " 'This recursive procedure gives its name to the model: MAR, which comes from \"Modelo de Alineamiento Recursivo\", which is Spanish for \"Recursive Alignment Model\". ',\n",
       " 'However, the parametrizations of SITGs and the MAR are completely different.',\n",
       " 'In contrast, our model clearly distinguishes the input and output sentences and the parameters are based on observable properties of the strings (their lengths and the words composing them).',\n",
       " 'Sentences are taken as concatenations of symbols (words) and represented using a letter and a small bar, like in x.',\n",
       " 'The individual words are designed by the name of the sentence and a subindex indicating the position, so x = x 1 x 2 . . .',\n",
       " 'The length of a sentence is indicated by |x|.',\n",
       " 'Segments of a sentence are denoted by xj',\n",
       " 'For the substrings of the form x|x|',\n",
       " 'The elements of this set are pairs (x, ȳ) where ȳ is a possible translation for x.',\n",
       " 'A word of warning is in order here.',\n",
       " 'The model we are going to present has an important difference with the original: we do not use the empty word.',\n",
       " 'This is a virtual word which does not belong to the vocabulary of the task and that is added to the beginning of each sentence in order to allow words in the output that cannot be justified by the words in the input.',\n",
       " 'In the second case, three steps are taken: a cut point of x is defined, each of the resulting parts are translated, and the corresponding translations are concatenated.',\n",
       " 'For the translation of the second step, the same process is recursively applied.',\n",
       " 'The first is the selection of the model.',\n",
       " 'The fourth is the translation of each of the halves of x.',\n",
       " 'c+1 | b, d, x, ȳc 1 ), where pref(ȳ) is the set of prefixes of ȳ.',\n",
       " 'That is, we cat set up two tables, M I and M M , so that Pr(M = IBM | x)',\n",
       " 'We use a table B such that: Pr(b | x)',\n",
       " 'Finally, a probability must be assigned to the translation of the two halves.',\n",
       " 'This is correct as long as V is a polynomial in P .',\n",
       " 'In the experiments we have followed some heuristics in order not to reestimate certain parameters: •',\n",
       " 'and therefore there is no need to estimate them. ',\n",
       " 'As a consequence, the values of ε for lengths above the same threshold, need not be reestimated. ',\n",
       " 'The values of t for pairs of words with counts under a certain threshold are not reestimated. ',\n",
       " 'Furthermore, during the computation of counts, the recursion is cut on those substring pairs where the value of the probability for the translation is very small.',\n",
       " 'Other source of optimization is the realization that for computing p T (ȳ | x), it is necessary to compute the value of p I for each possible pair (x ie ib , ȳoe ob ) (where ib, ie, ob and oe stand for input begin, input end, output begin and output end, respectively).',\n",
       " 'The translation is produced by looking for the substring of ȳ which has a length below l and which has the largest number of words aligned to positions between i and j.',\n",
       " 'The parameters of the MAR were trained using the algorithm above: first ten IBM model 1 iterations were used for giving initial values to the dictionary probabilities and then five more iterations for retraining the dictionary together with the rest of the parameters. ',\n",
       " 'The alignment of a pair has the form of a tree similar to the one in Figure 3 (this is one of the sentences from the Spanish-English part of the training corpus).',\n",
       " 'Each interior node has two children corresponding to the translation of the two parts in which the input sentence is divided.',\n",
       " 'The templates generated were those defined by the leaves.',\n",
       " 'Each template was assigned four weights 1 in order to use the pharaoh program.',\n",
       " 'For the templates obtained from the alignments, the first weight was the probability assigned to it by MAR, the second weight was the count for the template, i.e., the number of times that template was found in the corpus, the third weight was the normalized count, i.e., the number of times the template appeared in the corpus divided by the number of times the input part was present in the corpus, finally, the fourth weight was a small constant (10 −30 ).',\n",
       " 'For these, the first three weights were assigned the same small constant and the fourth was the probability of the translation of the pair obtained from the stochastic dictionary.',\n",
       " 'An automatic alignment for each corpus was also provided. ',\n",
       " 'The total number of sentences after the split is presented in Table 2.',\n",
       " \"Two different alignments were used: (a) the one provided in the definition of the task and (b) one obtained using GIZA++ (Och and Ney, 2003) to train an IBM's model 4.\",\n",
       " 'As it can be seen, the number of parts is very similar in both cases.',\n",
       " 'Again, the influence of the type of alignment was small.',\n",
       " 'The columns are for the probability given by the model, the counts of the templates, the normalized counts and the weight given to the dictionary.  ',\n",
       " 'Normalization of counts also had little impact.',\n",
       " 'It can be seen that, except for French, the influence of the initial alignment is very small.',\n",
       " 'The first is the influence of the split of the original corpora.',\n",
       " 'The Web interface includes search for words and phrases in the four languages used, and also displays all the contexts in which the word or phrase in question appears in the corpus.',\n",
       " 'The multilingual lexicon was then compared against the existing WordNets: PWN (Fellbaum, 1998) for English; BalkaNet (Tufis, 2000) for Czech, Romanian and Bulgarian.',\n",
       " 'Translations in the multilingual lexicon were then compared against the corresponding WordNet in Balka-Net (Tufis, 2000).',\n",
       " 'If all translations shared the same synset ID, the corresponding French translation was also assigned the same synset ID.',\n",
       " 'They used the Europarl parallel corpus and wordaligned a subset of it for four languages, English, German, French and Greek, using an off-the-shelf tool (GIZA++ (Och, 2003)).',\n",
       " 'English was used as the pivotal language.',\n",
       " 'Initially, all words are placed in the open list, and the closed list is empty.',\n",
       " 'Each processed word is transferred on to the closed list, which in the end, when the open list is empty, contains all words.',\n",
       " 'In other terms, all words forming a phrase and its translation into each language, are now indexed with the same ID.',\n",
       " 'The process is deterministic and is not prone to introducing errors on its own.',\n",
       " 'In other words, the quality of proto-synsets is only as good as the quality of word alignment, not worse.',\n",
       " 'Earlier research did not use this information to generate phrases from words (Fišer, 2007;Sagot, 2008).',\n",
       " 'This is a substantial figure which shows that phrase alignment can have a substantial impact on the overall result.',\n",
       " 'The quality of this alignment however cannot be tested without an appropriate annotated resource.',\n",
       " 'We made use of a resource which was part of the SemEval-2010 Task 3 on Cross-Lingual Word Sense Disambiguation (Lefever, 2009;Lefever, 2010a;Lefever, 2010b).',\n",
       " 'They also provided a sense inventory for each of the target nouns. ',\n",
       " 'It also contained combinations of words/phrases in all the six languages with semantics related to a particular meaning of the target word.',\n",
       " 'For instance, the word bank had five different meanings: Financial Institution, Supply/Stock, Sloping land beside water, Cisjordan, and group of similar objects (row/tiers).',\n",
       " 'The sentences were extracted from JRC-ACQUIS 2 and the British National Corpus (BNC) 3 .',\n",
       " 'The proposed translations were stored with their frequency counts, of how many times a word/phrase from the sense inventory was used to translate a target word for a given language. ',\n",
       " ...]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"sentence_certainty\"] >= 5].sentence.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "55baa790-5115-45ca-ab9f-9770a8d9c6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.boxplot(\"sentence_certainty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "85051a51-bc89-4043-b235-8466fea49036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As the excerpt in Figure 1 shows, the trigram \"天津港\" (Tianjin port) has no any label information, as it only occurs in unlabeled data, but fortunately its neighborhoods with similar syntax information, e.g., \"上海港\" (Shanghai port), \"广州 港\" (Guangzhou port), can assist to infer the correct tag \"M NN\".',\n",
       " 'There are no sentences expressing conflicting opinions about aspect terms (e.g., \"The screen is clear but small\"), nor are there any sentences that do not express opinions about their aspect terms (e.g., \"It has a 4.8-inch screen\").',\n",
       " 'It is worth pointing out that there were no lookup errors for the surface pattern method, even though it used the exact same lookup mechanism as the approach based on syntactic patterns (that did experience various lookup errors, as we have seen).',\n",
       " 'To our best knowledge, there is no mention of any investigation of diachronic changes of the four stylistic features we used in our study nor studies which describe automatic extraction of the features from the raw text corpora by using NLP techniques.',\n",
       " 'Thus, there is no Guster (the servant of Mr. Snagsby and Mrs. Snagsby) in the Finnish version of Bleak House but Molly, due to the wordplay.',\n",
       " 'For instance, there is no indication that a brick wall is a wall made of bricks, while a cheese knife is not a knife made of cheese, but rather a knife for cutting cheese (Girju et al., 2005). ',\n",
       " \"+ a • c) , there is no need to merge indices-so there is no need to use slow data structures such as hash maps for merging, and 3. compared with Bohnet (2010)'s approach, which uses a % (modulo) operator to gain the desired dimension, our approach uses & (bitwise mask), so it runs faster in common architectures.\",\n",
       " 'There is no bilingual pre-  (Antoun et al., 2020), mBERT (Devlin et al., 2019), XLM-RoBERTa (Conneau et al., 2020a), and GigaBERT (this work). ',\n",
       " \"In traditional Lithuanian dictionaries of idioms, there is no problem of MWE lemmatisation, because data are collected manually and represented following the rule that a verb of an idiom is provided in infinitive form (Paulauskas (ed), 2001), e.g.: Savo viet ą žinoti 'to know one's place', Vietos neturėti 'to have nowhere to go'.\",\n",
       " 'For hierarchical machine translation models (Chiang, 2005), there is no requirement for a syntactic relationship to exist between the lexicalised words of a rule and the words replaced by nonterminals, the only requirement being that substituted words form an SMT phrase (Koehn et al., 2003).',\n",
       " \"Further, there is no evidence of lenition in words such as vloeken 'to curse', spreken 'to speak', and zoeken 'to seek', which are lenited in German (fluchen, sprechen, suchen). \",\n",
       " 'With the development of neural models (Zhang et al., 2018c;He et al., 2018;Li et al., 2018;Cai et al., 2018;Zhang and Zhao, 2018), building an intelligent dialogue system as our personal assistant or chat companion, is no longer a fantasy, among which multi-turn natural language understanding still keeps extremely challenging, requiring the system to comprehend the conversation context and reply in an informative and coincident manner. ',\n",
       " 'Note that in (5) there is no dependency of e 6 = is on its predecessor e 5 = up and the empty word f 0 , but on its last aligned predecessor e 4 = us and the corresponding source word f 7 = uns.',\n",
       " 'A base phrase constituent has no children other than pre-terminal POS-tags, which all have a single terminal child, i.e., there is no internal structure in the base phrase involving non-POS non-terminals.',\n",
       " 'For example, English-speaking listeners have no difficulty with Zulu click contrasts (Best et al., 1988) or the Thai [W]- [7] vowel contrast (Tyler et al., 2014). ',\n",
       " 'For instance, there is no point to constructing features of the form {head POS=ADJ}∧{head POS=VERB} ∧ • • • ∧ {82A=SV} as the head POS takes a single value.',\n",
       " 'Although all languages in our sample shared constructions such as prepositional phrases and relative clauses, there is no evidence that the multilingual LM acquired abstract representations that enable transfer across those languages; if anything, the languages interfered with each other.',\n",
       " 'Each instance u ~ of one of the new trees introduced is replaced by one or more instances of t substituted into the appropriate tree u E I U A. Again, since TIGs do not treat the roots of initial trees in any special way, there is no problem converting any operation applied to the interior node of u ~ that corresponds to the root of t into an operation on the root of t. Further, if there is only one way to derive a given tree in G, there is no ambiguity in the mapping from derivations in G r to G, because there is no ambiguity in the mapping of u I to trees in G. The tree u ~ must be different from the trees that are generated by substituting t in other trees u, because u ~ contains complete information about the trees it was created from.',\n",
       " 'On the surface, there is no functional difference in system behavior between a subject\\'s use of a command to move the system onward (e.g., \"go on\" \"next\", \"continue\") and the use of an acknowledgment (\"okay,\" \"uh-huh\", or a repetition).',\n",
       " 'After this binding, as shown in figure 5, there is no A l/ \"(present tens (long) Japanese valency pattern for \"Ali,\" • refer to valency pattern unbound valency element in the valency structure for the predicate \"nagai (long)\".',\n",
       " 'A set of consistency checks showed that there are no crossing relations (i.e., no instances where for a causative hypernym C 1 and its hyponym C 2 , and a non-causative hypernym N 1 and its hyponym N 2 , C 1 causes N 2 and C 2 causes N 1 ).',\n",
       " 'Importantly, because MSO transductions are closed under composition, there is no breakdown of this process into a finite set of composite steps (such as those illustrated in Fig. 5) that are themselves MSO-definable.',\n",
       " 'In cases of other clinical care providers, there was no ownership on the part of the dictating physician, but of other members of the clinical care team e.g., \"Con-sulting Attending (Infection) thinks...\".',\n",
       " 'In contrast to English or French, there is no formal difference in German between adjectives used as predicates (e.g., Er ist schnell ) or as adverbs (e.g., Er fährt schnell ).',\n",
       " 'For the Frugally Pragmatic Agents 2, there is no data for the lexicon size of 15x10, an ambiguity level of 0.2 and entropy thresholds of 1.0 and 1.5 bits, as no agents went up from order 1 to order 2 in these conditions.',\n",
       " 'For the frugally pragmatic agents 2, there is no data for the lexicon size of 15x10, an ambiguity level of 0.2 and entropy thresholds of 1.0 and 1.5 bits, as no agents went up from an order of 1 to 2.',\n",
       " 'From a CLIR point of view, for single Kanji indexing, there is no need to (1) maintain a multilingual dictionary or thesaurus of words, (2) to extract words and morphemes, and (3) to employ machine learning and smoothing to prune trivial n-grams or to resolve ambiguity in word segmentation [21,34,22].',\n",
       " 'The results show that there is no interaction between textual relation and genre (F(48, 192)=1.070, p=0.366) as well as no main effect from genre (F(8, 32)=1.697, p=0.137).',\n",
       " 'The results show that there is no interaction between textual relation and genre (F(48, 144)=0.969, p=0.537) as well as no main effect from genre (F(8, 24)=2.062, p=0.082).',\n",
       " 'There is no prosodic break between oneword modifiers and their one-word partners or between a word-level argument and its predicate, because the two words are syntactically and semantically combined (marked \"#\"). ',\n",
       " 'In a language in which a Word-use is represented by a single arbitrary sign, such as a technical language, or a code like the International Code of Signals, there is no intra-linguistic information, not even recurrent signs, on which to base conceptual groupings.',\n",
       " 'For tasks where the student only has one way to ask questions (e.g., \"what do you mean\"), there is no need to perform hops of attention over candidates since the cardinality of A is just 1.',\n",
       " 'In the following steps, there is no action to make an additional arc between two different items in S i , and no arc is in {t → u, u → t} t,u∈S,t =u − Σ i .',\n",
       " 'Since we do not pre-train their ConvNets on an object recognition task, the dense representations u used to derive the message contain no bias towards any image-or scene-specific information (e.g, object color, shape or location).',\n",
       " 'As we can see, there is no directionality bias in the uniform tree model (all rows have constant probabilities), but in the R-COO parser, the probability of the right-most constituent a right-branching bias.',\n",
       " 'As another example with contextualized word embeddings, there are also no emoji or textual emoticons in the vocabulary list of BERT [6] by default and support for emoji is only recently added to the tokenizer.',\n",
       " 'Therefore, no additional neural networks are required for training in contrast to other models (e.g., the encoder in VAE (Kingma & Welling, 2014) or the discriminator in GAN (Goodfellow et al., 2014)).',\n",
       " \"To an untrained model, these strings of characters have no structure or semantic content whatsoever -nothing in the characters themselves conveys their semantics (e.g., that '2' is larger than '1') or the rules governing them (e.g., the correct order of operations). \",\n",
       " 'Concerning the MWE categories, there is no categories used only in the hateful speech or only in the non-hateful speech excepted for the cause light verb construction category, but this category is underrepresented).',\n",
       " \"As shown in Table 3, since plug-tagger switches tasks via the plugin vector on the input instead of changing the model's architecture and parameters, there is no need to redeploy the model when switching tasks.\",\n",
       " 'From a general point of view of the meaning of the word \"mediator\", there is no relation to cats (see the prediction made by the NLM trained on the CN+OIE-GP+NCD KB).',\n",
       " 'Because T5 is pre-trained to fill in the missing spans, there is no need to specific the number of [MASK] tokens here, which is more convenient than previous gradient-based prompt search methods (Wallace et al., 2019;Shin et al., 2020).',\n",
       " 'Indeed, there is no success without a generalizing and easyto-learn emergent language, or, in other words, a (linguistically) compositional emergent language [Brighton andKirby, 2001, Brighton, 2002].',\n",
       " 'Since the full language model will be finetuned (e.g., on 31 different tasks from 8 different domains), there is no need to include parameterefficient soft prompts as the additional trainable parameters (k 2 = 0).',\n",
       " 'Despite all these efforts in the audio-visual domain, there is no comparison to large-scale audio-based speech databases that cover more than a thousand languages with thousands of hours of data (Pratap et al., 2023;Zhang et al., 2023).',\n",
       " 'In GPST w/o surrogate , all constituent representations of non-terminals are replaced by embeddings of a placeholder COMP as in Transformer Grammars (Sartran et al., 2022), and thus there is no interaction between the composition model and the generative model (i.e., they are separately optimized).',\n",
       " '( b ) after iron depletion with phlebotomy , there were no active skin lesions , although hyperpigmentation , scarring , and milia ( especially over dorsal aspects of second and third interphalangeal joints ) persisted .',\n",
       " 'During the eight months of crowd-sourced annotating, there were no reported cases of hateful or toxic speech in the existing datasets nor were there any instances of offensive speech reported in the peerreviewing phase of new annotations. ']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"sentence_certainty\"] >= 5.9].sentence.values.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
