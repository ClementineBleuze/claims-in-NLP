id,submitter,authors,title,comments,journal-ref,doi,report-no,categories,license,abstract,versions,update_date,authors_parsed
2309.16039,Wenhan Xiong,"Wenhan Xiong, Jingyu Liu, Igor Molybog, Hejia Zhang, Prajjwal
  Bhargava, Rui Hou, Louis Martin, Rashi Rungta, Karthik Abinav Sankararaman,
  Barlas Oguz, Madian Khabsa, Han Fang, Yashar Mehdad, Sharan Narang, Kshitiz
  Malik, Angela Fan, Shruti Bhosale, Sergey Edunov, Mike Lewis, Sinong Wang,
  Hao Ma",Effective Long-Context Scaling of Foundation Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We present a series of long-context LLMs that support effective context
windows of up to 32,768 tokens. Our model series are built through continual
pretraining from Llama 2 with longer training sequences and on a dataset where
long texts are upsampled. We perform extensive evaluation on language modeling,
synthetic context probing tasks, and a wide range of research benchmarks. On
research benchmarks, our models achieve consistent improvements on most regular
tasks and significant improvements on long-context tasks over Llama 2. Notably,
with a cost-effective instruction tuning procedure that does not require
human-annotated long instruction data, the 70B variant can already surpass
gpt-3.5-turbo-16k's overall performance on a suite of long-context tasks.
Alongside these results, we provide an in-depth analysis on the individual
components of our method. We delve into Llama's position encodings and discuss
its limitation in modeling long dependencies. We also examine the impact of
various design choices in the pretraining process, including the data mix and
the training curriculum of sequence lengths -- our ablation experiments suggest
that having abundant long texts in the pretrain dataset is not the key to
achieving strong performance, and we empirically verify that long context
continual pretraining is more efficient and similarly effective compared to
pretraining from scratch with long sequences.
","[{'version': 'v1', 'created': 'Wed, 27 Sep 2023 21:41:49 GMT'}, {'version': 'v2', 'created': 'Tue, 17 Oct 2023 17:32:17 GMT'}, {'version': 'v3', 'created': 'Tue, 14 Nov 2023 01:40:13 GMT'}]",2023-11-15,"[['Xiong', 'Wenhan', ''], ['Liu', 'Jingyu', ''], ['Molybog', 'Igor', ''], ['Zhang', 'Hejia', ''], ['Bhargava', 'Prajjwal', ''], ['Hou', 'Rui', ''], ['Martin', 'Louis', ''], ['Rungta', 'Rashi', ''], ['Sankararaman', 'Karthik Abinav', ''], ['Oguz', 'Barlas', ''], ['Khabsa', 'Madian', ''], ['Fang', 'Han', ''], ['Mehdad', 'Yashar', ''], ['Narang', 'Sharan', ''], ['Malik', 'Kshitiz', ''], ['Fan', 'Angela', ''], ['Bhosale', 'Shruti', ''], ['Edunov', 'Sergey', ''], ['Lewis', 'Mike', ''], ['Wang', 'Sinong', ''], ['Ma', 'Hao', '']]"
2305.16433,Felix Petersen,"Felix Petersen, Moritz Schubotz, Andre Greiner-Petter, Bela Gipp",Neural Machine Translation for Mathematical Formulae,Published at ACL 2023,,,,cs.CL cs.SC stat.AP,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We tackle the problem of neural machine translation of mathematical formulae
between ambiguous presentation languages and unambiguous content languages.
Compared to neural machine translation on natural language, mathematical
formulae have a much smaller vocabulary and much longer sequences of symbols,
while their translation requires extreme precision to satisfy mathematical
information needs. In this work, we perform the tasks of translating from LaTeX
to Mathematica as well as from LaTeX to semantic LaTeX. While recurrent,
recursive, and transformer networks struggle with preserving all contained
information, we find that convolutional sequence-to-sequence networks achieve
95.1% and 90.7% exact matches, respectively.
","[{'version': 'v1', 'created': 'Thu, 25 May 2023 19:15:06 GMT'}]",2023-05-29,"[['Petersen', 'Felix', ''], ['Schubotz', 'Moritz', ''], ['Greiner-Petter', 'Andre', ''], ['Gipp', 'Bela', '']]"
1604.06650,Denis Gordeev,Rodmonga Potapova and Denis Gordeev,Detecting state of aggression in sentences using CNN,submitted for SPECOM-2016,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this article we study verbal expression of aggression and its detection
using machine learning and neural networks methods. We test our results using
our corpora of messages from anonymous imageboards. We also compare Random
forest classifier with convolutional neural network for ""Movie reviews with one
sentence per review"" corpus.
","[{'version': 'v1', 'created': 'Fri, 22 Apr 2016 13:33:08 GMT'}]",2016-04-25,"[['Potapova', 'Rodmonga', ''], ['Gordeev', 'Denis', '']]"
2305.09333,Yuzhou Peng,Yuzhou Peng,"Multi-modal Visual Understanding with Prompts for Semantic Information
  Disentanglement of Image",8 pages,,,,cs.CV cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multi-modal visual understanding of images with prompts involves using
various visual and textual cues to enhance the semantic understanding of
images. This approach combines both vision and language processing to generate
more accurate predictions and recognition of images. By utilizing prompt-based
techniques, models can learn to focus on certain features of an image to
extract useful information for downstream tasks. Additionally, multi-modal
understanding can improve upon single modality models by providing more robust
representations of images. Overall, the combination of visual and textual
information is a promising area of research for advancing image recognition and
understanding. In this paper we will try an amount of prompt design methods and
propose a new method for better extraction of semantic information
","[{'version': 'v1', 'created': 'Tue, 16 May 2023 10:15:44 GMT'}]",2023-05-17,"[['Peng', 'Yuzhou', '']]"
2003.04996,Fabio Massimo Zanzotto,"Fabio Massimo Zanzotto and Viviana Bono and Paola Vocca and Andrea
  Santilli and Danilo Croce and Giorgio Gambosi and Roberto Basili","GASP! Generating Abstracts of Scientific Papers from Abstracts of Cited
  Papers",8 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Creativity is one of the driving forces of human kind as it allows to break
current understanding to envision new ideas, which may revolutionize entire
fields of knowledge. Scientific research offers a challenging environment where
to learn a model for the creative process. In fact, scientific research is a
creative act in the formal settings of the scientific method and this creative
act is described in articles.
  In this paper, we dare to introduce the novel, scientifically and
philosophically challenging task of Generating Abstracts of Scientific Papers
from abstracts of cited papers (GASP) as a text-to-text task to investigate
scientific creativity, To foster research in this novel, challenging task, we
prepared a dataset by using services where that solve the problem of copyright
and, hence, the dataset is public available with its standard split. Finally,
we experimented with two vanilla summarization systems to start the analysis of
the complexity of the GASP task.
","[{'version': 'v1', 'created': 'Fri, 28 Feb 2020 14:58:41 GMT'}]",2020-03-12,"[['Zanzotto', 'Fabio Massimo', ''], ['Bono', 'Viviana', ''], ['Vocca', 'Paola', ''], ['Santilli', 'Andrea', ''], ['Croce', 'Danilo', ''], ['Gambosi', 'Giorgio', ''], ['Basili', 'Roberto', '']]"
2212.14548,Liwen Jing,"Bowen Zhang, Daijun Ding, Liwen Jing","How would Stance Detection Techniques Evolve after the Launch of
  ChatGPT?",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Stance detection refers to the task of extracting the standpoint (Favor,
Against or Neither) towards a target in given texts. Such research gains
increasing attention with the proliferation of social media contents. The
conventional framework of handling stance detection is converting it into text
classification tasks. Deep learning models have already replaced rule-based
models and traditional machine learning models in solving such problems.
Current deep neural networks are facing two main challenges which are
insufficient labeled data and information in social media posts and the
unexplainable nature of deep learning models. A new pre-trained language model
chatGPT was launched on Nov 30, 2022. For the stance detection tasks, our
experiments show that ChatGPT can achieve SOTA or similar performance for
commonly used datasets including SemEval-2016 and P-Stance. At the same time,
ChatGPT can provide explanation for its own prediction, which is beyond the
capability of any existing model. The explanations for the cases it cannot
provide classification results are especially useful. ChatGPT has the potential
to be the best AI model for stance detection tasks in NLP, or at least change
the research paradigm of this field. ChatGPT also opens up the possibility of
building explanatory AI for stance detection.
","[{'version': 'v1', 'created': 'Fri, 30 Dec 2022 05:03:15 GMT'}, {'version': 'v2', 'created': 'Sat, 18 Feb 2023 11:55:12 GMT'}, {'version': 'v3', 'created': 'Mon, 10 Apr 2023 11:43:12 GMT'}]",2023-04-11,"[['Zhang', 'Bowen', ''], ['Ding', 'Daijun', ''], ['Jing', 'Liwen', '']]"
2401.01667,Li Zhou,"Li Zhou, Wenyu Chen, Yong Cao, Dingyi Zeng, Wanlong Liu, Hong Qu",MLPs Compass: What is learned when MLPs are combined with PLMs?,Accepted by ICASSP 2024,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While Transformer-based pre-trained language models and their variants
exhibit strong semantic representation capabilities, the question of
comprehending the information gain derived from the additional components of
PLMs remains an open question in this field. Motivated by recent efforts that
prove Multilayer-Perceptrons (MLPs) modules achieving robust structural capture
capabilities, even outperforming Graph Neural Networks (GNNs), this paper aims
to quantify whether simple MLPs can further enhance the already potent ability
of PLMs to capture linguistic information. Specifically, we design a simple yet
effective probing framework containing MLPs components based on BERT structure
and conduct extensive experiments encompassing 10 probing tasks spanning three
distinct linguistic levels. The experimental results demonstrate that MLPs can
indeed enhance the comprehension of linguistic structure by PLMs. Our research
provides interpretable and valuable insights into crafting variations of PLMs
utilizing MLPs for tasks that emphasize diverse linguistic structures.
","[{'version': 'v1', 'created': 'Wed, 3 Jan 2024 11:06:01 GMT'}]",2024-01-04,"[['Zhou', 'Li', ''], ['Chen', 'Wenyu', ''], ['Cao', 'Yong', ''], ['Zeng', 'Dingyi', ''], ['Liu', 'Wanlong', ''], ['Qu', 'Hong', '']]"
2011.05864,Bohan Li,"Bohan Li and Hao Zhou and Junxian He and Mingxuan Wang and Yiming Yang
  and Lei Li",On the Sentence Embeddings from Pre-trained Language Models,EMNLP 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained contextual representations like BERT have achieved great success
in natural language processing. However, the sentence embeddings from the
pre-trained language models without fine-tuning have been found to poorly
capture semantic meaning of sentences. In this paper, we argue that the
semantic information in the BERT embeddings is not fully exploited. We first
reveal the theoretical connection between the masked language model
pre-training objective and the semantic similarity task theoretically, and then
analyze the BERT sentence embeddings empirically. We find that BERT always
induces a non-smooth anisotropic semantic space of sentences, which harms its
performance of semantic similarity. To address this issue, we propose to
transform the anisotropic sentence embedding distribution to a smooth and
isotropic Gaussian distribution through normalizing flows that are learned with
an unsupervised objective. Experimental results show that our proposed
BERT-flow method obtains significant performance gains over the
state-of-the-art sentence embeddings on a variety of semantic textual
similarity tasks. The code is available at
https://github.com/bohanli/BERT-flow.
","[{'version': 'v1', 'created': 'Mon, 2 Nov 2020 13:14:57 GMT'}]",2020-11-12,"[['Li', 'Bohan', ''], ['Zhou', 'Hao', ''], ['He', 'Junxian', ''], ['Wang', 'Mingxuan', ''], ['Yang', 'Yiming', ''], ['Li', 'Lei', '']]"
2402.05195,Maitreya Patel,"Maitreya Patel, Sangmin Jung, Chitta Baral, Yezhou Yang","$\lambda$-ECLIPSE: Multi-Concept Personalized Text-to-Image Diffusion
  Models by Leveraging CLIP Latent Space",Project page: https://eclipse-t2i.github.io/Lambda-ECLIPSE/,,,,cs.CV cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Despite the recent advances in personalized text-to-image (P-T2I) generative
models, subject-driven T2I remains challenging. The primary bottlenecks include
1) Intensive training resource requirements, 2) Hyper-parameter sensitivity
leading to inconsistent outputs, and 3) Balancing the intricacies of novel
visual concept and composition alignment. We start by re-iterating the core
philosophy of T2I diffusion models to address the above limitations.
Predominantly, contemporary subject-driven T2I approaches hinge on Latent
Diffusion Models (LDMs), which facilitate T2I mapping through cross-attention
layers. While LDMs offer distinct advantages, P-T2I methods' reliance on the
latent space of these diffusion models significantly escalates resource
demands, leading to inconsistent results and necessitating numerous iterations
for a single desired image. Recently, ECLIPSE has demonstrated a more
resource-efficient pathway for training UnCLIP-based T2I models, circumventing
the need for diffusion text-to-image priors. Building on this, we introduce
$\lambda$-ECLIPSE. Our method illustrates that effective P-T2I does not
necessarily depend on the latent space of diffusion models. $\lambda$-ECLIPSE
achieves single, multi-subject, and edge-guided T2I personalization with just
34M parameters and is trained on a mere 74 GPU hours using 1.6M image-text
interleaved data. Through extensive experiments, we also establish that
$\lambda$-ECLIPSE surpasses existing baselines in composition alignment while
preserving concept alignment performance, even with significantly lower
resource utilization.
","[{'version': 'v1', 'created': 'Wed, 7 Feb 2024 19:07:10 GMT'}]",2024-02-09,"[['Patel', 'Maitreya', ''], ['Jung', 'Sangmin', ''], ['Baral', 'Chitta', ''], ['Yang', 'Yezhou', '']]"
1807.11689,Muhao Chen,"Muhao Chen, Changping Meng, Gang Huang and Carlo Zaniolo",Neural Article Pair Modeling for Wikipedia Sub-article Matching,"ECML-PKDD 2018. 16 pages, 4 figures",,,,cs.IR cs.CL cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Nowadays, editors tend to separate different subtopics of a long Wiki-pedia
article into multiple sub-articles. This separation seeks to improve human
readability. However, it also has a deleterious effect on many Wikipedia-based
tasks that rely on the article-as-concept assumption, which requires each
entity (or concept) to be described solely by one article. This underlying
assumption significantly simplifies knowledge representation and extraction,
and it is vital to many existing technologies such as automated knowledge base
construction, cross-lingual knowledge alignment, semantic search and data
lineage of Wikipedia entities. In this paper we provide an approach to match
the scattered sub-articles back to their corresponding main-articles, with the
intent of facilitating automated Wikipedia curation and processing. The
proposed model adopts a hierarchical learning structure that combines multiple
variants of neural document pair encoders with a comprehensive set of explicit
features. A large crowdsourced dataset is created to support the evaluation and
feature extraction for the task. Based on the large dataset, the proposed model
achieves promising results of cross-validation and significantly outperforms
previous approaches. Large-scale serving on the entire English Wikipedia also
proves the practicability and scalability of the proposed model by effectively
extracting a vast collection of newly paired main and sub-articles.
","[{'version': 'v1', 'created': 'Tue, 31 Jul 2018 07:19:36 GMT'}, {'version': 'v2', 'created': 'Sat, 4 Aug 2018 21:30:17 GMT'}]",2019-06-24,"[['Chen', 'Muhao', ''], ['Meng', 'Changping', ''], ['Huang', 'Gang', ''], ['Zaniolo', 'Carlo', '']]"
2305.16967,Bohao Yang,"Kun Zhao, Bohao Yang, Chenghua Lin, Wenge Rong, Aline Villavicencio
  and Xiaohui Cui","Evaluating Open-Domain Dialogues in Latent Space with Next Sentence
  Prediction and Mutual Information",Accepted at ACL2023,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The long-standing one-to-many issue of the open-domain dialogues poses
significant challenges for automatic evaluation methods, i.e., there may be
multiple suitable responses which differ in semantics for a given
conversational context. To tackle this challenge, we propose a novel
learning-based automatic evaluation metric (CMN), which can robustly evaluate
open-domain dialogues by augmenting Conditional Variational Autoencoders
(CVAEs) with a Next Sentence Prediction (NSP) objective and employing Mutual
Information (MI) to model the semantic similarity of text in the latent space.
Experimental results on two open-domain dialogue datasets demonstrate the
superiority of our method compared with a wide range of baselines, especially
in handling responses which are distant to the golden reference responses in
semantics.
","[{'version': 'v1', 'created': 'Fri, 26 May 2023 14:21:54 GMT'}, {'version': 'v2', 'created': 'Tue, 30 May 2023 15:25:13 GMT'}, {'version': 'v3', 'created': 'Sat, 10 Jun 2023 13:23:41 GMT'}]",2023-06-13,"[['Zhao', 'Kun', ''], ['Yang', 'Bohao', ''], ['Lin', 'Chenghua', ''], ['Rong', 'Wenge', ''], ['Villavicencio', 'Aline', ''], ['Cui', 'Xiaohui', '']]"
2310.12575,Dmitry Nikolaev,Dmitry Nikolaev and Tanise Ceron and Sebastian Pad\'o,"Multilingual estimation of political-party positioning: From label
  aggregation to long-input Transformers",Accepted to EMNLP 2023,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Scaling analysis is a technique in computational political science that
assigns a political actor (e.g. politician or party) a score on a predefined
scale based on a (typically long) body of text (e.g. a parliamentary speech or
an election manifesto). For example, political scientists have often used the
left--right scale to systematically analyse political landscapes of different
countries. NLP methods for automatic scaling analysis can find broad
application provided they (i) are able to deal with long texts and (ii) work
robustly across domains and languages. In this work, we implement and compare
two approaches to automatic scaling analysis of political-party manifestos:
label aggregation, a pipeline strategy relying on annotations of individual
statements from the manifestos, and long-input-Transformer-based models, which
compute scaling values directly from raw text. We carry out the analysis of the
Comparative Manifestos Project dataset across 41 countries and 27 languages and
find that the task can be efficiently solved by state-of-the-art models, with
label aggregation producing the best results.
","[{'version': 'v1', 'created': 'Thu, 19 Oct 2023 08:34:48 GMT'}]",2023-10-20,"[['Nikolaev', 'Dmitry', ''], ['Ceron', 'Tanise', ''], ['Padó', 'Sebastian', '']]"
2403.01069,Weizhe Yuan,Weizhe Yuan and Pengfei Liu and Matthias Gall\'e,LLMCRIT: Teaching Large Language Models to Use Criteria,"8 pages, 4 tables, 3 figures in the main text",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Humans follow criteria when they execute tasks, and these criteria are
directly used to assess the quality of task completion. Therefore, having
models learn to use criteria to provide feedback can help humans or models to
perform tasks better. However, existing research in this field tends to
consider only a limited set of criteria or quality assessment aspects. To fill
this gap, we propose a general framework that enables large language models
(LLMs) to use comprehensive criteria for a task in delivering natural language
feedback on task execution. In particular, we present a model-in-the-loop
framework that semi-automatically derives criteria from collected guidelines
for different writing tasks and constructs in-context demonstrations for each
criterion. We choose three tasks from real-world scenarios to operationalize
this idea: paper introduction writing, Python code writing, and Reddit post
writing, and evaluate our feedback generation framework using different LLMs.
The results reveal the fine-grained effects of incorporating criteria and
demonstrations and provide valuable insights on how to teach LLMs to use
criteria more effectively.
","[{'version': 'v1', 'created': 'Sat, 2 Mar 2024 02:25:55 GMT'}]",2024-03-05,"[['Yuan', 'Weizhe', ''], ['Liu', 'Pengfei', ''], ['Gallé', 'Matthias', '']]"
2006.03274,Ankit Gupta,"Ankit Gupta, Jonathan Berant",GMAT: Global Memory Augmentation for Transformers,,,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transformer-based models have become ubiquitous in natural language
processing thanks to their large capacity, innate parallelism and high
performance. The contextualizing component of a Transformer block is the
$\textit{pairwise dot-product}$ attention that has a large $\Omega(L^2)$ memory
requirement for length $L$ sequences, limiting its ability to process long
documents. This has been the subject of substantial interest recently, where
multiple approximations were proposed to reduce the quadratic memory
requirement using sparse attention matrices. In this work, we propose to
augment sparse Transformer blocks with a dense attention-based $\textit{global
memory}$ of length $M$ ($\ll L$) which provides an aggregate global view of the
entire input sequence to each position. Our augmentation has a manageable
$O(M\cdot(L+M))$ memory overhead, and can be seamlessly integrated with prior
sparse solutions. Moreover, global memory can also be used for sequence
compression, by representing a long input sequence with the memory
representations only. We empirically show that our method leads to substantial
improvement on a range of tasks, including (a) synthetic tasks that require
global reasoning, (b) masked language modeling, and (c) reading comprehension.
","[{'version': 'v1', 'created': 'Fri, 5 Jun 2020 07:50:40 GMT'}]",2020-06-08,"[['Gupta', 'Ankit', ''], ['Berant', 'Jonathan', '']]"
1712.03897,Kenneth Leidal,"Kenneth Leidal, David Harwath, and James Glass",Learning Modality-Invariant Representations for Speech and Images,,,,,cs.LG cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we explore the unsupervised learning of a semantic embedding
space for co-occurring sensory inputs. Specifically, we focus on the task of
learning a semantic vector space for both spoken and handwritten digits using
the TIDIGITs and MNIST datasets. Current techniques encode image and
audio/textual inputs directly to semantic embeddings. In contrast, our
technique maps an input to the mean and log variance vectors of a diagonal
Gaussian from which sample semantic embeddings are drawn. In addition to
encouraging semantic similarity between co-occurring inputs,our loss function
includes a regularization term borrowed from variational autoencoders (VAEs)
which drives the posterior distributions over embeddings to be unit Gaussian.
We can use this regularization term to filter out modality information while
preserving semantic information. We speculate this technique may be more
broadly applicable to other areas of cross-modality/domain information
retrieval and transfer learning.
","[{'version': 'v1', 'created': 'Mon, 11 Dec 2017 17:18:34 GMT'}]",2017-12-12,"[['Leidal', 'Kenneth', ''], ['Harwath', 'David', ''], ['Glass', 'James', '']]"
2212.00921,Bhargavi Paranjape,"Bhargavi Paranjape, Pradeep Dasigi, Vivek Srikumar, Luke Zettlemoyer
  and Hannaneh Hajishirzi","AGRO: Adversarial Discovery of Error-prone groups for Robust
  Optimization",,,,,cs.LG cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Models trained via empirical risk minimization (ERM) are known to rely on
spurious correlations between labels and task-independent input features,
resulting in poor generalization to distributional shifts. Group
distributionally robust optimization (G-DRO) can alleviate this problem by
minimizing the worst-case loss over a set of pre-defined groups over training
data. G-DRO successfully improves performance of the worst-group, where the
correlation does not hold. However, G-DRO assumes that the spurious
correlations and associated worst groups are known in advance, making it
challenging to apply it to new tasks with potentially multiple unknown spurious
correlations. We propose AGRO -- Adversarial Group discovery for
Distributionally Robust Optimization -- an end-to-end approach that jointly
identifies error-prone groups and improves accuracy on them. AGRO equips G-DRO
with an adversarial slicing model to find a group assignment for training
examples which maximizes worst-case loss over the discovered groups. On the
WILDS benchmark, AGRO results in 8% higher model performance on average on
known worst-groups, compared to prior group discovery approaches used with
G-DRO. AGRO also improves out-of-distribution performance on SST2, QQP, and
MS-COCO -- datasets where potential spurious correlations are as yet
uncharacterized. Human evaluation of ARGO groups shows that they contain
well-defined, yet previously unstudied spurious correlations that lead to model
errors.
","[{'version': 'v1', 'created': 'Fri, 2 Dec 2022 00:57:03 GMT'}, {'version': 'v2', 'created': 'Thu, 8 Dec 2022 19:19:23 GMT'}]",2022-12-12,"[['Paranjape', 'Bhargavi', ''], ['Dasigi', 'Pradeep', ''], ['Srikumar', 'Vivek', ''], ['Zettlemoyer', 'Luke', ''], ['Hajishirzi', 'Hannaneh', '']]"
2008.06208,Taewoo Lee,"Taewoo Lee, Min-Joong Lee, Tae Gyoon Kang, Seokyeoung Jung, Minseok
  Kwon, Yeona Hong, Jungin Lee, Kyoung-Gu Woo, Ho-Gyeong Kim, Jiseung Jeong,
  Jihyun Lee, Hosik Lee, Young Sang Choi",Adaptable Multi-Domain Language Model for Transformer ASR,"This paper is accepted for presentation at IEEE International
  Conference on Acoustics, Speech and Signal Processing (IEEE ICASSP), 2021",,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose an adapter based multi-domain Transformer based language model
(LM) for Transformer ASR. The model consists of a big size common LM and small
size adapters. The model can perform multi-domain adaptation with only the
small size adapters and its related layers. The proposed model can reuse the
full fine-tuned LM which is fine-tuned using all layers of an original model.
The proposed LM can be expanded to new domains by adding about 2% of parameters
for a first domain and 13% parameters for after second domain. The proposed
model is also effective in reducing the model maintenance cost because it is
possible to omit the costly and time-consuming common LM pre-training process.
Using proposed adapter based approach, we observed that a general LM with
adapter can outperform a dedicated music domain LM in terms of word error rate
(WER).
","[{'version': 'v1', 'created': 'Fri, 14 Aug 2020 06:33:26 GMT'}, {'version': 'v2', 'created': 'Thu, 11 Feb 2021 03:17:30 GMT'}]",2021-02-12,"[['Lee', 'Taewoo', ''], ['Lee', 'Min-Joong', ''], ['Kang', 'Tae Gyoon', ''], ['Jung', 'Seokyeoung', ''], ['Kwon', 'Minseok', ''], ['Hong', 'Yeona', ''], ['Lee', 'Jungin', ''], ['Woo', 'Kyoung-Gu', ''], ['Kim', 'Ho-Gyeong', ''], ['Jeong', 'Jiseung', ''], ['Lee', 'Jihyun', ''], ['Lee', 'Hosik', ''], ['Choi', 'Young Sang', '']]"
1908.09982,Genta Indra Winata,"Genta Indra Winata, Andrea Madotto, Jamin Shin, Elham J. Barezi,
  Pascale Fung","On the Effectiveness of Low-Rank Matrix Factorization for LSTM Model
  Compression",Accepted in PACLIC 2019,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite their ubiquity in NLP tasks, Long Short-Term Memory (LSTM) networks
suffer from computational inefficiencies caused by inherent unparallelizable
recurrences, which further aggravates as LSTMs require more parameters for
larger memory capacity. In this paper, we propose to apply low-rank matrix
factorization (MF) algorithms to different recurrences in LSTMs, and explore
the effectiveness on different NLP tasks and model components. We discover that
additive recurrence is more important than multiplicative recurrence, and
explain this by identifying meaningful correlations between matrix norms and
compression performance. We compare our approach across two settings: 1)
compressing core LSTM recurrences in language models, 2) compressing biLSTM
layers of ELMo evaluated in three downstream NLP tasks.
","[{'version': 'v1', 'created': 'Tue, 27 Aug 2019 01:52:07 GMT'}]",2019-08-28,"[['Winata', 'Genta Indra', ''], ['Madotto', 'Andrea', ''], ['Shin', 'Jamin', ''], ['Barezi', 'Elham J.', ''], ['Fung', 'Pascale', '']]"
2302.04391,Tong Guo,Tong Guo,The Re-Label Method For Data-Centric Machine Learning,,,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In industry deep learning application, our manually labeled data has a
certain number of noisy data. To solve this problem and achieve more than 90
score in dev dataset, we present a simple method to find the noisy data and
re-label the noisy data by human, given the model predictions as references in
human labeling. In this paper, we illustrate our idea for a broad set of deep
learning tasks, includes classification, sequence tagging, object detection,
sequence generation, click-through rate prediction. The dev dataset evaluation
results and human evaluation results verify our idea.
","[{'version': 'v1', 'created': 'Thu, 9 Feb 2023 01:09:57 GMT'}, {'version': 'v2', 'created': 'Sat, 6 May 2023 01:27:14 GMT'}, {'version': 'v3', 'created': 'Tue, 4 Jul 2023 12:46:48 GMT'}, {'version': 'v4', 'created': 'Fri, 14 Jul 2023 10:19:45 GMT'}, {'version': 'v5', 'created': 'Mon, 28 Aug 2023 08:02:47 GMT'}, {'version': 'v6', 'created': 'Thu, 2 Nov 2023 03:46:34 GMT'}, {'version': 'v7', 'created': 'Sun, 14 Jan 2024 13:50:20 GMT'}]",2024-01-17,"[['Guo', 'Tong', '']]"
2401.11864,Xunyu Zhu,"Xunyu Zhu, Jian Li, Yong Liu, Can Ma, Weiping Wang","Distilling Mathematical Reasoning Capabilities into Small Language
  Models",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This work addresses the challenge of democratizing advanced Large Language
Models (LLMs) by compressing their mathematical reasoning capabilities into
sub-billion parameter Small Language Models (SLMs) without compromising
performance. We introduce Equation-of-Thought Distillation (EoTD), a novel
technique that encapsulates the reasoning process into equation-based
representations to construct an EoTD dataset for fine-tuning SLMs.
Additionally, we propose the Ensemble Thoughts Distillation (ETD) framework to
enhance the reasoning performance of SLMs. This involves creating a reasoning
dataset with multiple thought processes, including Chain-of-Thought (CoT),
Program-of-Thought (PoT), and Equation-of-Thought (EoT), and using it for
fine-tuning. Our experimental findings demonstrate that EoTD significantly
boosts the reasoning abilities of SLMs, while ETD enables these models to
achieve state-of-the-art reasoning performance.
","[{'version': 'v1', 'created': 'Mon, 22 Jan 2024 11:37:18 GMT'}, {'version': 'v2', 'created': 'Mon, 29 Jan 2024 10:53:36 GMT'}, {'version': 'v3', 'created': 'Wed, 31 Jan 2024 03:50:07 GMT'}, {'version': 'v4', 'created': 'Thu, 1 Feb 2024 18:16:04 GMT'}]",2024-02-02,"[['Zhu', 'Xunyu', ''], ['Li', 'Jian', ''], ['Liu', 'Yong', ''], ['Ma', 'Can', ''], ['Wang', 'Weiping', '']]"
2308.04857,Yarik Menchaca Resendiz,Yarik Menchaca Resendiz and Roman Klinger,"Emotion-Conditioned Text Generation through Automatic Prompt
  Optimization",,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Conditional natural language generation methods often require either
expensive fine-tuning or training a large language model from scratch. Both are
unlikely to lead to good results without a substantial amount of data and
computational resources. Prompt learning without changing the parameters of a
large language model presents a promising alternative. It is a cost-effective
approach, while still achieving competitive results. While this procedure is
now established for zero- and few-shot text classification and structured
prediction, it has received limited attention in conditional text generation.
We present the first automatic prompt optimization approach for
emotion-conditioned text generation with instruction-fine-tuned models. Our
method uses an iterative optimization procedure that changes the prompt by
adding, removing, or replacing tokens. As objective function, we only require a
text classifier that measures the realization of the conditional variable in
the generated text. We evaluate the method on emotion-conditioned text
generation with a focus on event reports and compare it to manually designed
prompts that also act as the seed for the optimization procedure. The optimized
prompts achieve 0.75 macro-average F1 to fulfill the emotion condition in
contrast to manually designed seed prompts with only 0.22 macro-average F1.
","[{'version': 'v1', 'created': 'Wed, 9 Aug 2023 10:42:38 GMT'}]",2023-08-10,"[['Resendiz', 'Yarik Menchaca', ''], ['Klinger', 'Roman', '']]"
2112.06462,Injy Hamed,"Injy Hamed, Alia El Bolock, Nader Rizk, Cornelia Herbert, Slim
  Abdennadher, Ngoc Thang Vu","Predicting User Code-Switching Level from Sociological and Psychological
  Profiles","To be published in the proceedings of the International Conference on
  Asian Language Information Processing",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Multilingual speakers tend to alternate between languages within a
conversation, a phenomenon referred to as ""code-switching"" (CS). CS is a
complex phenomenon that not only encompasses linguistic challenges, but also
contains a great deal of complexity in terms of its dynamic behaviour across
speakers. This dynamic behaviour has been studied by sociologists and
psychologists, identifying factors affecting CS. In this paper, we provide an
empirical user study on Arabic-English CS, where we show the correlation
between users' CS frequency and character traits. We use machine learning (ML)
to validate the findings, informing and confirming existing theories. The
predictive models were able to predict users' CS frequency with an accuracy
higher than 55%, where travel experiences and personality traits played the
biggest role in the modeling process.
","[{'version': 'v1', 'created': 'Mon, 13 Dec 2021 07:36:02 GMT'}]",2021-12-14,"[['Hamed', 'Injy', ''], ['Bolock', 'Alia El', ''], ['Rizk', 'Nader', ''], ['Herbert', 'Cornelia', ''], ['Abdennadher', 'Slim', ''], ['Vu', 'Ngoc Thang', '']]"
2004.00150,Mohammed Ibrahim,"Mohammed Ibrahim, Susan Gauch, Omar Salman, Mohammed Alqahatani",Enriching Consumer Health Vocabulary Using Enhanced GloVe Word Embedding,,,,,cs.CL cs.IR cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Open-Access and Collaborative Consumer Health Vocabulary (OAC CHV, or CHV for
short), is a collection of medical terms written in plain English. It provides
a list of simple, easy, and clear terms that laymen prefer to use rather than
an equivalent professional medical term. The National Library of Medicine (NLM)
has integrated and mapped the CHV terms to their Unified Medical Language
System (UMLS). These CHV terms mapped to 56000 professional concepts on the
UMLS. We found that about 48% of these laymen's terms are still jargon and
matched with the professional terms on the UMLS. In this paper, we present an
enhanced word embedding technique that generates new CHV terms from a
consumer-generated text. We downloaded our corpus from a healthcare social
media and evaluated our new method based on iterative feedback to word
embedding using ground truth built from the existing CHV terms. Our feedback
algorithm outperformed unmodified GLoVe and new CHV terms have been detected.
","[{'version': 'v1', 'created': 'Tue, 31 Mar 2020 22:50:24 GMT'}, {'version': 'v2', 'created': 'Mon, 13 Apr 2020 18:02:10 GMT'}]",2020-04-15,"[['Ibrahim', 'Mohammed', ''], ['Gauch', 'Susan', ''], ['Salman', 'Omar', ''], ['Alqahatani', 'Mohammed', '']]"
2307.07982,Sparsh Mittal,"Krishna Teja Chitty-Venkata, Sparsh Mittal, Murali Emani, Venkatram
  Vishwanath, Arun K. Somani",A Survey of Techniques for Optimizing Transformer Inference,,,,,cs.LG cs.AR cs.CL cs.CV,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Recent years have seen a phenomenal rise in performance and applications of
transformer neural networks. The family of transformer networks, including
Bidirectional Encoder Representations from Transformer (BERT), Generative
Pretrained Transformer (GPT) and Vision Transformer (ViT), have shown their
effectiveness across Natural Language Processing (NLP) and Computer Vision (CV)
domains. Transformer-based networks such as ChatGPT have impacted the lives of
common men. However, the quest for high predictive performance has led to an
exponential increase in transformers' memory and compute footprint. Researchers
have proposed techniques to optimize transformer inference at all levels of
abstraction. This paper presents a comprehensive survey of techniques for
optimizing the inference phase of transformer networks. We survey techniques
such as knowledge distillation, pruning, quantization, neural architecture
search and lightweight network design at the algorithmic level. We further
review hardware-level optimization techniques and the design of novel hardware
accelerators for transformers. We summarize the quantitative results on the
number of parameters/FLOPs and accuracy of several models/techniques to
showcase the tradeoff exercised by them. We also outline future directions in
this rapidly evolving field of research. We believe that this survey will
educate both novice and seasoned researchers and also spark a plethora of
research efforts in this field.
","[{'version': 'v1', 'created': 'Sun, 16 Jul 2023 08:50:50 GMT'}]",2023-07-18,"[['Chitty-Venkata', 'Krishna Teja', ''], ['Mittal', 'Sparsh', ''], ['Emani', 'Murali', ''], ['Vishwanath', 'Venkatram', ''], ['Somani', 'Arun K.', '']]"
2306.05861,Junyu Wang,Junyu Wang,"Efficient Encoder-Decoder and Dual-Path Conformer for Comprehensive
  Feature Learning in Speech Enhancement",Accepted at Interspeech2023,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current speech enhancement (SE) research has largely neglected channel
attention and spatial attention, and encoder-decoder architecture-based
networks have not adequately considered how to provide efficient inputs to the
intermediate enhancement layer. To address these issues, this paper proposes a
time-frequency (T-F) domain SE network (DPCFCS-Net) that incorporates improved
densely connected blocks, dual-path modules, convolution-augmented transformers
(conformers), channel attention, and spatial attention. Compared with previous
models, our proposed model has a more efficient encoder-decoder and can learn
comprehensive features. Experimental results on the VCTK+DEMAND dataset
demonstrate that our method outperforms existing techniques in SE performance.
Furthermore, the improved densely connected block and two dimensions attention
module developed in this work are highly adaptable and easily integrated into
existing networks.
","[{'version': 'v1', 'created': 'Fri, 9 Jun 2023 12:52:01 GMT'}]",2023-06-12,"[['Wang', 'Junyu', '']]"
2311.17041,Keunwoo Peter Yu,"Keunwoo Peter Yu, Zheyuan Zhang, Fengyuan Hu, Joyce Chai","Efficient In-Context Learning in Vision-Language Models for Egocentric
  Videos","10 pages, LaTeX; added acknowledgments",,,,cs.CV cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Recent advancements in text-only large language models (LLMs) have
highlighted the benefit of in-context learning for adapting to new tasks with a
few demonstrations. However, extending in-context learning to large
vision-language models (VLMs) using a huge amount of naturalistic
vision-language data has shown limited success, particularly for egocentric
videos, due to high data collection costs. We propose a novel training method
$\mathbb{E}$fficient $\mathbb{I}$n-context $\mathbb{L}$earning on
$\mathbb{E}$gocentric $\mathbb{V}$ideos ($\mathbb{EILEV}$), which elicits
in-context learning in VLMs for egocentric videos without requiring massive,
naturalistic egocentric video datasets. $\mathbb{EILEV}$ involves architectural
and training data adaptations to allow the model to process contexts
interleaved with video clips and narrations, sampling of in-context examples
with clusters of similar verbs and nouns, use of data with skewed marginal
distributions with a long tail of infrequent verbs and nouns, as well as
homonyms and synonyms. Our evaluations show that $\mathbb{EILEV}$-trained
models outperform larger VLMs trained on a huge amount of naturalistic data in
in-context learning. Furthermore, they can generalize to not only
out-of-distribution, but also novel, rare egocentric videos and texts via
in-context learning, demonstrating potential for applications requiring
cost-effective training, and rapid post-deployment adaptability. Our code and
demo are available at \url{https://github.com/yukw777/EILEV}.
","[{'version': 'v1', 'created': 'Tue, 28 Nov 2023 18:53:06 GMT'}, {'version': 'v2', 'created': 'Wed, 29 Nov 2023 15:52:55 GMT'}]",2023-11-30,"[['Yu', 'Keunwoo Peter', ''], ['Zhang', 'Zheyuan', ''], ['Hu', 'Fengyuan', ''], ['Chai', 'Joyce', '']]"
1507.07636,Sarath Chandar,"Sridhar Mahadevan, Sarath Chandar","Reasoning about Linguistic Regularities in Word Embeddings using Matrix
  Manifolds",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent work has explored methods for learning continuous vector space word
representations reflecting the underlying semantics of words. Simple vector
space arithmetic using cosine distances has been shown to capture certain types
of analogies, such as reasoning about plurals from singulars, past tense from
present tense, etc. In this paper, we introduce a new approach to capture
analogies in continuous word representations, based on modeling not just
individual word vectors, but rather the subspaces spanned by groups of words.
We exploit the property that the set of subspaces in n-dimensional Euclidean
space form a curved manifold space called the Grassmannian, a quotient subgroup
of the Lie group of rotations in n- dimensions. Based on this mathematical
model, we develop a modified cosine distance model based on geodesic kernels
that captures relation-specific distances across word categories. Our
experiments on analogy tasks show that our approach performs significantly
better than the previous approaches for the given task.
","[{'version': 'v1', 'created': 'Tue, 28 Jul 2015 03:51:43 GMT'}]",2015-07-29,"[['Mahadevan', 'Sridhar', ''], ['Chandar', 'Sarath', '']]"
2208.11484,Aly Mostafa,"Aly Mostafa, Omar Mohamed, Ali Ashraf, Ahmed Elbehery, Salma Jamal,
  Anas Salah, Amr S. Ghoneim","An End-to-End OCR Framework for Robust Arabic-Handwriting Recognition
  using a Novel Transformers-based Model and an Innovative 270 Million-Words
  Multi-Font Corpus of Classical Arabic with Diacritics",,,,,cs.CV cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This research is the second phase in a series of investigations on developing
an Optical Character Recognition (OCR) of Arabic historical documents and
examining how different modeling procedures interact with the problem. The
first research studied the effect of Transformers on our custom-built Arabic
dataset. One of the downsides of the first research was the size of the
training data, a mere 15000 images from our 30 million images, due to lack of
resources. Also, we add an image enhancement layer, time and space
optimization, and Post-Correction layer to aid the model in predicting the
correct word for the correct context. Notably, we propose an end-to-end text
recognition approach using Vision Transformers as an encoder, namely BEIT, and
vanilla Transformer as a decoder, eliminating CNNs for feature extraction and
reducing the model's complexity. The experiments show that our end-to-end model
outperforms Convolutions Backbones. The model attained a CER of 4.46%.
","[{'version': 'v1', 'created': 'Sat, 20 Aug 2022 22:21:19 GMT'}, {'version': 'v2', 'created': 'Fri, 26 Aug 2022 21:02:07 GMT'}]",2022-08-30,"[['Mostafa', 'Aly', ''], ['Mohamed', 'Omar', ''], ['Ashraf', 'Ali', ''], ['Elbehery', 'Ahmed', ''], ['Jamal', 'Salma', ''], ['Salah', 'Anas', ''], ['Ghoneim', 'Amr S.', '']]"
2402.17764,Shuming Ma,"Shuming Ma, Hongyu Wang, Lingxiao Ma, Lei Wang, Wenhui Wang, Shaohan
  Huang, Li Dong, Ruiping Wang, Jilong Xue, Furu Wei",The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits,Work in progress,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent research, such as BitNet, is paving the way for a new era of 1-bit
Large Language Models (LLMs). In this work, we introduce a 1-bit LLM variant,
namely BitNet b1.58, in which every single parameter (or weight) of the LLM is
ternary {-1, 0, 1}. It matches the full-precision (i.e., FP16 or BF16)
Transformer LLM with the same model size and training tokens in terms of both
perplexity and end-task performance, while being significantly more
cost-effective in terms of latency, memory, throughput, and energy consumption.
More profoundly, the 1.58-bit LLM defines a new scaling law and recipe for
training new generations of LLMs that are both high-performance and
cost-effective. Furthermore, it enables a new computation paradigm and opens
the door for designing specific hardware optimized for 1-bit LLMs.
","[{'version': 'v1', 'created': 'Tue, 27 Feb 2024 18:56:19 GMT'}]",2024-02-28,"[['Ma', 'Shuming', ''], ['Wang', 'Hongyu', ''], ['Ma', 'Lingxiao', ''], ['Wang', 'Lei', ''], ['Wang', 'Wenhui', ''], ['Huang', 'Shaohan', ''], ['Dong', 'Li', ''], ['Wang', 'Ruiping', ''], ['Xue', 'Jilong', ''], ['Wei', 'Furu', '']]"
2012.09392,Sangwoo Mo,"Seung Jun Moon, Sangwoo Mo, Kimin Lee, Jaeho Lee, Jinwoo Shin",MASKER: Masked Keyword Regularization for Reliable Text Classification,AAAI 2021. First two authors contributed equally,,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Pre-trained language models have achieved state-of-the-art accuracies on
various text classification tasks, e.g., sentiment analysis, natural language
inference, and semantic textual similarity. However, the reliability of the
fine-tuned text classifiers is an often underlooked performance criterion. For
instance, one may desire a model that can detect out-of-distribution (OOD)
samples (drawn far from training distribution) or be robust against domain
shifts. We claim that one central obstacle to the reliability is the
over-reliance of the model on a limited number of keywords, instead of looking
at the whole context. In particular, we find that (a) OOD samples often contain
in-distribution keywords, while (b) cross-domain samples may not always contain
keywords; over-relying on the keywords can be problematic for both cases. In
light of this observation, we propose a simple yet effective fine-tuning
method, coined masked keyword regularization (MASKER), that facilitates
context-based prediction. MASKER regularizes the model to reconstruct the
keywords from the rest of the words and make low-confidence predictions without
enough context. When applied to various pre-trained language models (e.g.,
BERT, RoBERTa, and ALBERT), we demonstrate that MASKER improves OOD detection
and cross-domain generalization without degrading classification accuracy. Code
is available at https://github.com/alinlab/MASKER.
","[{'version': 'v1', 'created': 'Thu, 17 Dec 2020 04:54:16 GMT'}]",2020-12-18,"[['Moon', 'Seung Jun', ''], ['Mo', 'Sangwoo', ''], ['Lee', 'Kimin', ''], ['Lee', 'Jaeho', ''], ['Shin', 'Jinwoo', '']]"
2402.03268,Xinyi Wang,"Xinyi Wang, Alfonso Amayuelas, Kexun Zhang, Liangming Pan, Wenhu Chen,
  William Yang Wang","Understanding the Reasoning Ability of Language Models From the
  Perspective of Reasoning Paths Aggregation",,,,,cs.LG cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained language models (LMs) are able to perform complex reasoning
without explicit fine-tuning. To understand how pre-training with a next-token
prediction objective contributes to the emergence of such reasoning capability,
we propose that we can view an LM as deriving new conclusions by aggregating
indirect reasoning paths seen at pre-training time. We found this perspective
effective in two important cases of reasoning: logic reasoning with knowledge
graphs (KGs) and math reasoning with math word problems (MWPs). More
specifically, we formalize the reasoning paths as random walk paths on the
knowledge/reasoning graphs. Analyses of learned LM distributions suggest that a
weighted sum of relevant random walk path probabilities is a reasonable way to
explain how LMs reason. Experiments and analysis on multiple KG and MWP
datasets reveal the effect of training on random walk paths and suggest that
augmenting unlabeled random walk reasoning paths can improve real-world
multi-step reasoning performance. code:
https://github.com/WANGXinyiLinda/LM_random_walk
","[{'version': 'v1', 'created': 'Mon, 5 Feb 2024 18:25:51 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Feb 2024 22:54:09 GMT'}]",2024-03-04,"[['Wang', 'Xinyi', ''], ['Amayuelas', 'Alfonso', ''], ['Zhang', 'Kexun', ''], ['Pan', 'Liangming', ''], ['Chen', 'Wenhu', ''], ['Wang', 'William Yang', '']]"
2105.02033,Anna Jonsson,"Johanna Bj\""orklund, Frank Drewes, and Anna Jonsson",Polynomial Graph Parsing with Non-Structural Reentrancies,23 pages with 7 figures,,,,cs.FL cs.CL cs.DM,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Graph-based semantic representations are valuable in natural language
processing, where it is often simple and effective to represent linguistic
concepts as nodes, and relations as edges between them. Several attempts has
been made to find a generative device that is sufficiently powerful to
represent languages of semantic graphs, while at the same allowing efficient
parsing. We add to this line of work by introducing graph extension grammar,
which consists of an algebra over graphs together with a regular tree grammar
that generates expressions over the operations of the algebra. Due to the
design of the operations, these grammars can generate graphs with
non-structural reentrancies; a type of node-sharing that is excessively common
in formalisms such as abstract meaning representation, but for which existing
devices offer little support. We provide a parsing algorithm for graph
extension grammars, which is proved to be correct and run in polynomial time.
","[{'version': 'v1', 'created': 'Wed, 5 May 2021 13:05:01 GMT'}, {'version': 'v2', 'created': 'Thu, 6 May 2021 11:20:22 GMT'}, {'version': 'v3', 'created': 'Fri, 7 May 2021 08:11:22 GMT'}]",2021-05-10,"[['Björklund', 'Johanna', ''], ['Drewes', 'Frank', ''], ['Jonsson', 'Anna', '']]"
2312.07280,Chen Huang,"Chen Huang, Peixin Qin, Wenqiang Lei, Jiancheng Lv","Towards Equipping Transformer with the Ability of Systematic
  Compositionality",Accepted to AAAI 2024. Paper with appendix,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  One of the key factors in language productivity and human cognition is the
ability of systematic compositionality, which refers to understanding composed
unseen examples of seen primitives. However, recent evidence reveals that the
Transformers have difficulty generalizing the composed context based on the
seen primitives. To this end, we take the first step to propose a
compositionality-aware Transformer called CAT and two novel pre-training tasks
to facilitate systematic compositionality. We tentatively provide a successful
implementation of a multi-layer CAT on the basis of the especially popular
BERT. The experimental results demonstrate that CAT outperforms baselines on
compositionality-aware tasks with minimal impact on the effectiveness on
standardized language understanding tasks.
","[{'version': 'v1', 'created': 'Tue, 12 Dec 2023 13:57:57 GMT'}]",2023-12-13,"[['Huang', 'Chen', ''], ['Qin', 'Peixin', ''], ['Lei', 'Wenqiang', ''], ['Lv', 'Jiancheng', '']]"
2110.00866,\.Ismail Aslan,"\.Ismail Aslan and Y\""ucel Top\c{c}u","A Case Study to Reveal if an Area of Interest has a Trend in Ongoing
  Tweets Using Word and Sentence Embeddings","25 pages, 7 figures",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In the field of Natural Language Processing, information extraction from
texts has been the objective of many researchers for years. Many different
techniques have been applied in order to reveal the opinion that a tweet might
have, thus understanding the sentiment of the small writing up to 280
characters. Other than figuring out the sentiment of a tweet, a study can also
focus on finding the correlation of the tweets with a certain area of interest,
which constitutes the purpose of this study. In order to reveal if an area of
interest has a trend in ongoing tweets, we have proposed an easily applicable
automated methodology in which the Daily Mean Similarity Scores that show the
similarity between the daily tweet corpus and the target words representing our
area of interest is calculated by using a na\""ive correlation-based technique
without training any Machine Learning Model. The Daily Mean Similarity Scores
have mainly based on cosine similarity and word/sentence embeddings computed by
Multilanguage Universal Sentence Encoder and showed main opinion stream of the
tweets with respect to a certain area of interest, which proves that an ongoing
trend of a specific subject on Twitter can easily be captured in almost real
time by using the proposed methodology in this study. We have also compared the
effectiveness of using word versus sentence embeddings while applying our
methodology and realized that both give almost the same results, whereas using
word embeddings requires less computational time than sentence embeddings, thus
being more effective. This paper will start with an introduction followed by
the background information about the basics, then continue with the explanation
of the proposed methodology and later on finish by interpreting the results and
concluding the findings.
","[{'version': 'v1', 'created': 'Sat, 2 Oct 2021 18:44:55 GMT'}]",2021-10-05,"[['Aslan', 'İsmail', ''], ['Topçu', 'Yücel', '']]"
2112.02265,Huy Nghiem,"Huy Nghiem, Fred Morstatter","""Stop Asian Hate!"" : Refining Detection of Anti-Asian Hate Speech During
  the COVID-19 Pandemic",,,,,cs.CL cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Content warning: This work displays examples of explicit and/or strongly
offensive language. Fueled by a surge of anti-Asian xenophobia and prejudice
during the COVID-19 pandemic, many have taken to social media to express these
negative sentiments. Identifying these posts is crucial for moderation and
understanding the nature of hate in online spaces. In this paper, we create and
annotate a corpus of tweets to explore anti-Asian hate speech with a finer
level of granularity. Our analysis reveals that this emergent form of hate
speech often eludes established approaches. To address this challenge, we
develop a model and an accompanied efficient training regimen that incorporates
agreement between annotators. Our approach produces up to 8.8% improvement in
macro F1 scores over a strong established baseline, indicating its
effectiveness even in settings where consensus among annotators is low. We
demonstrate that we are able to identify hate speech that is systematically
missed by established hate speech detectors.
","[{'version': 'v1', 'created': 'Sat, 4 Dec 2021 06:55:19 GMT'}, {'version': 'v2', 'created': 'Tue, 28 Jun 2022 06:58:32 GMT'}]",2022-06-29,"[['Nghiem', 'Huy', ''], ['Morstatter', 'Fred', '']]"
2112.04478,Chen Ju,"Chen Ju, Tengda Han, Kunhao Zheng, Ya Zhang, Weidi Xie",Prompting Visual-Language Models for Efficient Video Understanding,ECCV 2022. Project page: https://ju-chen.github.io/efficient-prompt/,,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Image-based visual-language (I-VL) pre-training has shown great success for
learning joint visual-textual representations from large-scale web data,
revealing remarkable ability for zero-shot generalisation. This paper presents
a simple but strong baseline to efficiently adapt the pre-trained I-VL model,
and exploit its powerful ability for resource-hungry video understanding tasks,
with minimal training. Specifically, we propose to optimise a few random
vectors, termed as continuous prompt vectors, that convert video-related tasks
into the same format as the pre-training objectives. In addition, to bridge the
gap between static images and videos, temporal information is encoded with
lightweight Transformers stacking on top of frame-wise visual features.
Experimentally, we conduct extensive ablation studies to analyse the critical
components. On 10 public benchmarks of action recognition, action localisation,
and text-video retrieval, across closed-set, few-shot, and zero-shot scenarios,
we achieve competitive or state-of-the-art performance to existing methods,
despite optimising significantly fewer parameters.
","[{'version': 'v1', 'created': 'Wed, 8 Dec 2021 18:58:16 GMT'}, {'version': 'v2', 'created': 'Fri, 15 Jul 2022 08:31:45 GMT'}]",2022-07-18,"[['Ju', 'Chen', ''], ['Han', 'Tengda', ''], ['Zheng', 'Kunhao', ''], ['Zhang', 'Ya', ''], ['Xie', 'Weidi', '']]"
2110.02200,Muktabh Mayank Srivastava,"Natesh Reddy, Muktabh Mayank Srivastava","Using Psuedolabels for training Sentiment Classifiers makes the model
  generalize better across datasets",,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  The problem statement addressed in this work is : For a public sentiment
classification API, how can we set up a classifier that works well on different
types of data, having limited ability to annotate data from across domains. We
show that given a large amount of unannotated data from across different
domains and pseudolabels on this dataset generated by a classifier trained on a
small annotated dataset from one domain, we can train a sentiment classifier
that generalizes better across different datasets.
","[{'version': 'v1', 'created': 'Tue, 5 Oct 2021 17:47:15 GMT'}]",2021-10-06,"[['Reddy', 'Natesh', ''], ['Srivastava', 'Muktabh Mayank', '']]"
2308.05696,Bowen Yu,"Yingxiu Zhao, Bowen Yu, Binyuan Hui, Haiyang Yu, Fei Huang, Yongbin
  Li, Nevin L. Zhang","A Preliminary Study of the Intrinsic Relationship between Complexity and
  Alignment",LREC-Coling 2024,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Training large language models (LLMs) with open-domain instruction data has
yielded remarkable success in aligning to end tasks and human preferences.
Extensive research has highlighted the importance of the quality and diversity
of instruction data. However, the impact of data complexity, as a crucial
metric, remains relatively unexplored from three aspects: (1)where the
sustainability of performance improvements with increasing complexity is
uncertain; (2)whether the improvement brought by complexity merely comes from
introducing more training tokens; and (3)where the potential benefits of
incorporating instructions from easy to difficult are not yet fully understood.
In this paper, we propose Tree-Instruct to systematically enhance the
instruction complexity in a controllable manner. By adding a specified number
of nodes to instructions' semantic trees, this approach not only yields new
instruction data from the modified tree but also allows us to control the
difficulty level of modified instructions. Our preliminary experiments reveal
the following insights: (1)Increasing complexity consistently leads to
sustained performance improvements of LLMs. (2)Under the same token budget, a
few complex instructions outperform diverse yet simple instructions.
(3)Curriculum instruction tuning might not yield the anticipated results;
focusing on increasing complexity appears to be the key.
","[{'version': 'v1', 'created': 'Thu, 10 Aug 2023 16:58:51 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Feb 2024 03:04:22 GMT'}]",2024-03-01,"[['Zhao', 'Yingxiu', ''], ['Yu', 'Bowen', ''], ['Hui', 'Binyuan', ''], ['Yu', 'Haiyang', ''], ['Huang', 'Fei', ''], ['Li', 'Yongbin', ''], ['Zhang', 'Nevin L.', '']]"
1908.10546,Bowen Shi,"Bowen Shi, Aurora Martinez Del Rio, Jonathan Keane, Diane Brentari,
  Greg Shakhnarovich, Karen Livescu",Fingerspelling recognition in the wild with iterative visual attention,ICCV 2019,,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sign language recognition is a challenging gesture sequence recognition
problem, characterized by quick and highly coarticulated motion. In this paper
we focus on recognition of fingerspelling sequences in American Sign Language
(ASL) videos collected in the wild, mainly from YouTube and Deaf social media.
Most previous work on sign language recognition has focused on controlled
settings where the data is recorded in a studio environment and the number of
signers is limited. Our work aims to address the challenges of real-life data,
reducing the need for detection or segmentation modules commonly used in this
domain. We propose an end-to-end model based on an iterative attention
mechanism, without explicit hand detection or segmentation. Our approach
dynamically focuses on increasingly high-resolution regions of interest. It
outperforms prior work by a large margin. We also introduce a newly collected
data set of crowdsourced annotations of fingerspelling in the wild, and show
that performance can be further improved with this additional data set.
","[{'version': 'v1', 'created': 'Wed, 28 Aug 2019 04:52:32 GMT'}]",2019-08-29,"[['Shi', 'Bowen', ''], ['Del Rio', 'Aurora Martinez', ''], ['Keane', 'Jonathan', ''], ['Brentari', 'Diane', ''], ['Shakhnarovich', 'Greg', ''], ['Livescu', 'Karen', '']]"
1903.02642,Adri\'an Javaloy Born\'as,Adri\'an Javaloy Born\'as and Gin\'es Garc\'ia Mateos,"A Character-Level Approach to the Text Normalization Problem Based on a
  New Causal Encoder","19 pages, 14 figures, journal",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text normalization is a ubiquitous process that appears as the first step of
many Natural Language Processing problems. However, previous Deep Learning
approaches have suffered from so-called silly errors, which are undetectable on
unsupervised frameworks, making those models unsuitable for deployment. In this
work, we make use of an attention-based encoder-decoder architecture that
overcomes these undetectable errors by using a fine-grained character-level
approach rather than a word-level one. Furthermore, our new general-purpose
encoder based on causal convolutions, called Causal Feature Extractor (CFE), is
introduced and compared to other common encoders. The experimental results show
the feasibility of this encoder, which leverages the attention mechanisms the
most and obtains better results in terms of accuracy, number of parameters and
convergence time. While our method results in a slightly worse initial accuracy
(92.74%), errors can be automatically detected and, thus, more readily solved,
obtaining a more robust model for deployment. Furthermore, there is still
plenty of room for future improvements that will push even further these
advantages.
","[{'version': 'v1', 'created': 'Wed, 6 Mar 2019 22:48:21 GMT'}]",2019-03-08,"[['Bornás', 'Adrián Javaloy', ''], ['Mateos', 'Ginés García', '']]"
2207.04453,"Mika H\""am\""al\""ainen","Teemu P\""oyh\""onen, Mika H\""am\""al\""ainen, Khalid Alnajjar","Multilingual Persuasion Detection: Video Games as an Invaluable Data
  Source for NLP",DiGRA 2022,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Role-playing games (RPGs) have a considerable amount of text in video game
dialogues. Quite often this text is semi-annotated by the game developers. In
this paper, we extract a multilingual dataset of persuasive dialogue from
several RPGs. We show the viability of this data in building a persuasion
detection system using a natural language processing (NLP) model called BERT.
We believe that video games have a lot of unused potential as a datasource for
a variety of NLP tasks. The code and data described in this paper are available
on Zenodo.
","[{'version': 'v1', 'created': 'Sun, 10 Jul 2022 12:38:02 GMT'}]",2022-07-12,"[['Pöyhönen', 'Teemu', ''], ['Hämäläinen', 'Mika', ''], ['Alnajjar', 'Khalid', '']]"
2305.14734,Bashar Alhafni,"Bashar Alhafni, Go Inoue, Christian Khairallah, Nizar Habash","Advancements in Arabic Grammatical Error Detection and Correction: An
  Empirical Investigation",Accepted to EMNLP 2023,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Grammatical error correction (GEC) is a well-explored problem in English with
many existing models and datasets. However, research on GEC in morphologically
rich languages has been limited due to challenges such as data scarcity and
language complexity. In this paper, we present the first results on Arabic GEC
using two newly developed Transformer-based pretrained sequence-to-sequence
models. We also define the task of multi-class Arabic grammatical error
detection (GED) and present the first results on multi-class Arabic GED. We
show that using GED information as an auxiliary input in GEC models improves
GEC performance across three datasets spanning different genres. Moreover, we
also investigate the use of contextual morphological preprocessing in aiding
GEC systems. Our models achieve SOTA results on two Arabic GEC shared task
datasets and establish a strong benchmark on a recently created dataset. We
make our code, data, and pretrained models publicly available.
","[{'version': 'v1', 'created': 'Wed, 24 May 2023 05:12:58 GMT'}, {'version': 'v2', 'created': 'Thu, 9 Nov 2023 16:10:59 GMT'}]",2023-11-10,"[['Alhafni', 'Bashar', ''], ['Inoue', 'Go', ''], ['Khairallah', 'Christian', ''], ['Habash', 'Nizar', '']]"
2206.04105,Raja Marjieh,"Raja Marjieh, Pol van Rijn, Ilia Sucholutsky, Theodore R. Sumers,
  Harin Lee, Thomas L. Griffiths, Nori Jacoby","Words are all you need? Language as an approximation for human
  similarity judgments","Accepted to ICLR 2023, final revision.
  https://openreview.net/forum?id=O-G91-4cMdv",,,,cs.CL cs.LG stat.ML,http://creativecommons.org/licenses/by/4.0/,"  Human similarity judgments are a powerful supervision signal for machine
learning applications based on techniques such as contrastive learning,
information retrieval, and model alignment, but classical methods for
collecting human similarity judgments are too expensive to be used at scale.
Recent methods propose using pre-trained deep neural networks (DNNs) to
approximate human similarity, but pre-trained DNNs may not be available for
certain domains (e.g., medical images, low-resource languages) and their
performance in approximating human similarity has not been extensively tested.
We conducted an evaluation of 611 pre-trained models across three domains --
images, audio, video -- and found that there is a large gap in performance
between human similarity judgments and pre-trained DNNs. To address this gap,
we propose a new class of similarity approximation methods based on language.
To collect the language data required by these new methods, we also developed
and validated a novel adaptive tag collection pipeline. We find that our
proposed language-based methods are significantly cheaper, in the number of
human judgments, than classical methods, but still improve performance over the
DNN-based methods. Finally, we also develop `stacked' methods that combine
language embeddings with DNN embeddings, and find that these consistently
provide the best approximations for human similarity across all three of our
modalities. Based on the results of this comprehensive study, we provide a
concise guide for researchers interested in collecting or approximating human
similarity data. To accompany this guide, we also release all of the similarity
and language data, a total of 206,339 human judgments, that we collected in our
experiments, along with a detailed breakdown of all modeling results.
","[{'version': 'v1', 'created': 'Wed, 8 Jun 2022 18:09:19 GMT'}, {'version': 'v2', 'created': 'Wed, 15 Jun 2022 17:31:17 GMT'}, {'version': 'v3', 'created': 'Thu, 23 Feb 2023 18:44:23 GMT'}]",2023-02-24,"[['Marjieh', 'Raja', ''], ['van Rijn', 'Pol', ''], ['Sucholutsky', 'Ilia', ''], ['Sumers', 'Theodore R.', ''], ['Lee', 'Harin', ''], ['Griffiths', 'Thomas L.', ''], ['Jacoby', 'Nori', '']]"
2102.13129,Michael A. Hedderich,"Michael A. Hedderich, Lukas Lange, Dietrich Klakow",ANEA: Distant Supervision for Low-Resource Named Entity Recognition,"Accepted at Practical Machine Learning For Developing Countries @
  ICLR 2021",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Distant supervision allows obtaining labeled training corpora for
low-resource settings where only limited hand-annotated data exists. However,
to be used effectively, the distant supervision must be easy to gather. In this
work, we present ANEA, a tool to automatically annotate named entities in texts
based on entity lists. It spans the whole pipeline from obtaining the lists to
analyzing the errors of the distant supervision. A tuning step allows the user
to improve the automatic annotation with their linguistic insights without
labelling or checking all tokens manually. In six low-resource scenarios, we
show that the F1-score can be increased by on average 18 points through
distantly supervised data obtained by ANEA.
","[{'version': 'v1', 'created': 'Thu, 25 Feb 2021 19:07:45 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Apr 2021 11:45:36 GMT'}]",2021-04-16,"[['Hedderich', 'Michael A.', ''], ['Lange', 'Lukas', ''], ['Klakow', 'Dietrich', '']]"
2306.09169,"Jan G\""opfert","Jan G\""opfert, Jann M. Weinand, Patrick Kuckertz, Detlef Stolten","Opportunities for Large Language Models and Discourse in Engineering
  Design",,,,,cs.CL cs.AI cs.CE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In recent years, large language models have achieved breakthroughs on a wide
range of benchmarks in natural language processing and continue to increase in
performance. Recently, the advances of large language models have raised
interest outside the natural language processing community and could have a
large impact on daily life. In this paper, we pose the question: How will large
language models and other foundation models shape the future product
development process? We provide the reader with an overview of the subject by
summarizing both recent advances in natural language processing and the use of
information technology in the engineering design process. We argue that
discourse should be regarded as the core of engineering design processes, and
therefore should be represented in a digital artifact. On this basis, we
describe how foundation models such as large language models could contribute
to the design discourse by automating parts thereof that involve creativity and
reasoning, and were previously reserved for humans. We describe how
simulations, experiments, topology optimizations, and other process steps can
be integrated into a machine-actionable, discourse-centric design process.
Finally, we outline the future research that will be necessary for the
implementation of the conceptualized framework.
","[{'version': 'v1', 'created': 'Thu, 15 Jun 2023 14:46:44 GMT'}]",2023-06-16,"[['Göpfert', 'Jan', ''], ['Weinand', 'Jann M.', ''], ['Kuckertz', 'Patrick', ''], ['Stolten', 'Detlef', '']]"
1610.09722,Jason Naradowsky,Jason Naradowsky and Sebastian Riedel,"Represent, Aggregate, and Constrain: A Novel Architecture for Machine
  Reading from Noisy Sources",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In order to extract event information from text, a machine reading model must
learn to accurately read and interpret the ways in which that information is
expressed. But it must also, as the human reader must, aggregate numerous
individual value hypotheses into a single coherent global analysis, applying
global constraints which reflect prior knowledge of the domain.
  In this work we focus on the task of extracting plane crash event information
from clusters of related news articles whose labels are derived via distant
supervision. Unlike previous machine reading work, we assume that while most
target values will occur frequently in most clusters, they may also be missing
or incorrect.
  We introduce a novel neural architecture to explicitly model the noisy nature
of the data and to deal with these aforementioned learning issues. Our models
are trained end-to-end and achieve an improvement of more than 12.1 F$_1$ over
previous work, despite using far less linguistic annotation. We apply factor
graph constraints to promote more coherent event analyses, with belief
propagation inference formulated within the transitions of a recurrent neural
network. We show this technique additionally improves maximum F$_1$ by up to
2.8 points, resulting in a relative improvement of $50\%$ over the previous
state-of-the-art.
","[{'version': 'v1', 'created': 'Sun, 30 Oct 2016 22:33:47 GMT'}]",2016-11-01,"[['Naradowsky', 'Jason', ''], ['Riedel', 'Sebastian', '']]"
1811.03511,Jiaxun Cai,"Zuchao Li, Jiaxun Cai, Hai Zhao",Effective Representation for Easy-First Dependency Parsing,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Easy-first parsing relies on subtree re-ranking to build the complete parse
tree. Whereas the intermediate state of parsing processing is represented by
various subtrees, whose internal structural information is the key lead for
later parsing action decisions, we explore a better representation for such
subtrees. In detail, this work introduces a bottom-up subtree encoding method
based on the child-sum tree-LSTM. Starting from an easy-first dependency parser
without other handcraft features, we show that the effective subtree encoder
does promote the parsing process, and can make a greedy search easy-first
parser achieve promising results on benchmark treebanks compared to
state-of-the-art baselines. Furthermore, with the help of the current
pre-training language model, we further improve the state-of-the-art results of
the easy-first approach.
","[{'version': 'v1', 'created': 'Thu, 8 Nov 2018 15:59:11 GMT'}, {'version': 'v2', 'created': 'Tue, 4 Jun 2019 01:10:30 GMT'}, {'version': 'v3', 'created': 'Tue, 11 Jun 2019 02:06:16 GMT'}]",2019-06-12,"[['Li', 'Zuchao', ''], ['Cai', 'Jiaxun', ''], ['Zhao', 'Hai', '']]"
2306.03067,Yujia Xie,"Yujia Xie, Xun Wang, Si-Qing Chen, Wayne Xiong, Pengcheng He",Interactive Editing for Text Summarization,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Summarizing lengthy documents is a common and essential task in our daily
lives. Although recent advancements in neural summarization models can assist
in crafting general-purpose summaries, human writers often have specific
requirements that call for a more customized approach. To address this need, we
introduce REVISE (Refinement and Editing via Iterative Summarization
Enhancement), an innovative framework designed to facilitate iterative editing
and refinement of draft summaries by human writers. Within our framework,
writers can effortlessly modify unsatisfactory segments at any location or
length and provide optional starting phrases -- our system will generate
coherent alternatives that seamlessly integrate with the existing summary. At
its core, REVISE incorporates a modified fill-in-the-middle model with the
encoder-decoder architecture while developing novel evaluation metrics tailored
for the summarization task. In essence, our framework empowers users to create
high-quality, personalized summaries by effectively harnessing both human
expertise and AI capabilities, ultimately transforming the summarization
process into a truly collaborative and adaptive experience.
","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 17:43:53 GMT'}]",2023-06-06,"[['Xie', 'Yujia', ''], ['Wang', 'Xun', ''], ['Chen', 'Si-Qing', ''], ['Xiong', 'Wayne', ''], ['He', 'Pengcheng', '']]"
1810.03459,Murali Karthick Baskar,"Jaejin Cho, Murali Karthick Baskar, Ruizhi Li, Matthew Wiesner, Sri
  Harish Mallidi, Nelson Yalta, Martin Karafiat, Shinji Watanabe, Takaaki Hori","Multilingual sequence-to-sequence speech recognition: architecture,
  transfer learning, and language modeling",,,,,cs.CL cs.LG cs.SD eess.AS,http://creativecommons.org/licenses/by/4.0/,"  Sequence-to-sequence (seq2seq) approach for low-resource ASR is a relatively
new direction in speech research. The approach benefits by performing model
training without using lexicon and alignments. However, this poses a new
problem of requiring more data compared to conventional DNN-HMM systems. In
this work, we attempt to use data from 10 BABEL languages to build a
multi-lingual seq2seq model as a prior model, and then port them towards 4
other BABEL languages using transfer learning approach. We also explore
different architectures for improving the prior multilingual seq2seq model. The
paper also discusses the effect of integrating a recurrent neural network
language model (RNNLM) with a seq2seq model during decoding. Experimental
results show that the transfer learning approach from the multilingual model
shows substantial gains over monolingual models across all 4 BABEL languages.
Incorporating an RNNLM also brings significant improvements in terms of %WER,
and achieves recognition performance comparable to the models trained with
twice more training data.
","[{'version': 'v1', 'created': 'Thu, 4 Oct 2018 08:53:42 GMT'}]",2018-10-09,"[['Cho', 'Jaejin', ''], ['Baskar', 'Murali Karthick', ''], ['Li', 'Ruizhi', ''], ['Wiesner', 'Matthew', ''], ['Mallidi', 'Sri Harish', ''], ['Yalta', 'Nelson', ''], ['Karafiat', 'Martin', ''], ['Watanabe', 'Shinji', ''], ['Hori', 'Takaaki', '']]"
2305.17304,Michael Levit,"Michael Levit, Sarangarajan Parthasarathy, Cem Aksoylar, Mohammad
  Sadegh Rasooli, Shuangyu Chang",External Language Model Integration for Factorized Neural Transducers,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We propose an adaptation method for factorized neural transducers (FNT) with
external language models. We demonstrate that both neural and n-gram external
LMs add significantly more value when linearly interpolated with predictor
output compared to shallow fusion, thus confirming that FNT forces the
predictor to act like regular language models. Further, we propose a method to
integrate class-based n-gram language models into FNT framework resulting in
accuracy gains similar to a hybrid setup. We show average gains of 18% WERR
with lexical adaptation across various scenarios and additive gains of up to
60% WERR in one entity-rich scenario through a combination of class-based
n-gram and neural LMs.
","[{'version': 'v1', 'created': 'Fri, 26 May 2023 23:30:21 GMT'}]",2023-05-30,"[['Levit', 'Michael', ''], ['Parthasarathy', 'Sarangarajan', ''], ['Aksoylar', 'Cem', ''], ['Rasooli', 'Mohammad Sadegh', ''], ['Chang', 'Shuangyu', '']]"
2008.05449,Sonia Laudanna,"Andrea Di Sorbo, Sonia Laudanna, Anna Vacca, Corrado A. Visaggio,
  Gerardo Canfora",Profiling Gas Consumption in Solidity Smart Contracts,,,,,cs.SE cs.CL cs.CR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Nowadays, more and more applications are developed for running on a
distributed ledger technology, namely dApps. The business logic of dApps is
usually implemented within smart contracts developed through Solidity, a
programming language for writing smart contracts on different blockchain
platforms, including the popular Ethereum. In Ethereum, the smart contracts run
on the machines of miners and the gas corresponds to the execution fee
compensating such computing resources. However, the deployment and execution
costs of a smart contract depend on the implementation choices done by
developers. Unappropriated design choices could lead to higher gas consumption
than necessary. In this paper, we (i) identify a set of 19 Solidity code smells
affecting the deployment and transaction costs of a smart contract, and (ii)
assess the relevance of such smells through a survey involving 34 participants.
On top of these smells, we propose GasMet, a suite of metrics for statically
evaluating the code quality of a smart contract from the gas consumption
perspective. An experiment involving 2,186 smart contracts demonstrates that
the proposed metrics have direct associations with deployment costs. The
metrics in our suite can be used for more easily identifying source code
segments that need optimizations.
","[{'version': 'v1', 'created': 'Wed, 12 Aug 2020 17:26:55 GMT'}, {'version': 'v2', 'created': 'Tue, 15 Dec 2020 10:24:04 GMT'}, {'version': 'v3', 'created': 'Wed, 15 Dec 2021 15:49:09 GMT'}]",2021-12-16,"[['Di Sorbo', 'Andrea', ''], ['Laudanna', 'Sonia', ''], ['Vacca', 'Anna', ''], ['Visaggio', 'Corrado A.', ''], ['Canfora', 'Gerardo', '']]"
2305.17442,Dawei Zhu,"Dawei Zhu, Xiaoyu Shen, Marius Mosbach, Andreas Stephan, Dietrich
  Klakow",Weaker Than You Think: A Critical Look at Weakly Supervised Learning,"ACL 2023, oral presentation",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Weakly supervised learning is a popular approach for training machine
learning models in low-resource settings. Instead of requesting high-quality
yet costly human annotations, it allows training models with noisy annotations
obtained from various weak sources. Recently, many sophisticated approaches
have been proposed for robust training under label noise, reporting impressive
results. In this paper, we revisit the setup of these approaches and find that
the benefits brought by these approaches are significantly overestimated.
Specifically, we find that the success of existing weakly supervised learning
approaches heavily relies on the availability of clean validation samples
which, as we show, can be leveraged much more efficiently by simply training on
them. After using these clean labels in training, the advantages of using these
sophisticated approaches are mostly wiped out. This remains true even when
reducing the size of the available clean data to just five samples per class,
making these approaches impractical. To understand the true value of weakly
supervised learning, we thoroughly analyze diverse NLP datasets and tasks to
ascertain when and why weakly supervised approaches work. Based on our
findings, we provide recommendations for future research.
","[{'version': 'v1', 'created': 'Sat, 27 May 2023 10:46:50 GMT'}, {'version': 'v2', 'created': 'Fri, 7 Jul 2023 13:56:53 GMT'}, {'version': 'v3', 'created': 'Sun, 17 Sep 2023 19:04:44 GMT'}]",2023-09-19,"[['Zhu', 'Dawei', ''], ['Shen', 'Xiaoyu', ''], ['Mosbach', 'Marius', ''], ['Stephan', 'Andreas', ''], ['Klakow', 'Dietrich', '']]"
2211.16853,John Glover,"John Glover, Federico Fancellu, Vasudevan Jagannathan, Matthew R.
  Gormley, Thomas Schaaf","Revisiting text decomposition methods for NLI-based factuality scoring
  of summaries","Generation, Evaluation & Metrics (GEM) Workshop 2022",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Scoring the factuality of a generated summary involves measuring the degree
to which a target text contains factual information using the input document as
support. Given the similarities in the problem formulation, previous work has
shown that Natural Language Inference models can be effectively repurposed to
perform this task. As these models are trained to score entailment at a
sentence level, several recent studies have shown that decomposing either the
input document or the summary into sentences helps with factuality scoring. But
is fine-grained decomposition always a winning strategy? In this paper we
systematically compare different granularities of decomposition -- from
document to sub-sentence level, and we show that the answer is no. Our results
show that incorporating additional context can yield improvement, but that this
does not necessarily apply to all datasets. We also show that small changes to
previously proposed entailment-based scoring methods can result in better
performance, highlighting the need for caution in model and methodology
selection for downstream tasks.
","[{'version': 'v1', 'created': 'Wed, 30 Nov 2022 09:54:37 GMT'}]",2022-12-01,"[['Glover', 'John', ''], ['Fancellu', 'Federico', ''], ['Jagannathan', 'Vasudevan', ''], ['Gormley', 'Matthew R.', ''], ['Schaaf', 'Thomas', '']]"
2210.07544,Paheli Bhattacharya,"Abhay Shukla, Paheli Bhattacharya, Soham Poddar, Rajdeep Mukherjee,
  Kripabandhu Ghosh, Pawan Goyal, Saptarshi Ghosh","Legal Case Document Summarization: Extractive and Abstractive Methods
  and their Evaluation","Accepted at The 2nd Conference of the Asia-Pacific Chapter of the
  Association for Computational Linguistics and the 12th International Joint
  Conference on Natural Language Processing (AACL-IJCNLP), 2022",,,,cs.CL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Summarization of legal case judgement documents is a challenging problem in
Legal NLP. However, not much analyses exist on how different families of
summarization models (e.g., extractive vs. abstractive) perform when applied to
legal case documents. This question is particularly important since many recent
transformer-based abstractive summarization models have restrictions on the
number of input tokens, and legal documents are known to be very long. Also, it
is an open question on how best to evaluate legal case document summarization
systems. In this paper, we carry out extensive experiments with several
extractive and abstractive summarization methods (both supervised and
unsupervised) over three legal summarization datasets that we have developed.
Our analyses, that includes evaluation by law practitioners, lead to several
interesting insights on legal summarization in specific and long document
summarization in general.
","[{'version': 'v1', 'created': 'Fri, 14 Oct 2022 05:43:08 GMT'}]",2022-10-17,"[['Shukla', 'Abhay', ''], ['Bhattacharya', 'Paheli', ''], ['Poddar', 'Soham', ''], ['Mukherjee', 'Rajdeep', ''], ['Ghosh', 'Kripabandhu', ''], ['Goyal', 'Pawan', ''], ['Ghosh', 'Saptarshi', '']]"
2402.02503,Ziyu Ma,"Ziyu Ma, Shutao Li, Bin Sun, Jianfei Cai, Zuxiang Long, and Fuyan Ma","GeReA: Question-Aware Prompt Captions for Knowledge-based Visual
  Question Answering",17 pages,,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Knowledge-based visual question answering (VQA) requires world knowledge
beyond the image for accurate answer. Recently, instead of extra knowledge
bases, a large language model (LLM) like GPT-3 is activated as an implicit
knowledge engine to jointly acquire and reason the necessary knowledge for
answering by converting images into textual information (e.g., captions and
answer candidates). However, such conversion may introduce irrelevant
information, which causes the LLM to misinterpret images and ignore visual
details crucial for accurate knowledge. We argue that multimodal large language
model (MLLM) is a better implicit knowledge engine than the LLM for its
superior capability of visual understanding. Despite this, how to activate the
capacity of MLLM as the implicit knowledge engine has not been explored yet.
Therefore, we propose GeReA, a generate-reason framework that prompts a MLLM
like InstructBLIP with question relevant vision and language information to
generate knowledge-relevant descriptions and reasons those descriptions for
knowledge-based VQA. Specifically, the question-relevant image regions and
question-specific manual prompts are encoded in the MLLM to generate the
knowledge relevant descriptions, referred to as question-aware prompt captions.
After that, the question-aware prompt captions, image-question pair, and
similar samples are sent into the multi-modal reasoning model to learn a joint
knowledge-image-question representation for answer prediction. GeReA unlocks
the use of MLLM as the implicit knowledge engine, surpassing all previous
state-of-the-art methods on OK-VQA and A-OKVQA datasets, with test accuracies
of 66.5% and 63.3% respectively. Our code will be released at
https://github.com/Upper9527/GeReA.
","[{'version': 'v1', 'created': 'Sun, 4 Feb 2024 14:28:23 GMT'}]",2024-02-07,"[['Ma', 'Ziyu', ''], ['Li', 'Shutao', ''], ['Sun', 'Bin', ''], ['Cai', 'Jianfei', ''], ['Long', 'Zuxiang', ''], ['Ma', 'Fuyan', '']]"
1603.07603,Fei Sun,"Fei Sun, Jiafeng Guo, Yanyan Lan, Jun Xu, and Xueqi Cheng",Semantic Regularities in Document Representations,6 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent work exhibited that distributed word representations are good at
capturing linguistic regularities in language. This allows vector-oriented
reasoning based on simple linear algebra between words. Since many different
methods have been proposed for learning document representations, it is natural
to ask whether there is also linear structure in these learned representations
to allow similar reasoning at document level. To answer this question, we
design a new document analogy task for testing the semantic regularities in
document representations, and conduct empirical evaluations over several
state-of-the-art document representation models. The results reveal that neural
embedding based document representations work better on this analogy task than
conventional methods, and we provide some preliminary explanations over these
observations.
","[{'version': 'v1', 'created': 'Thu, 24 Mar 2016 14:45:20 GMT'}]",2016-03-25,"[['Sun', 'Fei', ''], ['Guo', 'Jiafeng', ''], ['Lan', 'Yanyan', ''], ['Xu', 'Jun', ''], ['Cheng', 'Xueqi', '']]"
2312.09299,Mohammad Samragh,"Mohammad Samragh, Mehrdad Farajtabar, Sachin Mehta, Raviteja
  Vemulapalli, Fartash Faghri, Devang Naik, Oncel Tuzel, Mohammad Rastegari","Weight subcloning: direct initialization of transformers using larger
  pretrained ones",,,,,cs.LG cs.CL cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Training large transformer models from scratch for a target task requires
lots of data and is computationally demanding. The usual practice of transfer
learning overcomes this challenge by initializing the model with weights of a
pretrained model of the same size and specification to increase the convergence
and training speed. However, what if no pretrained model of the required size
is available? In this paper, we introduce a simple yet effective technique to
transfer the knowledge of a pretrained model to smaller variants. Our approach
called weight subcloning expedites the training of scaled-down transformers by
initializing their weights from larger pretrained models.
  Weight subcloning involves an operation on the pretrained model to obtain the
equivalent initialized scaled-down model. It consists of two key steps: first,
we introduce neuron importance ranking to decrease the embedding dimension per
layer in the pretrained model. Then, we remove blocks from the transformer
model to match the number of layers in the scaled-down network. The result is a
network ready to undergo training, which gains significant improvements in
training speed compared to random initialization. For instance, we achieve 4x
faster training for vision transformers in image classification and language
models designed for next token prediction.
","[{'version': 'v1', 'created': 'Thu, 14 Dec 2023 19:08:56 GMT'}]",2023-12-18,"[['Samragh', 'Mohammad', ''], ['Farajtabar', 'Mehrdad', ''], ['Mehta', 'Sachin', ''], ['Vemulapalli', 'Raviteja', ''], ['Faghri', 'Fartash', ''], ['Naik', 'Devang', ''], ['Tuzel', 'Oncel', ''], ['Rastegari', 'Mohammad', '']]"
2402.13936,Antoine Chaffin,"Antoine Chaffin, Ewa Kijak, Vincent Claveau","Distinctive Image Captioning: Leveraging Ground Truth Captions in CLIP
  Guided Reinforcement Learning",,,,,cs.CL cs.CV,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Training image captioning models using teacher forcing results in very
generic samples, whereas more distinctive captions can be very useful in
retrieval applications or to produce alternative texts describing images for
accessibility. Reinforcement Learning (RL) allows to use cross-modal retrieval
similarity score between the generated caption and the input image as reward to
guide the training, leading to more distinctive captions. Recent studies show
that pre-trained cross-modal retrieval models can be used to provide this
reward, completely eliminating the need for reference captions. However, we
argue in this paper that Ground Truth (GT) captions can still be useful in this
RL framework. We propose a new image captioning model training strategy that
makes use of GT captions in different ways. Firstly, they can be used to train
a simple MLP discriminator that serves as a regularization to prevent reward
hacking and ensures the fluency of generated captions, resulting in a textual
GAN setup extended for multimodal inputs. Secondly, they can serve as
additional trajectories in the RL strategy, resulting in a teacher forcing loss
weighted by the similarity of the GT to the image. This objective acts as an
additional learning signal grounded to the distribution of the GT captions.
Thirdly, they can serve as strong baselines when added to the pool of captions
used to compute the proposed contrastive reward to reduce the variance of
gradient estimate. Experiments on MS-COCO demonstrate the interest of the
proposed training strategy to produce highly distinctive captions while
maintaining high writing quality.
","[{'version': 'v1', 'created': 'Wed, 21 Feb 2024 17:05:06 GMT'}]",2024-02-22,"[['Chaffin', 'Antoine', ''], ['Kijak', 'Ewa', ''], ['Claveau', 'Vincent', '']]"
2302.07735,Ali Al-Kaswan,"Ali Al-Kaswan, Maliheh Izadi, Arie van Deursen","Targeted Attack on GPT-Neo for the SATML Language Model Data Extraction
  Challenge",,,,,cs.CL cs.AI cs.CR,http://creativecommons.org/licenses/by-sa/4.0/,"  Previous work has shown that Large Language Models are susceptible to
so-called data extraction attacks. This allows an attacker to extract a sample
that was contained in the training data, which has massive privacy
implications. The construction of data extraction attacks is challenging,
current attacks are quite inefficient, and there exists a significant gap in
the extraction capabilities of untargeted attacks and memorization. Thus,
targeted attacks are proposed, which identify if a given sample from the
training data, is extractable from a model. In this work, we apply a targeted
data extraction attack to the SATML2023 Language Model Training Data Extraction
Challenge. We apply a two-step approach. In the first step, we maximise the
recall of the model and are able to extract the suffix for 69% of the samples.
In the second step, we use a classifier-based Membership Inference Attack on
the generations. Our AutoSklearn classifier achieves a precision of 0.841. The
full approach reaches a score of 0.405 recall at a 10% false positive rate,
which is an improvement of 34% over the baseline of 0.301.
","[{'version': 'v1', 'created': 'Mon, 13 Feb 2023 18:00:44 GMT'}]",2023-02-16,"[['Al-Kaswan', 'Ali', ''], ['Izadi', 'Maliheh', ''], ['van Deursen', 'Arie', '']]"
1801.07495,Wafa Alorainy,"Wafa Alorainy, Pete Burnap, Han Liu, Matthew Williams","The Enemy Among Us: Detecting Hate Speech with Threats Based 'Othering'
  Language Embeddings",,,,,cs.CL cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Offensive or antagonistic language targeted at individuals and social groups
based on their personal characteristics (also known as cyber hate speech or
cyberhate) has been frequently posted and widely circulated viathe World Wide
Web. This can be considered as a key risk factor for individual and societal
tension linked toregional instability. Automated Web-based cyberhate detection
is important for observing and understandingcommunity and regional societal
tension - especially in online social networks where posts can be rapidlyand
widely viewed and disseminated. While previous work has involved using
lexicons, bags-of-words orprobabilistic language parsing approaches, they often
suffer from a similar issue which is that cyberhate can besubtle and indirect -
thus depending on the occurrence of individual words or phrases can lead to a
significantnumber of false negatives, providing inaccurate representation of
the trends in cyberhate. This problemmotivated us to challenge thinking around
the representation of subtle language use, such as references toperceived
threats from ""the other"" including immigration or job prosperity in a hateful
context. We propose anovel framework that utilises language use around the
concept of ""othering"" and intergroup threat theory toidentify these subtleties
and we implement a novel classification method using embedding learning to
computesemantic distances between parts of speech considered to be part of an
""othering"" narrative. To validate ourapproach we conduct several experiments on
different types of cyberhate, namely religion, disability, race andsexual
orientation, with F-measure scores for classifying hateful instances obtained
through applying ourmodel of 0.93, 0.86, 0.97 and 0.98 respectively, providing
a significant improvement in classifier accuracy overthe state-of-the-art
","[{'version': 'v1', 'created': 'Tue, 23 Jan 2018 11:43:54 GMT'}, {'version': 'v2', 'created': 'Sun, 28 Jan 2018 11:37:38 GMT'}, {'version': 'v3', 'created': 'Thu, 8 Mar 2018 12:25:38 GMT'}]",2018-03-09,"[['Alorainy', 'Wafa', ''], ['Burnap', 'Pete', ''], ['Liu', 'Han', ''], ['Williams', 'Matthew', '']]"
2002.09812,Xin Yang,"Yingyu Liang, Zhao Song, Mengdi Wang, Lin F. Yang, Xin Yang","Sketching Transformed Matrices with Applications to Natural Language
  Processing",AISTATS 2020,,,,cs.DS cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Suppose we are given a large matrix $A=(a_{i,j})$ that cannot be stored in
memory but is in a disk or is presented in a data stream. However, we need to
compute a matrix decomposition of the entry-wisely transformed matrix,
$f(A):=(f(a_{i,j}))$ for some function $f$. Is it possible to do it in a space
efficient way? Many machine learning applications indeed need to deal with such
large transformed matrices, for example word embedding method in NLP needs to
work with the pointwise mutual information (PMI) matrix, while the entrywise
transformation makes it difficult to apply known linear algebraic tools.
Existing approaches for this problem either need to store the whole matrix and
perform the entry-wise transformation afterwards, which is space consuming or
infeasible, or need to redesign the learning method, which is application
specific and requires substantial remodeling.
  In this paper, we first propose a space-efficient sketching algorithm for
computing the product of a given small matrix with the transformed matrix. It
works for a general family of transformations with provable small error bounds
and thus can be used as a primitive in downstream learning tasks. We then apply
this primitive to a concrete application: low-rank approximation. We show that
our approach obtains small error and is efficient in both space and time. We
complement our theoretical results with experiments on synthetic and real data.
","[{'version': 'v1', 'created': 'Sun, 23 Feb 2020 03:07:31 GMT'}]",2020-02-25,"[['Liang', 'Yingyu', ''], ['Song', 'Zhao', ''], ['Wang', 'Mengdi', ''], ['Yang', 'Lin F.', ''], ['Yang', 'Xin', '']]"
2310.17680,Mukul Singh,"Mukul Singh, Jos\'e Cambronero, Sumit Gulwani, Vu Le, Carina Negreanu,
  Gust Verbruggen",CodeFusion: A Pre-trained Diffusion Model for Code Generation,"Contains inappropriately sourced conjecture of OpenAI's ChatGPT
  parameter count from
  www.forbes.com/sites/forbestechcouncil/2023/02/17/is-bigger-better-why-the-chatgpt-vs-gpt-3-vs-gpt-4-battle-is-just-a-family-chat,
  a citation which was omitted. The authors do not have direct knowledge or
  verification of this information, and relied solely on this article, which
  may lead to public confusion",,,,cs.SE cs.AI cs.CL cs.PL,http://creativecommons.org/licenses/by/4.0/,"  Imagine a developer who can only change their last line of code, how often
would they have to start writing a function from scratch before it is correct?
Auto-regressive models for code generation from natural language have a similar
limitation: they do not easily allow reconsidering earlier tokens generated. We
introduce CodeFusion, a pre-trained diffusion code generation model that
addresses this limitation by iteratively denoising a complete program
conditioned on the encoded natural language. We evaluate CodeFusion on the task
of natural language to code generation for Bash, Python, and Microsoft Excel
conditional formatting (CF) rules. Experiments show that CodeFusion (75M
parameters) performs on par with state-of-the-art auto-regressive systems
(350M-175B parameters) in top-1 accuracy and outperforms them in top-3 and
top-5 accuracy due to its better balance in diversity versus quality.
","[{'version': 'v1', 'created': 'Thu, 26 Oct 2023 11:06:15 GMT'}, {'version': 'v2', 'created': 'Mon, 30 Oct 2023 19:29:36 GMT'}, {'version': 'v3', 'created': 'Wed, 1 Nov 2023 17:30:47 GMT'}]",2023-11-02,"[['Singh', 'Mukul', ''], ['Cambronero', 'José', ''], ['Gulwani', 'Sumit', ''], ['Le', 'Vu', ''], ['Negreanu', 'Carina', ''], ['Verbruggen', 'Gust', '']]"
2210.06772,Zhe Liu,"Zhe Liu, Xuedong Zhang, Fuchun Peng","Mitigating Unintended Memorization in Language Models via Alternating
  Teaching",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent research has shown that language models have a tendency to memorize
rare or unique sequences in the training corpora which can thus leak sensitive
attributes of user data. We employ a teacher-student framework and propose a
novel approach called alternating teaching to mitigate unintended memorization
in sequential modeling. In our method, multiple teachers are trained on
disjoint training sets whose privacy one wishes to protect, and teachers'
predictions supervise the training of a student model in an alternating manner
at each time step. Experiments on LibriSpeech datasets show that the proposed
method achieves superior privacy-preserving results than other counterparts. In
comparison with no prevention for unintended memorization, the overall utility
loss is small when training records are sufficient.
","[{'version': 'v1', 'created': 'Thu, 13 Oct 2022 06:26:41 GMT'}]",2022-10-14,"[['Liu', 'Zhe', ''], ['Zhang', 'Xuedong', ''], ['Peng', 'Fuchun', '']]"
2401.14931,Marco Bombieri,"Marco Bombieri, Paolo Fiorini, Simone Paolo Ponzetto, Marco Rospocher",Do LLMs Dream of Ontologies?,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have recently revolutionized automated text
understanding and generation. The performance of these models relies on the
high number of parameters of the underlying neural architectures, which allows
LLMs to memorize part of the vast quantity of data seen during the training.
This paper investigates whether and to what extent general-purpose pre-trained
LLMs have memorized information from known ontologies. Our results show that
LLMs partially know ontologies: they can, and do indeed, memorize concepts from
ontologies mentioned in the text, but the level of memorization of their
concepts seems to vary proportionally to their popularity on the Web, the
primary source of their training material. We additionally propose new metrics
to estimate the degree of memorization of ontological information in LLMs by
measuring the consistency of the output produced across different prompt
repetitions, query languages, and degrees of determinism.
","[{'version': 'v1', 'created': 'Fri, 26 Jan 2024 15:10:23 GMT'}]",2024-01-29,"[['Bombieri', 'Marco', ''], ['Fiorini', 'Paolo', ''], ['Ponzetto', 'Simone Paolo', ''], ['Rospocher', 'Marco', '']]"
1507.03223,Nisheeth Joshi,"Shruti Tyagi, Deepti Chopra, Iti Mathur, Nisheeth Joshi",Classifier-Based Text Simplification for Improved Machine Translation,"In Proceedings of International Conference on Advances in Computer
  Engineering and Applications 2015",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Machine Translation is one of the research fields of Computational
Linguistics. The objective of many MT Researchers is to develop an MT System
that produce good quality and high accuracy output translations and which also
covers maximum language pairs. As internet and Globalization is increasing day
by day, we need a way that improves the quality of translation. For this
reason, we have developed a Classifier based Text Simplification Model for
English-Hindi Machine Translation Systems. We have used support vector machines
and Na\""ive Bayes Classifier to develop this model. We have also evaluated the
performance of these classifiers.
","[{'version': 'v1', 'created': 'Sun, 12 Jul 2015 12:14:19 GMT'}]",2015-07-14,"[['Tyagi', 'Shruti', ''], ['Chopra', 'Deepti', ''], ['Mathur', 'Iti', ''], ['Joshi', 'Nisheeth', '']]"
2305.01155,Juan Pablo Zuluaga-Gomez,"Juan Zuluaga-Gomez, Iuliia Nigmatulina, Amrutha Prasad, Petr Motlicek,
  Driss Khalil, Srikanth Madikeri, Allan Tart, Igor Szoke, Vincent Lenders,
  Mickael Rigault, Khalid Choukri","Lessons Learned in ATCO2: 5000 hours of Air Traffic Control
  Communications for Robust Automatic Speech Recognition and Understanding",Manuscript under review,,,,eess.AS cs.CL cs.HC cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Voice communication between air traffic controllers (ATCos) and pilots is
critical for ensuring safe and efficient air traffic control (ATC). This task
requires high levels of awareness from ATCos and can be tedious and
error-prone. Recent attempts have been made to integrate artificial
intelligence (AI) into ATC in order to reduce the workload of ATCos. However,
the development of data-driven AI systems for ATC demands large-scale annotated
datasets, which are currently lacking in the field. This paper explores the
lessons learned from the ATCO2 project, a project that aimed to develop a
unique platform to collect and preprocess large amounts of ATC data from
airspace in real time. Audio and surveillance data were collected from publicly
accessible radio frequency channels with VHF receivers owned by a community of
volunteers and later uploaded to Opensky Network servers, which can be
considered an ""unlimited source"" of data. In addition, this paper reviews
previous work from ATCO2 partners, including (i) robust automatic speech
recognition, (ii) natural language processing, (iii) English language
identification of ATC communications, and (iv) the integration of surveillance
data such as ADS-B. We believe that the pipeline developed during the ATCO2
project, along with the open-sourcing of its data, will encourage research in
the ATC field. A sample of the ATCO2 corpus is available on the following
website: https://www.atco2.org/data, while the full corpus can be purchased
through ELDA at http://catalog.elra.info/en-us/repository/browse/ELRA-S0484. We
demonstrated that ATCO2 is an appropriate dataset to develop ASR engines when
little or near to no ATC in-domain data is available. For instance, with the
CNN-TDNNf kaldi model, we reached the performance of as low as 17.9% and 24.9%
WER on public ATC datasets which is 6.6/7.6% better than ""out-of-domain"" but
supervised CNN-TDNNf model.
","[{'version': 'v1', 'created': 'Tue, 2 May 2023 02:04:33 GMT'}]",2023-05-03,"[['Zuluaga-Gomez', 'Juan', ''], ['Nigmatulina', 'Iuliia', ''], ['Prasad', 'Amrutha', ''], ['Motlicek', 'Petr', ''], ['Khalil', 'Driss', ''], ['Madikeri', 'Srikanth', ''], ['Tart', 'Allan', ''], ['Szoke', 'Igor', ''], ['Lenders', 'Vincent', ''], ['Rigault', 'Mickael', ''], ['Choukri', 'Khalid', '']]"
2402.14298,Ang Li,"Bin Liang, Ang Li, Jingqian Zhao, Lin Gui, Min Yang, Yue Yu, Kam-Fai
  Wong and Ruifeng Xu",Multi-modal Stance Detection: New Datasets and Model,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Stance detection is a challenging task that aims to identify public opinion
from social media platforms with respect to specific targets. Previous work on
stance detection largely focused on pure texts. In this paper, we study
multi-modal stance detection for tweets consisting of texts and images, which
are prevalent in today's fast-growing social media platforms where people often
post multi-modal messages. To this end, we create five new multi-modal stance
detection datasets of different domains based on Twitter, in which each example
consists of a text and an image. In addition, we propose a simple yet effective
Targeted Multi-modal Prompt Tuning framework (TMPT), where target information
is leveraged to learn multi-modal stance features from textual and visual
modalities. Experimental results on our three benchmark datasets show that the
proposed TMPT achieves state-of-the-art performance in multi-modal stance
detection.
","[{'version': 'v1', 'created': 'Thu, 22 Feb 2024 05:24:19 GMT'}]",2024-02-23,"[['Liang', 'Bin', ''], ['Li', 'Ang', ''], ['Zhao', 'Jingqian', ''], ['Gui', 'Lin', ''], ['Yang', 'Min', ''], ['Yu', 'Yue', ''], ['Wong', 'Kam-Fai', ''], ['Xu', 'Ruifeng', '']]"
2402.10893,Moritz Stephan,"Moritz Stephan, Alexander Khazatsky, Eric Mitchell, Annie S Chen,
  Sheryl Hsu, Archit Sharma, Chelsea Finn",RLVF: Learning from Verbal Feedback without Overgeneralization,"9 pages, 9 figures",,,,cs.LG cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The diversity of contexts in which large language models (LLMs) are deployed
requires the ability to modify or customize default model behaviors to
incorporate nuanced requirements and preferences. A convenient interface to
specify such model adjustments is high-level verbal feedback, such as ""Don't
use emojis when drafting emails to my boss."" However, while writing high-level
feedback is far simpler than collecting annotations for reinforcement learning
from human feedback (RLHF), we find that simply prompting a model with such
feedback leads to overgeneralization of the feedback to contexts where it is
not relevant. We study the problem of incorporating verbal feedback without
such overgeneralization, inspiring a new method Contextualized Critiques with
Constrained Preference Optimization (C3PO). C3PO uses a piece of high-level
feedback to generate a small synthetic preference dataset specifying how the
feedback should (and should not) be applied. It then fine-tunes the model in
accordance with the synthetic preference data while minimizing the divergence
from the original model for prompts where the feedback does not apply. Our
experimental results indicate that our approach effectively applies verbal
feedback to relevant scenarios while preserving existing behaviors for other
contexts. For both human- and GPT-4-generated high-level feedback, C3PO
effectively adheres to the given feedback comparably to in-context baselines
while reducing overgeneralization by 30%.
","[{'version': 'v1', 'created': 'Fri, 16 Feb 2024 18:50:24 GMT'}]",2024-02-19,"[['Stephan', 'Moritz', ''], ['Khazatsky', 'Alexander', ''], ['Mitchell', 'Eric', ''], ['Chen', 'Annie S', ''], ['Hsu', 'Sheryl', ''], ['Sharma', 'Archit', ''], ['Finn', 'Chelsea', '']]"
2307.00787,Teun Van Der Weij,"Teun van der Weij, Simon Lermen, Leon lang",Evaluating Shutdown Avoidance of Language Models in Textual Scenarios,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Recently, there has been an increase in interest in evaluating large language
models for emergent and dangerous capabilities. Importantly, agents could
reason that in some scenarios their goal is better achieved if they are not
turned off, which can lead to undesirable behaviors. In this paper, we
investigate the potential of using toy textual scenarios to evaluate
instrumental reasoning and shutdown avoidance in language models such as GPT-4
and Claude. Furthermore, we explore whether shutdown avoidance is merely a
result of simple pattern matching between the dataset and the prompt or if it
is a consistent behaviour across different environments and variations.
  We evaluated behaviours manually and also experimented with using language
models for automatic evaluations, and these evaluations demonstrate that simple
pattern matching is likely not the sole contributing factor for shutdown
avoidance. This study provides insights into the behaviour of language models
in shutdown avoidance scenarios and inspires further research on the use of
textual scenarios for evaluations.
","[{'version': 'v1', 'created': 'Mon, 3 Jul 2023 07:05:59 GMT'}]",2023-07-04,"[['van der Weij', 'Teun', ''], ['Lermen', 'Simon', ''], ['lang', 'Leon', '']]"
2210.14473,Xinyun Chen,"Da Shen, Xinyun Chen, Chenguang Wang, Koushik Sen, Dawn Song",Benchmarking Language Models for Code Syntax Understanding,Findings of EMNLP 2022,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Pre-trained language models have demonstrated impressive performance in both
natural language processing and program understanding, which represent the
input as a token sequence without explicitly modeling its structure. Some prior
works show that pre-trained language models can capture the syntactic rules of
natural languages without finetuning on syntax understanding tasks. However,
there is limited understanding of how well pre-trained models understand the
code structure so far. In this work, we perform the first thorough benchmarking
of the state-of-the-art pre-trained models for identifying the syntactic
structures of programs. Specifically, we introduce CodeSyntax, a large-scale
dataset of programs annotated with the syntactic relationships in their
corresponding abstract syntax trees. Our key observation is that existing
language models pretrained on code still lack the understanding of code syntax.
In fact, these pre-trained programming language models fail to match the
performance of simple baselines based on positional offsets and keywords. We
also present a natural language benchmark to highlight the differences between
natural languages and programming languages in terms of syntactic structure
understanding. Our findings point out key limitations of existing pre-training
methods for programming languages, and suggest the importance of modeling code
syntactic structures.
","[{'version': 'v1', 'created': 'Wed, 26 Oct 2022 04:47:18 GMT'}]",2022-10-27,"[['Shen', 'Da', ''], ['Chen', 'Xinyun', ''], ['Wang', 'Chenguang', ''], ['Sen', 'Koushik', ''], ['Song', 'Dawn', '']]"
2401.14228,Mohammed Sabry,Mohammed Sabry and Anya Belz,"Assessing the Portability of Parameter Matrices Trained by
  Parameter-Efficient Finetuning Methods",Accepted to Findings of EACL 2024. Camera ready version,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  As the cost of training ever larger language models has grown, so has the
interest in reusing previously learnt knowledge. Transfer learning methods have
shown how reusing non-task-specific knowledge can help in subsequent
task-specific learning. In this paper, we investigate the inverse: porting
whole functional modules that encode task-specific knowledge from one model to
another. We designed a study comprising 1,440 training/testing runs to test the
portability of modules trained by parameter-efficient finetuning (PEFT)
techniques, using sentiment analysis as an example task. We test portability in
a wide range of scenarios, involving different PEFT techniques and different
pretrained host models, among other dimensions. We compare the performance of
ported modules with that of equivalent modules trained (i) from scratch, and
(ii) from parameters sampled from the same distribution as the ported module.
We find that the ported modules far outperform the two alternatives tested, but
that there are interesting performance differences between the four PEFT
techniques. We conclude that task-specific knowledge in the form of
structurally modular sets of parameters as produced by PEFT techniques is
highly portable, but that degree of success depends on type of PEFT and on
differences between originating and receiving pretrained models.
","[{'version': 'v1', 'created': 'Thu, 25 Jan 2024 15:11:07 GMT'}]",2024-01-26,"[['Sabry', 'Mohammed', ''], ['Belz', 'Anya', '']]"
1611.01599,Yannis Assael,"Yannis M. Assael, Brendan Shillingford, Shimon Whiteson, Nando de
  Freitas",LipNet: End-to-End Sentence-level Lipreading,,,,,cs.LG cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Lipreading is the task of decoding text from the movement of a speaker's
mouth. Traditional approaches separated the problem into two stages: designing
or learning visual features, and prediction. More recent deep lipreading
approaches are end-to-end trainable (Wand et al., 2016; Chung & Zisserman,
2016a). However, existing work on models trained end-to-end perform only word
classification, rather than sentence-level sequence prediction. Studies have
shown that human lipreading performance increases for longer words (Easton &
Basala, 1982), indicating the importance of features capturing temporal context
in an ambiguous communication channel. Motivated by this observation, we
present LipNet, a model that maps a variable-length sequence of video frames to
text, making use of spatiotemporal convolutions, a recurrent network, and the
connectionist temporal classification loss, trained entirely end-to-end. To the
best of our knowledge, LipNet is the first end-to-end sentence-level lipreading
model that simultaneously learns spatiotemporal visual features and a sequence
model. On the GRID corpus, LipNet achieves 95.2% accuracy in sentence-level,
overlapped speaker split task, outperforming experienced human lipreaders and
the previous 86.4% word-level state-of-the-art accuracy (Gergen et al., 2016).
","[{'version': 'v1', 'created': 'Sat, 5 Nov 2016 04:05:18 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Dec 2016 16:09:34 GMT'}]",2016-12-19,"[['Assael', 'Yannis M.', ''], ['Shillingford', 'Brendan', ''], ['Whiteson', 'Shimon', ''], ['de Freitas', 'Nando', '']]"
2210.15762,Charlie Welch,Severino Trotta and Lucie Flek and Charles Welch,Nearest Neighbor Language Models for Stylistic Controllable Generation,Accepted to GEM workshop at EMNLP 2022,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent language modeling performance has been greatly improved by the use of
external memory. This memory encodes the context so that similar contexts can
be recalled during decoding. This similarity depends on how the model learns to
encode context, which can be altered to include other attributes, such as
style. We construct and evaluate an architecture for this purpose, using
corpora annotated for politeness, formality, and toxicity. Through extensive
experiments and human evaluation we demonstrate the potential of our method to
generate text while controlling style. We find that style-specific datastores
improve generation performance, though results vary greatly across styles, and
the effect of pretraining data and specific styles should be explored in future
work.
","[{'version': 'v1', 'created': 'Thu, 27 Oct 2022 20:46:12 GMT'}]",2022-10-31,"[['Trotta', 'Severino', ''], ['Flek', 'Lucie', ''], ['Welch', 'Charles', '']]"
2202.00964,Yifan Hou,"Yifan Hou, Guoji Fu, Mrinmaya Sachan",What Has Been Enhanced in my Knowledge-Enhanced Language Model?,"Our code, demo, and instructions of the usage can be found in
  https://github.com/yifan-h/GCS_KI",,,,cs.CL cs.IT cs.LG math.IT,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pretrained language models (LMs) do not capture factual knowledge very well.
This has led to the development of a number of knowledge integration (KI)
methods which aim to incorporate external knowledge into pretrained LMs. Even
though KI methods show some performance gains over vanilla LMs, the
inner-workings of these methods are not well-understood. For instance, it is
unclear how and what kind of knowledge is effectively integrated into these
models and if such integration may lead to catastrophic forgetting of already
learned knowledge. This paper revisits the KI process in these models with an
information-theoretic view and shows that KI can be interpreted using a graph
convolution operation. We propose a probe model called \textit{Graph
Convolution Simulator} (GCS) for interpreting knowledge-enhanced LMs and
exposing what kind of knowledge is integrated into these models. We conduct
experiments to verify that our GCS can indeed be used to correctly interpret
the KI process, and we use it to analyze two well-known knowledge-enhanced LMs:
ERNIE and K-Adapter, and find that only a small amount of factual knowledge is
integrated in them. We stratify knowledge in terms of various relation types
and find that ERNIE and K-Adapter integrate different kinds of knowledge to
different extent. Our analysis also shows that simply increasing the size of
the KI corpus may not lead to better KI; fundamental advances may be needed.
","[{'version': 'v1', 'created': 'Wed, 2 Feb 2022 11:23:36 GMT'}, {'version': 'v2', 'created': 'Mon, 7 Feb 2022 12:32:42 GMT'}, {'version': 'v3', 'created': 'Thu, 10 Feb 2022 22:27:19 GMT'}, {'version': 'v4', 'created': 'Tue, 15 Feb 2022 08:58:36 GMT'}, {'version': 'v5', 'created': 'Mon, 24 Oct 2022 18:02:30 GMT'}, {'version': 'v6', 'created': 'Wed, 26 Oct 2022 09:03:52 GMT'}, {'version': 'v7', 'created': 'Wed, 16 Nov 2022 15:47:43 GMT'}]",2022-11-17,"[['Hou', 'Yifan', ''], ['Fu', 'Guoji', ''], ['Sachan', 'Mrinmaya', '']]"
2211.07712,Muhammad Nasir Zafar,"Dr. Omer Beg, Muhammad Nasir Zafar, Waleed Anjum",Cloning Ideology and Style using Deep Learning,"11 pages, 7 figures, 3 tables",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Text generation tasks have gotten the attention of researchers in the last
few years because of their applications on a large scale.In the past, many
researchers focused on task-based text generations.Our research focuses on text
generation based on the ideology and style of a specific author, and text
generation on a topic that was not written by the same author in the past.Our
trained model requires an input prompt containing initial few words of text to
produce a few paragraphs of text based on the ideology and style of the author
on which the model is trained.Our methodology to accomplish this task is based
on Bi-LSTM.The Bi-LSTM model is used to make predictions at the character
level, during the training corpus of a specific author is used along with the
ground truth corpus.A pre-trained model is used to identify the sentences of
ground truth having contradiction with the author's corpus to make our language
model inclined.During training, we have achieved a perplexity score of 2.23 at
the character level. The experiments show a perplexity score of around 3 over
the test dataset.
","[{'version': 'v1', 'created': 'Tue, 25 Oct 2022 11:37:19 GMT'}]",2022-11-16,"[['Beg', 'Dr. Omer', ''], ['Zafar', 'Muhammad Nasir', ''], ['Anjum', 'Waleed', '']]"
1606.05854,Dong Xu,Dong Xu and Wu-Jun Li,"Full-Time Supervision based Bidirectional RNN for Factoid Question
  Answering",9 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, bidirectional recurrent neural network (BRNN) has been widely used
for question answering (QA) tasks with promising performance. However, most
existing BRNN models extract the information of questions and answers by
directly using a pooling operation to generate the representation for loss or
similarity calculation. Hence, these existing models don't put supervision
(loss or similarity calculation) at every time step, which will lose some
useful information. In this paper, we propose a novel BRNN model called
full-time supervision based BRNN (FTS-BRNN), which can put supervision at every
time step. Experiments on the factoid QA task show that our FTS-BRNN can
outperform other baselines to achieve the state-of-the-art accuracy.
","[{'version': 'v1', 'created': 'Sun, 19 Jun 2016 11:03:47 GMT'}, {'version': 'v2', 'created': 'Tue, 21 Jun 2016 01:47:06 GMT'}]",2016-06-22,"[['Xu', 'Dong', ''], ['Li', 'Wu-Jun', '']]"
2402.05617,Elena Senger,"Elena Senger, Mike Zhang, Rob van der Goot, Barbara Plank","Deep Learning-based Computational Job Market Analysis: A Survey on Skill
  Extraction and Classification from Job Postings",Published at NLP4HR 2024 (EACL Workshop),,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Recent years have brought significant advances to Natural Language Processing
(NLP), which enabled fast progress in the field of computational job market
analysis. Core tasks in this application domain are skill extraction and
classification from job postings. Because of its quick growth and its
interdisciplinary nature, there is no exhaustive assessment of this emerging
field. This survey aims to fill this gap by providing a comprehensive overview
of deep learning methodologies, datasets, and terminologies specific to
NLP-driven skill extraction and classification. Our comprehensive cataloging of
publicly available datasets addresses the lack of consolidated information on
dataset creation and characteristics. Finally, the focus on terminology
addresses the current lack of consistent definitions for important concepts,
such as hard and soft skills, and terms relating to skill extraction and
classification.
","[{'version': 'v1', 'created': 'Thu, 8 Feb 2024 12:20:28 GMT'}]",2024-02-09,"[['Senger', 'Elena', ''], ['Zhang', 'Mike', ''], ['van der Goot', 'Rob', ''], ['Plank', 'Barbara', '']]"
2207.02393,Yi Xie,"Yi Xie, Jonathan Macoskey, Martin Radfar, Feng-Ju Chang, Brian King,
  Ariya Rastrow, Athanasios Mouchtaris, Grant P. Strimel",Compute Cost Amortized Transformer for Streaming ASR,,,,,cs.CL cs.SD eess.AS,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  We present a streaming, Transformer-based end-to-end automatic speech
recognition (ASR) architecture which achieves efficient neural inference
through compute cost amortization. Our architecture creates sparse computation
pathways dynamically at inference time, resulting in selective use of compute
resources throughout decoding, enabling significant reductions in compute with
minimal impact on accuracy. The fully differentiable architecture is trained
end-to-end with an accompanying lightweight arbitrator mechanism operating at
the frame-level to make dynamic decisions on each input while a tunable loss
function is used to regularize the overall level of compute against predictive
performance. We report empirical results from experiments using the compute
amortized Transformer-Transducer (T-T) model conducted on LibriSpeech data. Our
best model can achieve a 60% compute cost reduction with only a 3% relative
word error rate (WER) increase.
","[{'version': 'v1', 'created': 'Tue, 5 Jul 2022 03:06:53 GMT'}]",2022-07-07,"[['Xie', 'Yi', ''], ['Macoskey', 'Jonathan', ''], ['Radfar', 'Martin', ''], ['Chang', 'Feng-Ju', ''], ['King', 'Brian', ''], ['Rastrow', 'Ariya', ''], ['Mouchtaris', 'Athanasios', ''], ['Strimel', 'Grant P.', '']]"
1905.13350,Sabine Wehnert,"Sabine Wehnert and Sayed Anisul Hoque and Wolfram Fenske and Gunter
  Saake","Threshold-Based Retrieval and Textual Entailment Detection on Legal Bar
  Exam Questions",9 pages,,,,cs.IR cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Getting an overview over the legal domain has become challenging, especially
in a broad, international context. Legal question answering systems have the
potential to alleviate this task by automatically retrieving relevant legal
texts for a specific statement and checking whether the meaning of the
statement can be inferred from the found documents. We investigate a
combination of the BM25 scoring method of Elasticsearch with word embeddings
trained on English translations of the German and Japanese civil law. For this,
we define criteria which select a dynamic number of relevant documents
according to threshold scores. Exploiting two deep learning classifiers and
their respective prediction bias with a threshold-based answer inclusion
criterion has shown to be beneficial for the textual entailment task, when
compared to the baseline.
","[{'version': 'v1', 'created': 'Thu, 30 May 2019 23:17:26 GMT'}]",2019-06-03,"[['Wehnert', 'Sabine', ''], ['Hoque', 'Sayed Anisul', ''], ['Fenske', 'Wolfram', ''], ['Saake', 'Gunter', '']]"
1810.09597,Setu Shah,Setu Shah and Xiao Luo,"Biomedical Document Clustering and Visualization based on the Concepts
  of Diseases",KDD 2017's Data Driven Discovery Workshop,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Document clustering is a text mining technique used to provide better
document search and browsing in digital libraries or online corpora. A lot of
research has been done on biomedical document clustering that is based on using
existing ontology. But, associations and co-occurrences of the medical concepts
are not well represented by using ontology. In this research, a vector
representation of concepts of diseases and similarity measurement between
concepts are proposed. They identify the closest concepts of diseases in the
context of a corpus. Each document is represented by using the vector space
model. A weight scheme is proposed to consider both local content and
associations between concepts. A Self-Organizing Map is used as document
clustering algorithm. The vector projection and visualization features of SOM
enable visualization and analysis of the clusters distributions and
relationships on the two dimensional space. The experimental results show that
the proposed document clustering framework generates meaningful clusters and
facilitate visualization of the clusters based on the concepts of diseases.
","[{'version': 'v1', 'created': 'Mon, 22 Oct 2018 23:37:31 GMT'}]",2018-10-24,"[['Shah', 'Setu', ''], ['Luo', 'Xiao', '']]"
2302.07679,Caio Corro,"Alban Petit, Caio Corro",On graph-based reentrancy-free semantic parsing,"This work has been accepted for publication in TACL. This version is
  a pre-MIT Press publication version",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We propose a novel graph-based approach for semantic parsing that resolves
two problems observed in the literature: (1) seq2seq models fail on
compositional generalization tasks; (2) previous work using phrase structure
parsers cannot cover all the semantic parses observed in treebanks. We prove
that both MAP inference and latent tag anchoring (required for
weakly-supervised learning) are NP-hard problems. We propose two optimization
algorithms based on constraint smoothing and conditional gradient to
approximately solve these inference problems. Experimentally, our approach
delivers state-of-the-art results on Geoquery, Scan and Clevr, both for i.i.d.
splits and for splits that test for compositional generalization.
","[{'version': 'v1', 'created': 'Wed, 15 Feb 2023 14:14:09 GMT'}]",2023-02-16,"[['Petit', 'Alban', ''], ['Corro', 'Caio', '']]"
1606.00739,Stefan Riezler,Artem Sokolov and Julia Kreutzer and Christopher Lo and Stefan Riezler,Stochastic Structured Prediction under Bandit Feedback,"30th Conference on Neural Information Processing Systems (NIPS 2016),
  Barcelona, Spain",,,,cs.CL cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Stochastic structured prediction under bandit feedback follows a learning
protocol where on each of a sequence of iterations, the learner receives an
input, predicts an output structure, and receives partial feedback in form of a
task loss evaluation of the predicted structure. We present applications of
this learning scenario to convex and non-convex objectives for structured
prediction and analyze them as stochastic first-order methods. We present an
experimental evaluation on problems of natural language processing over
exponential output spaces, and compare convergence speed across different
objectives under the practical criterion of optimal task performance on
development data and the optimization-theoretic criterion of minimal squared
gradient norm. Best results under both criteria are obtained for a non-convex
objective for pairwise preference learning under bandit feedback.
","[{'version': 'v1', 'created': 'Thu, 2 Jun 2016 16:06:29 GMT'}, {'version': 'v2', 'created': 'Wed, 2 Nov 2016 16:29:42 GMT'}]",2017-04-24,"[['Sokolov', 'Artem', ''], ['Kreutzer', 'Julia', ''], ['Lo', 'Christopher', ''], ['Riezler', 'Stefan', '']]"
2307.08189,Zhengping Zhou,"Zhengping Zhou, Lezhi Li, Xinxi Chen, Andy Li","Mini-Giants: ""Small"" Language Models and Open Source Win-Win","16 pages, 1 figure",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  ChatGPT is phenomenal. However, it is prohibitively expensive to train and
refine such giant models. Fortunately, small language models are flourishing
and becoming more and more competent. We call them ""mini-giants"". We argue that
open source community like Kaggle and mini-giants will win-win in many ways,
technically, ethically and socially. In this article, we present a brief yet
rich background, discuss how to attain small language models, present a
comparative study of small language models and a brief discussion of evaluation
methods, discuss the application scenarios where small language models are most
needed in the real world, and conclude with discussion and outlook.
","[{'version': 'v1', 'created': 'Mon, 17 Jul 2023 01:35:56 GMT'}]",2023-07-18,"[['Zhou', 'Zhengping', ''], ['Li', 'Lezhi', ''], ['Chen', 'Xinxi', ''], ['Li', 'Andy', '']]"
2402.19088,Jader S\'a,"Jader Martins Camboim de S\'a, Marcos Da Silveira, C\'edric Pruski",Survey in Characterization of Semantic Change,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  Live languages continuously evolve to integrate the cultural change of human
societies. This evolution manifests through neologisms (new words) or
\textbf{semantic changes} of words (new meaning to existing words).
Understanding the meaning of words is vital for interpreting texts coming from
different cultures (regionalism or slang), domains (e.g., technical terms), or
periods. In computer science, these words are relevant to computational
linguistics algorithms such as translation, information retrieval, question
answering, etc. Semantic changes can potentially impact the quality of the
outcomes of these algorithms. Therefore, it is important to understand and
characterize these changes formally. The study of this impact is a recent
problem that has attracted the attention of the computational linguistics
community. Several approaches propose methods to detect semantic changes with
good precision, but more effort is needed to characterize how the meaning of
words changes and to reason about how to reduce the impact of semantic change.
This survey provides an understandable overview of existing approaches to the
\textit{characterization of semantic changes} and also formally defines three
classes of characterizations: if the meaning of a word becomes more general or
narrow (change in dimension) if the word is used in a more pejorative or
positive/ameliorated sense (change in orientation), and if there is a trend to
use the word in a, for instance, metaphoric or metonymic context (change in
relation). We summarized the main aspects of the selected publications in a
table and discussed the needs and trends in the research activities on semantic
change characterization.
","[{'version': 'v1', 'created': 'Thu, 29 Feb 2024 12:13:50 GMT'}, {'version': 'v2', 'created': 'Mon, 11 Mar 2024 15:21:57 GMT'}]",2024-03-12,"[['de Sá', 'Jader Martins Camboim', ''], ['Da Silveira', 'Marcos', ''], ['Pruski', 'Cédric', '']]"
2209.09480,Manjesh Kumar Hanawal,Hari Narayan N U and Manjesh K. Hanawal and Avinash Bhardwaj,Unsupervised Early Exit in DNNs with Multiple Exits,To be presented at International conference on AI-ML systems,,,,cs.LG cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Deep Neural Networks (DNNs) are generally designed as sequentially cascaded
differentiable blocks/layers with a prediction module connected only to its
last layer. DNNs can be attached with prediction modules at multiple points
along the backbone where inference can stop at an intermediary stage without
passing through all the modules. The last exit point may offer a better
prediction error but also involves more computational resources and latency. An
exit point that is `optimal' in terms of both prediction error and cost is
desirable. The optimal exit point may depend on the latent distribution of the
tasks and may change from one task type to another. During neural inference,
the ground truth of instances may not be available and error rates at each exit
point cannot be estimated. Hence one is faced with the problem of selecting the
optimal exit in an unsupervised setting. Prior works tackled this problem in an
offline supervised setting assuming that enough labeled data is available to
estimate the error rate at each exit point and tune the parameters for better
accuracy. However, pre-trained DNNs are often deployed in new domains for which
a large amount of ground truth may not be available. We model the problem of
exit selection as an unsupervised online learning problem and use bandit theory
to identify the optimal exit point. Specifically, we focus on Elastic BERT, a
pre-trained multi-exit DNN to demonstrate that it `nearly' satisfies the Strong
Dominance (SD) property making it possible to learn the optimal exit in an
online setup without knowing the ground truth labels. We develop upper
confidence bound (UCB) based algorithm named UEE-UCB that provably achieves
sub-linear regret under the SD property. Thus our method provides a means to
adaptively learn domain-specific optimal exit points in multi-exit DNNs. We
empirically validate our algorithm on IMDb and Yelp datasets.
","[{'version': 'v1', 'created': 'Tue, 20 Sep 2022 05:35:54 GMT'}]",2022-09-21,"[['U', 'Hari Narayan N', ''], ['Hanawal', 'Manjesh K.', ''], ['Bhardwaj', 'Avinash', '']]"
2401.06817,Tanwi Mallick,"Tanwi Mallick, John Murphy, Joshua David Bergerson, Duane R. Verner,
  John K Hutchison, Leslie-Anne Levy","Analyzing Regional Impacts of Climate Change using Natural Language
  Processing Techniques",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Understanding the multifaceted effects of climate change across diverse
geographic locations is crucial for timely adaptation and the development of
effective mitigation strategies. As the volume of scientific literature on this
topic continues to grow exponentially, manually reviewing these documents has
become an immensely challenging task. Utilizing Natural Language Processing
(NLP) techniques to analyze this wealth of information presents an efficient
and scalable solution. By gathering extensive amounts of peer-reviewed articles
and studies, we can extract and process critical information about the effects
of climate change in specific regions. We employ BERT (Bidirectional Encoder
Representations from Transformers) for Named Entity Recognition (NER), which
enables us to efficiently identify specific geographies within the climate
literature. This, in turn, facilitates location-specific analyses. We conduct
region-specific climate trend analyses to pinpoint the predominant themes or
concerns related to climate change within a particular area, trace the temporal
progression of these identified issues, and evaluate their frequency, severity,
and potential development over time. These in-depth examinations of
location-specific climate data enable the creation of more customized
policy-making, adaptation, and mitigation strategies, addressing each region's
unique challenges and providing more effective solutions rooted in data-driven
insights. This approach, founded on a thorough exploration of scientific texts,
offers actionable insights to a wide range of stakeholders, from policymakers
to engineers to environmentalists. By proactively understanding these impacts,
societies are better positioned to prepare, allocate resources wisely, and
design tailored strategies to cope with future climate conditions, ensuring a
more resilient future for all.
","[{'version': 'v1', 'created': 'Thu, 11 Jan 2024 16:44:59 GMT'}]",2024-01-17,"[['Mallick', 'Tanwi', ''], ['Murphy', 'John', ''], ['Bergerson', 'Joshua David', ''], ['Verner', 'Duane R.', ''], ['Hutchison', 'John K', ''], ['Levy', 'Leslie-Anne', '']]"
2210.04468,Ru Peng,"Ru Peng, Yawen Zeng, Junbo Zhao","Distill the Image to Nowhere: Inversion Knowledge Distillation for
  Multimodal Machine Translation",EMNLP2022 Oral Long paper,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Past works on multimodal machine translation (MMT) elevate bilingual setup by
incorporating additional aligned vision information. However, an image-must
requirement of the multimodal dataset largely hinders MMT's development --
namely that it demands an aligned form of [image, source text, target text].
This limitation is generally troublesome during the inference phase especially
when the aligned image is not provided as in the normal NMT setup. Thus, in
this work, we introduce IKD-MMT, a novel MMT framework to support the
image-free inference phase via an inversion knowledge distillation scheme. In
particular, a multimodal feature generator is executed with a knowledge
distillation module, which directly generates the multimodal feature from
(only) source texts as the input. While there have been a few prior works
entertaining the possibility to support image-free inference for machine
translation, their performances have yet to rival the image-must translation.
In our experiments, we identify our method as the first image-free approach to
comprehensively rival or even surpass (almost) all image-must frameworks, and
achieved the state-of-the-art result on the often-used Multi30k benchmark. Our
code and data are available at: https://github.com/pengr/IKD-mmt/tree/master..
","[{'version': 'v1', 'created': 'Mon, 10 Oct 2022 07:36:59 GMT'}, {'version': 'v2', 'created': 'Fri, 21 Apr 2023 09:40:09 GMT'}]",2023-04-24,"[['Peng', 'Ru', ''], ['Zeng', 'Yawen', ''], ['Zhao', 'Junbo', '']]"
2111.01676,Gilchan Park,Gilchan Park and Julia M. Taylor,Towards Text-based Phishing Detection,"Society for Design and Process Science (SDPS) 2013, pp.187-192.
  https://www.sdpsnet.org/sdps/documents/sdps-2013/SDPS_2013_proceedings.pdf",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This paper reports on an experiment into text-based phishing detection using
readily available resources and without the use of semantics. The developed
algorithm is a modified version of previously published work that works with
the same tools. The results obtained in recognizing phishing emails are
considerably better than the previously reported work; but the rate of text
falsely identified as phishing is slightly worse. It is expected that adding
semantic component will reduce the false positive rate while preserving the
detection accuracy.
","[{'version': 'v1', 'created': 'Tue, 2 Nov 2021 15:37:33 GMT'}, {'version': 'v2', 'created': 'Wed, 3 Nov 2021 13:57:58 GMT'}]",2021-11-04,"[['Park', 'Gilchan', ''], ['Taylor', 'Julia M.', '']]"
2305.06574,Jianheng Tang,"Jianheng Tang, Kangfei Zhao, Jia Li","A Fused Gromov-Wasserstein Framework for Unsupervised Knowledge Graph
  Entity Alignment",ACL 2023 (Findings),,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Entity alignment is the task of identifying corresponding entities across
different knowledge graphs (KGs). Although recent embedding-based entity
alignment methods have shown significant advancements, they still struggle to
fully utilize KG structural information. In this paper, we introduce FGWEA, an
unsupervised entity alignment framework that leverages the Fused
Gromov-Wasserstein (FGW) distance, allowing for a comprehensive comparison of
entity semantics and KG structures within a joint optimization framework. To
address the computational challenges associated with optimizing FGW, we devise
a three-stage progressive optimization algorithm. It starts with a basic
semantic embedding matching, proceeds to approximate cross-KG structural and
relational similarity matching based on iterative updates of high-confidence
entity links, and ultimately culminates in a global structural comparison
between KGs. We perform extensive experiments on four entity alignment datasets
covering 14 distinct KGs across five languages. Without any supervision or
hyper-parameter tuning, FGWEA surpasses 21 competitive baselines, including
cutting-edge supervised entity alignment methods. Our code is available at
https://github.com/squareRoot3/FusedGW-Entity-Alignment.
","[{'version': 'v1', 'created': 'Thu, 11 May 2023 05:17:54 GMT'}]",2023-05-12,"[['Tang', 'Jianheng', ''], ['Zhao', 'Kangfei', ''], ['Li', 'Jia', '']]"
1804.04526,Simon Gottschalk,"Simon Gottschalk, Elena Demidova",EventKG: A Multilingual Event-Centric Temporal Knowledge Graph,,,,,cs.CL cs.DB,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  One of the key requirements to facilitate semantic analytics of information
regarding contemporary and historical events on the Web, in the news and in
social media is the availability of reference knowledge repositories containing
comprehensive representations of events and temporal relations. Existing
knowledge graphs, with popular examples including DBpedia, YAGO and Wikidata,
focus mostly on entity-centric information and are insufficient in terms of
their coverage and completeness with respect to events and temporal relations.
EventKG presented in this paper is a multilingual event-centric temporal
knowledge graph that addresses this gap. EventKG incorporates over 690 thousand
contemporary and historical events and over 2.3 million temporal relations
extracted from several large-scale knowledge graphs and semi-structured sources
and makes them available through a canonical representation.
","[{'version': 'v1', 'created': 'Thu, 12 Apr 2018 14:12:48 GMT'}]",2018-04-13,"[['Gottschalk', 'Simon', ''], ['Demidova', 'Elena', '']]"
2305.14681,James Michaelov,"James A. Michaelov, Benjamin K. Bergen",Emergent inabilities? Inverse scaling over the course of pretraining,Accepted to Findings of EMNLP 2023,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Does inverse scaling only occur as a function of model size, or can it also
occur over the course of training? We carry out an exploratory study
investigating whether the performance of language models on specific tasks can
decrease (while general performance remains high) during training on the
language modeling task. We find 8 tasks on which Pythia 12B (Biderman et al.,
2023) shows decreased performance over the course of training. Five of these
tasks (TruthfulQA-MC1, TruthfulQA-MC2, Hindsight Neglect, Memo Trap, and
Pattern Match Suppression) additionally show a consistent relationship whereby
larger language models show a greater decrease in performance the more they are
trained, despite showing standard (positive) scaling overall. This highlights
the importance of testing performance at all relevant benchmarks any time
models are trained on additional data, even if their overall performance
improves
","[{'version': 'v1', 'created': 'Wed, 24 May 2023 03:42:43 GMT'}, {'version': 'v2', 'created': 'Wed, 15 Nov 2023 18:47:42 GMT'}]",2023-11-21,"[['Michaelov', 'James A.', ''], ['Bergen', 'Benjamin K.', '']]"
1811.00625,Jiaao Chen,"Jiaao Chen, Jianshu Chen, Zhou Yu",Incorporating Structured Commonsense Knowledge in Story Completion,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The ability to select an appropriate story ending is the first step towards
perfect narrative comprehension. Story ending prediction requires not only the
explicit clues within the context, but also the implicit knowledge (such as
commonsense) to construct a reasonable and consistent story. However, most
previous approaches do not explicitly use background commonsense knowledge. We
present a neural story ending selection model that integrates three types of
information: narrative sequence, sentiment evolution and commonsense knowledge.
Experiments show that our model outperforms state-of-the-art approaches on a
public dataset, ROCStory Cloze Task , and the performance gain from adding the
additional commonsense knowledge is significant.
","[{'version': 'v1', 'created': 'Thu, 1 Nov 2018 20:30:25 GMT'}]",2018-11-13,"[['Chen', 'Jiaao', ''], ['Chen', 'Jianshu', ''], ['Yu', 'Zhou', '']]"
2206.08053,Rudra Dhar,"Prantik Guha, Rudra Dhar, Dipankar Das","JU_NLP at HinglishEval: Quality Evaluation of the Low-Resource
  Code-Mixed Hinglish Text",,,,,cs.CL cs.SI,http://creativecommons.org/licenses/by/4.0/,"  In this paper we describe a system submitted to the INLG 2022 Generation
Challenge (GenChal) on Quality Evaluation of the Low-Resource Synthetically
Generated Code-Mixed Hinglish Text. We implement a Bi-LSTM-based neural network
model to predict the Average rating score and Disagreement score of the
synthetic Hinglish dataset. In our models, we used word embeddings for English
and Hindi data, and one hot encodings for Hinglish data. We achieved a F1 score
of 0.11, and mean squared error of 6.0 in the average rating score prediction
task. In the task of Disagreement score prediction, we achieve a F1 score of
0.18, and mean squared error of 5.0.
","[{'version': 'v1', 'created': 'Thu, 16 Jun 2022 10:12:44 GMT'}]",2022-06-17,"[['Guha', 'Prantik', ''], ['Dhar', 'Rudra', ''], ['Das', 'Dipankar', '']]"
1811.02959,Koustuv Sinha,"Koustuv Sinha, Shagun Sodhani, William L. Hamilton and Joelle Pineau","Compositional Language Understanding with Text-based Relational
  Reasoning","4 pages of main content, to be presented at Relational Representation
  Learning Workshop, NIPS 2018, Montreal",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural networks for natural language reasoning have largely focused on
extractive, fact-based question-answering (QA) and common-sense inference.
However, it is also crucial to understand the extent to which neural networks
can perform relational reasoning and combinatorial generalization from natural
language---abilities that are often obscured by annotation artifacts and the
dominance of language modeling in standard QA benchmarks. In this work, we
present a novel benchmark dataset for language understanding that isolates
performance on relational reasoning. We also present a neural message-passing
baseline and show that this model, which incorporates a relational inductive
bias, is superior at combinatorial generalization compared to a traditional
recurrent neural network approach.
","[{'version': 'v1', 'created': 'Wed, 7 Nov 2018 16:17:48 GMT'}, {'version': 'v2', 'created': 'Thu, 8 Nov 2018 02:32:05 GMT'}]",2018-11-09,"[['Sinha', 'Koustuv', ''], ['Sodhani', 'Shagun', ''], ['Hamilton', 'William L.', ''], ['Pineau', 'Joelle', '']]"
2012.04987,Biyang Guo,"Biyang Guo, Songqiao Han, Xiao Han, Hailiang Huang, Ting Lu",Label Confusion Learning to Enhance Text Classification Models,"8 pages,3 figures, 5 tables. Accepted by AAAI-21",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Representing a true label as a one-hot vector is a common practice in
training text classification models. However, the one-hot representation may
not adequately reflect the relation between the instances and labels, as labels
are often not completely independent and instances may relate to multiple
labels in practice. The inadequate one-hot representations tend to train the
model to be over-confident, which may result in arbitrary prediction and model
overfitting, especially for confused datasets (datasets with very similar
labels) or noisy datasets (datasets with labeling errors). While training
models with label smoothing (LS) can ease this problem in some degree, it still
fails to capture the realistic relation among labels. In this paper, we propose
a novel Label Confusion Model (LCM) as an enhancement component to current
popular text classification models. LCM can learn label confusion to capture
semantic overlap among labels by calculating the similarity between instances
and labels during training and generate a better label distribution to replace
the original one-hot label vector, thus improving the final classification
performance. Extensive experiments on five text classification benchmark
datasets reveal the effectiveness of LCM for several widely used deep learning
classification models. Further experiments also verify that LCM is especially
helpful for confused or noisy datasets and superior to the label smoothing
method.
","[{'version': 'v1', 'created': 'Wed, 9 Dec 2020 11:34:35 GMT'}]",2020-12-10,"[['Guo', 'Biyang', ''], ['Han', 'Songqiao', ''], ['Han', 'Xiao', ''], ['Huang', 'Hailiang', ''], ['Lu', 'Ting', '']]"
2205.02001,Minjong Cheon,"Minjong Cheon, Minseon Kim, Hanseon Joo","Design of a novel Korean learning application for efficient
  pronunciation correction",,,,,cs.CL cs.SD eess.AS,http://creativecommons.org/licenses/by/4.0/,"  The Korean wave, which denotes the global popularity of South Korea's
cultural economy, contributes to the increasing demand for the Korean language.
However, as there does not exist any application for foreigners to learn
Korean, this paper suggested a design of a novel Korean learning application.
Speech recognition, speech-to-text, and speech-to-waveform are the three key
systems in the proposed system. The Google API and the librosa library will
transform the user's voice into a sentence and MFCC. The software will then
display the user's phrase and answer, with mispronounced elements highlighted
in red, allowing users to more easily recognize the incorrect parts of their
pronunciation. Furthermore, the Siamese network might utilize those translated
spectrograms to provide a similarity score, which could subsequently be used to
offer feedback to the user. Despite the fact that we were unable to collect
sufficient foreigner data for this research, it is notable that we presented a
novel Korean pronunciation correction method for foreigners.
","[{'version': 'v1', 'created': 'Wed, 4 May 2022 11:19:29 GMT'}]",2022-05-05,"[['Cheon', 'Minjong', ''], ['Kim', 'Minseon', ''], ['Joo', 'Hanseon', '']]"
2210.09049,Jianing Wang,"Jianing Wang, Chengcheng Han, Chengyu Wang, Chuanqi Tan, Minghui Qiu,
  Songfang Huang, Jun Huang, Ming Gao","SpanProto: A Two-stage Span-based Prototypical Network for Few-shot
  Named Entity Recognition",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Few-shot Named Entity Recognition (NER) aims to identify named entities with
very little annotated data. Previous methods solve this problem based on
token-wise classification, which ignores the information of entity boundaries,
and inevitably the performance is affected by the massive non-entity tokens. To
this end, we propose a seminal span-based prototypical network (SpanProto) that
tackles few-shot NER via a two-stage approach, including span extraction and
mention classification. In the span extraction stage, we transform the
sequential tags into a global boundary matrix, enabling the model to focus on
the explicit boundary information. For mention classification, we leverage
prototypical learning to capture the semantic representations for each labeled
span and make the model better adapt to novel-class entities. To further
improve the model performance, we split out the false positives generated by
the span extractor but not labeled in the current episode set, and then present
a margin-based loss to separate them from each prototype region. Experiments
over multiple benchmarks demonstrate that our model outperforms strong
baselines by a large margin.
","[{'version': 'v1', 'created': 'Mon, 17 Oct 2022 12:59:33 GMT'}, {'version': 'v2', 'created': 'Mon, 21 Nov 2022 07:20:55 GMT'}]",2022-11-22,"[['Wang', 'Jianing', ''], ['Han', 'Chengcheng', ''], ['Wang', 'Chengyu', ''], ['Tan', 'Chuanqi', ''], ['Qiu', 'Minghui', ''], ['Huang', 'Songfang', ''], ['Huang', 'Jun', ''], ['Gao', 'Ming', '']]"
2311.09766,Yiqi Liu,"Yiqi Liu, Nafise Sadat Moosavi, Chenghua Lin",LLMs as Narcissistic Evaluators: When Ego Inflates Evaluation Scores,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic evaluation of generated textual content presents an ongoing
challenge within the field of NLP. Given the impressive capabilities of modern
language models (LMs) across diverse NLP tasks, there is a growing trend to
employ these models in creating innovative evaluation metrics for automated
assessment of generation tasks. This paper investigates a pivotal question: Do
language model-driven evaluation metrics inherently exhibit bias favoring texts
generated by the same underlying language model? Specifically, we assess
whether prominent LM-based evaluation metrics (e.g. BARTScore, T5Score, and
GPTScore) demonstrate a favorable bias toward their respective underlying LMs
in the context of summarization tasks. Our findings unveil a latent bias,
particularly pronounced when such evaluation metrics are used in an
reference-free manner without leveraging gold summaries. These results
underscore that assessments provided by generative evaluation models can be
influenced by factors beyond the inherent text quality, highlighting the
necessity of developing more dependable evaluation protocols in the future.
","[{'version': 'v1', 'created': 'Thu, 16 Nov 2023 10:43:26 GMT'}, {'version': 'v2', 'created': 'Sat, 17 Feb 2024 16:16:10 GMT'}, {'version': 'v3', 'created': 'Tue, 20 Feb 2024 17:21:51 GMT'}]",2024-02-21,"[['Liu', 'Yiqi', ''], ['Moosavi', 'Nafise Sadat', ''], ['Lin', 'Chenghua', '']]"
2005.12535,Benjamin Goertzel,"Ben Goertzel, Mike Duncan, Debbie Duong, Nil Geisweiller, Hedra Seid,
  Abdulrahman Semrie, Man Hin Leung, Matthew Ikle'","Embedding Vector Differences Can Be Aligned With Uncertain Intensional
  Logic Differences",,,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The DeepWalk algorithm is used to assign embedding vectors to nodes in the
Atomspace weighted, labeled hypergraph that is used to represent knowledge in
the OpenCog AGI system, in the context of an application to probabilistic
inference regarding the causes of longevity based on data from biological
ontologies and genomic analyses. It is shown that vector difference operations
between embedding vectors are, in appropriate conditions, approximately
alignable with ""intensional difference"" operations between the hypergraph nodes
corresponding to the embedding vectors. This relationship hints at a broader
functorial mapping between uncertain intensional logic and vector arithmetic,
and opens the door for using embedding vector algebra to guide intensional
inference control.
","[{'version': 'v1', 'created': 'Tue, 26 May 2020 06:20:32 GMT'}]",2020-05-27,"[['Goertzel', 'Ben', ''], ['Duncan', 'Mike', ''], ['Duong', 'Debbie', ''], ['Geisweiller', 'Nil', ''], ['Seid', 'Hedra', ''], ['Semrie', 'Abdulrahman', ''], ['Leung', 'Man Hin', ''], [""Ikle'"", 'Matthew', '']]"
1809.04179,Tal Linzen,Tal Linzen,What can linguistics and deep learning contribute to each other?,"Response to Joe Pater, ""Generative linguistics and neural networks at
  60: foundation, friction, and fusion"". To appear in Language",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Joe Pater's target article calls for greater interaction between neural
network research and linguistics. I expand on this call and show how such
interaction can benefit both fields. Linguists can contribute to research on
neural networks for language technologies by clearly delineating the linguistic
capabilities that can be expected of such systems, and by constructing
controlled experimental paradigms that can determine whether those desiderata
have been met. In the other direction, neural networks can benefit the
scientific study of language by providing infrastructure for modeling human
sentence processing and for evaluating the necessity of particular innate
constraints on language acquisition.
","[{'version': 'v1', 'created': 'Tue, 11 Sep 2018 21:55:11 GMT'}, {'version': 'v2', 'created': 'Fri, 14 Sep 2018 13:59:20 GMT'}]",2018-09-17,"[['Linzen', 'Tal', '']]"
2206.01987,Anna Berdichevskaia,"Anna Berdichevskaia (NUST ""MISiS"")",Atypical lexical abbreviations identification in Russian medical texts,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Abbreviation is a method of word formation that aims to construct the
shortened term from the first letters of the initial phrase. Implicit
abbreviations frequently cause the comprehension difficulties for unprepared
readers. In this paper, we propose an efficient ML-based algorithm which allows
to identify the abbreviations in Russian texts. The method achieves ROC AUC
score 0.926 and F1 score 0.706 which are confirmed as competitive in comparison
with the baselines. Along with the pipeline, we also establish first to our
knowledge Russian dataset that is relevant for the desired task.
","[{'version': 'v1', 'created': 'Sat, 4 Jun 2022 13:16:08 GMT'}]",2022-06-07,"[['Berdichevskaia', 'Anna', '', 'NUST ""MISiS""']]"
2112.03024,Denghui Zhang,"Denghui Zhang, Zixuan Yuan, Yanchi Liu, Hao Liu, Fuzhen Zhuang, Hui
  Xiong, Haifeng Chen","Domain-oriented Language Pre-training with Adaptive Hybrid Masking and
  Optimal Transport Alignment",,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Motivated by the success of pre-trained language models such as BERT in a
broad range of natural language processing (NLP) tasks, recent research efforts
have been made for adapting these models for different application domains.
Along this line, existing domain-oriented models have primarily followed the
vanilla BERT architecture and have a straightforward use of the domain corpus.
However, domain-oriented tasks usually require accurate understanding of domain
phrases, and such fine-grained phrase-level knowledge is hard to be captured by
existing pre-training scheme. Also, the word co-occurrences guided semantic
learning of pre-training models can be largely augmented by entity-level
association knowledge. But meanwhile, by doing so there is a risk of
introducing noise due to the lack of groundtruth word-level alignment. To
address the above issues, we provide a generalized domain-oriented approach,
which leverages auxiliary domain knowledge to improve the existing pre-training
framework from two aspects. First, to preserve phrase knowledge effectively, we
build a domain phrase pool as auxiliary training tool, meanwhile we introduce
Adaptive Hybrid Masked Model to incorporate such knowledge. It integrates two
learning modes, word learning and phrase learning, and allows them to switch
between each other. Second, we introduce Cross Entity Alignment to leverage
entity association as weak supervision to augment the semantic learning of
pre-trained models. To alleviate the potential noise in this process, we
introduce an interpretable Optimal Transport based approach to guide alignment
learning. Experiments on four domain-oriented tasks demonstrate the superiority
of our framework.
","[{'version': 'v1', 'created': 'Wed, 1 Dec 2021 15:47:01 GMT'}]",2021-12-07,"[['Zhang', 'Denghui', ''], ['Yuan', 'Zixuan', ''], ['Liu', 'Yanchi', ''], ['Liu', 'Hao', ''], ['Zhuang', 'Fuzhen', ''], ['Xiong', 'Hui', ''], ['Chen', 'Haifeng', '']]"
2305.03688,Zeqi Tan,"Zeqi Tan, Shen Huang, Zixia Jia, Jiong Cai, Yinghui Li, Weiming Lu,
  Yueting Zhuang, Kewei Tu, Pengjun Xie, Fei Huang and Yong Jiang","DAMO-NLP at SemEval-2023 Task 2: A Unified Retrieval-augmented System
  for Multilingual Named Entity Recognition","Accepted to SemEval 2023, winners for 9 out of 13 tracks, performance
  beyond ChatGPT",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The MultiCoNER \RNum{2} shared task aims to tackle multilingual named entity
recognition (NER) in fine-grained and noisy scenarios, and it inherits the
semantic ambiguity and low-context setting of the MultiCoNER \RNum{1} task. To
cope with these problems, the previous top systems in the MultiCoNER \RNum{1}
either incorporate the knowledge bases or gazetteers. However, they still
suffer from insufficient knowledge, limited context length, single retrieval
strategy. In this paper, our team \textbf{DAMO-NLP} proposes a unified
retrieval-augmented system (U-RaNER) for fine-grained multilingual NER. We
perform error analysis on the previous top systems and reveal that their
performance bottleneck lies in insufficient knowledge. Also, we discover that
the limited context length causes the retrieval knowledge to be invisible to
the model. To enhance the retrieval context, we incorporate the entity-centric
Wikidata knowledge base, while utilizing the infusion approach to broaden the
contextual scope of the model. Also, we explore various search strategies and
refine the quality of retrieval knowledge. Our system\footnote{We will release
the dataset, code, and scripts of our system at {\small
\url{https://github.com/modelscope/AdaSeq/tree/master/examples/U-RaNER}}.} wins
9 out of 13 tracks in the MultiCoNER \RNum{2} shared task. Additionally, we
compared our system with ChatGPT, one of the large language models which have
unlocked strong capabilities on many tasks. The results show that there is
still much room for improvement for ChatGPT on the extraction task.
","[{'version': 'v1', 'created': 'Fri, 5 May 2023 16:59:26 GMT'}, {'version': 'v2', 'created': 'Tue, 9 May 2023 03:43:10 GMT'}, {'version': 'v3', 'created': 'Wed, 17 May 2023 03:14:00 GMT'}]",2023-05-18,"[['Tan', 'Zeqi', ''], ['Huang', 'Shen', ''], ['Jia', 'Zixia', ''], ['Cai', 'Jiong', ''], ['Li', 'Yinghui', ''], ['Lu', 'Weiming', ''], ['Zhuang', 'Yueting', ''], ['Tu', 'Kewei', ''], ['Xie', 'Pengjun', ''], ['Huang', 'Fei', ''], ['Jiang', 'Yong', '']]"
1808.00265,Yundong Zhang,"Yundong Zhang, Juan Carlos Niebles, Alvaro Soto","Interpretable Visual Question Answering by Visual Grounding from
  Attention Supervision Mining","8 pages, 4 figures",,,,cs.CV cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A key aspect of VQA models that are interpretable is their ability to ground
their answers to relevant regions in the image. Current approaches with this
capability rely on supervised learning and human annotated groundings to train
attention mechanisms inside the VQA architecture. Unfortunately, obtaining
human annotations specific for visual grounding is difficult and expensive. In
this work, we demonstrate that we can effectively train a VQA architecture with
grounding supervision that can be automatically obtained from available region
descriptions and object annotations. We also show that our model trained with
this mined supervision generates visual groundings that achieve a higher
correlation with respect to manually-annotated groundings, meanwhile achieving
state-of-the-art VQA accuracy.
","[{'version': 'v1', 'created': 'Wed, 1 Aug 2018 11:06:08 GMT'}]",2018-08-02,"[['Zhang', 'Yundong', ''], ['Niebles', 'Juan Carlos', ''], ['Soto', 'Alvaro', '']]"
2107.00186,Akshat Gupta,"Zhiyuan Guo, Yuexin Li, Guo Chen, Xingyu Chen, Akshat Gupta",Word-Free Spoken Language Understanding for Mandarin-Chinese,,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Spoken dialogue systems such as Siri and Alexa provide great convenience to
people's everyday life. However, current spoken language understanding (SLU)
pipelines largely depend on automatic speech recognition (ASR) modules, which
require a large amount of language-specific training data. In this paper, we
propose a Transformer-based SLU system that works directly on phones. This
acoustic-based SLU system consists of only two blocks and does not require the
presence of ASR module. The first block is a universal phone recognition
system, and the second block is a Transformer-based language model for phones.
We verify the effectiveness of the system on an intent classification dataset
in Mandarin Chinese.
","[{'version': 'v1', 'created': 'Thu, 1 Jul 2021 02:31:22 GMT'}]",2021-07-02,"[['Guo', 'Zhiyuan', ''], ['Li', 'Yuexin', ''], ['Chen', 'Guo', ''], ['Chen', 'Xingyu', ''], ['Gupta', 'Akshat', '']]"
2402.02056,Myra Cheng,"Myra Cheng, Kristina Gligoric, Tiziano Piccardi, Dan Jurafsky",AnthroScore: A Computational Linguistic Measure of Anthropomorphism,EACL 2024 Main Conference,,,,cs.CL cs.AI cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Anthropomorphism, or the attribution of human-like characteristics to
non-human entities, has shaped conversations about the impacts and
possibilities of technology. We present AnthroScore, an automatic metric of
implicit anthropomorphism in language. We use a masked language model to
quantify how non-human entities are implicitly framed as human by the
surrounding context. We show that AnthroScore corresponds with human judgments
of anthropomorphism and dimensions of anthropomorphism described in social
science literature. Motivated by concerns of misleading anthropomorphism in
computer science discourse, we use AnthroScore to analyze 15 years of research
papers and downstream news articles. In research papers, we find that
anthropomorphism has steadily increased over time, and that papers related to
language models have the most anthropomorphism. Within ACL papers, temporal
increases in anthropomorphism are correlated with key neural advancements.
Building upon concerns of scientific misinformation in mass media, we identify
higher levels of anthropomorphism in news headlines compared to the research
papers they cite. Since AnthroScore is lexicon-free, it can be directly applied
to a wide range of text sources.
","[{'version': 'v1', 'created': 'Sat, 3 Feb 2024 06:36:11 GMT'}]",2024-02-06,"[['Cheng', 'Myra', ''], ['Gligoric', 'Kristina', ''], ['Piccardi', 'Tiziano', ''], ['Jurafsky', 'Dan', '']]"
2401.07964,Dimitri Coelho Mollo,Dimitri Coelho Mollo,AI-as-exploration: Navigating intelligence space,,,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Artificial Intelligence is a field that lives many lives, and the term has
come to encompass a motley collection of scientific and commercial endeavours.
In this paper, I articulate the contours of a rather neglected but central
scientific role that AI has to play, which I dub `AI-as-exploration'.The basic
thrust of AI-as-exploration is that of creating and studying systems that can
reveal candidate building blocks of intelligence that may differ from the forms
of human and animal intelligence we are familiar with. In other words, I
suggest that AI is one of the best tools we have for exploring intelligence
space, namely the space of possible intelligent systems. I illustrate the value
of AI-as-exploration by focusing on a specific case study, i.e., recent work on
the capacity to combine novel and invented concepts in humans and Large
Language Models. I show that the latter, despite showing human-level accuracy
in such a task, most probably solve it in ways radically different, but no less
relevant to intelligence research, to those hypothesised for humans.
","[{'version': 'v1', 'created': 'Mon, 15 Jan 2024 21:06:20 GMT'}, {'version': 'v2', 'created': 'Mon, 5 Feb 2024 17:34:17 GMT'}]",2024-02-06,"[['Mollo', 'Dimitri Coelho', '']]"
2403.09207,Viktor Moskvoretskii,"Viktor Moskvoretskii, Ekaterina Neminova, Alina Lobanova, Alexander
  Panchenko, Irina Nikishina","TaxoLLaMA: WordNet-based Model for Solving Multiple Lexical Sematic
  Tasks","18 pages, 8 figures",,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  In this paper, we explore the capabilities of LLMs in capturing
lexical-semantic knowledge from WordNet on the example of the LLaMA-2-7b model
and test it on multiple lexical semantic tasks. As the outcome of our
experiments, we present TaxoLLaMA, the everything-in-one model, lightweight due
to 4-bit quantization and LoRA. It achieves 11 SotA results, 4 top-2 results
out of 16 tasks for the Taxonomy Enrichment, Hypernym Discovery, Taxonomy
Construction, and Lexical Entailment tasks. Moreover, it demonstrates very
strong zero-shot performance on Lexical Entailment and Taxonomy Construction
with no fine-tuning. We also explore its hidden multilingual and domain
adaptation capabilities with a little tuning or few-shot learning. All
datasets, code, and model are available online at
https://github.com/VityaVitalich/TaxoLLaMA
","[{'version': 'v1', 'created': 'Thu, 14 Mar 2024 09:21:25 GMT'}]",2024-03-15,"[['Moskvoretskii', 'Viktor', ''], ['Neminova', 'Ekaterina', ''], ['Lobanova', 'Alina', ''], ['Panchenko', 'Alexander', ''], ['Nikishina', 'Irina', '']]"
2310.09430,Qiming Bao,"Qiming Bao, Gael Gendron, Alex Yuxuan Peng, Wanjun Zhong, Neset Tan,
  Yang Chen, Michael Witbrock, Jiamou Liu","A Systematic Evaluation of Large Language Models on Out-of-Distribution
  Logical Reasoning Tasks","Accepted for oral presentation at the LLM@IJCAI 2023 non-archival
  symposium",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Large language models (LLMs), such as GPT-3.5 and GPT-4, have greatly
advanced the performance of artificial systems on various natural language
processing tasks to human-like levels. However, their generalisation and
robustness to perform logical reasoning remain under-evaluated. To probe this
ability, we propose three new logical reasoning datasets named ""ReClor-plus"",
""LogiQA-plus"" and ""LogiQAv2-plus"", each featuring three subsets: the first with
randomly shuffled options, the second with the correct choices replaced by
""none of the other options are correct"", and a combination of the previous two
subsets. We carry out experiments on these datasets with both discriminative
and generative LLMs and show that these simple tricks greatly hinder the
performance of the language models. Despite their superior performance on the
original publicly available datasets, we find that all models struggle to
answer our newly constructed datasets. We show that introducing task variations
by perturbing a sizable training set can markedly improve the model's
generalisation and robustness in logical reasoning tasks. Moreover, applying
logic-driven data augmentation for fine-tuning, combined with prompting can
enhance the generalisation performance of both discriminative large language
models and generative large language models. These results offer insights into
assessing and improving the generalisation and robustness of large language
models for logical reasoning tasks. We make our source code and data publicly
available
\url{https://github.com/Strong-AI-Lab/Logical-and-abstract-reasoning}.
","[{'version': 'v1', 'created': 'Fri, 13 Oct 2023 22:29:15 GMT'}, {'version': 'v2', 'created': 'Tue, 17 Oct 2023 02:08:24 GMT'}, {'version': 'v3', 'created': 'Wed, 18 Oct 2023 22:46:12 GMT'}]",2023-10-20,"[['Bao', 'Qiming', ''], ['Gendron', 'Gael', ''], ['Peng', 'Alex Yuxuan', ''], ['Zhong', 'Wanjun', ''], ['Tan', 'Neset', ''], ['Chen', 'Yang', ''], ['Witbrock', 'Michael', ''], ['Liu', 'Jiamou', '']]"
2207.00883,Kun Wei,"Kun Wei, Pengcheng Guo, Ning Jiang","Improving Transformer-based Conversational ASR by Inter-Sentential
  Attention Mechanism",Accepted by Interspeech2022,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transformer-based models have demonstrated their effectiveness in automatic
speech recognition (ASR) tasks and even shown superior performance over the
conventional hybrid framework. The main idea of Transformers is to capture the
long-range global context within an utterance by self-attention layers.
However, for scenarios like conversational speech, such utterance-level
modeling will neglect contextual dependencies that span across utterances. In
this paper, we propose to explicitly model the inter-sentential information in
a Transformer based end-to-end architecture for conversational speech
recognition. Specifically, for the encoder network, we capture the contexts of
previous speech and incorporate such historic information into current input by
a context-aware residual attention mechanism. For the decoder, the prediction
of current utterance is also conditioned on the historic linguistic information
through a conditional decoder framework. We show the effectiveness of our
proposed method on several open-source dialogue corpora and the proposed method
consistently improved the performance from the utterance-level
Transformer-based ASR models.
","[{'version': 'v1', 'created': 'Sat, 2 Jul 2022 17:17:47 GMT'}]",2022-07-05,"[['Wei', 'Kun', ''], ['Guo', 'Pengcheng', ''], ['Jiang', 'Ning', '']]"
1210.7282,Ruggero Micheletto,Robert Bishop and Ruggero Micheletto,The Hangulphabet: A Descriptive Alphabet,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes the Hangulphabet, a new writing system that should prove
useful in a number of contexts. Using the Hangulphabet, a user can instantly
see voicing, manner and place of articulation of any phoneme found in human
language. The Hangulphabet places consonant graphemes on a grid with the x-axis
representing the place of articulation and the y-axis representing manner of
articulation. Each individual grapheme contains radicals from both axes where
the points intersect. The top radical represents manner of articulation where
the bottom represents place of articulation. A horizontal line running through
the middle of the bottom radical represents voicing. For vowels, place of
articulation is located on a grid that represents the position of the tongue in
the mouth. This grid is similar to that of the IPA vowel chart (International
Phonetic Association, 1999). The difference with the Hangulphabet being the
trapezoid representing the vocal apparatus is on a slight tilt. Place of
articulation for a vowel is represented by a breakout figure from the grid.
This system can be used as an alternative to the International Phonetic
Alphabet (IPA) or as a complement to it. Beginning students of linguistics may
find it particularly useful. A Hangulphabet font has been created to facilitate
switching between the Hangulphabet and the IPA.
","[{'version': 'v1', 'created': 'Sat, 27 Oct 2012 02:34:35 GMT'}]",2012-10-30,"[['Bishop', 'Robert', ''], ['Micheletto', 'Ruggero', '']]"
2210.16011,Maksud Sharipov,"Maksud Sharipov, Ollabergan Yuldashov","UzbekStemmer: Development of a Rule-Based Stemming Algorithm for Uzbek
  Language","Preprint of the paper to be published at The International Conference
  and Workshop on Agglutinative Language Technologies as a challenge of Natural
  Language Processing (ALTNLP), June 6, 2022, Koper, Slovenia",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In this paper we present a rule-based stemming algorithm for the Uzbek
language. Uzbek is an agglutinative language, so many words are formed by
adding suffixes, and the number of suffixes is also large. For this reason, it
is difficult to find a stem of words. The methodology is proposed for doing the
stemming of the Uzbek words with an affix stripping approach whereas not
including any database of the normal word forms of the Uzbek language. Word
affixes are classified into fifteen classes and designed as finite state
machines (FSMs) for each class according to morphological rules. We created
fifteen FSMs and linked them together to create the Basic FSM. A lexicon of
affixes in XML format was created and a stemming application for Uzbek words
has been developed based on the FSMs.
","[{'version': 'v1', 'created': 'Fri, 28 Oct 2022 09:29:22 GMT'}]",2022-10-31,"[['Sharipov', 'Maksud', ''], ['Yuldashov', 'Ollabergan', '']]"
1901.10430,Michael Auli,"Felix Wu, Angela Fan, Alexei Baevski, Yann N. Dauphin, Michael Auli",Pay Less Attention with Lightweight and Dynamic Convolutions,"14 pages, ICLR oral",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Self-attention is a useful mechanism to build generative models for language
and images. It determines the importance of context elements by comparing each
element to the current time step. In this paper, we show that a very
lightweight convolution can perform competitively to the best reported
self-attention results. Next, we introduce dynamic convolutions which are
simpler and more efficient than self-attention. We predict separate convolution
kernels based solely on the current time-step in order to determine the
importance of context elements. The number of operations required by this
approach scales linearly in the input length, whereas self-attention is
quadratic. Experiments on large-scale machine translation, language modeling
and abstractive summarization show that dynamic convolutions improve over
strong self-attention models. On the WMT'14 English-German test set dynamic
convolutions achieve a new state of the art of 29.7 BLEU.
","[{'version': 'v1', 'created': 'Tue, 29 Jan 2019 18:01:35 GMT'}, {'version': 'v2', 'created': 'Fri, 22 Feb 2019 23:46:38 GMT'}]",2019-02-26,"[['Wu', 'Felix', ''], ['Fan', 'Angela', ''], ['Baevski', 'Alexei', ''], ['Dauphin', 'Yann N.', ''], ['Auli', 'Michael', '']]"
2212.06039,You Zuo,"You Zuo (ALMAnaCH), Yixuan Li, Alma Parias Garc\'ia, Kim Gerdes (LISN)","Technological taxonomies for hypernym and hyponym retrieval in patent
  texts","ToTh 2022 - Terminology & Ontology: Theories and applications, Jun
  2022, Chamb{\'e}ry, France",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents an automatic approach to creating taxonomies of technical
terms based on the Cooperative Patent Classification (CPC). The resulting
taxonomy contains about 170k nodes in 9 separate technological branches and is
freely available. We also show that a Text-to-Text Transfer Transformer (T5)
model can be fine-tuned to generate hypernyms and hyponyms with relatively high
precision, confirming the manually assessed quality of the resource. The T5
model opens the taxonomy to any new technological terms for which a hypernym
can be generated, thus making the resource updateable with new terms, an
essential feature for the constantly evolving field of technological
terminology.
","[{'version': 'v1', 'created': 'Mon, 14 Nov 2022 19:01:55 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Dec 2022 15:26:25 GMT'}]",2022-12-14,"[['Zuo', 'You', '', 'ALMAnaCH'], ['Li', 'Yixuan', '', 'LISN'], ['García', 'Alma Parias', '', 'LISN'], ['Gerdes', 'Kim', '', 'LISN']]"
2211.08203,Edgar Altszyler,"Francisco Valentini, Juan Cruz Sosa, Diego Fernandez Slezak, Edgar
  Altszyler","Investigating the Frequency Distortion of Word Embeddings and Its Impact
  on Bias Metrics",Camera Ready for EMNLP 2023 (Findings),,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent research has shown that static word embeddings can encode word
frequency information. However, little has been studied about this phenomenon
and its effects on downstream tasks. In the present work, we systematically
study the association between frequency and semantic similarity in several
static word embeddings. We find that Skip-gram, GloVe and FastText embeddings
tend to produce higher semantic similarity between high-frequency words than
between other frequency combinations. We show that the association between
frequency and similarity also appears when words are randomly shuffled. This
proves that the patterns found are not due to real semantic associations
present in the texts, but are an artifact produced by the word embeddings.
Finally, we provide an example of how word frequency can strongly impact the
measurement of gender bias with embedding-based metrics. In particular, we
carry out a controlled experiment that shows that biases can even change sign
or reverse their order by manipulating word frequencies.
","[{'version': 'v1', 'created': 'Tue, 15 Nov 2022 15:11:06 GMT'}, {'version': 'v2', 'created': 'Thu, 19 Oct 2023 19:07:40 GMT'}]",2023-10-23,"[['Valentini', 'Francisco', ''], ['Sosa', 'Juan Cruz', ''], ['Slezak', 'Diego Fernandez', ''], ['Altszyler', 'Edgar', '']]"
1605.00090,Yu Wu,"Yu Wu, Wei Wu, Zhoujun Li, Ming Zhou",Response Selection with Topic Clues for Retrieval-based Chatbots,under reviewed of AAAI 2017,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We consider incorporating topic information into message-response matching to
boost responses with rich content in retrieval-based chatbots. To this end, we
propose a topic-aware convolutional neural tensor network (TACNTN). In TACNTN,
matching between a message and a response is not only conducted between a
message vector and a response vector generated by convolutional neural
networks, but also leverages extra topic information encoded in two topic
vectors. The two topic vectors are linear combinations of topic words of the
message and the response respectively, where the topic words are obtained from
a pre-trained LDA model and their weights are determined by themselves as well
as the message vector and the response vector. The message vector, the response
vector, and the two topic vectors are fed to neural tensors to calculate a
matching score. Empirical study on a public data set and a human annotated data
set shows that TACNTN can significantly outperform state-of-the-art methods for
message-response matching.
","[{'version': 'v1', 'created': 'Sat, 30 Apr 2016 10:48:29 GMT'}, {'version': 'v2', 'created': 'Wed, 15 Jun 2016 05:37:26 GMT'}, {'version': 'v3', 'created': 'Thu, 22 Sep 2016 03:02:40 GMT'}]",2016-09-23,"[['Wu', 'Yu', ''], ['Wu', 'Wei', ''], ['Li', 'Zhoujun', ''], ['Zhou', 'Ming', '']]"
2401.05707,Zhiyu Li,"Zhen Tao, Dinghao Xi, Zhiyu Li, Liumin Tang, Wei Xu","CAT-LLM: Prompting Large Language Models with Text Style Definition for
  Chinese Article-style Transfer",9 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text style transfer is increasingly prominent in online entertainment and
social media. However, existing research mainly concentrates on style transfer
within individual English sentences, while ignoring the complexity of long
Chinese texts, which limits the wider applicability of style transfer in
digital media realm. To bridge this gap, we propose a Chinese Article-style
Transfer framework (CAT-LLM), leveraging the capabilities of Large Language
Models (LLMs). CAT-LLM incorporates a bespoke, pluggable Text Style Definition
(TSD) module aimed at comprehensively analyzing text features in articles,
prompting LLMs to efficiently transfer Chinese article-style. The TSD module
integrates a series of machine learning algorithms to analyze article-style
from both words and sentences levels, thereby aiding LLMs thoroughly grasp the
target style without compromising the integrity of the original text. In
addition, this module supports dynamic expansion of internal style trees,
showcasing robust compatibility and allowing flexible optimization in
subsequent research. Moreover, we select five Chinese articles with distinct
styles and create five parallel datasets using ChatGPT, enhancing the models'
performance evaluation accuracy and establishing a novel paradigm for
evaluating subsequent research on article-style transfer. Extensive
experimental results affirm that CAT-LLM outperforms current research in terms
of transfer accuracy and content preservation, and has remarkable applicability
to various types of LLMs.
","[{'version': 'v1', 'created': 'Thu, 11 Jan 2024 07:18:46 GMT'}]",2024-01-12,"[['Tao', 'Zhen', ''], ['Xi', 'Dinghao', ''], ['Li', 'Zhiyu', ''], ['Tang', 'Liumin', ''], ['Xu', 'Wei', '']]"
1908.11425,Sameer Bansal,"Sameer Bansal, Herman Kamper, Adam Lopez, Sharon Goldwater",Cross-lingual topic prediction for speech using translations,Accepted to ICASSP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Given a large amount of unannotated speech in a low-resource language, can we
classify the speech utterances by topic? We consider this question in the
setting where a small amount of speech in the low-resource language is paired
with text translations in a high-resource language. We develop an effective
cross-lingual topic classifier by training on just 20 hours of translated
speech, using a recent model for direct speech-to-text translation. While the
translations are poor, they are still good enough to correctly classify the
topic of 1-minute speech segments over 70% of the time - a 20% improvement over
a majority-class baseline. Such a system could be useful for humanitarian
applications like crisis response, where incoming speech in a foreign
low-resource language must be quickly assessed for further action.
","[{'version': 'v1', 'created': 'Thu, 29 Aug 2019 19:11:26 GMT'}, {'version': 'v2', 'created': 'Sun, 29 Mar 2020 12:01:24 GMT'}]",2020-03-31,"[['Bansal', 'Sameer', ''], ['Kamper', 'Herman', ''], ['Lopez', 'Adam', ''], ['Goldwater', 'Sharon', '']]"
2211.15458,Michael Kuchnik,"Michael Kuchnik, Virginia Smith, George Amvrosiadis",Validating Large Language Models with ReLM,,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Although large language models (LLMs) have been touted for their ability to
generate natural-sounding text, there are growing concerns around possible
negative effects of LLMs such as data memorization, bias, and inappropriate
language. Unfortunately, the complexity and generation capacities of LLMs make
validating (and correcting) such concerns difficult. In this work, we introduce
ReLM, a system for validating and querying LLMs using standard regular
expressions. ReLM formalizes and enables a broad range of language model
evaluations, reducing complex evaluation rules to simple regular expression
queries. Our results exploring queries surrounding memorization, gender bias,
toxicity, and language understanding show that ReLM achieves up to 15x higher
system efficiency, 2.5x data efficiency, and increased statistical and
prompt-tuning coverage compared to state-of-the-art ad-hoc queries. ReLM offers
a competitive and general baseline for the increasingly important problem of
LLM validation.
","[{'version': 'v1', 'created': 'Mon, 21 Nov 2022 21:40:35 GMT'}, {'version': 'v2', 'created': 'Mon, 8 May 2023 18:01:28 GMT'}]",2023-05-10,"[['Kuchnik', 'Michael', ''], ['Smith', 'Virginia', ''], ['Amvrosiadis', 'George', '']]"
2205.12689,Monica Agrawal,"Monica Agrawal, Stefan Hegselmann, Hunter Lang, Yoon Kim, David Sontag",Large Language Models are Few-Shot Clinical Information Extractors,"Accepted as a long paper to The 2022 Conference on Empirical Methods
  in Natural Language Processing (EMNLP)",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A long-running goal of the clinical NLP community is the extraction of
important variables trapped in clinical notes. However, roadblocks have
included dataset shift from the general domain and a lack of public clinical
corpora and annotations. In this work, we show that large language models, such
as InstructGPT, perform well at zero- and few-shot information extraction from
clinical text despite not being trained specifically for the clinical domain.
Whereas text classification and generation performance have already been
studied extensively in such models, here we additionally demonstrate how to
leverage them to tackle a diverse set of NLP tasks which require more
structured outputs, including span identification, token-level sequence
classification, and relation extraction. Further, due to the dearth of
available data to evaluate these systems, we introduce new datasets for
benchmarking few-shot clinical information extraction based on a manual
re-annotation of the CASI dataset for new tasks. On the clinical extraction
tasks we studied, the GPT-3 systems significantly outperform existing zero- and
few-shot baselines.
","[{'version': 'v1', 'created': 'Wed, 25 May 2022 11:49:58 GMT'}, {'version': 'v2', 'created': 'Wed, 30 Nov 2022 18:43:44 GMT'}]",2022-12-01,"[['Agrawal', 'Monica', ''], ['Hegselmann', 'Stefan', ''], ['Lang', 'Hunter', ''], ['Kim', 'Yoon', ''], ['Sontag', 'David', '']]"
2305.14293,Chenxi Whitehouse,"Chenxi Whitehouse, Clara Vania, Alham Fikri Aji, Christos
  Christodoulopoulos, Andrea Pierleoni",WebIE: Faithful and Robust Information Extraction on the Web,ACL 2023 Main Conference,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Extracting structured and grounded fact triples from raw text is a
fundamental task in Information Extraction (IE). Existing IE datasets are
typically collected from Wikipedia articles, using hyperlinks to link entities
to the Wikidata knowledge base. However, models trained only on Wikipedia have
limitations when applied to web domains, which often contain noisy text or text
that does not have any factual information. We present WebIE, the first
large-scale, entity-linked closed IE dataset consisting of 1.6M sentences
automatically collected from the English Common Crawl corpus. WebIE also
includes negative examples, i.e. sentences without fact triples, to better
reflect the data on the web. We annotate ~21K triples from WebIE through
crowdsourcing and introduce mWebIE, a translation of the annotated set in four
other languages: French, Spanish, Portuguese, and Hindi. We evaluate the
in-domain, out-of-domain, and zero-shot cross-lingual performance of generative
IE models and find models trained on WebIE show better generalisability. We
also propose three training strategies that use entity linking as an auxiliary
task. Our experiments show that adding Entity-Linking objectives improves the
faithfulness of our generative IE models.
","[{'version': 'v1', 'created': 'Tue, 23 May 2023 17:37:53 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Jun 2023 13:51:36 GMT'}]",2023-06-16,"[['Whitehouse', 'Chenxi', ''], ['Vania', 'Clara', ''], ['Aji', 'Alham Fikri', ''], ['Christodoulopoulos', 'Christos', ''], ['Pierleoni', 'Andrea', '']]"
2210.12459,Xueliang Zhao,"Xueliang Zhao, Tingchen Fu, Chongyang Tao and Rui Yan","There Is No Standard Answer: Knowledge-Grounded Dialogue Generation with
  Adversarial Activated Multi-Reference Learning","To appear at EMNLP 2022 main conference. The first two authors
  contributed equally",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Knowledge-grounded conversation (KGC) shows excellent potential to deliver an
engaging and informative response. However, existing approaches emphasize
selecting one golden knowledge given a particular dialogue context, overlooking
the one-to-many phenomenon in dialogue. As a result, the existing paradigm
limits the diversity of knowledge selection and generation. To this end, we
establish a multi-reference KGC dataset and propose a series of metrics to
systematically assess the one-to-many efficacy of existing KGC models.
Furthermore, to extend the hypothesis space of knowledge selection to enhance
the mapping relationship between multiple knowledge and multiple responses, we
devise a span-based variational model and optimize the model in a wake-sleep
style with an ameliorated evidence lower bound objective to learn the
one-to-many generalization. Both automatic and human evaluations demonstrate
the efficacy of our approach.
","[{'version': 'v1', 'created': 'Sat, 22 Oct 2022 14:43:33 GMT'}]",2022-10-25,"[['Zhao', 'Xueliang', ''], ['Fu', 'Tingchen', ''], ['Tao', 'Chongyang', ''], ['Yan', 'Rui', '']]"
2306.13310,Chengmei Yang,"Chengmei Yang, Shuai Jiang, Bowei He, Chen Ma, and Lianghua He",Mutually Guided Few-shot Learning for Relational Triple Extraction,Accepted by ICASSP 2023,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Knowledge graphs (KGs), containing many entity-relation-entity triples,
provide rich information for downstream applications. Although extracting
triples from unstructured texts has been widely explored, most of them require
a large number of labeled instances. The performance will drop dramatically
when only few labeled data are available. To tackle this problem, we propose
the Mutually Guided Few-shot learning framework for Relational Triple
Extraction (MG-FTE). Specifically, our method consists of an entity-guided
relation proto-decoder to classify the relations firstly and a relation-guided
entity proto-decoder to extract entities based on the classified relations. To
draw the connection between entity and relation, we design a proto-level fusion
module to boost the performance of both entity extraction and relation
classification. Moreover, a new cross-domain few-shot triple extraction task is
introduced. Extensive experiments show that our method outperforms many
state-of-the-art methods by 12.6 F1 score on FewRel 1.0 (single-domain) and
20.5 F1 score on FewRel 2.0 (cross-domain).
","[{'version': 'v1', 'created': 'Fri, 23 Jun 2023 06:15:54 GMT'}]",2023-06-26,"[['Yang', 'Chengmei', ''], ['Jiang', 'Shuai', ''], ['He', 'Bowei', ''], ['Ma', 'Chen', ''], ['He', 'Lianghua', '']]"
1902.10525,Thomas Deselaers,"Victor Carbune and Pedro Gonnet and Thomas Deselaers and Henry A.
  Rowley and Alexander Daryin and Marcos Calvo and Li-Lun Wang and Daniel
  Keysers and Sandro Feuz and Philippe Gervais",Fast Multi-language LSTM-based Online Handwriting Recognition,accepted to IJDAR,,,,cs.CL cs.LG stat.ML,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  We describe an online handwriting system that is able to support 102
languages using a deep neural network architecture. This new system has
completely replaced our previous Segment-and-Decode-based system and reduced
the error rate by 20%-40% relative for most languages. Further, we report new
state-of-the-art results on IAM-OnDB for both the open and closed dataset
setting. The system combines methods from sequence recognition with a new input
encoding using B\'ezier curves. This leads to up to 10x faster recognition
times compared to our previous system. Through a series of experiments we
determine the optimal configuration of our models and report the results of our
setup on a number of additional public datasets.
","[{'version': 'v1', 'created': 'Fri, 22 Feb 2019 12:33:38 GMT'}, {'version': 'v2', 'created': 'Fri, 24 Jan 2020 09:52:41 GMT'}]",2020-01-27,"[['Carbune', 'Victor', ''], ['Gonnet', 'Pedro', ''], ['Deselaers', 'Thomas', ''], ['Rowley', 'Henry A.', ''], ['Daryin', 'Alexander', ''], ['Calvo', 'Marcos', ''], ['Wang', 'Li-Lun', ''], ['Keysers', 'Daniel', ''], ['Feuz', 'Sandro', ''], ['Gervais', 'Philippe', '']]"
2111.01908,Rhitabrat Pokharel,Rhitabrat Pokharel and Dixit Bhatta,Classifying YouTube Comments Based on Sentiment and Type of Sentence,"This paper was accepted at 2021 International Conference on Knowledge
  Discovery and Machine Learning (KDML 2021), but later withdrawn. The paper
  should be taken as a non peer-reviewed publication",,,,cs.IR cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  As a YouTube channel grows, each video can potentially collect enormous
amounts of comments that provide direct feedback from the viewers. These
comments are a major means of understanding viewer expectations and improving
channel engagement. However, the comments only represent a general collection
of user opinions about the channel and the content. Many comments are poorly
constructed, trivial, and have improper spellings and grammatical errors. As a
result, it is a tedious job to identify the comments that best interest the
content creators. In this paper, we extract and classify the raw comments into
different categories based on both sentiment and sentence types that will help
YouTubers find relevant comments for growing their viewership. Existing studies
have focused either on sentiment analysis (positive and negative) or
classification of sub-types within the same sentence types (e.g., types of
questions) on a text corpus. These have limited application on non-traditional
text corpus like YouTube comments. We address this challenge of text extraction
and classification from YouTube comments using well-known statistical measures
and machine learning models. We evaluate each combination of statistical
measure and the machine learning model using cross validation and $F_1$ scores.
The results show that our approach that incorporates conventional methods
performs well on the classification task, validating its potential in assisting
content creators increase viewer engagement on their channel.
","[{'version': 'v1', 'created': 'Sun, 31 Oct 2021 18:08:10 GMT'}]",2023-06-05,"[['Pokharel', 'Rhitabrat', ''], ['Bhatta', 'Dixit', '']]"
2202.13914,Edoardo Maria Ponti,"Edoardo M. Ponti, Alessandro Sordoni, Yoshua Bengio and Siva Reddy",Combining Modular Skills in Multitask Learning,,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A modular design encourages neural models to disentangle and recombine
different facets of knowledge to generalise more systematically to new tasks.
In this work, we assume that each task is associated with a subset of latent
discrete skills from a (potentially small) inventory. In turn, skills
correspond to parameter-efficient (sparse / low-rank) model parameterisations.
By jointly learning these and a task-skill allocation matrix, the network for
each task is instantiated as the average of the parameters of active skills. To
favour non-trivial soft partitions of skills across tasks, we experiment with a
series of inductive biases, such as an Indian Buffet Process prior and a
two-speed learning rate. We evaluate our latent-skill model on two main
settings: 1) multitask reinforcement learning for grounded instruction
following on 8 levels of the BabyAI platform; and 2) few-shot adaptation of
pre-trained text-to-text generative models on CrossFit, a benchmark comprising
160 NLP tasks. We find that the modular design of a network significantly
increases sample efficiency in reinforcement learning and few-shot
generalisation in supervised learning, compared to baselines with fully shared,
task-specific, or conditionally generated parameters where knowledge is
entangled across tasks. In addition, we show how discrete skills help
interpretability, as they yield an explicit hierarchy of tasks.
","[{'version': 'v1', 'created': 'Mon, 28 Feb 2022 16:07:19 GMT'}, {'version': 'v2', 'created': 'Tue, 1 Mar 2022 10:50:30 GMT'}]",2022-03-02,"[['Ponti', 'Edoardo M.', ''], ['Sordoni', 'Alessandro', ''], ['Bengio', 'Yoshua', ''], ['Reddy', 'Siva', '']]"
2108.03362,Sunipa Dev,"Sunipa Dev, Emily Sheng, Jieyu Zhao, Aubrie Amstutz, Jiao Sun, Yu Hou,
  Mattie Sanseverino, Jiin Kim, Akihiro Nishi, Nanyun Peng, Kai-Wei Chang",On Measures of Biases and Harms in NLP,,,,,cs.CL cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Recent studies show that Natural Language Processing (NLP) technologies
propagate societal biases about demographic groups associated with attributes
such as gender, race, and nationality. To create interventions and mitigate
these biases and associated harms, it is vital to be able to detect and measure
such biases. While existing works propose bias evaluation and mitigation
methods for various tasks, there remains a need to cohesively understand the
biases and the specific harms they measure, and how different measures compare
with each other. To address this gap, this work presents a practical framework
of harms and a series of questions that practitioners can answer to guide the
development of bias measures. As a validation of our framework and
documentation questions, we also present several case studies of how existing
bias measures in NLP -- both intrinsic measures of bias in representations and
extrinsic measures of bias of downstream applications -- can be aligned with
different harms and how our proposed documentation questions facilitates more
holistic understanding of what bias measures are measuring.
","[{'version': 'v1', 'created': 'Sat, 7 Aug 2021 04:08:47 GMT'}, {'version': 'v2', 'created': 'Thu, 13 Oct 2022 22:38:20 GMT'}]",2022-10-17,"[['Dev', 'Sunipa', ''], ['Sheng', 'Emily', ''], ['Zhao', 'Jieyu', ''], ['Amstutz', 'Aubrie', ''], ['Sun', 'Jiao', ''], ['Hou', 'Yu', ''], ['Sanseverino', 'Mattie', ''], ['Kim', 'Jiin', ''], ['Nishi', 'Akihiro', ''], ['Peng', 'Nanyun', ''], ['Chang', 'Kai-Wei', '']]"
2212.11456,Daniel DeGenaro,Dan DeGenaro and Jugal Kalita,CAMeMBERT: Cascading Assistant-Mediated Multilingual BERT,"4 pages, 2 figures, 3 tables",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models having hundreds of millions, and even billions, of
parameters have performed extremely well on a variety of natural language
processing (NLP) tasks. Their widespread use and adoption, however, is hindered
by the lack of availability and portability of sufficiently large computational
resources. This paper proposes a knowledge distillation (KD) technique building
on the work of LightMBERT, a student model of multilingual BERT (mBERT). By
repeatedly distilling mBERT through increasingly compressed toplayer distilled
teacher assistant networks, CAMeMBERT aims to improve upon the time and space
complexities of mBERT while keeping loss of accuracy beneath an acceptable
threshold. At present, CAMeMBERT has an average accuracy of around 60.1%, which
is subject to change after future improvements to the hyperparameters used in
fine-tuning.
","[{'version': 'v1', 'created': 'Thu, 22 Dec 2022 02:19:25 GMT'}]",2022-12-23,"[['DeGenaro', 'Dan', ''], ['Kalita', 'Jugal', '']]"
2209.06453,Haochun Wang,"Haochun Wang, Chi Liu, Nuwa Xi, Sendong Zhao, Meizhi Ju, Shiwei Zhang,
  Ziheng Zhang, Yefeng Zheng, Bing Qin and Ting Liu","Prompt Combines Paraphrase: Teaching Pre-trained Models to Understand
  Rare Biomedical Words",Accepted to COLING 2022,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Prompt-based fine-tuning for pre-trained models has proven effective for many
natural language processing tasks under few-shot settings in general domain.
However, tuning with prompt in biomedical domain has not been investigated
thoroughly. Biomedical words are often rare in general domain, but quite
ubiquitous in biomedical contexts, which dramatically deteriorates the
performance of pre-trained models on downstream biomedical applications even
after fine-tuning, especially in low-resource scenarios. We propose a simple
yet effective approach to helping models learn rare biomedical words during
tuning with prompt. Experimental results show that our method can achieve up to
6% improvement in biomedical natural language inference task without any extra
parameters or training steps using few-shot vanilla prompt settings.
","[{'version': 'v1', 'created': 'Wed, 14 Sep 2022 07:03:29 GMT'}]",2023-04-17,"[['Wang', 'Haochun', ''], ['Liu', 'Chi', ''], ['Xi', 'Nuwa', ''], ['Zhao', 'Sendong', ''], ['Ju', 'Meizhi', ''], ['Zhang', 'Shiwei', ''], ['Zhang', 'Ziheng', ''], ['Zheng', 'Yefeng', ''], ['Qin', 'Bing', ''], ['Liu', 'Ting', '']]"
1909.10416,Chih-Hsuan Wei,"Chih-Hsuan Wei, Kyubum Lee, Robert Leaman, Zhiyong Lu",Biomedical Mention Disambiguation using a Deep Learning Approach,,,,,cs.CL,http://creativecommons.org/publicdomain/zero/1.0/,"  Automatically locating named entities in natural language text - named entity
recognition - is an important task in the biomedical domain. Many named entity
mentions are ambiguous between several bioconcept types, however, causing text
spans to be annotated as more than one type when simultaneously recognizing
multiple entity types. The straightforward solution is a rule-based approach
applying a priority order based on the precision of each entity tagger (from
highest to lowest). While this method is straightforward and useful, imprecise
disambiguation remains a significant source of error. We address this issue by
generating a partially labeled corpus of ambiguous concept mentions. We first
collect named entity mentions from multiple human-curated databases (e.g.
CTDbase, gene2pubmed), then correlate them with the text mined span from
PubTator to provide the context where the mention appears. Our corpus contains
more than 3 million concept mentions that ambiguous between one or more concept
types in PubTator (about 3% of all mentions). We approached this task as a
classification problem and developed a deep learning-based method which uses
the semantics of the span being classified and the surrounding words to
identify the most likely bioconcept type. More specifically, we develop a
convolutional neural network (CNN) and along short-term memory (LSTM) network
to respectively handle the semantic syntax features, then concatenate these
within a fully connected layer for final classification. The priority ordering
rule-based approach demonstrated F1-scores of 71.29% (micro-averaged) and
41.19% (macro-averaged), while the new disambiguation method demonstrated
F1-scores of 91.94% (micro-averaged) and 85.42% (macro-averaged), a very
substantial increase.
","[{'version': 'v1', 'created': 'Mon, 23 Sep 2019 15:14:56 GMT'}]",2019-09-24,"[['Wei', 'Chih-Hsuan', ''], ['Lee', 'Kyubum', ''], ['Leaman', 'Robert', ''], ['Lu', 'Zhiyong', '']]"
2302.10143,Shizhe Diao,"Shizhe Diao, Sedrick Scott Keh, Liangming Pan, Zhiliang Tian, Yan
  Song, Tong Zhang",Hashtag-Guided Low-Resource Tweet Classification,WWW 2023,,,,cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Social media classification tasks (e.g., tweet sentiment analysis, tweet
stance detection) are challenging because social media posts are typically
short, informal, and ambiguous. Thus, training on tweets is challenging and
demands large-scale human-annotated labels, which are time-consuming and costly
to obtain. In this paper, we find that providing hashtags to social media
tweets can help alleviate this issue because hashtags can enrich short and
ambiguous tweets in terms of various information, such as topic, sentiment, and
stance. This motivates us to propose a novel Hashtag-guided Tweet
Classification model (HashTation), which automatically generates meaningful
hashtags for the input tweet to provide useful auxiliary signals for tweet
classification. To generate high-quality and insightful hashtags, our hashtag
generation model retrieves and encodes the post-level and entity-level
information across the whole corpus. Experiments show that HashTation achieves
significant improvements on seven low-resource tweet classification tasks, in
which only a limited amount of training data is provided, showing that
automatically enriching tweets with model-generated hashtags could
significantly reduce the demand for large-scale human-labeled data. Further
analysis demonstrates that HashTation is able to generate high-quality hashtags
that are consistent with the tweets and their labels. The code is available at
https://github.com/shizhediao/HashTation.
","[{'version': 'v1', 'created': 'Mon, 20 Feb 2023 18:21:02 GMT'}]",2023-02-21,"[['Diao', 'Shizhe', ''], ['Keh', 'Sedrick Scott', ''], ['Pan', 'Liangming', ''], ['Tian', 'Zhiliang', ''], ['Song', 'Yan', ''], ['Zhang', 'Tong', '']]"
2307.04408,Jiali Zeng,Jiali Zeng and Fandong Meng and Yongjing Yin and Jie Zhou,TIM: Teaching Large Language Models to Translate with Comparison,AAAI 2024,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Open-sourced large language models (LLMs) have demonstrated remarkable
efficacy in various tasks with instruction tuning. However, these models can
sometimes struggle with tasks that require more specialized knowledge such as
translation. One possible reason for such deficiency is that instruction tuning
aims to generate fluent and coherent text that continues from a given
instruction without being constrained by any task-specific requirements.
Moreover, it can be more challenging for tuning smaller LLMs with lower-quality
training data. To address this issue, we propose a novel framework using
examples in comparison to teach LLMs to learn translation. Our approach
involves presenting the model with examples of correct and incorrect
translations and using a preference loss to guide the model's learning. We
evaluate our method on WMT2022 test sets and show that it outperforms existing
methods. Our findings offer a new perspective on fine-tuning LLMs for
translation tasks and provide a promising solution for generating high-quality
translations. Please refer to Github for more details:
https://github.com/lemon0830/TIM.
","[{'version': 'v1', 'created': 'Mon, 10 Jul 2023 08:15:40 GMT'}, {'version': 'v2', 'created': 'Thu, 14 Sep 2023 07:58:00 GMT'}, {'version': 'v3', 'created': 'Mon, 22 Jan 2024 07:40:02 GMT'}]",2024-01-23,"[['Zeng', 'Jiali', ''], ['Meng', 'Fandong', ''], ['Yin', 'Yongjing', ''], ['Zhou', 'Jie', '']]"
2301.11716,Phuong-Hang Le,"Phuong-Hang Le, Hongyu Gong, Changhan Wang, Juan Pino, Benjamin
  Lecouteux, Didier Schwab",Pre-training for Speech Translation: CTC Meets Optimal Transport,"ICML 2023 (oral presentation). This version fixed URLs, updated
  affiliations & acknowledgements, and improved formatting",,,,cs.CL cs.LG cs.SD eess.AS,http://creativecommons.org/licenses/by/4.0/,"  The gap between speech and text modalities is a major challenge in
speech-to-text translation (ST). Different methods have been proposed to reduce
this gap, but most of them require architectural changes in ST training. In
this work, we propose to mitigate this issue at the pre-training stage,
requiring no change in the ST model. First, we show that the connectionist
temporal classification (CTC) loss can reduce the modality gap by design. We
provide a quantitative comparison with the more common cross-entropy loss,
showing that pre-training with CTC consistently achieves better final ST
accuracy. Nevertheless, CTC is only a partial solution and thus, in our second
contribution, we propose a novel pre-training method combining CTC and optimal
transport to further reduce this gap. Our method pre-trains a Siamese-like
model composed of two encoders, one for acoustic inputs and the other for
textual inputs, such that they produce representations that are close to each
other in the Wasserstein space. Extensive experiments on the standard CoVoST-2
and MuST-C datasets show that our pre-training method applied to the vanilla
encoder-decoder Transformer achieves state-of-the-art performance under the
no-external-data setting, and performs on par with recent strong multi-task
learning systems trained with external data. Finally, our method can also be
applied on top of these multi-task systems, leading to further improvements for
these models. Code and pre-trained models are available at
https://github.com/formiel/fairseq.
","[{'version': 'v1', 'created': 'Fri, 27 Jan 2023 14:03:09 GMT'}, {'version': 'v2', 'created': 'Tue, 30 May 2023 09:06:22 GMT'}, {'version': 'v3', 'created': 'Mon, 5 Jun 2023 11:44:02 GMT'}]",2023-06-06,"[['Le', 'Phuong-Hang', ''], ['Gong', 'Hongyu', ''], ['Wang', 'Changhan', ''], ['Pino', 'Juan', ''], ['Lecouteux', 'Benjamin', ''], ['Schwab', 'Didier', '']]"
2004.14555,Jingbo Shang,"Peiran Li, Fang Guo, Jingbo Shang",User-Guided Aspect Classification for Domain-Specific Texts,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Aspect classification, identifying aspects of text segments, facilitates
numerous applications, such as sentiment analysis and review summarization. To
alleviate the human effort on annotating massive texts, in this paper, we study
the problem of classifying aspects based on only a few user-provided seed words
for pre-defined aspects. The major challenge lies in how to handle the noisy
misc aspect, which is designed for texts without any pre-defined aspects. Even
domain experts have difficulties to nominate seed words for the misc aspect,
making existing seed-driven text classification methods not applicable. We
propose a novel framework, ARYA, which enables mutual enhancements between
pre-defined aspects and the misc aspect via iterative classifier training and
seed updating. Specifically, it trains a classifier for pre-defined aspects and
then leverages it to induce the supervision for the misc aspect. The prediction
results of the misc aspect are later utilized to filter out noisy seed words
for pre-defined aspects. Experiments in two domains demonstrate the superior
performance of our proposed framework, as well as the necessity and importance
of properly modeling the misc aspect.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 03:14:16 GMT'}]",2020-05-01,"[['Li', 'Peiran', ''], ['Guo', 'Fang', ''], ['Shang', 'Jingbo', '']]"
2205.06203,Antonio Laverghetta Jr.,"Antonio Laverghetta Jr., Animesh Nighojkar, Jamshidbek Mirzakhalov,
  John Licato","Predicting Human Psychometric Properties Using Computational Language
  Models","To appear in Quantitative Psychology, The 86th Annual Meeting of the
  Psychometric Society, Virtual. arXiv admin note: substantial text overlap
  with arXiv:2106.06849",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Transformer-based language models (LMs) continue to achieve state-of-the-art
performance on natural language processing (NLP) benchmarks, including tasks
designed to mimic human-inspired ""commonsense"" competencies. To better
understand the degree to which LMs can be said to have certain linguistic
reasoning skills, researchers are beginning to adapt the tools and concepts
from psychometrics. But to what extent can benefits flow in the other
direction? In other words, can LMs be of use in predicting the psychometric
properties of test items, when those items are given to human participants? If
so, the benefit for psychometric practitioners is enormous, as it can reduce
the need for multiple rounds of empirical testing. We gather responses from
numerous human participants and LMs (transformer- and non-transformer-based) on
a broad diagnostic test of linguistic competencies. We then use the human
responses to calculate standard psychometric properties of the items in the
diagnostic test, using the human responses and the LM responses separately. We
then determine how well these two sets of predictions correlate. We find that
transformer-based LMs predict the human psychometric data consistently well
across most categories, suggesting that they can be used to gather human-like
psychometric data without the need for extensive human trials.
","[{'version': 'v1', 'created': 'Thu, 12 May 2022 16:40:12 GMT'}]",2022-05-13,"[['Laverghetta', 'Antonio', 'Jr.'], ['Nighojkar', 'Animesh', ''], ['Mirzakhalov', 'Jamshidbek', ''], ['Licato', 'John', '']]"
2204.02269,Marc-Antoine Georges,"Marc-Antoine Georges, Julien Diard, Laurent Girin, Jean-Luc Schwartz,
  Thomas Hueber","Repeat after me: Self-supervised learning of acoustic-to-articulatory
  mapping by vocal imitation",,,,,cs.SD cs.CL eess.AS,http://creativecommons.org/licenses/by/4.0/,"  We propose a computational model of speech production combining a pre-trained
neural articulatory synthesizer able to reproduce complex speech stimuli from a
limited set of interpretable articulatory parameters, a DNN-based internal
forward model predicting the sensory consequences of articulatory commands, and
an internal inverse model based on a recurrent neural network recovering
articulatory commands from the acoustic speech input. Both forward and inverse
models are jointly trained in a self-supervised way from raw acoustic-only
speech data from different speakers. The imitation simulations are evaluated
objectively and subjectively and display quite encouraging performances.
","[{'version': 'v1', 'created': 'Tue, 5 Apr 2022 15:02:49 GMT'}]",2022-04-06,"[['Georges', 'Marc-Antoine', ''], ['Diard', 'Julien', ''], ['Girin', 'Laurent', ''], ['Schwartz', 'Jean-Luc', ''], ['Hueber', 'Thomas', '']]"
2101.03634,Hiroyoshi Komatsu,Hiroyoshi Komatsu,"The Logic for a Mildly Context-Sensitive Fragment of the Lambek-Grishin
  Calculus",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While context-free grammars are characterized by a simple proof-theoretic
grammatical formalism namely categorial grammar and its logic the Lambek
calculus, no such characterizations were known for tree-adjoining grammars, and
even for any mildly context-sensitive languages classes in the last forty years
despite some efforts. We settle this problem in this paper. On the basis of the
existing fragment of the Lambek-Grishin calculus which captures tree-adjoining
languages, we present a logic called HLG: a proof-theoretic characterization of
tree-adjoining languages based on the Lambek-Grishin calculus restricted to
Hyperedge-replacement grammar with rank two studied by Moot. HLG is defined in
display calculus with cut-admissibility. Several new techniques are introduced
for the proofs, such as purely structural connectives, usefulness, and a
graph-theoretic argument on proof nets for HLG.
","[{'version': 'v1', 'created': 'Sun, 10 Jan 2021 22:28:05 GMT'}]",2021-01-12,"[['Komatsu', 'Hiroyoshi', '']]"
2108.07073,Zhou Yu,"Yuhao Cui, Zhou Yu, Chunqi Wang, Zhongzhou Zhao, Ji Zhang, Meng Wang,
  Jun Yu","ROSITA: Enhancing Vision-and-Language Semantic Alignments via Cross- and
  Intra-modal Knowledge Integration","Accepted at ACM Multimedia 2021. Code available at
  https://github.com/MILVLG/rosita",,,,cs.CV cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Vision-and-language pretraining (VLP) aims to learn generic multimodal
representations from massive image-text pairs. While various successful
attempts have been proposed, learning fine-grained semantic alignments between
image-text pairs plays a key role in their approaches. Nevertheless, most
existing VLP approaches have not fully utilized the intrinsic knowledge within
the image-text pairs, which limits the effectiveness of the learned alignments
and further restricts the performance of their models. To this end, we
introduce a new VLP method called ROSITA, which integrates the cross- and
intra-modal knowledge in a unified scene graph to enhance the semantic
alignments. Specifically, we introduce a novel structural knowledge masking
(SKM) strategy to use the scene graph structure as a priori to perform masked
language (region) modeling, which enhances the semantic alignments by
eliminating the interference information within and across modalities.
Extensive ablation studies and comprehensive analysis verifies the
effectiveness of ROSITA in semantic alignments. Pretrained with both in-domain
and out-of-domain datasets, ROSITA significantly outperforms existing
state-of-the-art VLP methods on three typical vision-and-language tasks over
six benchmark datasets.
","[{'version': 'v1', 'created': 'Mon, 16 Aug 2021 13:16:58 GMT'}]",2021-08-17,"[['Cui', 'Yuhao', ''], ['Yu', 'Zhou', ''], ['Wang', 'Chunqi', ''], ['Zhao', 'Zhongzhou', ''], ['Zhang', 'Ji', ''], ['Wang', 'Meng', ''], ['Yu', 'Jun', '']]"
2204.13362,Kexin Yang,"Kexin Yang, Dayiheng Liu, Wenqiang Lei, Baosong Yang, Mingfeng Xue,
  Boxing Chen, Jun Xie","Tailor: A Prompt-Based Approach to Attribute-Based Controlled Text
  Generation",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Attribute-based Controlled Text Generation (CTG) refers to generating
sentences that satisfy desirable attributes (e.g., emotions and topics).
Existing works often utilize fine-tuning or resort to extra attribute
classifiers, yet suffer from storage and inference time increases. To address
these concerns, we explore attribute-based CTG in a prompt-based manner. In
short, the proposed Tailor represents each attribute as a pre-trained
continuous vector (i.e., single-attribute prompt) and guides the generation of
a fixed PLM switch to a pre-specified attribute. We experimentally find that
these prompts can be simply concatenated as a whole to multi-attribute CTG
without any re-training, yet raises problems of fluency decrease and position
sensitivity. To this end, Tailor provides a multi-attribute prompt mask and a
re-indexing position-ids sequence to bridge the gap between the training (one
prompt for each task) and testing stage (concatenating more than one prompt).
To further enhance such single-attribute prompt combinations, Tailor also
introduces a trainable prompt connector, which can be concatenated with any two
single-attribute prompts to multi-attribute text generation. Experiments on 11
attribute-specific generation tasks demonstrate strong performances of Tailor
on both single-attribute and multi-attribute CTG, with 0.08\% training
parameters of a GPT-2.
","[{'version': 'v1', 'created': 'Thu, 28 Apr 2022 09:09:45 GMT'}]",2022-04-29,"[['Yang', 'Kexin', ''], ['Liu', 'Dayiheng', ''], ['Lei', 'Wenqiang', ''], ['Yang', 'Baosong', ''], ['Xue', 'Mingfeng', ''], ['Chen', 'Boxing', ''], ['Xie', 'Jun', '']]"
1909.08053,Mohammad Shoeybi,"Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared
  Casper, and Bryan Catanzaro","Megatron-LM: Training Multi-Billion Parameter Language Models Using
  Model Parallelism",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent work in language modeling demonstrates that training large transformer
models advances the state of the art in Natural Language Processing
applications. However, very large models can be quite difficult to train due to
memory constraints. In this work, we present our techniques for training very
large transformer models and implement a simple, efficient intra-layer model
parallel approach that enables training transformer models with billions of
parameters. Our approach does not require a new compiler or library changes, is
orthogonal and complimentary to pipeline model parallelism, and can be fully
implemented with the insertion of a few communication operations in native
PyTorch. We illustrate this approach by converging transformer based models up
to 8.3 billion parameters using 512 GPUs. We sustain 15.1 PetaFLOPs across the
entire application with 76% scaling efficiency when compared to a strong single
GPU baseline that sustains 39 TeraFLOPs, which is 30% of peak FLOPs. To
demonstrate that large language models can further advance the state of the art
(SOTA), we train an 8.3 billion parameter transformer language model similar to
GPT-2 and a 3.9 billion parameter model similar to BERT. We show that careful
attention to the placement of layer normalization in BERT-like models is
critical to achieving increased performance as the model size grows. Using the
GPT-2 model we achieve SOTA results on the WikiText103 (10.8 compared to SOTA
perplexity of 15.8) and LAMBADA (66.5% compared to SOTA accuracy of 63.2%)
datasets. Our BERT model achieves SOTA results on the RACE dataset (90.9%
compared to SOTA accuracy of 89.4%).
","[{'version': 'v1', 'created': 'Tue, 17 Sep 2019 19:42:54 GMT'}, {'version': 'v2', 'created': 'Thu, 19 Sep 2019 00:30:15 GMT'}, {'version': 'v3', 'created': 'Sat, 5 Oct 2019 03:27:58 GMT'}, {'version': 'v4', 'created': 'Fri, 13 Mar 2020 23:45:18 GMT'}]",2020-03-17,"[['Shoeybi', 'Mohammad', ''], ['Patwary', 'Mostofa', ''], ['Puri', 'Raul', ''], ['LeGresley', 'Patrick', ''], ['Casper', 'Jared', ''], ['Catanzaro', 'Bryan', '']]"
2401.06796,Negar Maleki,"Negar Maleki, Balaji Padmanabhan, Kaushik Dutta",AI Hallucinations: A Misnomer Worth Clarifying,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As large language models continue to advance in Artificial Intelligence (AI),
text generation systems have been shown to suffer from a problematic phenomenon
termed often as ""hallucination."" However, with AI's increasing presence across
various domains including medicine, concerns have arisen regarding the use of
the term itself. In this study, we conducted a systematic review to identify
papers defining ""AI hallucination"" across fourteen databases. We present and
analyze definitions obtained across all databases, categorize them based on
their applications, and extract key points within each category. Our results
highlight a lack of consistency in how the term is used, but also help identify
several alternative terms in the literature. We discuss implications of these
and call for a more unified effort to bring consistency to an important
contemporary AI issue that can affect multiple domains significantly.
","[{'version': 'v1', 'created': 'Tue, 9 Jan 2024 01:49:41 GMT'}]",2024-01-17,"[['Maleki', 'Negar', ''], ['Padmanabhan', 'Balaji', ''], ['Dutta', 'Kaushik', '']]"
1703.00317,Ceyda Sanli,"Ceyda Sanli, Anupam Mondal, Erik Cambria","Tracing Linguistic Relations in Winning and Losing Sides of Explicit
  Opposing Groups","Full paper, Proceedings of FLAIRS-2017 (30th Florida Artificial
  Intelligence Research Society), Special Track, Artificial Intelligence for
  Big Social Data Analysis",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Linguistic relations in oral conversations present how opinions are
constructed and developed in a restricted time. The relations bond ideas,
arguments, thoughts, and feelings, re-shape them during a speech, and finally
build knowledge out of all information provided in the conversation. Speakers
share a common interest to discuss. It is expected that each speaker's reply
includes duplicated forms of words from previous speakers. However, linguistic
adaptation is observed and evolves in a more complex path than just
transferring slightly modified versions of common concepts. A conversation
aiming a benefit at the end shows an emergent cooperation inducing the
adaptation. Not only cooperation, but also competition drives the adaptation or
an opposite scenario and one can capture the dynamic process by tracking how
the concepts are linguistically linked. To uncover salient complex dynamic
events in verbal communications, we attempt to discover self-organized
linguistic relations hidden in a conversation with explicitly stated winners
and losers. We examine open access data of the United States Supreme Court. Our
understanding is crucial in big data research to guide how transition states in
opinion mining and decision-making should be modeled and how this required
knowledge to guide the model should be pinpointed, by filtering large amount of
data.
","[{'version': 'v1', 'created': 'Wed, 1 Mar 2017 14:40:22 GMT'}]",2017-03-02,"[['Sanli', 'Ceyda', ''], ['Mondal', 'Anupam', ''], ['Cambria', 'Erik', '']]"
2304.08823,V\'esteinn Sn{\ae}bjarnarson,"V\'esteinn Sn{\ae}bjarnarson, Annika Simonsen, Goran Glava\v{s} and
  Ivan Vuli\'c","Transfer to a Low-Resource Language via Close Relatives: The Case Study
  on Faroese",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Multilingual language models have pushed state-of-the-art in cross-lingual
NLP transfer. The majority of zero-shot cross-lingual transfer, however, use
one and the same massively multilingual transformer (e.g., mBERT or XLM-R) to
transfer to all target languages, irrespective of their typological,
etymological, and phylogenetic relations to other languages. In particular,
readily available data and models of resource-rich sibling languages are often
ignored. In this work, we empirically show, in a case study for Faroese -- a
low-resource language from a high-resource language family -- that by
leveraging the phylogenetic information and departing from the
'one-size-fits-all' paradigm, one can improve cross-lingual transfer to
low-resource languages. In particular, we leverage abundant resources of other
Scandinavian languages (i.e., Danish, Norwegian, Swedish, and Icelandic) for
the benefit of Faroese. Our evaluation results show that we can substantially
improve the transfer performance to Faroese by exploiting data and models of
closely-related high-resource languages. Further, we release a new web corpus
of Faroese and Faroese datasets for named entity recognition (NER), semantic
text similarity (STS), and new language models trained on all Scandinavian
languages.
","[{'version': 'v1', 'created': 'Tue, 18 Apr 2023 08:42:38 GMT'}]",2023-04-19,"[['Snæbjarnarson', 'Vésteinn', ''], ['Simonsen', 'Annika', ''], ['Glavaš', 'Goran', ''], ['Vulić', 'Ivan', '']]"
2307.02792,Xinming Tu,"Xinming Tu, James Zou, Weijie J. Su, Linjun Zhang",What Should Data Science Education Do with Large Language Models?,,,,,cs.CY cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The rapid advances of large language models (LLMs), such as ChatGPT, are
revolutionizing data science and statistics. These state-of-the-art tools can
streamline complex processes. As a result, it reshapes the role of data
scientists. We argue that LLMs are transforming the responsibilities of data
scientists, shifting their focus from hands-on coding, data-wrangling and
conducting standard analyses to assessing and managing analyses performed by
these automated AIs. This evolution of roles is reminiscent of the transition
from a software engineer to a product manager. We illustrate this transition
with concrete data science case studies using LLMs in this paper. These
developments necessitate a meaningful evolution in data science education.
Pedagogy must now place greater emphasis on cultivating diverse skillsets among
students, such as LLM-informed creativity, critical thinking, AI-guided
programming. LLMs can also play a significant role in the classroom as
interactive teaching and learning tools, contributing to personalized
education. This paper discusses the opportunities, resources and open
challenges for each of these directions. As with any transformative technology,
integrating LLMs into education calls for careful consideration. While LLMs can
perform repetitive tasks efficiently, it's crucial to remember that their role
is to supplement human intelligence and creativity, not to replace it.
Therefore, the new era of data science education should balance the benefits of
LLMs while fostering complementary human expertise and innovations. In
conclusion, the rise of LLMs heralds a transformative period for data science
and its education. This paper seeks to shed light on the emerging trends,
potential opportunities, and challenges accompanying this paradigm shift,
hoping to spark further discourse and investigation into this exciting,
uncharted territory.
","[{'version': 'v1', 'created': 'Thu, 6 Jul 2023 06:07:29 GMT'}, {'version': 'v2', 'created': 'Fri, 7 Jul 2023 17:56:39 GMT'}]",2023-07-10,"[['Tu', 'Xinming', ''], ['Zou', 'James', ''], ['Su', 'Weijie J.', ''], ['Zhang', 'Linjun', '']]"
1904.09408,Chenguang Wang,"Chenguang Wang, Mu Li, Alexander J. Smola",Language Models with Transformers,"12 pages, 7 tables, 4 figures",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Transformer architecture is superior to RNN-based models in computational
efficiency. Recently, GPT and BERT demonstrate the efficacy of Transformer
models on various NLP tasks using pre-trained language models on large-scale
corpora. Surprisingly, these Transformer architectures are suboptimal for
language model itself. Neither self-attention nor the positional encoding in
the Transformer is able to efficiently incorporate the word-level sequential
context crucial to language modeling.
  In this paper, we explore effective Transformer architectures for language
model, including adding additional LSTM layers to better capture the sequential
context while still keeping the computation efficient. We propose Coordinate
Architecture Search (CAS) to find an effective architecture through iterative
refinement of the model. Experimental results on the PTB, WikiText-2, and
WikiText-103 show that CAS achieves perplexities between 20.42 and 34.11 on all
problems, i.e. on average an improvement of 12.0 perplexity units compared to
state-of-the-art LSTMs. The source code is publicly available.
","[{'version': 'v1', 'created': 'Sat, 20 Apr 2019 06:43:14 GMT'}, {'version': 'v2', 'created': 'Thu, 17 Oct 2019 04:25:15 GMT'}]",2019-10-18,"[['Wang', 'Chenguang', ''], ['Li', 'Mu', ''], ['Smola', 'Alexander J.', '']]"
2312.03724,Junyuan Hong,"Junyuan Hong, Jiachen T. Wang, Chenhui Zhang, Zhangheng Li, Bo Li,
  Zhangyang Wang","DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt
  Engineer",Accepted to ICLR'24 Splotlight (updated version),,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) have emerged as dominant tools for various
tasks, particularly when tailored for a specific target by prompt tuning.
Nevertheless, concerns surrounding data privacy present obstacles due to the
tuned prompts' dependency on sensitive private information. A practical
solution is to host a local LLM and optimize a soft prompt privately using
data. Yet, hosting a local model becomes problematic when model ownership is
protected. Alternative methods, like sending data to the model's provider for
training, intensify these privacy issues facing an untrusted provider. In this
paper, we present a novel solution called Differentially-Private Offsite Prompt
Tuning (DP-OPT) to address this challenge. Our approach involves tuning a
discrete prompt on the client side and then applying it to the desired cloud
models. We demonstrate that prompts suggested by LLMs themselves can be
transferred without compromising performance significantly. To ensure that the
prompts do not leak private information, we introduce the first private prompt
generation mechanism, by a differentially-private (DP) ensemble of in-context
learning with private demonstrations. With DP-OPT, generating
privacy-preserving prompts by Vicuna-7b can yield competitive performance
compared to non-private in-context learning on GPT3.5 or local private prompt
tuning. Codes are available at https://github.com/VITA-Group/DP-OPT .
","[{'version': 'v1', 'created': 'Mon, 27 Nov 2023 02:01:10 GMT'}, {'version': 'v2', 'created': 'Sun, 17 Mar 2024 23:16:41 GMT'}]",2024-03-19,"[['Hong', 'Junyuan', ''], ['Wang', 'Jiachen T.', ''], ['Zhang', 'Chenhui', ''], ['Li', 'Zhangheng', ''], ['Li', 'Bo', ''], ['Wang', 'Zhangyang', '']]"
2401.04854,Kyle Mahowald,"Harvey Lederman, Kyle Mahowald","Are Language Models More Like Libraries or Like Librarians?
  Bibliotechnism, the Novel Reference Problem, and the Attitudes of LLMs",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Are LLMs cultural technologies like photocopiers or printing presses, which
transmit information but cannot create new content? A challenge for this idea,
which we call bibliotechnism, is that LLMs often generate entirely novel text.
We begin (Part I) with a sustained defense of bibliotechnism against this
challenge showing how even entirely novel text may be meaningful only in a
derivative sense, and arguing that, in particular, much novel text generated by
LLMs is only derivatively meaningful. But we argue (Part II) that
bibliotechnism faces a different, novel challenge, stemming from examples in
which LLMs generate ""novel reference"", using novel names to refer to novel
entities. Such examples could be smoothly explained if LLMs were not cultural
technologies but possessed a limited form of agency (beliefs, desires, and
intentions). According to interpretationism in the philosophy of mind, a system
has beliefs, desires and intentions if and only if its behavior is well
explained by the hypothesis that it has such states. So, according to
interpretationism, cases of novel reference provide evidence that LLMs have
beliefs, desires, and intentions. Given that interpretationism is a live
hypothesis about the nature of these states, we suggest that cases of novel
reference provide evidence that LLMs do have beliefs, desires, and intentions.
","[{'version': 'v1', 'created': 'Wed, 10 Jan 2024 00:05:45 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Feb 2024 22:02:32 GMT'}]",2024-02-19,"[['Lederman', 'Harvey', ''], ['Mahowald', 'Kyle', '']]"
2011.04451,Alper Ahmeto\u{g}lu,"\c{C}a\u{g}la Aksoy, Alper Ahmeto\u{g}lu, Tunga G\""ung\""or",Hierarchical Multitask Learning Approach for BERT,"9 pages, 3 figures",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent works show that learning contextualized embeddings for words is
beneficial for downstream tasks. BERT is one successful example of this
approach. It learns embeddings by solving two tasks, which are masked language
model (masked LM) and the next sentence prediction (NSP). The pre-training of
BERT can also be framed as a multitask learning problem. In this work, we adopt
hierarchical multitask learning approaches for BERT pre-training. Pre-training
tasks are solved at different layers instead of the last layer, and information
from the NSP task is transferred to the masked LM task. Also, we propose a new
pre-training task bigram shift to encode word order information. We choose two
downstream tasks, one of which requires sentence-level embeddings (textual
entailment), and the other requires contextualized embeddings of words
(question answering). Due to computational restrictions, we use the downstream
task data instead of a large dataset for the pre-training to see the
performance of proposed models when given a restricted dataset. We test their
performance on several probing tasks to analyze learned embeddings. Our results
show that imposing a task hierarchy in pre-training improves the performance of
embeddings.
","[{'version': 'v1', 'created': 'Sat, 17 Oct 2020 09:23:04 GMT'}]",2020-11-10,"[['Aksoy', 'Çağla', ''], ['Ahmetoğlu', 'Alper', ''], ['Güngör', 'Tunga', '']]"
2002.00175,Kiet Nguyen Van,"Quan Hoang Lam, Quang Duy Le, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen","UIT-ViIC: A Dataset for the First Evaluation on Vietnamese Image
  Captioning","Submitted to the 2020 ICCCI Conference (The 12th International
  Conference on Computational Collective Intelligence)",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Image Captioning, the task of automatic generation of image captions, has
attracted attentions from researchers in many fields of computer science, being
computer vision, natural language processing and machine learning in recent
years. This paper contributes to research on Image Captioning task in terms of
extending dataset to a different language - Vietnamese. So far, there is no
existed Image Captioning dataset for Vietnamese language, so this is the
foremost fundamental step for developing Vietnamese Image Captioning. In this
scope, we first build a dataset which contains manually written captions for
images from Microsoft COCO dataset relating to sports played with balls, we
called this dataset UIT-ViIC. UIT-ViIC consists of 19,250 Vietnamese captions
for 3,850 images. Following that, we evaluate our dataset on deep neural
network models and do comparisons with English dataset and two Vietnamese
datasets built by different methods. UIT-ViIC is published on our lab website
for research purposes.
","[{'version': 'v1', 'created': 'Sat, 1 Feb 2020 09:26:07 GMT'}]",2020-02-04,"[['Lam', 'Quan Hoang', ''], ['Le', 'Quang Duy', ''], ['Van Nguyen', 'Kiet', ''], ['Nguyen', 'Ngan Luu-Thuy', '']]"
2310.15797,Jiaang Li,"Jiaang Li, Quan Wang, Yi Liu, Licheng Zhang, Zhendong Mao","Random Entity Quantization for Parameter-Efficient Compositional
  Knowledge Graph Representation",Accepted to EMNLP 2023,,,,cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Representation Learning on Knowledge Graphs (KGs) is essential for downstream
tasks. The dominant approach, KG Embedding (KGE), represents entities with
independent vectors and faces the scalability challenge. Recent studies propose
an alternative way for parameter efficiency, which represents entities by
composing entity-corresponding codewords matched from predefined small-scale
codebooks. We refer to the process of obtaining corresponding codewords of each
entity as entity quantization, for which previous works have designed
complicated strategies. Surprisingly, this paper shows that simple random
entity quantization can achieve similar results to current strategies. We
analyze this phenomenon and reveal that entity codes, the quantization outcomes
for expressing entities, have higher entropy at the code level and Jaccard
distance at the codeword level under random entity quantization. Therefore,
different entities become more easily distinguished, facilitating effective KG
representation. The above results show that current quantization strategies are
not critical for KG representation, and there is still room for improvement in
entity distinguishability beyond current strategies. The code to reproduce our
results is available at https://github.com/JiaangL/RandomQuantization.
","[{'version': 'v1', 'created': 'Tue, 24 Oct 2023 12:48:52 GMT'}]",2023-10-25,"[['Li', 'Jiaang', ''], ['Wang', 'Quan', ''], ['Liu', 'Yi', ''], ['Zhang', 'Licheng', ''], ['Mao', 'Zhendong', '']]"
2203.11591,Yanyuan Qiao,"Yanyuan Qiao, Yuankai Qi, Yicong Hong, Zheng Yu, Peng Wang, Qi Wu","HOP: History-and-Order Aware Pre-training for Vision-and-Language
  Navigation",,,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-training has been adopted in a few of recent works for
Vision-and-Language Navigation (VLN). However, previous pre-training methods
for VLN either lack the ability to predict future actions or ignore the
trajectory contexts, which are essential for a greedy navigation process. In
this work, to promote the learning of spatio-temporal visual-textual
correspondence as well as the agent's capability of decision making, we propose
a novel history-and-order aware pre-training paradigm (HOP) with VLN-specific
objectives that exploit the past observations and support future action
prediction. Specifically, in addition to the commonly used Masked Language
Modeling (MLM) and Trajectory-Instruction Matching (TIM), we design two proxy
tasks to model temporal order information: Trajectory Order Modeling (TOM) and
Group Order Modeling (GOM). Moreover, our navigation action prediction is also
enhanced by introducing the task of Action Prediction with History (APH), which
takes into account the history visual perceptions. Extensive experimental
results on four downstream VLN tasks (R2R, REVERIE, NDH, RxR) demonstrate the
effectiveness of our proposed method compared against several state-of-the-art
agents.
","[{'version': 'v1', 'created': 'Tue, 22 Mar 2022 10:17:12 GMT'}]",2022-03-23,"[['Qiao', 'Yanyuan', ''], ['Qi', 'Yuankai', ''], ['Hong', 'Yicong', ''], ['Yu', 'Zheng', ''], ['Wang', 'Peng', ''], ['Wu', 'Qi', '']]"
2306.03853,Arie Cattan,"Arie Cattan, Lilach Eden, Yoav Kantor and Roy Bar-Haim","From Key Points to Key Point Hierarchy: Structured and Expressive
  Opinion Summarization",ACL 2023,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Key Point Analysis (KPA) has been recently proposed for deriving fine-grained
insights from collections of textual comments. KPA extracts the main points in
the data as a list of concise sentences or phrases, termed key points, and
quantifies their prevalence. While key points are more expressive than word
clouds and key phrases, making sense of a long, flat list of key points, which
often express related ideas in varying levels of granularity, may still be
challenging. To address this limitation of KPA, we introduce the task of
organizing a given set of key points into a hierarchy, according to their
specificity. Such hierarchies may be viewed as a novel type of Textual
Entailment Graph. We develop ThinkP, a high quality benchmark dataset of key
point hierarchies for business and product reviews, obtained by consolidating
multiple annotations. We compare different methods for predicting pairwise
relations between key points, and for inferring a hierarchy from these pairwise
predictions. In particular, for the task of computing pairwise key point
relations, we achieve significant gains over existing strong baselines by
applying directional distributional similarity methods to a novel
distributional representation of key points, and further boost performance via
weak supervision.
","[{'version': 'v1', 'created': 'Tue, 6 Jun 2023 16:45:44 GMT'}]",2023-06-07,"[['Cattan', 'Arie', ''], ['Eden', 'Lilach', ''], ['Kantor', 'Yoav', ''], ['Bar-Haim', 'Roy', '']]"
1809.01816,Marcus Rohrbach,"Satwik Kottur, Jos\'e M. F. Moura, Devi Parikh, Dhruv Batra, Marcus
  Rohrbach","Visual Coreference Resolution in Visual Dialog using Neural Module
  Networks",ECCV 2018 + results on VisDial v1.0 dataset,,,,cs.CV cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Visual dialog entails answering a series of questions grounded in an image,
using dialog history as context. In addition to the challenges found in visual
question answering (VQA), which can be seen as one-round dialog, visual dialog
encompasses several more. We focus on one such problem called visual
coreference resolution that involves determining which words, typically noun
phrases and pronouns, co-refer to the same entity/object instance in an image.
This is crucial, especially for pronouns (e.g., `it'), as the dialog agent must
first link it to a previous coreference (e.g., `boat'), and only then can rely
on the visual grounding of the coreference `boat' to reason about the pronoun
`it'. Prior work (in visual dialog) models visual coreference resolution either
(a) implicitly via a memory network over history, or (b) at a coarse level for
the entire question; and not explicitly at a phrase level of granularity. In
this work, we propose a neural module network architecture for visual dialog by
introducing two novel modules - Refer and Exclude - that perform explicit,
grounded, coreference resolution at a finer word level. We demonstrate the
effectiveness of our model on MNIST Dialog, a visually simple yet
coreference-wise complex dataset, by achieving near perfect accuracy, and on
VisDial, a large and challenging visual dialog dataset on real images, where
our model outperforms other approaches, and is more interpretable, grounded,
and consistent qualitatively.
","[{'version': 'v1', 'created': 'Thu, 6 Sep 2018 04:36:22 GMT'}]",2018-09-07,"[['Kottur', 'Satwik', ''], ['Moura', 'José M. F.', ''], ['Parikh', 'Devi', ''], ['Batra', 'Dhruv', ''], ['Rohrbach', 'Marcus', '']]"
2302.09236,Yuhang Zhou,Yuhang Zhou and Suraj Maharjan and Beiye Liu,"Scalable Prompt Generation for Semi-supervised Learning with Language
  Models",Accepted by EACL2023 Findings,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Prompt-based learning methods in semi-supervised learning (SSL) settings have
been shown to be effective on multiple natural language understanding (NLU)
datasets and tasks in the literature. However, manually designing multiple
prompts and verbalizers requires domain knowledge and human effort, making it
difficult and expensive to scale across different datasets. In this paper, we
propose two methods to automatically design multiple prompts and integrate
automatic verbalizer in SSL settings without sacrificing performance. The first
method uses various demonstration examples with learnable continuous prompt
tokens to create diverse prompt models. The second method uses a varying number
of soft prompt tokens to encourage language models to learn different prompts.
For the verbalizer, we use the prototypical verbalizer to replace the manual
one. In summary, we obtained the best average accuracy of 73.2% (a relative
improvement of 2.52% over even the previous state-of-the-art SSL method with
manual prompts and verbalizers) in different few-shot learning settings.
","[{'version': 'v1', 'created': 'Sat, 18 Feb 2023 05:06:28 GMT'}]",2023-02-21,"[['Zhou', 'Yuhang', ''], ['Maharjan', 'Suraj', ''], ['Liu', 'Beiye', '']]"
2309.16283,Yunbin Tu,"Yunbin Tu, Liang Li, Li Su, Zheng-Jun Zha, Chenggang Yan, Qingming
  Huang","Self-supervised Cross-view Representation Reconstruction for Change
  Captioning",Accepted by ICCV 2023,,,,cs.CV cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Change captioning aims to describe the difference between a pair of similar
images. Its key challenge is how to learn a stable difference representation
under pseudo changes caused by viewpoint change. In this paper, we address this
by proposing a self-supervised cross-view representation reconstruction
(SCORER) network. Concretely, we first design a multi-head token-wise matching
to model relationships between cross-view features from similar/dissimilar
images. Then, by maximizing cross-view contrastive alignment of two similar
images, SCORER learns two view-invariant image representations in a
self-supervised way. Based on these, we reconstruct the representations of
unchanged objects by cross-attention, thus learning a stable difference
representation for caption generation. Further, we devise a cross-modal
backward reasoning to improve the quality of caption. This module reversely
models a ``hallucination'' representation with the caption and ``before''
representation. By pushing it closer to the ``after'' representation, we
enforce the caption to be informative about the difference in a self-supervised
manner. Extensive experiments show our method achieves the state-of-the-art
results on four datasets. The code is available at
https://github.com/tuyunbin/SCORER.
","[{'version': 'v1', 'created': 'Thu, 28 Sep 2023 09:28:50 GMT'}]",2023-09-29,"[['Tu', 'Yunbin', ''], ['Li', 'Liang', ''], ['Su', 'Li', ''], ['Zha', 'Zheng-Jun', ''], ['Yan', 'Chenggang', ''], ['Huang', 'Qingming', '']]"
1205.4387,Yoav Goldberg,"Yoav Goldberg, Michael Elhadad",Precision-biased Parsing and High-Quality Parse Selection,Rejected from EMNLP 2012 (among others),,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce precision-biased parsing: a parsing task which favors precision
over recall by allowing the parser to abstain from decisions deemed uncertain.
We focus on dependency-parsing and present an ensemble method which is capable
of assigning parents to 84% of the text tokens while being over 96% accurate on
these tokens. We use the precision-biased parsing task to solve the related
high-quality parse-selection task: finding a subset of high-quality (accurate)
trees in a large collection of parsed text. We present a method for choosing
over a third of the input trees while keeping unlabeled dependency parsing
accuracy of 97% on these trees. We also present a method which is not based on
an ensemble but rather on directly predicting the risk associated with
individual parser decisions. In addition to its efficiency, this method
demonstrates that a parsing system can provide reasonable estimates of
confidence in its predictions without relying on ensembles or aggregate corpus
counts.
","[{'version': 'v1', 'created': 'Sun, 20 May 2012 06:36:19 GMT'}]",2012-05-22,"[['Goldberg', 'Yoav', ''], ['Elhadad', 'Michael', '']]"
cmp-lg/9406030,Michael Niv,Michael Niv (Technion),The complexity of normal form rewrite sequences for Associativity,5 pages,,,"Computer Science Department, LCL 94-6",cmp-lg cs.CL,,"  The complexity of a particular term-rewrite system is considered: the rule of
associativity (x*y)*z --> x*(y*z). Algorithms and exact calculations are given
for the longest and shortest sequences of applications of --> that result in
normal form (NF). The shortest NF sequence for a term x is always n-drm(x),
where n is the number of occurrences of * in x and drm(x) is the depth of the
rightmost leaf of x. The longest NF sequence for any term is of length
n(n-1)/2.
","[{'version': 'v1', 'created': 'Mon, 20 Jun 1994 20:29:54 GMT'}, {'version': 'v2', 'created': 'Mon, 20 Jun 1994 23:04:06 GMT'}]",2008-02-03,"[['Niv', 'Michael', '', 'Technion']]"
2311.03732,Stella Ho,"Stella Ho, Ming Liu, Shang Gao, Longxiang Gao",Learning to Learn for Few-shot Continual Active Learning,"This is the pre-print version which has not been fully undergone peer
  review",,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Continual learning strives to ensure stability in solving previously seen
tasks while demonstrating plasticity in a novel domain. Recent advances in CL
are mostly confined to a supervised learning setting, especially in NLP domain.
In this work, we consider a few-shot continual active learning (CAL) setting
where labeled data are inadequate, and unlabeled data are abundant but with a
limited annotation budget. We propose a simple but efficient method, called
Meta-Continual Active Learning. Specifically, we employ meta-learning and
experience replay to address inter-task confusion and catastrophic forgetting.
We further incorporate textual augmentations to ensure generalization. We
conduct extensive experiments on benchmark text classification datasets to
validate the effectiveness of the proposed method and analyze the effect of
different active learning strategies in few-shot CAL setting. Our experimental
results demonstrate that random sampling is the best default strategy for
active learning and memory sample selection to solve few-shot CAL problems.
","[{'version': 'v1', 'created': 'Tue, 7 Nov 2023 05:22:11 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Feb 2024 05:59:34 GMT'}]",2024-02-27,"[['Ho', 'Stella', ''], ['Liu', 'Ming', ''], ['Gao', 'Shang', ''], ['Gao', 'Longxiang', '']]"
2302.13584,Daichi Guo,"Daichi Guo and Guanting Dong and Dayuan Fu and Yuxiang Wu and Chen
  Zeng and Tingfeng Hui and Liwen Wang and Xuefeng Li and Zechen Wang and
  Keqing He and Xinyue Cui and Weiran Xu","Revisit Out-Of-Vocabulary Problem for Slot Filling: A Unified
  Contrastive Frameword with Multi-level Data Augmentations","5 pages, 3 figures, published to ICASSP 2023",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In real dialogue scenarios, the existing slot filling model, which tends to
memorize entity patterns, has a significantly reduced generalization facing
Out-of-Vocabulary (OOV) problems. To address this issue, we propose an OOV
robust slot filling model based on multi-level data augmentations to solve the
OOV problem from both word and slot perspectives. We present a unified
contrastive learning framework, which pull representations of the origin sample
and augmentation samples together, to make the model resistant to OOV problems.
We evaluate the performance of the model from some specific slots and carefully
design test data with OOV word perturbation to further demonstrate the
effectiveness of OOV words. Experiments on two datasets show that our approach
outperforms the previous sota methods in terms of both OOV slots and words.
","[{'version': 'v1', 'created': 'Mon, 27 Feb 2023 08:42:30 GMT'}]",2023-02-28,"[['Guo', 'Daichi', ''], ['Dong', 'Guanting', ''], ['Fu', 'Dayuan', ''], ['Wu', 'Yuxiang', ''], ['Zeng', 'Chen', ''], ['Hui', 'Tingfeng', ''], ['Wang', 'Liwen', ''], ['Li', 'Xuefeng', ''], ['Wang', 'Zechen', ''], ['He', 'Keqing', ''], ['Cui', 'Xinyue', ''], ['Xu', 'Weiran', '']]"
1302.5645,Djallel Bouneffouf,Djallel Bouneffouf,Role of temporal inference in the recognition of textual inference,"2008 thesis, in French",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This project is a part of nature language processing and its aims to develop
a system of recognition inference text-appointed TIMINF. This type of system
can detect, given two portions of text, if a text is semantically deducted from
the other. We focused on making the inference time in this type of system. For
that we have built and analyzed a body built from questions collected through
the web. This study has enabled us to classify different types of times
inferences and for designing the architecture of TIMINF which seeks to
integrate a module inference time in a detection system inference text. We also
assess the performance of sorties TIMINF system on a test corpus with the same
strategy adopted in the challenge RTE.
","[{'version': 'v1', 'created': 'Mon, 18 Feb 2013 15:28:51 GMT'}]",2013-02-25,"[['Bouneffouf', 'Djallel', '']]"
1406.0079,Shashishekar Ramakrishna,Shashishekar Ramakrishna and Adrian Paschke,"Bridging the gap between Legal Practitioners and Knowledge Engineers
  using semi-formal KR","published in proceedings of the 8th International Workshop on Value
  Modeling and Business Ontology, VMBO, Berlin, 2014",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The use of Structured English as a computation independent knowledge
representation format for non-technical users in business rules representation
has been proposed in OMGs Semantics and Business Vocabulary Representation
(SBVR). In the legal domain we face a similar problem. Formal representation
languages, such as OASIS LegalRuleML and legal ontologies (LKIF, legal OWL2
ontologies etc.) support the technical knowledge engineer and the automated
reasoning. But, they can be hardly used directly by the legal domain experts
who do not have a computer science background. In this paper we adapt the SBVR
Structured English approach for the legal domain and implement a
proof-of-concept, called KR4IPLaw, which enables legal domain experts to
represent their knowledge in Structured English in a computational independent
and hence, for them, more usable way. The benefit of this approach is that the
underlying pre-defined semantics of the Structured English approach makes
transformations into formal languages such as OASIS LegalRuleML and OWL2
ontologies possible. We exemplify our approach in the domain of patent law.
","[{'version': 'v1', 'created': 'Sat, 31 May 2014 14:16:30 GMT'}]",2014-06-03,"[['Ramakrishna', 'Shashishekar', ''], ['Paschke', 'Adrian', '']]"
2312.07405,Marc-Etienne Brunet,"Marc-Etienne Brunet, Ashton Anderson, Richard Zemel",ICL Markup: Structuring In-Context Learning using Soft-Token Tags,"R0-FoMo: Workshop on Robustness of Few-shot and Zero-shot Learning in
  Foundation Models at NeurIPS 2023",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large pretrained language models (LLMs) can be rapidly adapted to a wide
variety of tasks via a text-to-text approach, where the instruction and input
are fed to the model in natural language. Combined with in-context learning
(ICL), this paradigm is impressively flexible and powerful. However, it also
burdens users with an overwhelming number of choices, many of them arbitrary.
Inspired by markup languages like HTML, we contribute a method of using
soft-token tags to compose prompt templates. This approach reduces arbitrary
decisions and streamlines the application of ICL. Our method is a form of
meta-learning for ICL; it learns these tags in advance during a
parameter-efficient fine-tuning ``warm-up'' process. The tags can subsequently
be used in templates for ICL on new, unseen tasks without any additional
fine-tuning. Our experiments with this approach yield promising initial
results, improving LLM performance on important enterprise applications such as
few-shot and open-world intent detection, as well as text classification in
news and legal domains.
","[{'version': 'v1', 'created': 'Tue, 12 Dec 2023 16:25:05 GMT'}]",2023-12-13,"[['Brunet', 'Marc-Etienne', ''], ['Anderson', 'Ashton', ''], ['Zemel', 'Richard', '']]"
1909.11218,Manaal Faruqui,"Shikhar Vashishth, Shyam Upadhyay, Gaurav Singh Tomar, Manaal Faruqui",Attention Interpretability Across NLP Tasks,,,,2019,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The attention layer in a neural network model provides insights into the
model's reasoning behind its prediction, which are usually criticized for being
opaque. Recently, seemingly contradictory viewpoints have emerged about the
interpretability of attention weights (Jain & Wallace, 2019; Vig & Belinkov,
2019). Amid such confusion arises the need to understand attention mechanism
more systematically. In this work, we attempt to fill this gap by giving a
comprehensive explanation which justifies both kinds of observations (i.e.,
when is attention interpretable and when it is not). Through a series of
experiments on diverse NLP tasks, we validate our observations and reinforce
our claim of interpretability of attention through manual evaluation.
","[{'version': 'v1', 'created': 'Tue, 24 Sep 2019 22:58:44 GMT'}]",2019-09-26,"[['Vashishth', 'Shikhar', ''], ['Upadhyay', 'Shyam', ''], ['Tomar', 'Gaurav Singh', ''], ['Faruqui', 'Manaal', '']]"
1705.02203,Tesfamariam Mulugeta Abuhay,"Tesfamariam M. Abuhay, Sergey V. Kovalchuk, Klavdiya O. Bochenina,
  George Kampis, Valeria V. Krzhizhanovskaya, Michael H. Lees","Analysis of Computational Science Papers from ICCS 2001-2016 using Topic
  Modeling and Graph Theory","Accepted by International Conference on Computational Science (ICCS)
  2017 which will be held in Zurich, Switzerland from June 11-June 14",,,,cs.DL cs.CL cs.IR cs.SI,http://creativecommons.org/publicdomain/zero/1.0/,"  This paper presents results of topic modeling and network models of topics
using the International Conference on Computational Science corpus, which
contains domain-specific (computational science) papers over sixteen years (a
total of 5695 papers). We discuss topical structures of International
Conference on Computational Science, how these topics evolve over time in
response to the topicality of various problems, technologies and methods, and
how all these topics relate to one another. This analysis illustrates
multidisciplinary research and collaborations among scientific communities, by
constructing static and dynamic networks from the topic modeling results and
the keywords of authors. The results of this study give insights about the past
and future trends of core discussion topics in computational science. We used
the Non-negative Matrix Factorization topic modeling algorithm to discover
topics and labeled and grouped results hierarchically.
","[{'version': 'v1', 'created': 'Tue, 18 Apr 2017 13:24:41 GMT'}]",2017-05-08,"[['Abuhay', 'Tesfamariam M.', ''], ['Kovalchuk', 'Sergey V.', ''], ['Bochenina', 'Klavdiya O.', ''], ['Kampis', 'George', ''], ['Krzhizhanovskaya', 'Valeria V.', ''], ['Lees', 'Michael H.', '']]"
cs/0208020,Masaki Murata,Masaki Murata and Hitoshi Isahara,Using the DIFF Command for Natural Language Processing,"10 pages. Computation and Language. This paper is the rough English
  translation of our Japanese papar",,,,cs.CL,,"  Diff is a software program that detects differences between two data sets and
is useful in natural language processing. This paper shows several examples of
the application of diff. They include the detection of differences between two
different datasets, extraction of rewriting rules, merging of two different
datasets, and the optimal matching of two different data sets. Since diff comes
with any standard UNIX system, it is readily available and very easy to use.
Our studies showed that diff is a practical tool for research into natural
language processing.
","[{'version': 'v1', 'created': 'Tue, 13 Aug 2002 03:39:20 GMT'}]",2007-05-23,"[['Murata', 'Masaki', ''], ['Isahara', 'Hitoshi', '']]"
1504.04751,"Dilek K\""u\c{c}\""uk","Dilek K\""u\c{c}\""uk and Meltem Turhan Y\""ondem",A Knowledge-poor Pronoun Resolution System for Turkish,"Appears in Proceedings of the 6th Discourse Anaphora and Anaphora
  Resolution Colloquium (DAARC), 2007",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A pronoun resolution system which requires limited syntactic knowledge to
identify the antecedents of personal and reflexive pronouns in Turkish is
presented. As in its counterparts for languages like English, Spanish and
French, the core of the system is the constraints and preferences determined
empirically. In the evaluation phase, it performed considerably better than the
baseline algorithm used for comparison. The system is significant for its being
the first fully specified knowledge-poor computational framework for pronoun
resolution in Turkish where Turkish possesses different structural properties
from the languages for which knowledge-poor systems had been developed.
","[{'version': 'v1', 'created': 'Sat, 18 Apr 2015 18:34:19 GMT'}]",2015-04-21,"[['Küçük', 'Dilek', ''], ['Yöndem', 'Meltem Turhan', '']]"
2202.12299,Erik Jones,"Erik Jones, Jacob Steinhardt",Capturing Failures of Large Language Models via Human Cognitive Biases,Published at NeurIPS 2022,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models generate complex, open-ended outputs: instead of
outputting a class label they write summaries, generate dialogue, or produce
working code. In order to asses the reliability of these open-ended generation
systems, we aim to identify qualitative categories of erroneous behavior,
beyond identifying individual errors. To hypothesize and test for such
qualitative errors, we draw inspiration from human cognitive biases --
systematic patterns of deviation from rational judgement. Specifically, we use
cognitive biases as motivation to (i) generate hypotheses for problems that
models may have, and (ii) develop experiments that elicit these problems. Using
code generation as a case study, we find that OpenAI's Codex errs predictably
based on how the input prompt is framed, adjusts outputs towards anchors, and
is biased towards outputs that mimic frequent training examples. We then use
our framework to elicit high-impact errors such as incorrectly deleting files.
Our results indicate that experimental methodology from cognitive science can
help characterize how machine learning systems behave.
","[{'version': 'v1', 'created': 'Thu, 24 Feb 2022 18:58:52 GMT'}, {'version': 'v2', 'created': 'Thu, 24 Nov 2022 03:27:47 GMT'}]",2022-11-28,"[['Jones', 'Erik', ''], ['Steinhardt', 'Jacob', '']]"
2211.13437,Yatai Ji,"Yatai Ji, Rongcheng Tu, Jie Jiang, Weijie Kong, Chengfei Cai, Wenzhe
  Zhao, Hongfa Wang, Yujiu Yang, Wei Liu","Seeing What You Miss: Vision-Language Pre-training with Semantic
  Completion Learning",CVPR 2023 accept,,,,cs.CV cs.CL cs.MM,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Cross-modal alignment is essential for vision-language pre-training (VLP)
models to learn the correct corresponding information across different
modalities. For this purpose, inspired by the success of masked language
modeling (MLM) tasks in the NLP pre-training area, numerous masked modeling
tasks have been proposed for VLP to further promote cross-modal interactions.
The core idea of previous masked modeling tasks is to focus on reconstructing
the masked tokens based on visible context for learning local-to-local
alignment. However, most of them pay little attention to the global semantic
features generated for the masked data, resulting in a limited cross-modal
alignment ability of global representations. Therefore, in this paper, we
propose a novel Semantic Completion Learning (SCL) task, complementary to
existing masked modeling tasks, to facilitate global-to-local alignment.
Specifically, the SCL task complements the missing semantics of masked data by
capturing the corresponding information from the other modality, promoting
learning more representative global features which have a great impact on the
performance of downstream tasks. Moreover, we present a flexible vision
encoder, which enables our model to perform image-text and video-text
multimodal tasks simultaneously. Experimental results show that our proposed
method obtains state-of-the-art performance on various vision-language
benchmarks, such as visual question answering, image-text retrieval, and
video-text retrieval.
","[{'version': 'v1', 'created': 'Thu, 24 Nov 2022 06:39:16 GMT'}, {'version': 'v2', 'created': 'Sun, 26 Mar 2023 13:59:36 GMT'}]",2023-03-28,"[['Ji', 'Yatai', ''], ['Tu', 'Rongcheng', ''], ['Jiang', 'Jie', ''], ['Kong', 'Weijie', ''], ['Cai', 'Chengfei', ''], ['Zhao', 'Wenzhe', ''], ['Wang', 'Hongfa', ''], ['Yang', 'Yujiu', ''], ['Liu', 'Wei', '']]"
2203.05482,Mitchell Wortsman,"Mitchell Wortsman, Gabriel Ilharco, Samir Yitzhak Gadre, Rebecca
  Roelofs, Raphael Gontijo-Lopes, Ari S. Morcos, Hongseok Namkoong, Ali
  Farhadi, Yair Carmon, Simon Kornblith, Ludwig Schmidt","Model soups: averaging weights of multiple fine-tuned models improves
  accuracy without increasing inference time",ICML 2022. The last three authors contributed equally,,,,cs.LG cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The conventional recipe for maximizing model accuracy is to (1) train
multiple models with various hyperparameters and (2) pick the individual model
which performs best on a held-out validation set, discarding the remainder. In
this paper, we revisit the second step of this procedure in the context of
fine-tuning large pre-trained models, where fine-tuned models often appear to
lie in a single low error basin. We show that averaging the weights of multiple
models fine-tuned with different hyperparameter configurations often improves
accuracy and robustness. Unlike a conventional ensemble, we may average many
models without incurring any additional inference or memory costs -- we call
the results ""model soups."" When fine-tuning large pre-trained models such as
CLIP, ALIGN, and a ViT-G pre-trained on JFT, our soup recipe provides
significant improvements over the best model in a hyperparameter sweep on
ImageNet. The resulting ViT-G model, which attains 90.94% top-1 accuracy on
ImageNet, achieved a new state of the art. Furthermore, we show that the model
soup approach extends to multiple image classification and natural language
processing tasks, improves out-of-distribution performance, and improves
zero-shot performance on new downstream tasks. Finally, we analytically relate
the performance similarity of weight-averaging and logit-ensembling to flatness
of the loss and confidence of the predictions, and validate this relation
empirically. Code is available at https://github.com/mlfoundations/model-soups.
","[{'version': 'v1', 'created': 'Thu, 10 Mar 2022 17:03:49 GMT'}, {'version': 'v2', 'created': 'Tue, 21 Jun 2022 22:09:26 GMT'}, {'version': 'v3', 'created': 'Fri, 1 Jul 2022 23:48:19 GMT'}]",2022-07-05,"[['Wortsman', 'Mitchell', ''], ['Ilharco', 'Gabriel', ''], ['Gadre', 'Samir Yitzhak', ''], ['Roelofs', 'Rebecca', ''], ['Gontijo-Lopes', 'Raphael', ''], ['Morcos', 'Ari S.', ''], ['Namkoong', 'Hongseok', ''], ['Farhadi', 'Ali', ''], ['Carmon', 'Yair', ''], ['Kornblith', 'Simon', ''], ['Schmidt', 'Ludwig', '']]"
2107.02024,Hadi Mansourifar,"Hadi Mansourifar, Dana Alsagheer, Weidong Shi, Lan Ni, Yan Huang",Statistical Analysis of Perspective Scores on Hate Speech Detection,"Accepted paper in International IJCAI Workshop on Artificial
  Intelligence for Social Good 2021",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Hate speech detection has become a hot topic in recent years due to the
exponential growth of offensive language in social media. It has proven that,
state-of-the-art hate speech classifiers are efficient only when tested on the
data with the same feature distribution as training data. As a consequence,
model architecture plays the second role to improve the current results. In
such a diverse data distribution relying on low level features is the main
cause of deficiency due to natural bias in data. That's why we need to use high
level features to avoid a biased judgement. In this paper, we statistically
analyze the Perspective Scores and their impact on hate speech detection. We
show that, different hate speech datasets are very similar when it comes to
extract their Perspective Scores. Eventually, we prove that, over-sampling the
Perspective Scores of a hate speech dataset can significantly improve the
generalization performance when it comes to be tested on other hate speech
datasets.
","[{'version': 'v1', 'created': 'Tue, 22 Jun 2021 17:17:35 GMT'}]",2021-07-06,"[['Mansourifar', 'Hadi', ''], ['Alsagheer', 'Dana', ''], ['Shi', 'Weidong', ''], ['Ni', 'Lan', ''], ['Huang', 'Yan', '']]"
2310.09949,Wenqi Jiang,"Wenqi Jiang, Marco Zeller, Roger Waleffe, Torsten Hoefler, Gustavo
  Alonso","Chameleon: a heterogeneous and disaggregated accelerator system for
  retrieval-augmented language models",,,,,cs.LG cs.AI cs.AR cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  A Retrieval-Augmented Language Model (RALM) augments a generative language
model by retrieving context-specific knowledge from an external database. This
strategy facilitates impressive text generation quality even with smaller
models, thus reducing orders of magnitude of computational demands. However,
RALMs introduce unique system design challenges due to (a) the diverse workload
characteristics between LM inference and retrieval and (b) the various system
requirements and bottlenecks for different RALM configurations such as model
sizes, database sizes, and retrieval frequencies. We propose Chameleon, a
heterogeneous accelerator system that integrates both LM and retrieval
accelerators in a disaggregated architecture. The heterogeneity ensures
efficient acceleration of both LM inference and retrieval, while the
accelerator disaggregation enables the system to independently scale both types
of accelerators to fulfill diverse RALM requirements. Our Chameleon prototype
implements retrieval accelerators on FPGAs and assigns LM inference to GPUs,
with a CPU server orchestrating these accelerators over the network. Compared
to CPU-based and CPU-GPU vector search systems, Chameleon achieves up to 23.72x
speedup and 26.2x energy efficiency. Evaluated on various RALMs, Chameleon
exhibits up to 2.16x reduction in latency and 3.18x speedup in throughput
compared to the hybrid CPU-GPU architecture. These promising results pave the
way for bringing accelerator heterogeneity and disaggregation into future RALM
systems.
","[{'version': 'v1', 'created': 'Sun, 15 Oct 2023 20:57:25 GMT'}, {'version': 'v2', 'created': 'Thu, 9 Nov 2023 18:23:59 GMT'}, {'version': 'v3', 'created': 'Wed, 29 Nov 2023 16:34:49 GMT'}]",2023-11-30,"[['Jiang', 'Wenqi', ''], ['Zeller', 'Marco', ''], ['Waleffe', 'Roger', ''], ['Hoefler', 'Torsten', ''], ['Alonso', 'Gustavo', '']]"
2403.11124,Feifan Song,"Feifan Song, Bowen Yu, Hao Lang, Haiyang Yu, Fei Huang, Houfeng Wang,
  Yongbin Li","Scaling Data Diversity for Fine-Tuning Language Models in Human
  Alignment",Accepted by LREC-COLING 2024,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Alignment with human preference prevents large language models (LLMs) from
generating misleading or toxic content while requiring high-cost human
feedback. Assuming resources of human annotation are limited, there are two
different ways of allocating considered: more diverse PROMPTS or more diverse
RESPONSES to be labeled. Nonetheless, a straightforward comparison between
their impact is absent. In this work, we first control the diversity of both
sides according to the number of samples for fine-tuning, which can directly
reflect their influence. We find that instead of numerous prompts, more
responses but fewer prompts better trigger LLMs for human alignment.
Additionally, the concept of diversity for prompts can be more complex than
responses that are typically quantified by single digits. Consequently, a new
formulation of prompt diversity is proposed, further implying a linear
correlation with the final performance of LLMs after fine-tuning. We also
leverage it on data augmentation and conduct experiments to show its effect on
different algorithms.
","[{'version': 'v1', 'created': 'Sun, 17 Mar 2024 07:08:55 GMT'}]",2024-03-19,"[['Song', 'Feifan', ''], ['Yu', 'Bowen', ''], ['Lang', 'Hao', ''], ['Yu', 'Haiyang', ''], ['Huang', 'Fei', ''], ['Wang', 'Houfeng', ''], ['Li', 'Yongbin', '']]"
2210.12720,Bin Ji,"Bin Ji, Shasha Li, Hao Xu, Jie Yu, Jun Ma, Huijun Liu, Jing Yang","Span-based joint entity and relation extraction augmented with sequence
  tagging mechanism",Accept by Science China-Information Sciences,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Span-based joint extraction simultaneously conducts named entity recognition
(NER) and relation extraction (RE) in text span form. However, since previous
span-based models rely on span-level classifications, they cannot benefit from
token-level label information, which has been proven advantageous for the task.
In this paper, we propose a Sequence Tagging augmented Span-based Network
(STSN), a span-based joint model that can make use of token-level label
information. In STSN, we construct a core neural architecture by deep stacking
multiple attention layers, each of which consists of three basic attention
units. On the one hand, the core architecture enables our model to learn
token-level label information via the sequence tagging mechanism and then uses
the information in the span-based joint extraction; on the other hand, it
establishes a bi-directional information interaction between NER and RE.
Experimental results on three benchmark datasets show that STSN consistently
outperforms the strongest baselines in terms of F1, creating new
state-of-the-art results.
","[{'version': 'v1', 'created': 'Sun, 23 Oct 2022 12:39:27 GMT'}]",2022-10-25,"[['Ji', 'Bin', ''], ['Li', 'Shasha', ''], ['Xu', 'Hao', ''], ['Yu', 'Jie', ''], ['Ma', 'Jun', ''], ['Liu', 'Huijun', ''], ['Yang', 'Jing', '']]"
2002.01030,Mohammad Hadi Goldani,"Mohammad Hadi Goldani, Saeedeh Momtazi, Reza Safabakhsh",Detecting Fake News with Capsule Neural Networks,"25 pages, 4 figures",,,,cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Fake news is dramatically increased in social media in recent years. This has
prompted the need for effective fake news detection algorithms. Capsule neural
networks have been successful in computer vision and are receiving attention
for use in Natural Language Processing (NLP). This paper aims to use capsule
neural networks in the fake news detection task. We use different embedding
models for news items of different lengths. Static word embedding is used for
short news items, whereas non-static word embeddings that allow incremental
up-training and updating in the training phase are used for medium length or
large news statements. Moreover, we apply different levels of n-grams for
feature extraction. Our proposed architectures are evaluated on two recent
well-known datasets in the field, namely ISOT and LIAR. The results show
encouraging performance, outperforming the state-of-the-art methods by 7.8% on
ISOT and 3.1% on the validation set, and 1% on the test set of the LIAR
dataset.
","[{'version': 'v1', 'created': 'Mon, 3 Feb 2020 22:13:07 GMT'}]",2020-02-05,"[['Goldani', 'Mohammad Hadi', ''], ['Momtazi', 'Saeedeh', ''], ['Safabakhsh', 'Reza', '']]"
2304.02496,Shan Chen,"Shan Chen, Yingya Li, Sheng Lu, Hoang Van, Hugo JWL Aerts, Guergana K.
  Savova, Danielle S. Bitterman","Evaluation of ChatGPT Family of Models for Biomedical Reasoning and
  Classification","28 pages, 2 tables and 4 figures. Submitting for review",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  Recent advances in large language models (LLMs) have shown impressive ability
in biomedical question-answering, but have not been adequately investigated for
more specific biomedical applications. This study investigates the performance
of LLMs such as the ChatGPT family of models (GPT-3.5s, GPT-4) in biomedical
tasks beyond question-answering. Because no patient data can be passed to the
OpenAI API public interface, we evaluated model performance with over 10000
samples as proxies for two fundamental tasks in the clinical domain -
classification and reasoning. The first task is classifying whether statements
of clinical and policy recommendations in scientific literature constitute
health advice. The second task is causal relation detection from the biomedical
literature. We compared LLMs with simpler models, such as bag-of-words (BoW)
with logistic regression, and fine-tuned BioBERT models. Despite the excitement
around viral ChatGPT, we found that fine-tuning for two fundamental NLP tasks
remained the best strategy. The simple BoW model performed on par with the most
complex LLM prompting. Prompt engineering required significant investment.
","[{'version': 'v1', 'created': 'Wed, 5 Apr 2023 15:11:25 GMT'}]",2023-04-06,"[['Chen', 'Shan', ''], ['Li', 'Yingya', ''], ['Lu', 'Sheng', ''], ['Van', 'Hoang', ''], ['Aerts', 'Hugo JWL', ''], ['Savova', 'Guergana K.', ''], ['Bitterman', 'Danielle S.', '']]"
1611.06950,Jie Mei,"Jie Mei, Aminul Islam, Yajing Wu, Abidalrahman Moh'd, Evangelos E.
  Milios",Statistical Learning for OCR Text Correction,,,,,cs.CV cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The accuracy of Optical Character Recognition (OCR) is crucial to the success
of subsequent applications used in text analyzing pipeline. Recent models of
OCR post-processing significantly improve the quality of OCR-generated text,
but are still prone to suggest correction candidates from limited observations
while insufficiently accounting for the characteristics of OCR errors. In this
paper, we show how to enlarge candidate suggestion space by using external
corpus and integrating OCR-specific features in a regression approach to
correct OCR-generated errors. The evaluation results show that our model can
correct 61.5% of the OCR-errors (considering the top 1 suggestion) and 71.5% of
the OCR-errors (considering the top 3 suggestions), for cases where the
theoretical correction upper-bound is 78%.
","[{'version': 'v1', 'created': 'Mon, 21 Nov 2016 19:00:32 GMT'}]",2016-11-22,"[['Mei', 'Jie', ''], ['Islam', 'Aminul', ''], ['Wu', 'Yajing', ''], [""Moh'd"", 'Abidalrahman', ''], ['Milios', 'Evangelos E.', '']]"
2212.03813,Jiasheng Gu,"Jiasheng Gu, Hongyu Zhao, Hanzi Xu, Liangyu Nie, Hongyuan Mei and
  Wenpeng Yin",Robustness of Learning from Task Instructions,ACL'23 Finding Accepted,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Traditional supervised learning mostly works on individual tasks and requires
training on a large set of task-specific examples. This paradigm seriously
hinders the development of task generalization since preparing a task-specific
example set is costly. To build a system that can quickly and easily generalize
to new tasks, task instructions have been adopted as an emerging trend of
supervision recently. These instructions give the model the definition of the
task and allow the model to output the appropriate answer based on the
instructions and inputs. However, task instructions are often expressed in
different forms, which can be interpreted from two threads: first, some
instructions are short sentences and are pretrained language model (PLM)
oriented, such as prompts, while other instructions are paragraphs and are
human-oriented, such as those in Amazon MTurk; second, different end-users very
likely explain the same task with instructions of different textual
expressions. A robust system for task generalization should be able to handle
any new tasks regardless of the variability of instructions.
  However, the system robustness in dealing with instruction-driven task
generalization is still unexplored. This work investigates the system
robustness when the instructions of new tasks are (i) manipulated, (ii)
paraphrased, or (iii) from different levels of conciseness. To our knowledge,
this is the first work that systematically studies how robust a PLM is when it
is supervised by instructions with different factors of variability.
","[{'version': 'v1', 'created': 'Wed, 7 Dec 2022 17:54:59 GMT'}, {'version': 'v2', 'created': 'Tue, 2 May 2023 20:18:06 GMT'}, {'version': 'v3', 'created': 'Fri, 5 May 2023 19:28:10 GMT'}, {'version': 'v4', 'created': 'Tue, 23 May 2023 13:39:39 GMT'}]",2023-05-24,"[['Gu', 'Jiasheng', ''], ['Zhao', 'Hongyu', ''], ['Xu', 'Hanzi', ''], ['Nie', 'Liangyu', ''], ['Mei', 'Hongyuan', ''], ['Yin', 'Wenpeng', '']]"
2308.08181,Jie Li,Mengjie Du and Xiang Fang and Jie Li,"ChinaTelecom System Description to VoxCeleb Speaker Recognition
  Challenge 2023",System description of VoxSRC 2023,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This technical report describes ChinaTelecom system for Track 1 (closed) of
the VoxCeleb2023 Speaker Recognition Challenge (VoxSRC 2023). Our system
consists of several ResNet variants trained only on VoxCeleb2, which were fused
for better performance later. Score calibration was also applied for each
variant and the fused system. The final submission achieved minDCF of 0.1066
and EER of 1.980%.
","[{'version': 'v1', 'created': 'Wed, 16 Aug 2023 07:21:01 GMT'}]",2023-08-17,"[['Du', 'Mengjie', ''], ['Fang', 'Xiang', ''], ['Li', 'Jie', '']]"
2109.01934,Pratyay Banerjee,"Pratyay Banerjee, Tejas Gokhale, Yezhou Yang, Chitta Baral","Weakly Supervised Relative Spatial Reasoning for Visual Question
  Answering","Accepted to ICCV 2021. PaperId : ICCV2021-10857 Copyright transferred
  to IEEE ICCV. DOI will be updated later",,,,cs.CV cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Vision-and-language (V\&L) reasoning necessitates perception of visual
concepts such as objects and actions, understanding semantics and language
grounding, and reasoning about the interplay between the two modalities. One
crucial aspect of visual reasoning is spatial understanding, which involves
understanding relative locations of objects, i.e.\ implicitly learning the
geometry of the scene. In this work, we evaluate the faithfulness of V\&L
models to such geometric understanding, by formulating the prediction of
pair-wise relative locations of objects as a classification as well as a
regression task. Our findings suggest that state-of-the-art transformer-based
V\&L models lack sufficient abilities to excel at this task. Motivated by this,
we design two objectives as proxies for 3D spatial reasoning (SR) -- object
centroid estimation, and relative position estimation, and train V\&L with weak
supervision from off-the-shelf depth estimators. This leads to considerable
improvements in accuracy for the ""GQA"" visual question answering challenge (in
fully supervised, few-shot, and O.O.D settings) as well as improvements in
relative spatial reasoning. Code and data will be released
\href{https://github.com/pratyay-banerjee/weak_sup_vqa}{here}.
","[{'version': 'v1', 'created': 'Sat, 4 Sep 2021 21:29:06 GMT'}]",2021-09-07,"[['Banerjee', 'Pratyay', ''], ['Gokhale', 'Tejas', ''], ['Yang', 'Yezhou', ''], ['Baral', 'Chitta', '']]"
2311.09829,Renren Jin,"Yimin Jing, Renren Jin, Jiahao Hu, Huishi Qiu, Xiaohua Wang, Peng
  Wang, Deyi Xiong","FollowEval: A Multi-Dimensional Benchmark for Assessing the
  Instruction-Following Capability of Large Language Models",Work in progress,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The effective assessment of the instruction-following ability of large
language models (LLMs) is of paramount importance. A model that cannot adhere
to human instructions might be not able to provide reliable and helpful
responses. In pursuit of this goal, various benchmarks have been constructed to
evaluate the instruction-following capacity of these models. However, these
benchmarks are limited to a single language and are constructed using automated
approaches, which restricts their applicability and the quality of the test
examples they contain. To bridge this gap, we introduce the FollowEval
benchmark in this paper. This benchmark is composed of instances in both
English and Chinese, and all test examples are crafted by human experts.
Furthermore, the FollowEval benchmark is designed to assess LLMs across five
critical dimensions of instruction following: string manipulation, commonsense
reasoning, logical reasoning, spatial reasoning, and response constraints. To
enhance the complexity and present a sufficient challenge, each test example is
designed to evaluate more than one dimension. We have evaluated various LLMs
using the FollowEval benchmark and found that their performance significantly
lags behind that of humans. This highlights the considerable room for
improvement in the instruction-following ability of these models.
","[{'version': 'v1', 'created': 'Thu, 16 Nov 2023 11:53:31 GMT'}]",2023-11-17,"[['Jing', 'Yimin', ''], ['Jin', 'Renren', ''], ['Hu', 'Jiahao', ''], ['Qiu', 'Huishi', ''], ['Wang', 'Xiaohua', ''], ['Wang', 'Peng', ''], ['Xiong', 'Deyi', '']]"
2305.12256,Hao Fei,"Hao Fei, Qian Liu, Meishan Zhang, Min Zhang, Tat-Seng Chua","Scene Graph as Pivoting: Inference-time Image-free Unsupervised
  Multimodal Machine Translation with Visual Scene Hallucination",ACL 2023,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  In this work, we investigate a more realistic unsupervised multimodal machine
translation (UMMT) setup, inference-time image-free UMMT, where the model is
trained with source-text image pairs, and tested with only source-text inputs.
First, we represent the input images and texts with the visual and language
scene graphs (SG), where such fine-grained vision-language features ensure a
holistic understanding of the semantics. To enable pure-text input during
inference, we devise a visual scene hallucination mechanism that dynamically
generates pseudo visual SG from the given textual SG. Several SG-pivoting based
learning objectives are introduced for unsupervised translation training. On
the benchmark Multi30K data, our SG-based method outperforms the
best-performing baseline by significant BLEU scores on the task and setup,
helping yield translations with better completeness, relevance and fluency
without relying on paired images. Further in-depth analyses reveal how our
model advances in the task setting.
","[{'version': 'v1', 'created': 'Sat, 20 May 2023 18:17:20 GMT'}, {'version': 'v2', 'created': 'Thu, 25 May 2023 04:24:34 GMT'}]",2023-05-26,"[['Fei', 'Hao', ''], ['Liu', 'Qian', ''], ['Zhang', 'Meishan', ''], ['Zhang', 'Min', ''], ['Chua', 'Tat-Seng', '']]"
2312.00912,Benjamin Brimacombe,"Benjamin Brimacombe, Jiawei Zhou",Quick Back-Translation for Unsupervised Machine Translation,"Published in EMNLP 2023 Findings. Source code can be found at the
  following link: https://github.com/bbrimacombe/Quick-Back-Translation",,,,cs.CL cs.LG cs.PL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The field of unsupervised machine translation has seen significant
advancement from the marriage of the Transformer and the back-translation
algorithm. The Transformer is a powerful generative model, and back-translation
leverages Transformer's high-quality translations for iterative
self-improvement. However, the Transformer is encumbered by the run-time of
autoregressive inference during back-translation, and back-translation is
limited by a lack of synthetic data efficiency. We propose a two-for-one
improvement to Transformer back-translation: Quick Back-Translation (QBT). QBT
re-purposes the encoder as a generative model, and uses encoder-generated
sequences to train the decoder in conjunction with the original autoregressive
back-translation step, improving data throughput and utilization. Experiments
on various WMT benchmarks demonstrate that a relatively small number of
refining steps of QBT improve current unsupervised machine translation models,
and that QBT dramatically outperforms standard back-translation only method in
terms of training efficiency for comparable translation qualities.
","[{'version': 'v1', 'created': 'Fri, 1 Dec 2023 20:27:42 GMT'}]",2023-12-05,"[['Brimacombe', 'Benjamin', ''], ['Zhou', 'Jiawei', '']]"
1507.04808,Iulian Vlad Serban,"Iulian V. Serban, Alessandro Sordoni, Yoshua Bengio, Aaron Courville
  and Joelle Pineau","Building End-To-End Dialogue Systems Using Generative Hierarchical
  Neural Network Models","8 pages with references; Published in AAAI 2016 (Special Track on
  Cognitive Systems)",,,,cs.CL cs.AI cs.LG cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigate the task of building open domain, conversational dialogue
systems based on large dialogue corpora using generative models. Generative
models produce system responses that are autonomously generated word-by-word,
opening up the possibility for realistic, flexible interactions. In support of
this goal, we extend the recently proposed hierarchical recurrent
encoder-decoder neural network to the dialogue domain, and demonstrate that
this model is competitive with state-of-the-art neural language models and
back-off n-gram models. We investigate the limitations of this and similar
approaches, and show how its performance can be improved by bootstrapping the
learning from a larger question-answer pair corpus and from pretrained word
embeddings.
","[{'version': 'v1', 'created': 'Fri, 17 Jul 2015 00:21:39 GMT'}, {'version': 'v2', 'created': 'Wed, 25 Nov 2015 19:49:39 GMT'}, {'version': 'v3', 'created': 'Wed, 6 Apr 2016 23:20:41 GMT'}]",2016-04-08,"[['Serban', 'Iulian V.', ''], ['Sordoni', 'Alessandro', ''], ['Bengio', 'Yoshua', ''], ['Courville', 'Aaron', ''], ['Pineau', 'Joelle', '']]"
2306.02920,Miyu Oba,"Miyu Oba, Tatsuki Kuribayashi, Hiroki Ouchi, Taro Watanabe",Second Language Acquisition of Neural Language Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  With the success of neural language models (LMs), their language acquisition
has gained much attention. This work sheds light on the second language (L2)
acquisition of LMs, while previous work has typically explored their first
language (L1) acquisition. Specifically, we trained bilingual LMs with a
scenario similar to human L2 acquisition and analyzed their cross-lingual
transfer from linguistic perspectives. Our exploratory experiments demonstrated
that the L1 pretraining accelerated their linguistic generalization in L2, and
language transfer configurations (e.g., the L1 choice, and presence of parallel
texts) substantially affected their generalizations. These clarify their
(non-)human-like L2 acquisition in particular aspects.
","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 14:32:41 GMT'}]",2023-06-06,"[['Oba', 'Miyu', ''], ['Kuribayashi', 'Tatsuki', ''], ['Ouchi', 'Hiroki', ''], ['Watanabe', 'Taro', '']]"
2106.15102,Mohd Zeeshan Ansari,"M Zeeshan Ansari, Tanvir Ahmad, M M Sufyan Beg, Asma Ikram",A Simple and Efficient Probabilistic Language model for Code-Mixed Text,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  The conventional natural language processing approaches are not accustomed to
the social media text due to colloquial discourse and non-homogeneous
characteristics. Significantly, the language identification in a multilingual
document is ascertained to be a preceding subtask in several information
extraction applications such as information retrieval, named entity
recognition, relation extraction, etc. The problem is often more challenging in
code-mixed documents wherein foreign languages words are drawn into base
language while framing the text. The word embeddings are powerful language
modeling tools for representation of text documents useful in obtaining
similarity between words or documents. We present a simple probabilistic
approach for building efficient word embedding for code-mixed text and
exemplifying it over language identification of Hindi-English short test
messages scrapped from Twitter. We examine its efficacy for the classification
task using bidirectional LSTMs and SVMs and observe its improved scores over
various existing code-mixed embeddings
","[{'version': 'v1', 'created': 'Tue, 29 Jun 2021 05:37:57 GMT'}]",2021-06-30,"[['Ansari', 'M Zeeshan', ''], ['Ahmad', 'Tanvir', ''], ['Beg', 'M M Sufyan', ''], ['Ikram', 'Asma', '']]"
2312.06099,Yonghui Wu,"Cheng Peng, Xi Yang, Aokun Chen, Zehao Yu, Kaleb E Smith, Anthony B
  Costa, Mona G Flores, Jiang Bian, Yonghui Wu","Generative Large Language Models Are All-purpose Text Analytics Engines:
  Text-to-text Learning Is All Your Need",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Objective To solve major clinical natural language processing (NLP) tasks
using a unified text-to-text learning architecture based on a generative large
language model (LLM) via prompt tuning. Methods We formulated 7 key clinical
NLP tasks as text-to-text learning and solved them using one unified generative
clinical LLM, GatorTronGPT, developed using GPT-3 architecture and trained with
up to 20 billion parameters. We adopted soft prompts (i.e., trainable vectors)
with frozen LLM, where the LLM parameters were not updated (i.e., frozen) and
only the vectors of soft prompts were updated, known as prompt tuning. We added
additional soft prompts as a prefix to the input layer, which were optimized
during the prompt tuning. We evaluated the proposed method using 7 clinical NLP
tasks and compared them with previous task-specific solutions based on
Transformer models. Results and Conclusion The proposed approach achieved
state-of-the-art performance for 5 out of 7 major clinical NLP tasks using one
unified generative LLM. Our approach outperformed previous task-specific
transformer models by ~3% for concept extraction and 7% for relation extraction
applied to social determinants of health, 3.4% for clinical concept
normalization, 3.4~10% for clinical abbreviation disambiguation, and 5.5~9% for
natural language inference. Our approach also outperformed a previously
developed prompt-based machine reading comprehension (MRC) model,
GatorTron-MRC, for clinical concept and relation extraction. The proposed
approach can deliver the ``one model for all`` promise from training to
deployment using a unified generative LLM.
","[{'version': 'v1', 'created': 'Mon, 11 Dec 2023 04:00:26 GMT'}]",2023-12-12,"[['Peng', 'Cheng', ''], ['Yang', 'Xi', ''], ['Chen', 'Aokun', ''], ['Yu', 'Zehao', ''], ['Smith', 'Kaleb E', ''], ['Costa', 'Anthony B', ''], ['Flores', 'Mona G', ''], ['Bian', 'Jiang', ''], ['Wu', 'Yonghui', '']]"
2110.10027,Xiong Liu,"Xiong Liu, Greg L. Hersch, Iya Khalil, Murthy Devarakonda",Clinical Trial Information Extraction with BERT,"HealthNLP 2021, IEEE International Conference on Healthcare
  Informatics (ICHI 2021)",,,,q-bio.QM cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Natural language processing (NLP) of clinical trial documents can be useful
in new trial design. Here we identify entity types relevant to clinical trial
design and propose a framework called CT-BERT for information extraction from
clinical trial text. We trained named entity recognition (NER) models to
extract eligibility criteria entities by fine-tuning a set of pre-trained BERT
models. We then compared the performance of CT-BERT with recent baseline
methods including attention-based BiLSTM and Criteria2Query. The results
demonstrate the superiority of CT-BERT in clinical trial NLP.
","[{'version': 'v1', 'created': 'Sat, 11 Sep 2021 17:15:10 GMT'}]",2021-10-20,"[['Liu', 'Xiong', ''], ['Hersch', 'Greg L.', ''], ['Khalil', 'Iya', ''], ['Devarakonda', 'Murthy', '']]"
2305.17760,Khanh Nguyen,Khanh Nguyen,"Language Models are Bounded Pragmatic Speakers: Understanding RLHF from
  a Bayesian Cognitive Modeling Perspective","Proceedings of the First Workshop on Theory of Mind in Communicating
  Agents at (TOM @ ICML 2023)",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  How do language models ""think""? This paper formulates a probabilistic
cognitive model called the bounded pragmatic speaker, which can characterize
the operation of different variations of language models. Specifically, we
demonstrate that large language models fine-tuned with reinforcement learning
from human feedback (Ouyang et al., 2022) embody a model of thought that
conceptually resembles a fast-and-slow model (Kahneman, 2011), which
psychologists have attributed to humans. We discuss the limitations of
reinforcement learning from human feedback as a fast-and-slow model of thought
and propose avenues for expanding this framework. In essence, our research
highlights the value of adopting a cognitive probabilistic modeling approach to
gain insights into the comprehension, evaluation, and advancement of language
models.
","[{'version': 'v1', 'created': 'Sun, 28 May 2023 16:04:48 GMT'}, {'version': 'v2', 'created': 'Mon, 26 Jun 2023 15:37:55 GMT'}, {'version': 'v3', 'created': 'Tue, 27 Jun 2023 13:16:42 GMT'}, {'version': 'v4', 'created': 'Fri, 7 Jul 2023 16:21:50 GMT'}, {'version': 'v5', 'created': 'Sat, 29 Jul 2023 13:43:50 GMT'}, {'version': 'v6', 'created': 'Mon, 1 Jan 2024 21:06:57 GMT'}]",2024-01-03,"[['Nguyen', 'Khanh', '']]"
2306.14422,Wen-Chin Huang,"Wen-Chin Huang, Lester Phillip Violeta, Songxiang Liu, Jiatong Shi,
  Tomoki Toda",The Singing Voice Conversion Challenge 2023,,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present the latest iteration of the voice conversion challenge (VCC)
series, a bi-annual scientific event aiming to compare and understand different
voice conversion (VC) systems based on a common dataset. This year we shifted
our focus to singing voice conversion (SVC), thus named the challenge the
Singing Voice Conversion Challenge (SVCC). A new database was constructed for
two tasks, namely in-domain and cross-domain SVC. The challenge was run for two
months, and in total we received 26 submissions, including 2 baselines. Through
a large-scale crowd-sourced listening test, we observed that for both tasks,
although human-level naturalness was achieved by the top system, no team was
able to obtain a similarity score as high as the target speakers. Also, as
expected, cross-domain SVC is harder than in-domain SVC, especially in the
similarity aspect. We also investigated whether existing objective measurements
were able to predict perceptual performance, and found that only few of them
could reach a significant correlation.
","[{'version': 'v1', 'created': 'Mon, 26 Jun 2023 05:04:58 GMT'}, {'version': 'v2', 'created': 'Thu, 6 Jul 2023 08:17:31 GMT'}]",2023-07-07,"[['Huang', 'Wen-Chin', ''], ['Violeta', 'Lester Phillip', ''], ['Liu', 'Songxiang', ''], ['Shi', 'Jiatong', ''], ['Toda', 'Tomoki', '']]"
2307.07262,Haris Jabbar,Haris Jabbar,MorphPiece : A Linguistic Tokenizer for Large Language Models,Manuscript under review. Patent pending,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Tokenization is a critical part of modern NLP pipelines. However,
contemporary tokenizers for Large Language Models are based on statistical
analysis of text corpora, without much consideration to the linguistic
features. I propose a linguistically motivated tokenization scheme, MorphPiece,
which is based partly on morphological segmentation of the underlying text. A
GPT-style causal language model trained on this tokenizer (called MorphGPT)
shows comparable or superior performance on a variety of supervised and
unsupervised NLP tasks, compared to the OpenAI GPT-2 model. Specifically I
evaluated MorphGPT on language modeling tasks, zero-shot performance on GLUE
Benchmark with various prompt templates, massive text embedding benchmark
(MTEB) for supervised and unsupervised performance, and lastly with another
morphological tokenization scheme (FLOTA, Hoffmann et al., 2022) and find that
the model trained on MorphPiece outperforms GPT-2 on most evaluations, at times
with considerable margin, despite being trained for about half the training
iterations.
","[{'version': 'v1', 'created': 'Fri, 14 Jul 2023 10:35:04 GMT'}, {'version': 'v2', 'created': 'Sat, 3 Feb 2024 05:42:54 GMT'}]",2024-02-06,"[['Jabbar', 'Haris', '']]"
1708.09163,Phuong Le-Hong,"Phuong Le-Hong, Minh Pham Quang Nhat, Thai-Hoang Pham, Tuan-Anh Tran,
  Dang-Minh Nguyen","An Empirical Study of Discriminative Sequence Labeling Models for
  Vietnamese Text Processing","To appear in the Proceedings of the 9th International Conference on
  Knowledge and Systems Engineering (KSE) 2017",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents an empirical study of two widely-used sequence prediction
models, Conditional Random Fields (CRFs) and Long Short-Term Memory Networks
(LSTMs), on two fundamental tasks for Vietnamese text processing, including
part-of-speech tagging and named entity recognition. We show that a strong
lower bound for labeling accuracy can be obtained by relying only on simple
word-based features with minimal hand-crafted feature engineering, of 90.65\%
and 86.03\% performance scores on the standard test sets for the two tasks
respectively. In particular, we demonstrate empirically the surprising
efficiency of word embeddings in both of the two tasks, with both of the two
models. We point out that the state-of-the-art LSTMs model does not always
outperform significantly the traditional CRFs model, especially on
moderate-sized data sets. Finally, we give some suggestions and discussions for
efficient use of sequence labeling models in practical applications.
","[{'version': 'v1', 'created': 'Wed, 30 Aug 2017 08:32:32 GMT'}]",2017-08-31,"[['Le-Hong', 'Phuong', ''], ['Nhat', 'Minh Pham Quang', ''], ['Pham', 'Thai-Hoang', ''], ['Tran', 'Tuan-Anh', ''], ['Nguyen', 'Dang-Minh', '']]"
2401.04695,Gal Yona,"Gal Yona, Roee Aharoni, Mor Geva","Narrowing the Knowledge Evaluation Gap: Open-Domain Question Answering
  with Multi-Granularity Answers",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Factual questions typically can be answered correctly at different levels of
granularity. For example, both ``August 4, 1961'' and ``1961'' are correct
answers to the question ``When was Barack Obama born?''. Standard question
answering (QA) evaluation protocols, however, do not explicitly take this into
account and compare a predicted answer against answers of a single granularity
level. In this work, we propose GRANOLA QA, a novel evaluation setting where a
predicted answer is evaluated in terms of accuracy and informativeness against
a set of multi-granularity answers. We present a simple methodology for
enriching existing datasets with multi-granularity answers, and create
GRANOLA-EQ, a multi-granularity version of the EntityQuestions dataset. We
evaluate a range of decoding methods on GRANOLA-EQ, including a new algorithm,
called Decoding with Response Aggregation (DRAG), that is geared towards
aligning the response granularity with the model's uncertainty. Our experiments
show that large language models with standard decoding tend to generate
specific answers, which are often incorrect. In contrast, when evaluated on
multi-granularity answers, DRAG yields a nearly 20 point increase in accuracy
on average, which further increases for rare entities. Overall, this reveals
that standard evaluation and decoding schemes may significantly underestimate
the knowledge encapsulated in LMs.
","[{'version': 'v1', 'created': 'Tue, 9 Jan 2024 17:44:36 GMT'}]",2024-01-10,"[['Yona', 'Gal', ''], ['Aharoni', 'Roee', ''], ['Geva', 'Mor', '']]"
2306.03460,Apurva Gandhi,"Apurva Gandhi, Thong Q. Nguyen, Huitian Jiao, Robert Steen, Ameya
  Bhatawdekar",Natural Language Commanding via Program Synthesis,,,,,cs.LG cs.CL cs.HC,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  We present Semantic Interpreter, a natural language-friendly AI system for
productivity software such as Microsoft Office that leverages large language
models (LLMs) to execute user intent across application features. While LLMs
are excellent at understanding user intent expressed as natural language, they
are not sufficient for fulfilling application-specific user intent that
requires more than text-to-text transformations. We therefore introduce the
Office Domain Specific Language (ODSL), a concise, high-level language
specialized for performing actions in and interacting with entities in Office
applications. Semantic Interpreter leverages an Analysis-Retrieval prompt
construction method with LLMs for program synthesis, translating natural
language user utterances to ODSL programs that can be transpiled to application
APIs and then executed. We focus our discussion primarily on a research
exploration for Microsoft PowerPoint.
","[{'version': 'v1', 'created': 'Tue, 6 Jun 2023 07:28:49 GMT'}]",2023-06-07,"[['Gandhi', 'Apurva', ''], ['Nguyen', 'Thong Q.', ''], ['Jiao', 'Huitian', ''], ['Steen', 'Robert', ''], ['Bhatawdekar', 'Ameya', '']]"
2301.02228,Chaoyi Wu,"Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, Weidi Xie","MedKLIP: Medical Knowledge Enhanced Language-Image Pre-Training in
  Radiology",,,,,eess.IV cs.CL cs.CV,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we consider enhancing medical visual-language pre-training
(VLP) with domain-specific knowledge, by exploiting the paired image-text
reports from the radiological daily practice. In particular, we make the
following contributions: First, unlike existing works that directly process the
raw reports, we adopt a novel triplet extraction module to extract the
medical-related information, avoiding unnecessary complexity from language
grammar and enhancing the supervision signals; Second, we propose a novel
triplet encoding module with entity translation by querying a knowledge base,
to exploit the rich domain knowledge in medical field, and implicitly build
relationships between medical entities in the language embedding space; Third,
we propose to use a Transformer-based fusion model for spatially aligning the
entity description with visual signals at the image patch level, enabling the
ability for medical diagnosis; Fourth, we conduct thorough experiments to
validate the effectiveness of our architecture, and benchmark on numerous
public benchmarks, e.g., ChestX-ray14, RSNA Pneumonia, SIIM-ACR Pneumothorax,
COVIDx CXR-2, COVID Rural, and EdemaSeverity. In both zero-shot and fine-tuning
settings, our model has demonstrated strong performance compared with the
former methods on disease classification and grounding.
","[{'version': 'v1', 'created': 'Thu, 5 Jan 2023 18:55:09 GMT'}, {'version': 'v2', 'created': 'Thu, 9 Mar 2023 12:45:10 GMT'}, {'version': 'v3', 'created': 'Mon, 3 Apr 2023 09:57:51 GMT'}]",2023-04-04,"[['Wu', 'Chaoyi', ''], ['Zhang', 'Xiaoman', ''], ['Zhang', 'Ya', ''], ['Wang', 'Yanfeng', ''], ['Xie', 'Weidi', '']]"
2103.11647,Ning Ding,"Ning Ding, Xiaobin Wang, Yao Fu, Guangwei Xu, Rui Wang, Pengjun Xie,
  Ying Shen, Fei Huang, Hai-Tao Zheng, Rui Zhang",Prototypical Representation Learning for Relation Extraction,Accepted by ICLR 2021,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recognizing relations between entities is a pivotal task of relational
learning. Learning relation representations from distantly-labeled datasets is
difficult because of the abundant label noise and complicated expressions in
human language. This paper aims to learn predictive, interpretable, and robust
relation representations from distantly-labeled data that are effective in
different settings, including supervised, distantly supervised, and few-shot
learning. Instead of solely relying on the supervision from noisy labels, we
propose to learn prototypes for each relation from contextual information to
best explore the intrinsic semantics of relations. Prototypes are
representations in the feature space abstracting the essential semantics of
relations between entities in sentences. We learn prototypes based on
objectives with clear geometric interpretation, where the prototypes are unit
vectors uniformly dispersed in a unit ball, and statement embeddings are
centered at the end of their corresponding prototype vectors on the surface of
the ball. This approach allows us to learn meaningful, interpretable prototypes
for the final classification. Results on several relation learning tasks show
that our model significantly outperforms the previous state-of-the-art models.
We further demonstrate the robustness of the encoder and the interpretability
of prototypes with extensive experiments.
","[{'version': 'v1', 'created': 'Mon, 22 Mar 2021 08:11:43 GMT'}]",2021-03-23,"[['Ding', 'Ning', ''], ['Wang', 'Xiaobin', ''], ['Fu', 'Yao', ''], ['Xu', 'Guangwei', ''], ['Wang', 'Rui', ''], ['Xie', 'Pengjun', ''], ['Shen', 'Ying', ''], ['Huang', 'Fei', ''], ['Zheng', 'Hai-Tao', ''], ['Zhang', 'Rui', '']]"
1709.05522,Xingyu Na,"Hui Bu, Jiayu Du, Xingyu Na, Bengu Wu, Hao Zheng","AISHELL-1: An Open-Source Mandarin Speech Corpus and A Speech
  Recognition Baseline",Oriental COCOSDA 2017,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  An open-source Mandarin speech corpus called AISHELL-1 is released. It is by
far the largest corpus which is suitable for conducting the speech recognition
research and building speech recognition systems for Mandarin. The recording
procedure, including audio capturing devices and environments are presented in
details. The preparation of the related resources, including transcriptions and
lexicon are described. The corpus is released with a Kaldi recipe. Experimental
results implies that the quality of audio recordings and transcriptions are
promising.
","[{'version': 'v1', 'created': 'Sat, 16 Sep 2017 14:33:27 GMT'}]",2017-09-19,"[['Bu', 'Hui', ''], ['Du', 'Jiayu', ''], ['Na', 'Xingyu', ''], ['Wu', 'Bengu', ''], ['Zheng', 'Hao', '']]"
1006.1343,Fionn Murtagh,Fionn Murtagh and Adam Ganz,"Segmentation and Nodal Points in Narrative: Study of Multiple Variations
  of a Ballad","27 pp., 13 figures. Submitted",,,,cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Lady Maisry ballads afford us a framework within which to segment a
storyline into its major components. Segments and as a consequence nodal points
are discussed for nine different variants of the Lady Maisry story of a (young)
woman being burnt to death by her family, on account of her becoming pregnant
by a foreign personage. We motivate the importance of nodal points in textual
and literary analysis. We show too how the openings of the nine variants can be
analyzed comparatively, and also the conclusions of the ballads.
","[{'version': 'v1', 'created': 'Mon, 7 Jun 2010 19:36:18 GMT'}]",2010-06-08,"[['Murtagh', 'Fionn', ''], ['Ganz', 'Adam', '']]"
2307.16811,Angus Williams,"Hannah Rose Kirk, Angus R. Williams, Liam Burke, Yi-Ling Chung, Ivan
  Debono, Pica Johansson, Francesca Stevens, Jonathan Bright, and Scott A. Hale","DoDo Learning: DOmain-DemOgraphic Transfer in Language Models for
  Detecting Abuse Targeted at Public Figures","15 pages, 7 figures, 4 tables",,,,cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Public figures receive a disproportionate amount of abuse on social media,
impacting their active participation in public life. Automated systems can
identify abuse at scale but labelling training data is expensive, complex and
potentially harmful. So, it is desirable that systems are efficient and
generalisable, handling both shared and specific aspects of online abuse. We
explore the dynamics of cross-group text classification in order to understand
how well classifiers trained on one domain or demographic can transfer to
others, with a view to building more generalisable abuse classifiers. We
fine-tune language models to classify tweets targeted at public figures across
DOmains (sport and politics) and DemOgraphics (women and men) using our novel
DODO dataset, containing 28,000 labelled entries, split equally across four
domain-demographic pairs. We find that (i) small amounts of diverse data are
hugely beneficial to generalisation and model adaptation; (ii) models transfer
more easily across demographics but models trained on cross-domain data are
more generalisable; (iii) some groups contribute more to generalisability than
others; and (iv) dataset similarity is a signal of transferability.
","[{'version': 'v1', 'created': 'Mon, 31 Jul 2023 16:29:08 GMT'}, {'version': 'v2', 'created': 'Mon, 21 Aug 2023 10:20:02 GMT'}]",2023-08-22,"[['Kirk', 'Hannah Rose', ''], ['Williams', 'Angus R.', ''], ['Burke', 'Liam', ''], ['Chung', 'Yi-Ling', ''], ['Debono', 'Ivan', ''], ['Johansson', 'Pica', ''], ['Stevens', 'Francesca', ''], ['Bright', 'Jonathan', ''], ['Hale', 'Scott A.', '']]"
2304.05336,Artur Nowakowski,Gabriela Pa{\l}ka and Artur Nowakowski,"Exploring the Use of Foundation Models for Named Entity Recognition and
  Lemmatization Tasks in Slavic Languages",Slavic NLP 2023 @ EACL 2023,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes Adam Mickiewicz University's (AMU) solution for the 4th
Shared Task on SlavNER. The task involves the identification, categorization,
and lemmatization of named entities in Slavic languages. Our approach involved
exploring the use of foundation models for these tasks. In particular, we used
models based on the popular BERT and T5 model architectures. Additionally, we
used external datasets to further improve the quality of our models. Our
solution obtained promising results, achieving high metrics scores in both
tasks. We describe our approach and the results of our experiments in detail,
showing that the method is effective for NER and lemmatization in Slavic
languages. Additionally, our models for lemmatization will be available at:
https://huggingface.co/amu-cai.
","[{'version': 'v1', 'created': 'Tue, 11 Apr 2023 16:55:11 GMT'}]",2023-04-12,"[['Pałka', 'Gabriela', ''], ['Nowakowski', 'Artur', '']]"
2111.01231,Khyathi Raghavi Chandu,"Parul Chopra, Sai Krishna Rallabandi, Alan W Black, Khyathi Raghavi
  Chandu","Switch Point biased Self-Training: Re-purposing Pretrained Models for
  Code-Switching",Accepted at EMNLP Findings 2021,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Code-switching (CS), a ubiquitous phenomenon due to the ease of communication
it offers in multilingual communities still remains an understudied problem in
language processing. The primary reasons behind this are: (1) minimal efforts
in leveraging large pretrained multilingual models, and (2) the lack of
annotated data. The distinguishing case of low performance of multilingual
models in CS is the intra-sentence mixing of languages leading to switch
points. We first benchmark two sequence labeling tasks -- POS and NER on 4
different language pairs with a suite of pretrained models to identify the
problems and select the best performing model, char-BERT, among them
(addressing (1)). We then propose a self training method to repurpose the
existing pretrained models using a switch-point bias by leveraging unannotated
data (addressing (2)). We finally demonstrate that our approach performs well
on both tasks by reducing the gap between the switch point performance while
retaining the overall performance on two distinct language pairs in both the
tasks. Our code is available here:
https://github.com/PC09/EMNLP2021-Switch-Point-biased-Self-Training.
","[{'version': 'v1', 'created': 'Mon, 1 Nov 2021 19:42:08 GMT'}]",2021-11-03,"[['Chopra', 'Parul', ''], ['Rallabandi', 'Sai Krishna', ''], ['Black', 'Alan W', ''], ['Chandu', 'Khyathi Raghavi', '']]"
2310.01290,Wenxuan Ding,"Wenxuan Ding, Shangbin Feng, Yuhan Liu, Zhaoxuan Tan, Vidhisha
  Balachandran, Tianxing He, Yulia Tsvetkov","Knowledge Crosswords: Geometric Reasoning over Structured Knowledge with
  Large Language Models",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) are widely adopted in knowledge-intensive tasks
and have achieved impressive performance thanks to their knowledge abilities.
While LLMs have demonstrated outstanding performance on atomic or linear
(multi-hop) QA tasks, whether they can reason in knowledge-rich scenarios with
interweaving constraints remains an underexplored problem. In this work, we
propose geometric reasoning over structured knowledge, where pieces of
knowledge are connected in a graph structure and models need to fill in the
missing information. Such geometric knowledge reasoning would require the
ability to handle structured knowledge, reason with uncertainty, verify facts,
and backtrack when an error occurs. We propose Knowledge Crosswords, a
multi-blank QA dataset where each problem consists of a natural language
question representing the geometric constraints of an incomplete entity
network, where LLMs are tasked with working out the missing entities while
meeting all factual constraints. Knowledge Crosswords contains 2,101 individual
problems, covering various knowledge domains and further divided into three
difficulty levels. We conduct extensive experiments to evaluate existing LLM
prompting approaches on the Knowledge Crosswords benchmark. We additionally
propose two new approaches, Staged Prompting and Verify-All, to augment LLMs'
ability to backtrack and verify structured constraints. Our results demonstrate
that while baseline approaches perform well on easier problems but struggle
with hard ones, our proposed Verify-All outperforms other methods by a large
margin and is more robust with hard problems. Further analysis reveals that
LLMs' ability of geometric reasoning over structured knowledge is still far
from robust or perfect, susceptible to confounders such as the order of
options, certain structural patterns, assumption of existence of correct
answer, and more.
","[{'version': 'v1', 'created': 'Mon, 2 Oct 2023 15:43:53 GMT'}]",2023-10-03,"[['Ding', 'Wenxuan', ''], ['Feng', 'Shangbin', ''], ['Liu', 'Yuhan', ''], ['Tan', 'Zhaoxuan', ''], ['Balachandran', 'Vidhisha', ''], ['He', 'Tianxing', ''], ['Tsvetkov', 'Yulia', '']]"
2312.01032,Subhankar Maity,"Subhankar Maity, Aniket Deroy, Sudeshna Sarkar","Harnessing the Power of Prompt-based Techniques for Generating
  School-Level Questions using Large Language Models",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Designing high-quality educational questions is a challenging and
time-consuming task. In this work, we propose a novel approach that utilizes
prompt-based techniques to generate descriptive and reasoning-based questions.
However, current question-answering (QA) datasets are inadequate for conducting
our experiments on prompt-based question generation (QG) in an educational
setting. Therefore, we curate a new QG dataset called EduProbe for school-level
subjects, by leveraging the rich content of NCERT textbooks. We carefully
annotate this dataset as quadruples of 1) Context: a segment upon which the
question is formed; 2) Long Prompt: a long textual cue for the question (i.e.,
a longer sequence of words or phrases, covering the main theme of the context);
3) Short Prompt: a short textual cue for the question (i.e., a condensed
representation of the key information or focus of the context); 4) Question: a
deep question that aligns with the context and is coherent with the prompts. We
investigate several prompt-based QG methods by fine-tuning pre-trained
transformer-based large language models (LLMs), namely PEGASUS, T5, MBART, and
BART. Moreover, we explore the performance of two general-purpose pre-trained
LLMs such as Text-Davinci-003 and GPT-3.5-Turbo without any further training.
By performing automatic evaluation, we show that T5 (with long prompt)
outperforms all other models, but still falls short of the human baseline.
Under human evaluation criteria, TextDavinci-003 usually shows better results
than other models under various prompt settings. Even in the case of human
evaluation criteria, QG models mostly fall short of the human baseline. Our
code and dataset are available at: https://github.com/my625/PromptQG
","[{'version': 'v1', 'created': 'Sat, 2 Dec 2023 05:13:28 GMT'}]",2023-12-05,"[['Maity', 'Subhankar', ''], ['Deroy', 'Aniket', ''], ['Sarkar', 'Sudeshna', '']]"
2202.07023,Alexandre Cremers,Alexandre Cremers and Ethan G. Wilcox and Benjamin Spector,"Exhaustivity and anti-exhaustivity in the RSA framework: Testing the
  effect of prior beliefs",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  During communication, the interpretation of utterances is sensitive to a
listener's probabilistic prior beliefs, something which is captured by one
currently influential model of pragmatics, the Rational Speech Act (RSA)
framework. In this paper we focus on cases when this sensitivity to priors
leads to counterintuitive predictions of the framework. Our domain of interest
is exhaustivity effects, whereby a sentence such as ""Mary came"" is understood
to mean that only Mary came. We show that in the baseline RSA model, under
certain conditions, anti-exhaustive readings are predicted (e.g., ""Mary came""
would be used to convey that both Mary and Peter came). The specific question
we ask is the following: should exhaustive interpretations be derived as purely
pragmatic inferences (as in the classical Gricean view, endorsed in the
baseline RSA model), or should they rather be generated by an encapsulated
semantic mechanism (as argued in some of the recent formal literature)? To
answer this question, we provide a detailed theoretical analysis of different
RSA models and evaluate them against data obtained in a new study which tested
the effects of prior beliefs on both production and comprehension, improving on
previous empirical work. We found no anti-exhaustivity effects, but observed
that message choice is sensitive to priors, as predicted by the RSA framework
overall. The best models turn out to be those which include an encapsulated
exhaustivity mechanism (as other studies concluded on the basis of very
different data). We conclude that, on the one hand, in the division of labor
between semantics and pragmatics, semantics plays a larger role than is often
thought, but, on the other hand, the tradeoff between informativity and cost
which characterizes all RSA models does play a central role for genuine
pragmatic effects.
","[{'version': 'v1', 'created': 'Mon, 14 Feb 2022 20:35:03 GMT'}]",2022-02-16,"[['Cremers', 'Alexandre', ''], ['Wilcox', 'Ethan G.', ''], ['Spector', 'Benjamin', '']]"
2005.04277,Peng Su,Peng Su and K. Vijay-Shanker,"Adversarial Learning for Supervised and Semi-supervised Relation
  Extraction in Biomedical Literature",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Adversarial training is a technique of improving model performance by
involving adversarial examples in the training process. In this paper, we
investigate adversarial training with multiple adversarial examples to benefit
the relation extraction task. We also apply adversarial training technique in
semi-supervised scenarios to utilize unlabeled data. The evaluation results on
protein-protein interaction and protein subcellular localization task
illustrate adversarial training provides improvement on the supervised model,
and is also effective on involving unlabeled data in the semi-supervised
training case. In addition, our method achieves state-of-the-art performance on
two benchmarking datasets.
","[{'version': 'v1', 'created': 'Fri, 8 May 2020 20:19:26 GMT'}, {'version': 'v2', 'created': 'Fri, 25 Sep 2020 15:21:50 GMT'}]",2020-09-28,"[['Su', 'Peng', ''], ['Vijay-Shanker', 'K.', '']]"
2303.17651,Uri Alon,"Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao,
  Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,
  Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, Sean Welleck,
  Amir Yazdanbakhsh, Peter Clark",Self-Refine: Iterative Refinement with Self-Feedback,"Code, data, and demo at https://selfrefine.info/",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Like humans, large language models (LLMs) do not always generate the best
output on their first try. Motivated by how humans refine their written text,
we introduce Self-Refine, an approach for improving initial outputs from LLMs
through iterative feedback and refinement. The main idea is to generate an
initial output using an LLMs; then, the same LLMs provides feedback for its
output and uses it to refine itself, iteratively. Self-Refine does not require
any supervised training data, additional training, or reinforcement learning,
and instead uses a single LLM as the generator, refiner, and feedback provider.
We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response
generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT,
and GPT-4) LLMs. Across all evaluated tasks, outputs generated with Self-Refine
are preferred by humans and automatic metrics over those generated with the
same LLM using conventional one-step generation, improving by ~20% absolute on
average in task performance. Our work demonstrates that even state-of-the-art
LLMs like GPT-4 can be further improved at test time using our simple,
standalone approach.
","[{'version': 'v1', 'created': 'Thu, 30 Mar 2023 18:30:01 GMT'}, {'version': 'v2', 'created': 'Thu, 25 May 2023 19:13:47 GMT'}]",2023-05-29,"[['Madaan', 'Aman', ''], ['Tandon', 'Niket', ''], ['Gupta', 'Prakhar', ''], ['Hallinan', 'Skyler', ''], ['Gao', 'Luyu', ''], ['Wiegreffe', 'Sarah', ''], ['Alon', 'Uri', ''], ['Dziri', 'Nouha', ''], ['Prabhumoye', 'Shrimai', ''], ['Yang', 'Yiming', ''], ['Gupta', 'Shashank', ''], ['Majumder', 'Bodhisattwa Prasad', ''], ['Hermann', 'Katherine', ''], ['Welleck', 'Sean', ''], ['Yazdanbakhsh', 'Amir', ''], ['Clark', 'Peter', '']]"
2212.11219,Biplav Srivastava,"Bharath Muppasani, Vishal Pallagani, Kausik Lakkaraju, Shuge Lei,
  Biplav Srivastava, Brett Robertson, Andrea Hickerson, Vignesh Narayanan",On Safe and Usable Chatbots for Promoting Voter Participation,"7 pages, In AAAI 2023 Workshop on AI for Credible Elections",,,,cs.HC cs.CL cs.CY,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Chatbots, or bots for short, are multi-modal collaborative assistants that
can help people complete useful tasks. Usually, when chatbots are referenced in
connection with elections, they often draw negative reactions due to the fear
of mis-information and hacking. Instead, in this paper, we explore how chatbots
may be used to promote voter participation in vulnerable segments of society
like senior citizens and first-time voters. In particular, we build a system
that amplifies official information while personalizing it to users' unique
needs transparently. We discuss its design, build prototypes with frequently
asked questions (FAQ) election information for two US states that are low on an
ease-of-voting scale, and report on its initial evaluation in a focus group.
Our approach can be a win-win for voters, election agencies trying to fulfill
their mandate and democracy at large.
","[{'version': 'v1', 'created': 'Fri, 16 Dec 2022 08:07:51 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Dec 2022 08:09:45 GMT'}]",2022-12-29,"[['Muppasani', 'Bharath', ''], ['Pallagani', 'Vishal', ''], ['Lakkaraju', 'Kausik', ''], ['Lei', 'Shuge', ''], ['Srivastava', 'Biplav', ''], ['Robertson', 'Brett', ''], ['Hickerson', 'Andrea', ''], ['Narayanan', 'Vignesh', '']]"
2007.14587,T.J. Tsai,TJ Tsai and Kevin Ji,"Composer Style Classification of Piano Sheet Music Images Using Language
  Model Pretraining","8 pages, 7 figures. Accepted paper at the International Society for
  Music Information Retrieval Conference (ISMIR) 2020",,,,cs.CV cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  This paper studies composer style classification of piano sheet music images.
Previous approaches to the composer classification task have been limited by a
scarcity of data. We address this issue in two ways: (1) we recast the problem
to be based on raw sheet music images rather than a symbolic music format, and
(2) we propose an approach that can be trained on unlabeled data. Our approach
first converts the sheet music image into a sequence of musical ""words"" based
on the bootleg feature representation, and then feeds the sequence into a text
classifier. We show that it is possible to significantly improve classifier
performance by first training a language model on a set of unlabeled data,
initializing the classifier with the pretrained language model weights, and
then finetuning the classifier on a small amount of labeled data. We train
AWD-LSTM, GPT-2, and RoBERTa language models on all piano sheet music images in
IMSLP. We find that transformer-based architectures outperform CNN and LSTM
models, and pretraining boosts classification accuracy for the GPT-2 model from
46\% to 70\% on a 9-way classification task. The trained model can also be used
as a feature extractor that projects piano sheet music into a feature space
that characterizes compositional style.
","[{'version': 'v1', 'created': 'Wed, 29 Jul 2020 04:13:59 GMT'}]",2020-07-30,"[['Tsai', 'TJ', ''], ['Ji', 'Kevin', '']]"
2211.05994,Zeyi Liu,"Linmei Hu, Zeyi Liu, Ziwang Zhao, Lei Hou, Liqiang Nie, and Juanzi Li",A Survey of Knowledge Enhanced Pre-trained Language Models,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained Language Models (PLMs) which are trained on large text corpus via
self-supervised learning method, have yielded promising performance on various
tasks in Natural Language Processing (NLP). However, though PLMs with huge
parameters can effectively possess rich knowledge learned from massive training
text and benefit downstream tasks at the fine-tuning stage, they still have
some limitations such as poor reasoning ability due to the lack of external
knowledge. Research has been dedicated to incorporating knowledge into PLMs to
tackle these issues. In this paper, we present a comprehensive review of
Knowledge Enhanced Pre-trained Language Models (KE-PLMs) to provide a clear
insight into this thriving field. We introduce appropriate taxonomies
respectively for Natural Language Understanding (NLU) and Natural Language
Generation (NLG) to highlight these two main tasks of NLP. For NLU, we divide
the types of knowledge into four categories: linguistic knowledge, text
knowledge, knowledge graph (KG), and rule knowledge. The KE-PLMs for NLG are
categorized into KG-based and retrieval-based methods. Finally, we point out
some promising future directions of KE-PLMs.
","[{'version': 'v1', 'created': 'Fri, 11 Nov 2022 04:29:02 GMT'}, {'version': 'v2', 'created': 'Thu, 17 Nov 2022 06:03:11 GMT'}, {'version': 'v3', 'created': 'Fri, 18 Nov 2022 14:59:21 GMT'}, {'version': 'v4', 'created': 'Wed, 30 Aug 2023 08:02:56 GMT'}]",2023-08-31,"[['Hu', 'Linmei', ''], ['Liu', 'Zeyi', ''], ['Zhao', 'Ziwang', ''], ['Hou', 'Lei', ''], ['Nie', 'Liqiang', ''], ['Li', 'Juanzi', '']]"
2403.06925,Bhavya Vasudeva,"Bhavya Vasudeva, Deqing Fu, Tianyi Zhou, Elliott Kau, Youqi Huang,
  Vatsal Sharan",Simplicity Bias of Transformers to Learn Low Sensitivity Functions,"24 pages, 19 figures, 3 tables",,,,cs.LG cs.AI cs.CL stat.ML,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Transformers achieve state-of-the-art accuracy and robustness across many
tasks, but an understanding of the inductive biases that they have and how
those biases are different from other neural network architectures remains
elusive. Various neural network architectures such as fully connected networks
have been found to have a simplicity bias towards simple functions of the data;
one version of this simplicity bias is a spectral bias to learn simple
functions in the Fourier space. In this work, we identify the notion of
sensitivity of the model to random changes in the input as a notion of
simplicity bias which provides a unified metric to explain the simplicity and
spectral bias of transformers across different data modalities. We show that
transformers have lower sensitivity than alternative architectures, such as
LSTMs, MLPs and CNNs, across both vision and language tasks. We also show that
low-sensitivity bias correlates with improved robustness; furthermore, it can
also be used as an efficient intervention to further improve the robustness of
transformers.
","[{'version': 'v1', 'created': 'Mon, 11 Mar 2024 17:12:09 GMT'}]",2024-03-12,"[['Vasudeva', 'Bhavya', ''], ['Fu', 'Deqing', ''], ['Zhou', 'Tianyi', ''], ['Kau', 'Elliott', ''], ['Huang', 'Youqi', ''], ['Sharan', 'Vatsal', '']]"
2401.03401,Wei Xia,"Wei Xia, Shaoguang Mao, Chanjing Zheng","Empirical Study of Large Language Models as Automated Essay Scoring
  Tools in English Composition__Taking TOEFL Independent Writing Task for
  Example",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models have demonstrated exceptional capabilities in tasks
involving natural language generation, reasoning, and comprehension. This study
aims to construct prompts and comments grounded in the diverse scoring criteria
delineated within the official TOEFL guide. The primary objective is to assess
the capabilities and constraints of ChatGPT, a prominent representative of
large language models, within the context of automated essay scoring. The
prevailing methodologies for automated essay scoring involve the utilization of
deep neural networks, statistical machine learning techniques, and fine-tuning
pre-trained models. However, these techniques face challenges when applied to
different contexts or subjects, primarily due to their substantial data
requirements and limited adaptability to small sample sizes. In contrast, this
study employs ChatGPT to conduct an automated evaluation of English essays,
even with a small sample size, employing an experimental approach. The
empirical findings indicate that ChatGPT can provide operational functionality
for automated essay scoring, although the results exhibit a regression effect.
It is imperative to underscore that the effective design and implementation of
ChatGPT prompts necessitate a profound domain expertise and technical
proficiency, as these prompts are subject to specific threshold criteria.
Keywords: ChatGPT, Automated Essay Scoring, Prompt Learning, TOEFL Independent
Writing Task
","[{'version': 'v1', 'created': 'Sun, 7 Jan 2024 07:13:50 GMT'}]",2024-01-09,"[['Xia', 'Wei', ''], ['Mao', 'Shaoguang', ''], ['Zheng', 'Chanjing', '']]"
2305.01099,Charlie Cowen-Breen,"Charlie Cowen-Breen (1), Creston Brooks (2), Johannes Haubold (2),
  Barbara Graziosi (2) ((1) University of Cambridge, (2) Princeton University)",Logion: Machine Learning for Greek Philology,"14 pages, 4 figures",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  This paper presents machine-learning methods to address various problems in
Greek philology. After training a BERT model on the largest premodern Greek
dataset used for this purpose to date, we identify and correct previously
undetected errors made by scribes in the process of textual transmission, in
what is, to our knowledge, the first successful identification of such errors
via machine learning. Additionally, we demonstrate the model's capacity to fill
gaps caused by material deterioration of premodern manuscripts and compare the
model's performance to that of a domain expert. We find that best performance
is achieved when the domain expert is provided with model suggestions for
inspiration. With such human-computer collaborations in mind, we explore the
model's interpretability and find that certain attention heads appear to encode
select grammatical features of premodern Greek.
","[{'version': 'v1', 'created': 'Mon, 1 May 2023 21:56:25 GMT'}]",2023-05-03,"[['Cowen-Breen', 'Charlie', '', 'University of Cambridge'], ['Brooks', 'Creston', '', 'Princeton University'], ['Haubold', 'Johannes', '', 'Princeton University'], ['Graziosi', 'Barbara', '', 'Princeton University']]"
2204.05979,Fran\c{c}ois Mercier,"Francois Mercier, Makesh Narsimhan","Discovering material information using hierarchical Reformer model on
  financial regulatory filings",KDD ML in Finance workshop 2021,,,,q-fin.ST cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Most applications of machine learning for finance are related to forecasting
tasks for investment decisions. Instead, we aim to promote a better
understanding of financial markets with machine learning techniques. Leveraging
the tremendous progress in deep learning models for natural language
processing, we construct a hierarchical Reformer ([15]) model capable of
processing a large document level dataset, SEDAR, from canadian financial
regulatory filings. Using this model, we show that it is possible to predict
trade volume changes using regulatory filings. We adapt the pretraining task of
HiBERT ([36]) to obtain good sentence level representations using a large
unlabelled document dataset. Finetuning the model to successfully predict trade
volume changes indicates that the model captures a view from financial markets
and processing regulatory filings is beneficial. Analyzing the attention
patterns of our model reveals that it is able to detect some indications of
material information without explicit training, which is highly relevant for
investors and also for the market surveillance mandate of financial regulators.
","[{'version': 'v1', 'created': 'Mon, 28 Mar 2022 19:47:34 GMT'}]",2022-04-13,"[['Mercier', 'Francois', ''], ['Narsimhan', 'Makesh', '']]"
1709.06901,Chao Zhao,"Zhipeng Jiang, Chao Zhao, Bin He, Yi Guan, Jingchi Jiang","De-identification of medical records using conditional random fields and
  long short-term memory networks",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The CEGS N-GRID 2016 Shared Task 1 in Clinical Natural Language Processing
focuses on the de-identification of psychiatric evaluation records. This paper
describes two participating systems of our team, based on conditional random
fields (CRFs) and long short-term memory networks (LSTMs). A pre-processing
module was introduced for sentence detection and tokenization before
de-identification. For CRFs, manually extracted rich features were utilized to
train the model. For LSTMs, a character-level bi-directional LSTM network was
applied to represent tokens and classify tags for each token, following which a
decoding layer was stacked to decode the most probable protected health
information (PHI) terms. The LSTM-based system attained an i2b2 strict
micro-F_1 measure of 89.86%, which was higher than that of the CRF-based
system.
","[{'version': 'v1', 'created': 'Wed, 20 Sep 2017 14:30:17 GMT'}, {'version': 'v2', 'created': 'Fri, 29 Sep 2017 12:03:57 GMT'}]",2017-10-02,"[['Jiang', 'Zhipeng', ''], ['Zhao', 'Chao', ''], ['He', 'Bin', ''], ['Guan', 'Yi', ''], ['Jiang', 'Jingchi', '']]"
2302.01823,Pawan Kumar Rajpoot,"Nikita Katyal, Pawan Kumar Rajpoot",Lexical Simplification using multi level and modular approach,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Text Simplification is an ongoing problem in Natural Language Processing,
solution to which has varied implications. In conjunction with the TSAR-2022
Workshop @EMNLP2022 Lexical Simplification is the process of reducing the
lexical complexity of a text by replacing difficult words with easier to read
(or understand) expressions while preserving the original information and
meaning. This paper explains the work done by our team ""teamPN"" for English sub
task. We created a modular pipeline which combines modern day transformers
based models with traditional NLP methods like paraphrasing and verb sense
disambiguation. We created a multi level and modular pipeline where the target
text is treated according to its semantics(Part of Speech Tag). Pipeline is
multi level as we utilize multiple source models to find potential candidates
for replacement, It is modular as we can switch the source models and their
weight-age in the final re-ranking.
","[{'version': 'v1', 'created': 'Fri, 3 Feb 2023 15:57:54 GMT'}]",2023-02-06,"[['Katyal', 'Nikita', ''], ['Rajpoot', 'Pawan Kumar', '']]"
2307.00101,Harnoor Dhingra,"Harnoor Dhingra, Preetiha Jayashanker, Sayali Moghe, Emma Strubell","Queer People are People First: Deconstructing Sexual Identity
  Stereotypes in Large Language Models",Accepted to Queer in AI Workshop at ACL 2023,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) are trained primarily on minimally processed web
text, which exhibits the same wide range of social biases held by the humans
who created that content. Consequently, text generated by LLMs can
inadvertently perpetuate stereotypes towards marginalized groups, like the
LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs
generate text describing people with different sexual identities. Analyzing
bias in the text generated by an LLM using regard score shows measurable bias
against queer people. We then show that a post-hoc method based on
chain-of-thought prompting using SHAP analysis can increase the regard of the
sentence, representing a promising approach towards debiasing the output of
LLMs in this setting.
","[{'version': 'v1', 'created': 'Fri, 30 Jun 2023 19:39:01 GMT'}]",2023-07-04,"[['Dhingra', 'Harnoor', ''], ['Jayashanker', 'Preetiha', ''], ['Moghe', 'Sayali', ''], ['Strubell', 'Emma', '']]"
2401.02369,Griffin Adams,"Griffin Adams, Jason Zucker, No\'emie Elhadad","SPEER: Sentence-Level Planning of Long Clinical Summaries via Embedded
  Entity Retrieval",Preprint,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Clinician must write a lengthy summary each time a patient is discharged from
the hospital. This task is time-consuming due to the sheer number of unique
clinical concepts covered in the admission. Identifying and covering salient
entities is vital for the summary to be clinically useful. We fine-tune
open-source LLMs (Mistral-7B-Instruct and Zephyr-7B-\b{eta}) on the task and
find that they generate incomplete and unfaithful summaries. To increase entity
coverage, we train a smaller, encoder-only model to predict salient entities,
which are treated as content-plans to guide the LLM. To encourage the LLM to
focus on specific mentions in the source notes, we propose SPEER:
Sentence-level Planning via Embedded Entity Retrieval. Specifically, we mark
each salient entity span with special ""{{ }}"" boundary tags and instruct the
LLM to retrieve marked spans before generating each sentence. Sentence-level
planning acts as a form of state tracking in that the model is explicitly
recording the entities it uses. We fine-tune Mistral and Zephyr variants on a
large-scale, diverse dataset of ~167k in-patient hospital admissions and
evaluate on 3 datasets. SPEER shows gains in both coverage and faithfulness
metrics over non-guided and guided baselines.
","[{'version': 'v1', 'created': 'Thu, 4 Jan 2024 17:23:44 GMT'}]",2024-01-05,"[['Adams', 'Griffin', ''], ['Zucker', 'Jason', ''], ['Elhadad', 'Noémie', '']]"
1803.05820,Alexander Panchenko,"Alexander Panchenko, Natalia Loukachevitch, Dmitry Ustalov, Denis
  Paperno, Christian Meyer, Natalia Konstantinova",RUSSE: The First Workshop on Russian Semantic Similarity,"In Proceedings of the 21st International Conference on Computational
  Linguistics and Intellectual Technologies (Dialogue'2015)",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The paper gives an overview of the Russian Semantic Similarity Evaluation
(RUSSE) shared task held in conjunction with the Dialogue 2015 conference.
There exist a lot of comparative studies on semantic similarity, yet no
analysis of such measures was ever performed for the Russian language.
Exploring this problem for the Russian language is even more interesting,
because this language has features, such as rich morphology and free word
order, which make it significantly different from English, German, and other
well-studied languages. We attempt to bridge this gap by proposing a shared
task on the semantic similarity of Russian nouns. Our key contribution is an
evaluation methodology based on four novel benchmark datasets for the Russian
language. Our analysis of the 105 submissions from 19 teams reveals that
successful approaches for English, such as distributional and skip-gram models,
are directly applicable to Russian as well. On the one hand, the best results
in the contest were obtained by sophisticated supervised models that combine
evidence from different sources. On the other hand, completely unsupervised
approaches, such as a skip-gram model estimated on a large-scale corpus, were
able score among the top 5 systems.
","[{'version': 'v1', 'created': 'Thu, 15 Mar 2018 15:50:58 GMT'}]",2018-03-16,"[['Panchenko', 'Alexander', ''], ['Loukachevitch', 'Natalia', ''], ['Ustalov', 'Dmitry', ''], ['Paperno', 'Denis', ''], ['Meyer', 'Christian', ''], ['Konstantinova', 'Natalia', '']]"
1805.08983,Jonggu Kim,"Jonggu Kim, Doyeon Kong, Jong-Hyeok Lee","Self-Attention-Based Message-Relevant Response Generation for Neural
  Conversation Model",8 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Using a sequence-to-sequence framework, many neural conversation models for
chit-chat succeed in naturalness of the response. Nevertheless, the neural
conversation models tend to give generic responses which are not specific to
given messages, and it still remains as a challenge. To alleviate the tendency,
we propose a method to promote message-relevant and diverse responses for
neural conversation model by using self-attention, which is time-efficient as
well as effective. Furthermore, we present an investigation of why and how
effective self-attention is in deep comparison with the standard dialogue
generation. The experiment results show that the proposed method improves the
standard dialogue generation in various evaluation metrics.
","[{'version': 'v1', 'created': 'Wed, 23 May 2018 07:14:21 GMT'}]",2018-05-24,"[['Kim', 'Jonggu', ''], ['Kong', 'Doyeon', ''], ['Lee', 'Jong-Hyeok', '']]"
2310.09762,Liang Ding,"Boan Liu, Liang Ding, Li Shen, Keqin Peng, Yu Cao, Dazhao Cheng,
  Dacheng Tao","Diversifying the Mixture-of-Experts Representation for Language Models
  with Orthogonal Optimizer",,,,,cs.CL cs.AI,http://creativecommons.org/publicdomain/zero/1.0/,"  The Mixture of Experts (MoE) has emerged as a highly successful technique in
deep learning, based on the principle of divide-and-conquer to maximize model
capacity without significant additional computational cost. Even in the era of
large-scale language models (LLMs), MoE continues to play a crucial role, as
some researchers have indicated that GPT-4 adopts the MoE structure to ensure
diverse inference results. However, MoE is susceptible to performance
degeneracy, particularly evident in the issues of imbalance and homogeneous
representation among experts. While previous studies have extensively addressed
the problem of imbalance, the challenge of homogeneous representation remains
unresolved. In this study, we shed light on the homogeneous representation
problem, wherein experts in the MoE fail to specialize and lack diversity,
leading to frustratingly high similarities in their representations (up to 99%
in a well-performed MoE model). This problem restricts the expressive power of
the MoE and, we argue, contradicts its original intention. To tackle this
issue, we propose a straightforward yet highly effective solution: OMoE, an
orthogonal expert optimizer. Additionally, we introduce an alternating training
strategy that encourages each expert to update in a direction orthogonal to the
subspace spanned by other experts. Our algorithm facilitates MoE training in
two key ways: firstly, it explicitly enhances representation diversity, and
secondly, it implicitly fosters interaction between experts during orthogonal
weights computation. Through extensive experiments, we demonstrate that our
proposed optimization algorithm significantly improves the performance of
fine-tuning the MoE model on the GLUE benchmark, SuperGLUE benchmark,
question-answering task, and name entity recognition tasks.
","[{'version': 'v1', 'created': 'Sun, 15 Oct 2023 07:20:28 GMT'}]",2023-10-17,"[['Liu', 'Boan', ''], ['Ding', 'Liang', ''], ['Shen', 'Li', ''], ['Peng', 'Keqin', ''], ['Cao', 'Yu', ''], ['Cheng', 'Dazhao', ''], ['Tao', 'Dacheng', '']]"
2306.04544,Muhao Chen,"Shudi Hou, Yu Xia, Muhao Chen, Sujian Li",Contrastive Bootstrapping for Label Refinement,ACL 2023,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Traditional text classification typically categorizes texts into pre-defined
coarse-grained classes, from which the produced models cannot handle the
real-world scenario where finer categories emerge periodically for accurate
services. In this work, we investigate the setting where fine-grained
classification is done only using the annotation of coarse-grained categories
and the coarse-to-fine mapping. We propose a lightweight contrastive
clustering-based bootstrapping method to iteratively refine the labels of
passages. During clustering, it pulls away negative passage-prototype pairs
under the guidance of the mapping from both global and local perspectives.
Experiments on NYT and 20News show that our method outperforms the
state-of-the-art methods by a large margin.
","[{'version': 'v1', 'created': 'Wed, 7 Jun 2023 15:49:04 GMT'}]",2023-06-08,"[['Hou', 'Shudi', ''], ['Xia', 'Yu', ''], ['Chen', 'Muhao', ''], ['Li', 'Sujian', '']]"
1603.06571,Oren Barkan,Oren Barkan,Bayesian Neural Word Embedding,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, several works in the domain of natural language processing
presented successful methods for word embedding. Among them, the Skip-Gram with
negative sampling, known also as word2vec, advanced the state-of-the-art of
various linguistics tasks. In this paper, we propose a scalable Bayesian neural
word embedding algorithm. The algorithm relies on a Variational Bayes solution
for the Skip-Gram objective and a detailed step by step description is
provided. We present experimental results that demonstrate the performance of
the proposed algorithm for word analogy and similarity tasks on six different
datasets and show it is competitive with the original Skip-Gram method.
","[{'version': 'v1', 'created': 'Mon, 21 Mar 2016 16:32:06 GMT'}, {'version': 'v2', 'created': 'Sun, 5 Jun 2016 16:49:11 GMT'}, {'version': 'v3', 'created': 'Mon, 20 Feb 2017 20:45:33 GMT'}]",2017-02-22,"[['Barkan', 'Oren', '']]"
2306.02679,Wei Hu,"Zequn Sun and Jiacheng Huang and Jinghao Lin and Xiaozhou Xu and Qijin
  Chen and Wei Hu","Joint Pre-training and Local Re-training: Transferable Representation
  Learning on Multi-source Knowledge Graphs","Accepted in the 29th ACM SIGKDD International Conference on Knowledge
  Discovery and Data Mining (KDD 2023)",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we present the ``joint pre-training and local re-training''
framework for learning and applying multi-source knowledge graph (KG)
embeddings. We are motivated by the fact that different KGs contain
complementary information to improve KG embeddings and downstream tasks. We
pre-train a large teacher KG embedding model over linked multi-source KGs and
distill knowledge to train a student model for a task-specific KG. To enable
knowledge transfer across different KGs, we use entity alignment to build a
linked subgraph for connecting the pre-trained KGs and the target KG. The
linked subgraph is re-trained for three-level knowledge distillation from the
teacher to the student, i.e., feature knowledge distillation, network knowledge
distillation, and prediction knowledge distillation, to generate more
expressive embeddings. The teacher model can be reused for different target KGs
and tasks without having to train from scratch. We conduct extensive
experiments to demonstrate the effectiveness and efficiency of our framework.
","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 08:11:59 GMT'}]",2023-06-06,"[['Sun', 'Zequn', ''], ['Huang', 'Jiacheng', ''], ['Lin', 'Jinghao', ''], ['Xu', 'Xiaozhou', ''], ['Chen', 'Qijin', ''], ['Hu', 'Wei', '']]"
1809.02040,Linfeng Song,"Linfeng Song, Zhiguo Wang, Mo Yu, Yue Zhang, Radu Florian and Daniel
  Gildea","Exploring Graph-structured Passage Representation for Multi-hop Reading
  Comprehension with Graph Neural Networks",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multi-hop reading comprehension focuses on one type of factoid question,
where a system needs to properly integrate multiple pieces of evidence to
correctly answer a question. Previous work approximates global evidence with
local coreference information, encoding coreference chains with DAG-styled GRU
layers within a gated-attention reader. However, coreference is limited in
providing information for rich inference. We introduce a new method for better
connecting global evidence, which forms more complex graphs compared to DAGs.
To perform evidence integration on our graphs, we investigate two recent graph
neural networks, namely graph convolutional network (GCN) and graph recurrent
network (GRN). Experiments on two standard datasets show that richer global
information leads to better answers. Our method performs better than all
published results on these datasets.
","[{'version': 'v1', 'created': 'Thu, 6 Sep 2018 15:18:14 GMT'}]",2018-09-07,"[['Song', 'Linfeng', ''], ['Wang', 'Zhiguo', ''], ['Yu', 'Mo', ''], ['Zhang', 'Yue', ''], ['Florian', 'Radu', ''], ['Gildea', 'Daniel', '']]"
2210.14367,Michael Carl,Michael Carl,The Monitor Model and its Misconceptions: A Clarification,"Accepted for publication in: Lacruz, Isabel (ed.) Translation in
  Transition: Human and Machine Intelligence. American Translators Association
  Scholarly Monograph series. Amsterdam/ Philadelphia: John Benjamins",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Horizontal (automatic) and vertical (control) processes have been observed
and reported for a long time in translation production. Schaeffer and Carl's
Monitor Model integrates these two processes into one framework, assuming that
priming mechanisms underlie horizontal/automatic processes, while
vertical/monitoring processes implement consciously accessible control
mechanisms. The Monitor Model has been criticized in various ways and several
misconceptions have accumulated over the past years. In this chapter, I update
the Monitor Model with additional evidence and argue that it is compatible with
an enactivist approach to cognition. I address several misconceptions related
to the Monitor Model.
","[{'version': 'v1', 'created': 'Tue, 25 Oct 2022 22:15:55 GMT'}, {'version': 'v2', 'created': 'Tue, 7 Feb 2023 23:10:03 GMT'}]",2023-02-09,"[['Carl', 'Michael', '']]"
2308.07891,Yan Tai,"Yan Tai, Weichen Fan, Zhao Zhang, Feng Zhu, Rui Zhao, Ziwei Liu",Link-Context Learning for Multimodal LLMs,"10 pages, 8 figures",,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The ability to learn from context with novel concepts, and deliver
appropriate responses are essential in human conversations. Despite current
Multimodal Large Language Models (MLLMs) and Large Language Models (LLMs) being
trained on mega-scale datasets, recognizing unseen images or understanding
novel concepts in a training-free manner remains a challenge. In-Context
Learning (ICL) explores training-free few-shot learning, where models are
encouraged to ``learn to learn"" from limited tasks and generalize to unseen
tasks. In this work, we propose link-context learning (LCL), which emphasizes
""reasoning from cause and effect"" to augment the learning capabilities of
MLLMs. LCL goes beyond traditional ICL by explicitly strengthening the causal
relationship between the support set and the query set. By providing
demonstrations with causal links, LCL guides the model to discern not only the
analogy but also the underlying causal associations between data points, which
empowers MLLMs to recognize unseen images and understand novel concepts more
effectively. To facilitate the evaluation of this novel approach, we introduce
the ISEKAI dataset, comprising exclusively of unseen generated image-label
pairs designed for link-context learning. Extensive experiments show that our
LCL-MLLM exhibits strong link-context learning capabilities to novel concepts
over vanilla MLLMs. Code and data will be released at
https://github.com/isekai-portal/Link-Context-Learning.
","[{'version': 'v1', 'created': 'Tue, 15 Aug 2023 17:33:24 GMT'}]",2023-08-16,"[['Tai', 'Yan', ''], ['Fan', 'Weichen', ''], ['Zhang', 'Zhao', ''], ['Zhu', 'Feng', ''], ['Zhao', 'Rui', ''], ['Liu', 'Ziwei', '']]"
2311.17351,Yuebing Liang,"Yuebing Liang, Yichao Liu, Xiaohan Wang, Zhan Zhao","Exploring Large Language Models for Human Mobility Prediction under
  Public Events",,,,,cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Public events, such as concerts and sports games, can be major attractors for
large crowds, leading to irregular surges in travel demand. Accurate human
mobility prediction for public events is thus crucial for event planning as
well as traffic or crowd management. While rich textual descriptions about
public events are commonly available from online sources, it is challenging to
encode such information in statistical or machine learning models. Existing
methods are generally limited in incorporating textual information, handling
data sparsity, or providing rationales for their predictions. To address these
challenges, we introduce a framework for human mobility prediction under public
events (LLM-MPE) based on Large Language Models (LLMs), leveraging their
unprecedented ability to process textual data, learn from minimal examples, and
generate human-readable explanations. Specifically, LLM-MPE first transforms
raw, unstructured event descriptions from online sources into a standardized
format, and then segments historical mobility data into regular and
event-related components. A prompting strategy is designed to direct LLMs in
making and rationalizing demand predictions considering historical mobility and
event features. A case study is conducted for Barclays Center in New York City,
based on publicly available event information and taxi trip data. Results show
that LLM-MPE surpasses traditional models, particularly on event days, with
textual data significantly enhancing its accuracy. Furthermore, LLM-MPE offers
interpretable insights into its predictions. Despite the great potential of
LLMs, we also identify key challenges including misinformation and high costs
that remain barriers to their broader adoption in large-scale human mobility
analysis.
","[{'version': 'v1', 'created': 'Wed, 29 Nov 2023 04:25:15 GMT'}]",2023-11-30,"[['Liang', 'Yuebing', ''], ['Liu', 'Yichao', ''], ['Wang', 'Xiaohan', ''], ['Zhao', 'Zhan', '']]"
2311.01876,Jiwei Li,"Xiaofei Sun, Xiaoya Li, Shengyu Zhang, Shuhe Wang, Fei Wu, Jiwei Li,
  Tianwei Zhang, Guoyin Wang",Sentiment Analysis through LLM Negotiations,Pre-print Version,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  A standard paradigm for sentiment analysis is to rely on a singular LLM and
makes the decision in a single round under the framework of in-context
learning. This framework suffers the key disadvantage that the single-turn
output generated by a single LLM might not deliver the perfect decision, just
as humans sometimes need multiple attempts to get things right. This is
especially true for the task of sentiment analysis where deep reasoning is
required to address the complex linguistic phenomenon (e.g., clause
composition, irony, etc) in the input.
  To address this issue, this paper introduces a multi-LLM negotiation
framework for sentiment analysis. The framework consists of a reasoning-infused
generator to provide decision along with rationale, a explanation-deriving
discriminator to evaluate the credibility of the generator. The generator and
the discriminator iterate until a consensus is reached. The proposed framework
naturally addressed the aforementioned challenge, as we are able to take the
complementary abilities of two LLMs, have them use rationale to persuade each
other for correction.
  Experiments on a wide range of sentiment analysis benchmarks (SST-2, Movie
Review, Twitter, yelp, amazon, IMDB) demonstrate the effectiveness of proposed
approach: it consistently yields better performances than the ICL baseline
across all benchmarks, and even superior performances to supervised baselines
on the Twitter and movie review datasets.
","[{'version': 'v1', 'created': 'Fri, 3 Nov 2023 12:35:29 GMT'}]",2023-11-06,"[['Sun', 'Xiaofei', ''], ['Li', 'Xiaoya', ''], ['Zhang', 'Shengyu', ''], ['Wang', 'Shuhe', ''], ['Wu', 'Fei', ''], ['Li', 'Jiwei', ''], ['Zhang', 'Tianwei', ''], ['Wang', 'Guoyin', '']]"
1901.09957,Fanchao Qi,"Fanchao Qi, Chenghao Yang, Zhiyuan Liu, Qiang Dong, Maosong Sun,
  Zhendong Dong",OpenHowNet: An Open Sememe-based Lexical Knowledge Base,"4 pages, 3 figures",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  In this paper, we present an open sememe-based lexical knowledge base
OpenHowNet. Based on well-known HowNet, OpenHowNet comprises three components:
core data which is composed of more than 100 thousand senses annotated with
sememes, OpenHowNet Web which gives a brief introduction to OpenHowNet as well
as provides online exhibition of OpenHowNet information, and OpenHowNet API
which includes several useful APIs such as accessing OpenHowNet core data and
drawing sememe tree structures of senses. In the main text, we first give some
backgrounds including definition of sememe and details of HowNet. And then we
introduce some previous HowNet and sememe-based research works. Last but not
least, we detail the constituents of OpenHowNet and their basic features and
functionalities. Additionally, we briefly make a summary and list some future
works.
","[{'version': 'v1', 'created': 'Mon, 28 Jan 2019 19:35:17 GMT'}]",2019-01-30,"[['Qi', 'Fanchao', ''], ['Yang', 'Chenghao', ''], ['Liu', 'Zhiyuan', ''], ['Dong', 'Qiang', ''], ['Sun', 'Maosong', ''], ['Dong', 'Zhendong', '']]"
1310.1249,Andrzej Jarynowski,"Andrzej Jarynowski, Amir Rostami",Reading Stockholm Riots 2013 in social media by text-mining,5p,,,,cs.SI cs.CL physics.soc-ph stat.AP,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The riots in Stockholm in May 2013 were an event that reverberated in the
world media for its dimension of violence that had spread through the Swedish
capital. In this study we have investigated the role of social media in
creating media phenomena via text mining and natural language processing. We
have focused on two channels of communication for our analysis: Twitter and
Poloniainfo.se (Forum of Polish community in Sweden). Our preliminary results
show some hot topics driving discussion related mostly to Swedish Police and
Swedish Politics by counting word usage. Typical features for media
intervention are presented. We have built networks of most popular phrases,
clustered by categories (geography, media institution, etc.). Sentiment
analysis shows negative connotation with Police. The aim of this preliminary
exploratory quantitative study was to generate questions and hypotheses, which
we could carefully follow by deeper more qualitative methods.
","[{'version': 'v1', 'created': 'Fri, 4 Oct 2013 13:04:45 GMT'}]",2013-10-07,"[['Jarynowski', 'Andrzej', ''], ['Rostami', 'Amir', '']]"
2205.11463,Tatsuki Kuribayashi,"Tatsuki Kuribayashi, Yohei Oseki, Ana Brassard, Kentaro Inui",Context Limitations Make Neural Language Models More Human-Like,Accepted by EMNLP2022 (main long),,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Language models (LMs) have been used in cognitive modeling as well as
engineering studies -- they compute information-theoretic complexity metrics
that simulate humans' cognitive load during reading. This study highlights a
limitation of modern neural LMs as the model of choice for this purpose: there
is a discrepancy between their context access capacities and that of humans.
Our results showed that constraining the LMs' context access improved their
simulation of human reading behavior. We also showed that LM-human gaps in
context access were associated with specific syntactic constructions;
incorporating syntactic biases into LMs' context access might enhance their
cognitive plausibility.
","[{'version': 'v1', 'created': 'Mon, 23 May 2022 17:01:13 GMT'}, {'version': 'v2', 'created': 'Tue, 1 Nov 2022 07:10:26 GMT'}]",2022-11-02,"[['Kuribayashi', 'Tatsuki', ''], ['Oseki', 'Yohei', ''], ['Brassard', 'Ana', ''], ['Inui', 'Kentaro', '']]"
2104.04670,Ruiqi Zhong,"Ruiqi Zhong, Kristy Lee, Zheng Zhang, Dan Klein","Adapting Language Models for Zero-shot Learning by Meta-tuning on
  Dataset and Prompt Collections","EMNLP 2021, Findings",,,,cs.CL cs.AI,http://creativecommons.org/publicdomain/zero/1.0/,"  Large pre-trained language models (LMs) such as GPT-3 have acquired a
surprising ability to perform zero-shot learning. For example, to classify
sentiment without any training examples, we can ""prompt"" the LM with the review
and the label description ""Does the user like this movie?"", and ask whether the
next word is ""yes"" or ""no"". However, the next word prediction training
objective is still misaligned with the target zero-shot learning objective. To
address this weakness, we propose meta-tuning, which directly optimizes the
zero-shot learning objective by fine-tuning pre-trained language models on a
collection of datasets. We focus on classification tasks, and construct the
meta-dataset by aggregating 43 existing datasets and annotating 441 label
descriptions in a question-answering (QA) format. When evaluated on unseen
tasks, meta-tuned models outperform a same-sized QA model and the previous SOTA
zero-shot learning system based on natural language inference. Additionally,
increasing parameter count from 220M to 770M improves AUC-ROC scores by 6.3%,
and we forecast that even larger models would perform better. Therefore,
measuring zero-shot learning performance on language models out-of-the-box
might underestimate their true potential, and community-wide efforts on
aggregating datasets and unifying their formats can help build models that
answer prompts better.
","[{'version': 'v1', 'created': 'Sat, 10 Apr 2021 02:57:22 GMT'}, {'version': 'v2', 'created': 'Sat, 17 Apr 2021 03:43:15 GMT'}, {'version': 'v3', 'created': 'Thu, 26 Aug 2021 15:27:20 GMT'}, {'version': 'v4', 'created': 'Fri, 3 Sep 2021 15:28:50 GMT'}, {'version': 'v5', 'created': 'Wed, 8 Sep 2021 16:29:59 GMT'}]",2021-09-09,"[['Zhong', 'Ruiqi', ''], ['Lee', 'Kristy', ''], ['Zhang', 'Zheng', ''], ['Klein', 'Dan', '']]"
1905.02430,Iva Gornishka,"Iva Gornishka, Stevan Rudinac, Marcel Worring","Interactive Search and Exploration in Online Discussion Forums Using
  Multimodal Embeddings",,,,,cs.IR cs.CL cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper we present a novel interactive multimodal learning system,
which facilitates search and exploration in large networks of social multimedia
users. It allows the analyst to identify and select users of interest, and to
find similar users in an interactive learning setting. Our approach is based on
novel multimodal representations of users, words and concepts, which we
simultaneously learn by deploying a general-purpose neural embedding model. We
show these representations to be useful not only for categorizing users, but
also for automatically generating user and community profiles. Inspired by
traditional summarization approaches, we create the profiles by selecting
diverse and representative content from all available modalities, i.e. the
text, image and user modality. The usefulness of the approach is evaluated
using artificial actors, which simulate user behavior in a relevance feedback
scenario. Multiple experiments were conducted in order to evaluate the quality
of our multimodal representations, to compare different embedding strategies,
and to determine the importance of different modalities. We demonstrate the
capabilities of the proposed approach on two different multimedia collections
originating from the violent online extremism forum Stormfront and the
microblogging platform Twitter, which are particularly interesting due to the
high semantic level of the discussions they feature.
","[{'version': 'v1', 'created': 'Tue, 7 May 2019 09:23:12 GMT'}]",2019-05-08,"[['Gornishka', 'Iva', ''], ['Rudinac', 'Stevan', ''], ['Worring', 'Marcel', '']]"
2010.01556,Qianying Liu,"Qianying Liu, Wenyu Guan, Sujian Li, Fei Cheng, Daisuke Kawahara and
  Sadao Kurohashi",Reverse Operation based Data Augmentation for Solving Math Word Problems,"11 pages. Accepted by IEEE Transactions on Audio, Speech and Language
  Processing",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatically solving math word problems is a critical task in the field of
natural language processing. Recent models have reached their performance
bottleneck and require more high-quality data for training. We propose a novel
data augmentation method that reverses the mathematical logic of math word
problems to produce new high-quality math problems and introduce new knowledge
points that can benefit learning the mathematical reasoning logic. We apply the
augmented data on two SOTA math word problem solving models and compare our
results with a strong data augmentation baseline. Experimental results show the
effectiveness of our approach. We release our code and data at
https://github.com/yiyunya/RODA.
","[{'version': 'v1', 'created': 'Sun, 4 Oct 2020 11:59:59 GMT'}, {'version': 'v2', 'created': 'Wed, 10 Nov 2021 16:12:16 GMT'}]",2021-11-11,"[['Liu', 'Qianying', ''], ['Guan', 'Wenyu', ''], ['Li', 'Sujian', ''], ['Cheng', 'Fei', ''], ['Kawahara', 'Daisuke', ''], ['Kurohashi', 'Sadao', '']]"
2106.14619,Fuqi Song,Fuqi Song,Classification of Contract-Amendment Relationships,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  In Contract Life-cycle Management (CLM), managing and tracking the master
agreements and their associated amendments is essential, in order to be kept
informed with different due dates and obligations. An automatic solution can
facilitate the daily jobs and improve the efficiency of legal practitioners. In
this paper, we propose an approach based on machine learning (ML) and Natural
Language Processing (NLP) to detect the amendment relationship between two
documents. The algorithm takes two PDF documents preprocessed by OCR (Optical
Character Recognition) and NER (Named Entity Recognition) as input, and then it
builds the features of each document pair and classifies the relationship. We
experimented with different configurations on a dataset consisting of 1124
pairs of contract-amendment documents in English and French. The best result
obtained a F1-score of 91%, which outperformed 23% compared to a
heuristic-based baseline.
","[{'version': 'v1', 'created': 'Tue, 8 Jun 2021 07:57:10 GMT'}]",2021-06-29,"[['Song', 'Fuqi', '']]"
1212.3023,Mahyuddin K. M.  Nasution,"Mahyuddin K. M. Nasution, Shahrul Azman Mohd Noah",Keyword Extraction for Identifying Social Actors,"7 pages, nothing, draft to ICOCSIM 2012",,,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Identifying the social actor has become one of tasks in Artificial
Intelligence, whereby extracting keyword from Web snippets depend on the use of
web is steadily gaining ground in this research. We develop therefore an
approach based on overlap principle for utilizing a collection of features in
web snippets, where use of keyword will eliminate the un-relevant web pages.
","[{'version': 'v1', 'created': 'Thu, 13 Dec 2012 00:34:23 GMT'}]",2012-12-14,"[['Nasution', 'Mahyuddin K. M.', ''], ['Noah', 'Shahrul Azman Mohd', '']]"
2307.16457,Huachuan Qiu,"Huachuan Qiu, Tong Zhao, Anqi Li, Shuai Zhang, Hongliang He, Zhenzhong
  Lan",A Benchmark for Understanding Dialogue Safety in Mental Health Support,"accepted to The 12th CCF International Conference on Natural Language
  Processing and Chinese Computing (NLPCC2023)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Dialogue safety remains a pervasive challenge in open-domain human-machine
interaction. Existing approaches propose distinctive dialogue safety taxonomies
and datasets for detecting explicitly harmful responses. However, these
taxonomies may not be suitable for analyzing response safety in mental health
support. In real-world interactions, a model response deemed acceptable in
casual conversations might have a negligible positive impact on users seeking
mental health support. To address these limitations, this paper aims to develop
a theoretically and factually grounded taxonomy that prioritizes the positive
impact on help-seekers. Additionally, we create a benchmark corpus with
fine-grained labels for each dialogue session to facilitate further research.
We analyze the dataset using popular language models, including BERT-base,
RoBERTa-large, and ChatGPT, to detect and understand unsafe responses within
the context of mental health support. Our study reveals that ChatGPT struggles
to detect safety categories with detailed safety definitions in a zero- and
few-shot paradigm, whereas the fine-tuned model proves to be more suitable. The
developed dataset and findings serve as valuable benchmarks for advancing
research on dialogue safety in mental health support, with significant
implications for improving the design and deployment of conversation agents in
real-world applications. We release our code and data here:
https://github.com/qiuhuachuan/DialogueSafety.
","[{'version': 'v1', 'created': 'Mon, 31 Jul 2023 07:33:16 GMT'}]",2023-08-01,"[['Qiu', 'Huachuan', ''], ['Zhao', 'Tong', ''], ['Li', 'Anqi', ''], ['Zhang', 'Shuai', ''], ['He', 'Hongliang', ''], ['Lan', 'Zhenzhong', '']]"
2210.14011,Nitish Joshi,"Nitish Joshi, Xiang Pan, He He","Are All Spurious Features in Natural Language Alike? An Analysis through
  a Causal Lens",EMNLP 2022,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The term `spurious correlations' has been used in NLP to informally denote
any undesirable feature-label correlations. However, a correlation can be
undesirable because (i) the feature is irrelevant to the label (e.g.
punctuation in a review), or (ii) the feature's effect on the label depends on
the context (e.g. negation words in a review), which is ubiquitous in language
tasks. In case (i), we want the model to be invariant to the feature, which is
neither necessary nor sufficient for prediction. But in case (ii), even an
ideal model (e.g. humans) must rely on the feature, since it is necessary (but
not sufficient) for prediction. Therefore, a more fine-grained treatment of
spurious features is needed to specify the desired model behavior. We formalize
this distinction using a causal model and probabilities of necessity and
sufficiency, which delineates the causal relations between a feature and a
label. We then show that this distinction helps explain results of existing
debiasing methods on different spurious features, and demystifies surprising
results such as the encoding of spurious features in model representations
after debiasing.
","[{'version': 'v1', 'created': 'Tue, 25 Oct 2022 13:31:28 GMT'}]",2022-10-26,"[['Joshi', 'Nitish', ''], ['Pan', 'Xiang', ''], ['He', 'He', '']]"
2005.09406,Sebastian Garcia-Valencia,Sebastian Garcia-Valencia,Embeddings as representation for symbolic music,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  A representation technique that allows encoding music in a way that contains
musical meaning would improve the results of any model trained for computer
music tasks like generation of melodies and harmonies of better quality. The
field of natural language processing has done a lot of work in finding a way to
capture the semantic meaning of words and sentences, and word embeddings have
successfully shown the capabilities for such a task. In this paper, we
experiment with embeddings to represent musical notes from 3 different
variations of a dataset and analyze if the model can capture useful musical
patterns. To do this, the resulting embeddings are visualized in projections
using the t-SNE technique.
","[{'version': 'v1', 'created': 'Tue, 19 May 2020 13:04:02 GMT'}]",2020-05-20,"[['Garcia-Valencia', 'Sebastian', '']]"
2311.11855,Xiao Yang,"Yu Tian, Xiao Yang, Jingyuan Zhang, Yinpeng Dong, Hang Su",Evil Geniuses: Delving into the Safety of LLM-based Agents,11 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Rapid advancements in large language models (LLMs) have revitalized in
LLM-based agents, exhibiting impressive human-like behaviors and cooperative
capabilities in various scenarios. However, these agents also bring some
exclusive risks, stemming from the complexity of interaction environments and
the usability of tools. This paper delves into the safety of LLM-based agents
from three perspectives: agent quantity, role definition, and attack level.
Specifically, we initially propose to employ a template-based attack strategy
on LLM-based agents to find the influence of agent quantity. In addition, to
address interaction environment and role specificity issues, we introduce Evil
Geniuses (EG), an effective attack method that autonomously generates prompts
related to the original role to examine the impact across various role
definitions and attack levels. EG leverages Red-Blue exercises, significantly
improving the generated prompt aggressiveness and similarity to original roles.
Our evaluations on CAMEL, Metagpt and ChatDev based on GPT-3.5 and GPT-4,
demonstrate high success rates. Extensive evaluation and discussion reveal that
these agents are less robust, prone to more harmful behaviors, and capable of
generating stealthier content than LLMs, highlighting significant safety
challenges and guiding future research. Our code is available at
https://github.com/T1aNS1R/Evil-Geniuses.
","[{'version': 'v1', 'created': 'Mon, 20 Nov 2023 15:50:09 GMT'}, {'version': 'v2', 'created': 'Fri, 2 Feb 2024 08:28:01 GMT'}]",2024-02-05,"[['Tian', 'Yu', ''], ['Yang', 'Xiao', ''], ['Zhang', 'Jingyuan', ''], ['Dong', 'Yinpeng', ''], ['Su', 'Hang', '']]"
2301.13688,Albert Webson,"Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay,
  Denny Zhou, Quoc V. Le, Barret Zoph, Jason Wei, Adam Roberts","The Flan Collection: Designing Data and Methods for Effective
  Instruction Tuning",,,,,cs.AI cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We study the design decisions of publicly available instruction tuning
methods, and break down the development of Flan 2022 (Chung et al., 2022).
Through careful ablation studies on the Flan Collection of tasks and methods,
we tease apart the effect of design decisions which enable Flan-T5 to
outperform prior work by 3-17%+ across evaluation settings. We find task
balancing and enrichment techniques are overlooked but critical to effective
instruction tuning, and in particular, training with mixed prompt settings
(zero-shot, few-shot, and chain-of-thought) actually yields stronger (2%+)
performance in all settings. In further experiments, we show Flan-T5 requires
less finetuning to converge higher and faster than T5 on single downstream
tasks, motivating instruction-tuned models as more computationally-efficient
starting checkpoints for new tasks. Finally, to accelerate research on
instruction tuning, we make the Flan 2022 collection of datasets, templates,
and methods publicly available at
https://github.com/google-research/FLAN/tree/main/flan/v2.
","[{'version': 'v1', 'created': 'Tue, 31 Jan 2023 15:03:44 GMT'}, {'version': 'v2', 'created': 'Tue, 14 Feb 2023 16:33:33 GMT'}]",2023-02-15,"[['Longpre', 'Shayne', ''], ['Hou', 'Le', ''], ['Vu', 'Tu', ''], ['Webson', 'Albert', ''], ['Chung', 'Hyung Won', ''], ['Tay', 'Yi', ''], ['Zhou', 'Denny', ''], ['Le', 'Quoc V.', ''], ['Zoph', 'Barret', ''], ['Wei', 'Jason', ''], ['Roberts', 'Adam', '']]"
1712.02186,Hu Xu,"Hu Xu, Sihong Xie, Lei Shu, Philip S. Yu",Product Function Need Recognition via Semi-supervised Attention Network,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Functionality is of utmost importance to customers when they purchase
products. However, it is unclear to customers whether a product can really
satisfy their needs on functions. Further, missing functions may be
intentionally hidden by the manufacturers or the sellers. As a result, a
customer needs to spend a fair amount of time before purchasing or just
purchase the product on his/her own risk. In this paper, we first identify a
novel QA corpus that is dense on product functionality information
\footnote{The annotated corpus can be found at
\url{https://www.cs.uic.edu/~hxu/}.}. We then design a neural network called
Semi-supervised Attention Network (SAN) to discover product functions from
questions. This model leverages unlabeled data as contextual information to
perform semi-supervised sequence labeling. We conduct experiments to show that
the extracted function have both high coverage and accuracy, compared with a
wide spectrum of baselines.
","[{'version': 'v1', 'created': 'Wed, 6 Dec 2017 13:48:57 GMT'}]",2017-12-07,"[['Xu', 'Hu', ''], ['Xie', 'Sihong', ''], ['Shu', 'Lei', ''], ['Yu', 'Philip S.', '']]"
2310.18073,Xinyu Wang,"Xinyu Wang, Lin Gui, Yulan He","A Scalable Framework for Table of Contents Extraction from Complex ESG
  Annual Reports",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Table of contents (ToC) extraction centres on structuring documents in a
hierarchical manner. In this paper, we propose a new dataset, ESGDoc,
comprising 1,093 ESG annual reports from 563 companies spanning from 2001 to
2022. These reports pose significant challenges due to their diverse structures
and extensive length. To address these challenges, we propose a new framework
for Toc extraction, consisting of three steps: (1) Constructing an initial tree
of text blocks based on reading order and font sizes; (2) Modelling each tree
node (or text block) independently by considering its contextual information
captured in node-centric subtree; (3) Modifying the original tree by taking
appropriate action on each tree node (Keep, Delete, or Move). This
construction-modelling-modification (CMM) process offers several benefits. It
eliminates the need for pairwise modelling of section headings as in previous
approaches, making document segmentation practically feasible. By incorporating
structured information, each section heading can leverage both local and
long-distance context relevant to itself. Experimental results show that our
approach outperforms the previous state-of-the-art baseline with a fraction of
running time. Our framework proves its scalability by effectively handling
documents of any length.
","[{'version': 'v1', 'created': 'Fri, 27 Oct 2023 11:40:32 GMT'}]",2023-10-30,"[['Wang', 'Xinyu', ''], ['Gui', 'Lin', ''], ['He', 'Yulan', '']]"
2212.07914,Zheyuan Zhang,"Chris Sanchez, Zheyuan Zhang",The Effects of In-domain Corpus Size on pre-training BERT,6 pages,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Many prior language modeling efforts have shown that pre-training on an
in-domain corpus can significantly improve performance on downstream
domain-specific NLP tasks. However, the difficulties associated with collecting
enough in-domain data might discourage researchers from approaching this
pre-training task. In this paper, we conducted a series of experiments by
pre-training Bidirectional Encoder Representations from Transformers (BERT)
with different sizes of biomedical corpora. The results demonstrate that
pre-training on a relatively small amount of in-domain data (4GB) with limited
training steps, can lead to better performance on downstream domain-specific
NLP tasks compared with fine-tuning models pre-trained on general corpora.
","[{'version': 'v1', 'created': 'Thu, 15 Dec 2022 15:49:27 GMT'}]",2022-12-16,"[['Sanchez', 'Chris', ''], ['Zhang', 'Zheyuan', '']]"
2106.12566,Shengjie Luo,"Shengjie Luo, Shanda Li, Tianle Cai, Di He, Dinglan Peng, Shuxin
  Zheng, Guolin Ke, Liwei Wang, Tie-Yan Liu","Stable, Fast and Accurate: Kernelized Attention with Relative Positional
  Encoding","NeurIPS 2021, camera ready version",,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The attention module, which is a crucial component in Transformer, cannot
scale efficiently to long sequences due to its quadratic complexity. Many works
focus on approximating the dot-then-exponentiate softmax function in the
original attention, leading to sub-quadratic or even linear-complexity
Transformer architectures. However, we show that these methods cannot be
applied to more powerful attention modules that go beyond the
dot-then-exponentiate style, e.g., Transformers with relative positional
encoding (RPE). Since in many state-of-the-art models, relative positional
encoding is used as default, designing efficient Transformers that can
incorporate RPE is appealing. In this paper, we propose a novel way to
accelerate attention calculation for Transformers with RPE on top of the
kernelized attention. Based upon the observation that relative positional
encoding forms a Toeplitz matrix, we mathematically show that kernelized
attention with RPE can be calculated efficiently using Fast Fourier Transform
(FFT). With FFT, our method achieves $\mathcal{O}(n\log n)$ time complexity.
Interestingly, we further demonstrate that properly using relative positional
encoding can mitigate the training instability problem of vanilla kernelized
attention. On a wide range of tasks, we empirically show that our models can be
trained from scratch without any optimization issues. The learned model
performs better than many efficient Transformer variants and is faster than
standard Transformer in the long-sequence regime.
","[{'version': 'v1', 'created': 'Wed, 23 Jun 2021 17:51:26 GMT'}, {'version': 'v2', 'created': 'Wed, 3 Nov 2021 03:55:01 GMT'}]",2021-11-04,"[['Luo', 'Shengjie', ''], ['Li', 'Shanda', ''], ['Cai', 'Tianle', ''], ['He', 'Di', ''], ['Peng', 'Dinglan', ''], ['Zheng', 'Shuxin', ''], ['Ke', 'Guolin', ''], ['Wang', 'Liwei', ''], ['Liu', 'Tie-Yan', '']]"
1511.02669,Adrian Groza,Adrian Groza and Roxana Szabo,"Enacting textual entailment and ontologies for automated essay grading
  in chemical domain","16th Int. Symposium on Computational Intelligence and Informatics
  (CINTI2015), Budapest, Hungary, 19-21 November, 2015",,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a system for automated essay grading using ontologies and textual
entailment. The process of textual entailment is guided by hypotheses, which
are extracted from a domain ontology. Textual entailment checks if the truth of
the hypothesis follows from a given text. We enact textual entailment to
compare students answer to a model answer obtained from ontology. We validated
the solution against various essays written by students in the chemistry
domain.
","[{'version': 'v1', 'created': 'Mon, 9 Nov 2015 13:21:02 GMT'}]",2015-11-10,"[['Groza', 'Adrian', ''], ['Szabo', 'Roxana', '']]"
2403.03521,Carinne Cherf,"Carinne Cherf, Yuval Pinter","BiVert: Bidirectional Vocabulary Evaluation using Relations for Machine
  Translation",LREC-COLING 2024,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Neural machine translation (NMT) has progressed rapidly in the past few
years, promising improvements and quality translations for different languages.
Evaluation of this task is crucial to determine the quality of the translation.
Overall, insufficient emphasis is placed on the actual sense of the translation
in traditional methods. We propose a bidirectional semantic-based evaluation
method designed to assess the sense distance of the translation from the source
text. This approach employs the comprehensive multilingual encyclopedic
dictionary BabelNet. Through the calculation of the semantic distance between
the source and its back translation of the output, our method introduces a
quantifiable approach that empowers sentence comparison on the same linguistic
level. Factual analysis shows a strong correlation between the average
evaluation scores generated by our method and the human assessments across
various machine translation systems for English-German language pair. Finally,
our method proposes a new multilingual approach to rank MT systems without the
need for parallel corpora.
","[{'version': 'v1', 'created': 'Wed, 6 Mar 2024 08:02:21 GMT'}]",2024-03-07,"[['Cherf', 'Carinne', ''], ['Pinter', 'Yuval', '']]"
2312.01954,Andrea Papaluca,"Andrea Papaluca, Daniel Krefl, Sergio Mendez Rodriguez, Artem Lensky,
  Hanna Suominen","Zero- and Few-Shots Knowledge Graph Triplet Extraction with Large
  Language Models",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In this work, we tested the Triplet Extraction (TE) capabilities of a variety
of Large Language Models (LLMs) of different sizes in the Zero- and Few-Shots
settings. In detail, we proposed a pipeline that dynamically gathers contextual
information from a Knowledge Base (KB), both in the form of context triplets
and of (sentence, triplets) pairs as examples, and provides it to the LLM
through a prompt. The additional context allowed the LLMs to be competitive
with all the older fully trained baselines based on the Bidirectional Long
Short-Term Memory (BiLSTM) Network architecture. We further conducted a
detailed analysis of the quality of the gathered KB context, finding it to be
strongly correlated with the final TE performance of the model. In contrast,
the size of the model appeared to only logarithmically improve the TE
capabilities of the LLMs.
","[{'version': 'v1', 'created': 'Mon, 4 Dec 2023 15:12:04 GMT'}]",2023-12-05,"[['Papaluca', 'Andrea', ''], ['Krefl', 'Daniel', ''], ['Rodriguez', 'Sergio Mendez', ''], ['Lensky', 'Artem', ''], ['Suominen', 'Hanna', '']]"
1612.07215,Tengfei Ma,"Tengfei Ma, Tetsuya Nasukawa","Inverted Bilingual Topic Models for Lexicon Extraction from Non-parallel
  Data",To appear in IJCAI 2017,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Topic models have been successfully applied in lexicon extraction. However,
most previous methods are limited to document-aligned data. In this paper, we
try to address two challenges of applying topic models to lexicon extraction in
non-parallel data: 1) hard to model the word relationship and 2) noisy seed
dictionary. To solve these two challenges, we propose two new bilingual topic
models to better capture the semantic information of each word while
discriminating the multiple translations in a noisy seed dictionary. We extend
the scope of topic models by inverting the roles of ""word"" and ""document"". In
addition, to solve the problem of noise in seed dictionary, we incorporate the
probability of translation selection in our models. Moreover, we also propose
an effective measure to evaluate the similarity of words in different languages
and select the optimal translation pairs. Experimental results using real world
data demonstrate the utility and efficacy of the proposed models.
","[{'version': 'v1', 'created': 'Wed, 21 Dec 2016 16:12:45 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Jun 2017 01:14:04 GMT'}]",2017-06-22,"[['Ma', 'Tengfei', ''], ['Nasukawa', 'Tetsuya', '']]"
1610.08557,Ramakanth Kavuluru,"A.K.M. Sabbir, Antonio Jimeno Yepes, and Ramakanth Kavuluru","Knowledge-Based Biomedical Word Sense Disambiguation with Neural Concept
  Embeddings","8 pages, accepted to appear in proceedings of IEEE BIBE 2017",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Biomedical word sense disambiguation (WSD) is an important intermediate task
in many natural language processing applications such as named entity
recognition, syntactic parsing, and relation extraction. In this paper, we
employ knowledge-based approaches that also exploit recent advances in neural
word/concept embeddings to improve over the state-of-the-art in biomedical WSD
using the MSH WSD dataset as the test set. Our methods involve weak supervision
- we do not use any hand-labeled examples for WSD to build our prediction
models; however, we employ an existing well known named entity recognition and
concept mapping program, MetaMap, to obtain our concept vectors. Over the MSH
WSD dataset, our linear time (in terms of numbers of senses and words in the
test instance) method achieves an accuracy of 92.24% which is an absolute 3%
improvement over the best known results obtained via unsupervised or
knowledge-based means. A more expensive approach that we developed relies on a
nearest neighbor framework and achieves an accuracy of 94.34%. Employing dense
vector representations learned from unlabeled free text has been shown to
benefit many language processing tasks recently and our efforts show that
biomedical WSD is no exception to this trend. For a complex and rapidly
evolving domain such as biomedicine, building labeled datasets for larger sets
of ambiguous terms may be impractical. Here, we show that weak supervision that
leverages recent advances in representation learning can rival supervised
approaches in biomedical WSD. However, external knowledge bases (here sense
inventories) play a key role in the improvements achieved.
","[{'version': 'v1', 'created': 'Wed, 26 Oct 2016 21:49:15 GMT'}, {'version': 'v2', 'created': 'Sun, 4 Dec 2016 00:57:16 GMT'}, {'version': 'v3', 'created': 'Mon, 27 Feb 2017 20:38:45 GMT'}, {'version': 'v4', 'created': 'Wed, 28 Jun 2017 02:13:13 GMT'}, {'version': 'v5', 'created': 'Sat, 30 Sep 2017 01:01:50 GMT'}]",2017-10-03,"[['Sabbir', 'A. K. M.', ''], ['Yepes', 'Antonio Jimeno', ''], ['Kavuluru', 'Ramakanth', '']]"
2204.06328,Ji Won Yoon,"Ji Won Yoon, Beom Jun Woo, and Nam Soo Kim",HuBERT-EE: Early Exiting HuBERT for Efficient Speech Recognition,Submitted to INTERSPEECH 2022,,,,cs.CL cs.SD eess.AS,http://creativecommons.org/licenses/by-sa/4.0/,"  Pre-training with self-supervised models, such as Hidden-unit BERT (HuBERT)
and wav2vec 2.0, has brought significant improvements in automatic speech
recognition (ASR). However, these models usually require an expensive
computational cost to achieve outstanding performance, slowing down the
inference speed. To improve the model efficiency, we propose an early exit
scheme for ASR, namely HuBERT-EE, that allows the model to stop the inference
dynamically. In HuBERT-EE, multiple early exit branches are added at the
intermediate layers, and each branch is used to decide whether a prediction can
be exited early. Experimental results on the LibriSpeech dataset show that
HuBERT-EE can accelerate the inference of a large-scale HuBERT model while
simultaneously balancing the trade-off between the word error rate (WER)
performance and the latency.
","[{'version': 'v1', 'created': 'Wed, 13 Apr 2022 12:11:44 GMT'}]",2022-04-14,"[['Yoon', 'Ji Won', ''], ['Woo', 'Beom Jun', ''], ['Kim', 'Nam Soo', '']]"
2102.00924,Yida Xin,"Yida Xin, Henry Lieberman and Peter Chin","Revisiting the Prepositional-Phrase Attachment Problem Using Explicit
  Commonsense Knowledge",,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  We revisit the challenging problem of resolving prepositional-phrase (PP)
attachment ambiguity. To date, proposed solutions are either rule-based, where
explicit grammar rules direct how to resolve ambiguities; or statistical, where
the decision is learned from a corpus of labeled examples. We argue that
explicit commonsense knowledge bases can provide an essential ingredient for
making good attachment decisions. We implemented a module, named Patch-Comm,
that can be used by a variety of conventional parsers, to make attachment
decisions. Where the commonsense KB does not provide direct answers, we fall
back on a more general system that infers ""out-of-knowledge-base"" assertions in
a manner similar to the way some NLP systems handle out-of-vocabulary words.
Our results suggest that the commonsense knowledge-based approach can provide
the best of both worlds, integrating rule-based and statistical techniques. As
the field is increasingly coming to recognize the importance of explainability
in AI, a commonsense approach can enable NLP developers to better understand
the behavior of systems, and facilitate natural dialogues with end users.
","[{'version': 'v1', 'created': 'Mon, 1 Feb 2021 15:48:36 GMT'}, {'version': 'v2', 'created': 'Fri, 5 Feb 2021 17:51:30 GMT'}]",2021-02-08,"[['Xin', 'Yida', ''], ['Lieberman', 'Henry', ''], ['Chin', 'Peter', '']]"
1907.02606,Saeedeh Shekarpour,Saeedeh Shekarpour and Faisal Alshargi,"A Road-map Towards Explainable Question Answering A Solution for
  Information Pollution",,,,,cs.IR cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The increasing rate of information pollution on the Web requires novel
solutions to tackle that. Question Answering (QA) interfaces are simplified and
user-friendly interfaces to access information on the Web. However, similar to
other AI applications, they are black boxes which do not manifest the details
of the learning or reasoning steps for augmenting an answer. The Explainable
Question Answering (XQA) system can alleviate the pain of information pollution
where it provides transparency to the underlying computational model and
exposes an interface enabling the end-user to access and validate provenance,
validity, context, circulation, interpretation, and feedbacks of information.
This position paper sheds light on the core concepts, expectations, and
challenges in favor of the following questions (i) What is an XQA system?, (ii)
Why do we need XQA?, (iii) When do we need XQA? (iv) How to represent the
explanations? (iv) How to evaluate XQA systems?
","[{'version': 'v1', 'created': 'Thu, 4 Jul 2019 21:42:29 GMT'}]",2019-07-08,"[['Shekarpour', 'Saeedeh', ''], ['Alshargi', 'Faisal', '']]"
cmp-lg/9807012,Kim Binsted,Kim Binsted (Sony Computer Science Laboratory),Character design for soccer commmentary,"uuencoded gzipped tar file. Latex. Uses psfig, times, llncs",,,,cmp-lg cs.CL,,"  In this paper we present early work on an animated talking head commentary
system called {\bf Byrne}\footnote{David Byrne is the lead singer of the
Talking Heads.}. The goal of this project is to develop a system which can take
the output from the RoboCup soccer simulator, and generate appropriate
affective speech and facial expressions, based on the character's personality,
emotional state, and the state of play. Here we describe a system which takes
pre-analysed simulator output as input, and which generates text marked-up for
use by a speech generator and a face animation system. We make heavy use of
inter-system standards, so that future versions of Byrne will be able to take
advantage of advances in the technologies that it incorporates.
","[{'version': 'v1', 'created': 'Fri, 31 Jul 1998 06:50:56 GMT'}]",2009-09-25,"[['Binsted', 'Kim', '', 'Sony Computer Science Laboratory']]"
2101.05225,Rohan Alexander,Ke-Li Chiu and Rohan Alexander,On consistency scores in text data with an implementation in R,"13 pages, 0 figures",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we introduce a reproducible cleaning process for the text
extracted from PDFs using n-gram models. Our approach compares the originally
extracted text with the text generated from, or expected by, these models using
earlier text as stimulus. To guide this process, we introduce the notion of a
consistency score, which refers to the proportion of text that is expected by
the model. This is used to monitor changes during the cleaning process, and
across different corpuses. We illustrate our process on text from the book Jane
Eyre and introduce both a Shiny application and an R package to make our
process easier for others to adopt.
","[{'version': 'v1', 'created': 'Wed, 13 Jan 2021 17:37:07 GMT'}]",2021-01-14,"[['Chiu', 'Ke-Li', ''], ['Alexander', 'Rohan', '']]"
1811.06179,Yuan Luo,"Yuan Luo, Peter Szolovits","Implementing a Portable Clinical NLP System with a Common Data Model - a
  Lisp Perspective","6 pages, accepted by IEEE BIBM 2018 as regular paper",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents a Lisp architecture for a portable NLP system, termed
LAPNLP, for processing clinical notes. LAPNLP integrates multiple standard,
customized and in-house developed NLP tools. Our system facilitates portability
across different institutions and data systems by incorporating an enriched
Common Data Model (CDM) to standardize necessary data elements. It utilizes
UMLS to perform domain adaptation when integrating generic domain NLP tools. It
also features stand-off annotations that are specified by positional reference
to the original document. We built an interval tree based search engine to
efficiently query and retrieve the stand-off annotations by specifying
positional requirements. We also developed a utility to convert an inline
annotation format to stand-off annotations to enable the reuse of clinical text
datasets with inline annotations. We experimented with our system on several
NLP facilitated tasks including computational phenotyping for lymphoma patients
and semantic relation extraction for clinical notes. These experiments
showcased the broader applicability and utility of LAPNLP.
","[{'version': 'v1', 'created': 'Thu, 15 Nov 2018 04:58:21 GMT'}]",2018-11-16,"[['Luo', 'Yuan', ''], ['Szolovits', 'Peter', '']]"
cs/0408027,Henning Christiansen,Henning Christiansen,CHR Grammars,"36 pp. To appear in TPLP, 2005",,,,cs.CL cs.PL,,"  A grammar formalism based upon CHR is proposed analogously to the way
Definite Clause Grammars are defined and implemented on top of Prolog. These
grammars execute as robust bottom-up parsers with an inherent treatment of
ambiguity and a high flexibility to model various linguistic phenomena. The
formalism extends previous logic programming based grammars with a form of
context-sensitive rules and the possibility to include extra-grammatical
hypotheses in both head and body of grammar rules. Among the applications are
straightforward implementations of Assumption Grammars and abduction under
integrity constraints for language analysis. CHR grammars appear as a powerful
tool for specification and implementation of language processors and may be
proposed as a new standard for bottom-up grammars in logic programming.
  To appear in Theory and Practice of Logic Programming (TPLP), 2005
","[{'version': 'v1', 'created': 'Thu, 12 Aug 2004 11:15:17 GMT'}]",2007-05-23,"[['Christiansen', 'Henning', '']]"
2304.01242,Maolin Luo,"Maolin Luo, and Xiang Zhang","Enhancing Clinical Evidence Recommendation with Multi-Channel
  Heterogeneous Learning on Evidence Graphs",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Clinical evidence encompasses the associations and impacts between patients,
interventions (such as drugs or physiotherapy), problems, and outcomes. The
goal of recommending clinical evidence is to provide medical practitioners with
relevant information to support their decision-making processes and to generate
new evidence. Our specific task focuses on recommending evidence based on
clinical problems. However, the direct connections between certain clinical
problems and related evidence are often sparse, creating a challenge of link
sparsity. Additionally, to recommend appropriate evidence, it is essential to
jointly exploit both topological relationships among evidence and textual
information describing them. To address these challenges, we define two
knowledge graphs: an Evidence Co-reference Graph and an Evidence Text Graph, to
represent the topological and linguistic relations among evidential elements,
respectively. We also introduce a multi-channel heterogeneous learning model
and a fusional attention mechanism to handle the co-reference-text
heterogeneity in evidence recommendation. Our experiments demonstrate that our
model outperforms state-of-the-art methods on open data.
","[{'version': 'v1', 'created': 'Mon, 3 Apr 2023 12:15:53 GMT'}]",2023-04-05,"[['Luo', 'Maolin', ''], ['Zhang', 'Xiang', '']]"
2206.14659,Andrew Koh,"Andrew Koh, Eng Siong Chng","Language-Based Audio Retrieval with Converging Tied Layers and
  Contrastive Loss",,,,,cs.SD cs.CL cs.IR eess.AS,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we tackle the new Language-Based Audio Retrieval task proposed
in DCASE 2022. Firstly, we introduce a simple, scalable architecture which ties
both the audio and text encoder together. Secondly, we show that using this
architecture along with contrastive loss allows the model to significantly beat
the performance of the baseline model. Finally, in addition to having an
extremely low training memory requirement, we are able to use pretrained models
as it is without needing to finetune them. We test our methods and show that
using a combination of our methods beats the baseline scores significantly.
","[{'version': 'v1', 'created': 'Wed, 29 Jun 2022 13:59:19 GMT'}]",2022-06-30,"[['Koh', 'Andrew', ''], ['Chng', 'Eng Siong', '']]"
2305.09400,Jiasheng Si,"Jiasheng Si, Yingjie Zhu, Deyu Zhou","Consistent Multi-Granular Rationale Extraction for Explainable Multi-hop
  Fact Verification",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The success of deep learning models on multi-hop fact verification has
prompted researchers to understand the behavior behind their veracity. One
possible way is erasure search: obtaining the rationale by entirely removing a
subset of input without compromising the veracity prediction. Although
extensively explored, existing approaches fall within the scope of the
single-granular (tokens or sentences) explanation, which inevitably leads to
explanation redundancy and inconsistency. To address such issues, this paper
explores the viability of multi-granular rationale extraction with consistency
and faithfulness for explainable multi-hop fact verification. In particular,
given a pretrained veracity prediction model, both the token-level explainer
and sentence-level explainer are trained simultaneously to obtain
multi-granular rationales via differentiable masking. Meanwhile, three
diagnostic properties (fidelity, consistency, salience) are introduced and
applied to the training process, to ensure that the extracted rationales
satisfy faithfulness and consistency. Experimental results on three multi-hop
fact verification datasets show that the proposed approach outperforms some
state-of-the-art baselines.
","[{'version': 'v1', 'created': 'Tue, 16 May 2023 12:31:53 GMT'}]",2023-05-17,"[['Si', 'Jiasheng', ''], ['Zhu', 'Yingjie', ''], ['Zhou', 'Deyu', '']]"
1807.02162,Shweta Yadav Shweta,"Shweta Yadav, Ankit Kumar, Asif Ekbal, Sriparna Saha and Pushpak
  Bhattacharyya","Feature Assisted bi-directional LSTM Model for Protein-Protein
  Interaction Identification from Biomedical Texts",,,,,cs.IR cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Knowledge about protein-protein interactions is essential in understanding
the biological processes such as metabolic pathways, DNA replication, and
transcription etc. However, a majority of the existing Protein-Protein
Interaction (PPI) systems are dependent primarily on the scientific literature,
which is yet not accessible as a structured database. Thus, efficient
information extraction systems are required for identifying PPI information
from the large collection of biomedical texts. Most of the existing systems
model the PPI extraction task as a classification problem and are tailored to
the handcrafted feature set including domain dependent features. In this paper,
we present a novel method based on deep bidirectional long short-term memory
(B-LSTM) technique that exploits word sequences and dependency path related
information to identify PPI information from text. This model leverages joint
modeling of proteins and relations in a single unified framework, which we name
as Shortest Dependency Path B-LSTM (sdpLSTM) model. We perform experiments on
two popular benchmark PPI datasets, namely AiMed & BioInfer. The evaluation
shows the F1-score values of 86.45% and 77.35% on AiMed and BioInfer,
respectively. Comparisons with the existing systems show that our proposed
approach attains state-of-the-art performance.
","[{'version': 'v1', 'created': 'Thu, 5 Jul 2018 19:37:29 GMT'}]",2018-07-09,"[['Yadav', 'Shweta', ''], ['Kumar', 'Ankit', ''], ['Ekbal', 'Asif', ''], ['Saha', 'Sriparna', ''], ['Bhattacharyya', 'Pushpak', '']]"
2005.10219,Jack Weston,"Abhishek Shivkumar, Jack Weston, Raphael Lenain, Emil Fristed","BlaBla: Linguistic Feature Extraction for Clinical Analysis in Multiple
  Languages",5 pages. 1 figure. Under review,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce BlaBla, an open-source Python library for extracting linguistic
features with proven clinical relevance to neurological and psychiatric
diseases across many languages. BlaBla is a unifying framework for accelerating
and simplifying clinical linguistic research. The library is built on
state-of-the-art NLP frameworks and supports multithreaded/GPU-enabled feature
extraction via both native Python calls and a command line interface. We
describe BlaBla's architecture and clinical validation of its features across
12 diseases. We further demonstrate the application of BlaBla to a task
visualizing and classifying language disorders in three languages on real
clinical data from the AphasiaBank dataset. We make the codebase freely
available to researchers with the hope of providing a consistent,
well-validated foundation for the next generation of clinical linguistic
research.
","[{'version': 'v1', 'created': 'Wed, 20 May 2020 17:31:35 GMT'}]",2020-05-21,"[['Shivkumar', 'Abhishek', ''], ['Weston', 'Jack', ''], ['Lenain', 'Raphael', ''], ['Fristed', 'Emil', '']]"
2110.03756,Charalambos Themistocleous,"Charalambos Themistocleous, Valantis Fyndanis, Kyrana Tsapkini","Sonorant spectra and coarticulation distinguish speakers with different
  dialects",,,,,cs.CL cs.SD eess.AS,http://creativecommons.org/licenses/by/4.0/,"  The aim of this study is to determine the effect of language varieties on the
spectral distribution of stressed and unstressed sonorants (nasals /m, n/,
lateral approximants /l/, and rhotics /r/) and on their coarticulatory effects
on adjacent sounds. To quantify the shape of the spectral distribution, we
calculated the spectral moments from the sonorant spectra of nasals /m, n/,
lateral approximants /l/, and rhotics /r/ produced by Athenian Greek and
Cypriot Greek speakers. To estimate the co-articulatory effects of sonorants on
the adjacent vowels' F1 - F4 formant frequencies, we developed polynomial
models of the adjacent vowel's formant contours. We found significant effects
of language variety (sociolinguistic information) on the spectral moments of
each sonorant /m/, /n/, /l/, /r/ (except between /m/ and /n/) and on the
formant contours of the adjacent vowel. All sonorants (including /m/ and /n/)
had distinct effects on adjacent vowel's formant contours, especially for F3
and F4. The study highlights that the combination of spectral moments and
coarticulatory effects of sonorants determines linguistic (stress and phonemic
category) and sociolinguistic (language variety) characteristics of sonorants.
It also provides the first comparative acoustic analysis of Athenian Greek and
Cypriot Greek sonorants.
","[{'version': 'v1', 'created': 'Thu, 7 Oct 2021 19:18:18 GMT'}]",2021-10-11,"[['Themistocleous', 'Charalambos', ''], ['Fyndanis', 'Valantis', ''], ['Tsapkini', 'Kyrana', '']]"
2402.01591,Zhisheng Zheng,"Zhisheng Zheng, Puyuan Peng, Ziyang Ma, Xie Chen, Eunsol Choi, David
  Harwath",BAT: Learning to Reason about Spatial Sounds with Large Language Models,"Preprint, work in progress",,,,eess.AS cs.AI cs.CL cs.SD,http://creativecommons.org/licenses/by/4.0/,"  Spatial sound reasoning is a fundamental human skill, enabling us to navigate
and interpret our surroundings based on sound. In this paper we present BAT,
which combines the spatial sound perception ability of a binaural acoustic
scene analysis model with the natural language reasoning capabilities of a
large language model (LLM) to replicate this innate ability. To address the
lack of existing datasets of in-the-wild spatial sounds, we synthesized a
binaural audio dataset using AudioSet and SoundSpaces 2.0. Next, we developed
SpatialSoundQA, a spatial sound-based question-answering dataset, offering a
range of QA tasks that train BAT in various aspects of spatial sound perception
and reasoning. The acoustic front end encoder of BAT is a novel spatial audio
encoder named Spatial Audio Spectrogram Transformer, or Spatial-AST, which by
itself achieves strong performance across sound event detection, spatial
localization, and distance estimation. By integrating Spatial-AST with LLaMA-2
7B model, BAT transcends standard Sound Event Localization and Detection (SELD)
tasks, enabling the model to reason about the relationships between the sounds
in its environment. Our experiments demonstrate BAT's superior performance on
both spatial sound perception and reasoning, showcasing the immense potential
of LLMs in navigating and interpreting complex spatial audio environments.
","[{'version': 'v1', 'created': 'Fri, 2 Feb 2024 17:34:53 GMT'}]",2024-02-05,"[['Zheng', 'Zhisheng', ''], ['Peng', 'Puyuan', ''], ['Ma', 'Ziyang', ''], ['Chen', 'Xie', ''], ['Choi', 'Eunsol', ''], ['Harwath', 'David', '']]"
1709.05038,Yang Xian,"Yang Xian, Yingli Tian","Self-Guiding Multimodal LSTM - when we do not have a perfect training
  dataset for image captioning","The paper is under consideration at Computer Vision and Image
  Understanding",,,,cs.CV cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, a self-guiding multimodal LSTM (sg-LSTM) image captioning
model is proposed to handle uncontrolled imbalanced real-world image-sentence
dataset. We collect FlickrNYC dataset from Flickr as our testbed with 306,165
images and the original text descriptions uploaded by the users are utilized as
the ground truth for training. Descriptions in FlickrNYC dataset vary
dramatically ranging from short term-descriptions to long
paragraph-descriptions and can describe any visual aspects, or even refer to
objects that are not depicted. To deal with the imbalanced and noisy situation
and to fully explore the dataset itself, we propose a novel guiding textual
feature extracted utilizing a multimodal LSTM (m-LSTM) model. Training of
m-LSTM is based on the portion of data in which the image content and the
corresponding descriptions are strongly bonded. Afterwards, during the training
of sg-LSTM on the rest training data, this guiding information serves as
additional input to the network along with the image representations and the
ground-truth descriptions. By integrating these input components into a
multimodal block, we aim to form a training scheme with the textual information
tightly coupled with the image content. The experimental results demonstrate
that the proposed sg-LSTM model outperforms the traditional state-of-the-art
multimodal RNN captioning framework in successfully describing the key
components of the input images.
","[{'version': 'v1', 'created': 'Fri, 15 Sep 2017 02:53:16 GMT'}]",2017-09-18,"[['Xian', 'Yang', ''], ['Tian', 'Yingli', '']]"
2007.13802,Jinxi Guo,"Jinxi Guo, Gautam Tiwari, Jasha Droppo, Maarten Van Segbroeck, Che-Wei
  Huang, Andreas Stolcke, Roland Maas","Efficient minimum word error rate training of RNN-Transducer for
  end-to-end speech recognition",Accepted to Interspeech 2020,,,,eess.AS cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work, we propose a novel and efficient minimum word error rate (MWER)
training method for RNN-Transducer (RNN-T). Unlike previous work on this topic,
which performs on-the-fly limited-size beam-search decoding and generates
alignment scores for expected edit-distance computation, in our proposed
method, we re-calculate and sum scores of all the possible alignments for each
hypothesis in N-best lists. The hypothesis probability scores and
back-propagated gradients are calculated efficiently using the forward-backward
algorithm. Moreover, the proposed method allows us to decouple the decoding and
training processes, and thus we can perform offline parallel-decoding and MWER
training for each subset iteratively. Experimental results show that this
proposed semi-on-the-fly method can speed up the on-the-fly method by 6 times
and result in a similar WER improvement (3.6%) over a baseline RNN-T model. The
proposed MWER training can also effectively reduce high-deletion errors (9.2%
WER-reduction) introduced by RNN-T models when EOS is added for endpointer.
Further improvement can be achieved if we use a proposed RNN-T rescoring method
to re-rank hypotheses and use external RNN-LM to perform additional rescoring.
The best system achieves a 5% relative improvement on an English test-set of
real far-field recordings and a 11.6% WER reduction on music-domain utterances.
","[{'version': 'v1', 'created': 'Mon, 27 Jul 2020 18:33:35 GMT'}]",2020-07-29,"[['Guo', 'Jinxi', ''], ['Tiwari', 'Gautam', ''], ['Droppo', 'Jasha', ''], ['Van Segbroeck', 'Maarten', ''], ['Huang', 'Che-Wei', ''], ['Stolcke', 'Andreas', ''], ['Maas', 'Roland', '']]"
2004.14973,Arjun Majumdar,"Arjun Majumdar, Ayush Shrivastava, Stefan Lee, Peter Anderson, Devi
  Parikh, Dhruv Batra","Improving Vision-and-Language Navigation with Image-Text Pairs from the
  Web",,,,,cs.CV cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Following a navigation instruction such as 'Walk down the stairs and stop at
the brown sofa' requires embodied AI agents to ground scene elements referenced
via language (e.g. 'stairs') to visual content in the environment (pixels
corresponding to 'stairs').
  We ask the following question -- can we leverage abundant 'disembodied'
web-scraped vision-and-language corpora (e.g. Conceptual Captions) to learn
visual groundings (what do 'stairs' look like?) that improve performance on a
relatively data-starved embodied perception task (Vision-and-Language
Navigation)? Specifically, we develop VLN-BERT, a visiolinguistic
transformer-based model for scoring the compatibility between an instruction
('...stop at the brown sofa') and a sequence of panoramic RGB images captured
by the agent. We demonstrate that pretraining VLN-BERT on image-text pairs from
the web before fine-tuning on embodied path-instruction data significantly
improves performance on VLN -- outperforming the prior state-of-the-art in the
fully-observed setting by 4 absolute percentage points on success rate.
Ablations of our pretraining curriculum show each stage to be impactful -- with
their combination resulting in further positive synergistic effects.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 17:22:40 GMT'}, {'version': 'v2', 'created': 'Fri, 1 May 2020 17:16:50 GMT'}]",2020-05-04,"[['Majumdar', 'Arjun', ''], ['Shrivastava', 'Ayush', ''], ['Lee', 'Stefan', ''], ['Anderson', 'Peter', ''], ['Parikh', 'Devi', ''], ['Batra', 'Dhruv', '']]"
1511.01974,Xu Chen,"Xu Chen, Han Zhang, Judith Gelernter",Multi-lingual Geoparsing based on Machine Translation,"7 pages, 4 figures,",,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Our method for multi-lingual geoparsing uses monolingual tools and resources
along with machine translation and alignment to return location words in many
languages. Not only does our method save the time and cost of developing
geoparsers for each language separately, but also it allows the possibility of
a wide range of language capabilities within a single interface. We evaluated
our method in our LanguageBridge prototype on location named entities using
newswire, broadcast news and telephone conversations in English, Arabic and
Chinese data from the Linguistic Data Consortium (LDC). Our results for
geoparsing Chinese and Arabic text using our multi-lingual geoparsing method
are comparable to our results for geoparsing English text with our English
tools. Furthermore, experiments using our machine translation approach results
in accuracy comparable to results from the same data that was translated
manually.
","[{'version': 'v1', 'created': 'Fri, 6 Nov 2015 03:07:20 GMT'}]",2015-11-09,"[['Chen', 'Xu', ''], ['Zhang', 'Han', ''], ['Gelernter', 'Judith', '']]"
2308.10380,Bilgehan Sel,"Ming Jin, Bilgehan Sel, Fnu Hardeep, Wotao Yin","A Human-on-the-Loop Optimization Autoformalism Approach for
  Sustainability",,,,,cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This paper outlines a natural conversational approach to solving personalized
energy-related problems using large language models (LLMs). We focus on
customizable optimization problems that necessitate repeated solving with
slight variations in modeling and are user-specific, hence posing a challenge
to devising a one-size-fits-all model. We put forward a strategy that augments
an LLM with an optimization solver, enhancing its proficiency in understanding
and responding to user specifications and preferences while providing nonlinear
reasoning capabilities. Our approach pioneers the novel concept of human-guided
optimization autoformalism, translating a natural language task specification
automatically into an optimization instance. This enables LLMs to analyze,
explain, and tackle a variety of instance-specific energy-related problems,
pushing beyond the limits of current prompt-based techniques.
  Our research encompasses various commonplace tasks in the energy sector, from
electric vehicle charging and Heating, Ventilation, and Air Conditioning (HVAC)
control to long-term planning problems such as cost-benefit evaluations for
installing rooftop solar photovoltaics (PVs) or heat pumps. This pilot study
marks an essential stride towards the context-based formulation of optimization
using LLMs, with the potential to democratize optimization processes. As a
result, stakeholders are empowered to optimize their energy consumption,
promoting sustainable energy practices customized to personal needs and
preferences.
","[{'version': 'v1', 'created': 'Sun, 20 Aug 2023 22:42:04 GMT'}, {'version': 'v2', 'created': 'Wed, 23 Aug 2023 00:52:13 GMT'}]",2023-08-24,"[['Jin', 'Ming', ''], ['Sel', 'Bilgehan', ''], ['Hardeep', 'Fnu', ''], ['Yin', 'Wotao', '']]"
2403.04031,Yebowen Hu,"Yebowen Hu, Kaiqiang Song, Sangwoo Cho, Xiaoyang Wang, Hassan Foroosh,
  Dong Yu, Fei Liu",Can Large Language Models do Analytical Reasoning?,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper explores the cutting-edge Large Language Model with analytical
reasoning on sports. Our analytical reasoning embodies the tasks of letting
large language models count how many points each team scores in a quarter in
the NBA and NFL games. Our major discoveries are in two folds. Firstly, we find
among all the models we employed, GPT-4 stands out in effectiveness, followed
by Claude-2.1, with GPT-3.5, Gemini-Pro, and Llama-2-70b lagging behind.
Specifically, we compare three different prompting techniques and a
divide-and-conquer approach, we find that the latter was the most effective.
Our divide-and-conquer approach breaks down play-by-play data into smaller,
more manageable segments, solves each piece individually, and then aggregates
them together. Besides the divide-and-conquer approach, we also explore the
Chain of Thought (CoT) strategy, which markedly improves outcomes for certain
models, notably GPT-4 and Claude-2.1, with their accuracy rates increasing
significantly. However, the CoT strategy has negligible or even detrimental
effects on the performance of other models like GPT-3.5 and Gemini-Pro.
Secondly, to our surprise, we observe that most models, including GPT-4,
struggle to accurately count the total scores for NBA quarters despite showing
strong performance in counting NFL quarter scores. This leads us to further
investigate the factors that impact the complexity of analytical reasoning
tasks with extensive experiments, through which we conclude that task
complexity depends on the length of context, the information density, and the
presence of related information. Our research provides valuable insights into
the complexity of analytical reasoning tasks and potential directions for
developing future large language models.
","[{'version': 'v1', 'created': 'Wed, 6 Mar 2024 20:22:08 GMT'}]",2024-03-08,"[['Hu', 'Yebowen', ''], ['Song', 'Kaiqiang', ''], ['Cho', 'Sangwoo', ''], ['Wang', 'Xiaoyang', ''], ['Foroosh', 'Hassan', ''], ['Yu', 'Dong', ''], ['Liu', 'Fei', '']]"
2303.10560,Yinping Yang Dr,"Brandon Siyuan Loh, Raj Kumar Gupta, Ajay Vishwanath, Andrew Ortony,
  Yinping Yang","How People Respond to the COVID-19 Pandemic on Twitter: A Comparative
  Analysis of Emotional Expressions from US and India","13 pages, 3 figures, 1 table, 2 appendices",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The COVID-19 pandemic has claimed millions of lives worldwide and elicited
heightened emotions. This study examines the expression of various emotions
pertaining to COVID-19 in the United States and India as manifested in over 54
million tweets, covering the fifteen-month period from February 2020 through
April 2021, a period which includes the beginnings of the huge and disastrous
increase in COVID-19 cases that started to ravage India in March 2021.
Employing pre-trained emotion analysis and topic modeling algorithms, four
distinct types of emotions (fear, anger, happiness, and sadness) and their
time- and location-associated variations were examined. Results revealed
significant country differences and temporal changes in the relative
proportions of fear, anger, and happiness, with fear declining and anger and
happiness fluctuating in 2020 until new situations over the first four months
of 2021 reversed the trends. Detected differences are discussed briefly in
terms of the latent topics revealed and through the lens of appraisal theories
of emotions, and the implications of the findings are discussed.
","[{'version': 'v1', 'created': 'Sun, 19 Mar 2023 04:05:10 GMT'}]",2023-03-21,"[['Loh', 'Brandon Siyuan', ''], ['Gupta', 'Raj Kumar', ''], ['Vishwanath', 'Ajay', ''], ['Ortony', 'Andrew', ''], ['Yang', 'Yinping', '']]"
2312.17475,Zonghai Yao,"Xiaocheng Zhang, Zonghai Yao, Hong Yu",EHR Interaction Between Patients and AI: NoteAid EHR Interaction,To appear in the AAAI2024 Workshop on AI for Education (AI4ED),,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  With the rapid advancement of Large Language Models (LLMs) and their
outstanding performance in semantic and contextual comprehension, the potential
of LLMs in specialized domains warrants exploration. This paper introduces the
NoteAid EHR Interaction Pipeline, an innovative approach developed using
generative LLMs to assist in patient education, a task stemming from the need
to aid patients in understanding Electronic Health Records (EHRs). Building
upon the NoteAid work, we designed two novel tasks from the patient's
perspective: providing explanations for EHR content that patients may not
understand and answering questions posed by patients after reading their EHRs.
We extracted datasets containing 10,000 instances from MIMIC Discharge
Summaries and 876 instances from the MADE medical notes collection,
respectively, executing the two tasks through the NoteAid EHR Interaction
Pipeline with these data. Performance data of LLMs on these tasks were
collected and constructed as the corresponding NoteAid EHR Interaction Dataset.
Through a comprehensive evaluation of the entire dataset using LLM assessment
and a rigorous manual evaluation of 64 instances, we showcase the potential of
LLMs in patient education. Besides, the results provide valuable data support
for future exploration and applications in this domain while also supplying
high-quality synthetic datasets for in-house system training.
","[{'version': 'v1', 'created': 'Fri, 29 Dec 2023 05:13:40 GMT'}]",2024-01-01,"[['Zhang', 'Xiaocheng', ''], ['Yao', 'Zonghai', ''], ['Yu', 'Hong', '']]"
2012.11587,Chuang Gan,"Jianwei Yang, Jiayuan Mao, Jiajun Wu, Devi Parikh, David D. Cox,
  Joshua B. Tenenbaum, Chuang Gan",Object-Centric Diagnosis of Visual Reasoning,,,,,cs.CV cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  When answering questions about an image, it not only needs knowing what --
understanding the fine-grained contents (e.g., objects, relationships) in the
image, but also telling why -- reasoning over grounding visual cues to derive
the answer for a question. Over the last few years, we have seen significant
progress on visual question answering. Though impressive as the accuracy grows,
it still lags behind to get knowing whether these models are undertaking
grounding visual reasoning or just leveraging spurious correlations in the
training data. Recently, a number of works have attempted to answer this
question from perspectives such as grounding and robustness. However, most of
them are either focusing on the language side or coarsely studying the
pixel-level attention maps. In this paper, by leveraging the step-wise object
grounding annotations provided in the GQA dataset, we first present a
systematical object-centric diagnosis of visual reasoning on grounding and
robustness, particularly on the vision side. According to the extensive
comparisons across different models, we find that even models with high
accuracy are not good at grounding objects precisely, nor robust to visual
content perturbations. In contrast, symbolic and modular models have a
relatively better grounding and robustness, though at the cost of accuracy. To
reconcile these different aspects, we further develop a diagnostic model,
namely Graph Reasoning Machine. Our model replaces purely symbolic visual
representation with probabilistic scene graph and then applies teacher-forcing
training for the visual reasoning module. The designed model improves the
performance on all three metrics over the vanilla neural-symbolic model while
inheriting the transparency. Further ablation studies suggest that this
improvement is mainly due to more accurate image understanding and proper
intermediate reasoning supervisions.
","[{'version': 'v1', 'created': 'Mon, 21 Dec 2020 18:59:28 GMT'}]",2020-12-22,"[['Yang', 'Jianwei', ''], ['Mao', 'Jiayuan', ''], ['Wu', 'Jiajun', ''], ['Parikh', 'Devi', ''], ['Cox', 'David D.', ''], ['Tenenbaum', 'Joshua B.', ''], ['Gan', 'Chuang', '']]"
1502.02655,Simon \v{S}uster,Simon \v{S}uster,"An investigation into language complexity of World-of-Warcraft
  game-external texts",10 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a language complexity analysis of World of Warcraft (WoW)
community texts, which we compare to texts from a general corpus of web
English. Results from several complexity types are presented, including lexical
diversity, density, readability and syntactic complexity. The language of WoW
texts is found to be comparable to the general corpus on some complexity
measures, yet more specialized on other measures. Our findings can be used by
educators willing to include game-related activities into school curricula.
","[{'version': 'v1', 'created': 'Sat, 7 Feb 2015 21:59:21 GMT'}]",2015-02-11,"[['Šuster', 'Simon', '']]"
2106.08914,Hung Le,"Hung Le, Nancy F. Chen, Steven C.H. Hoi","$C^3$: Compositional Counterfactual Contrastive Learning for
  Video-grounded Dialogues","24th Meeting of the Special Interest Group on Discourse and Dialogue
  (SIGDIAL)",,,,cs.LG cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Video-grounded dialogue systems aim to integrate video understanding and
dialogue understanding to generate responses that are relevant to both the
dialogue and video context. Most existing approaches employ deep learning
models and have achieved remarkable performance, given the relatively small
datasets available. However, the results are partly accomplished by exploiting
biases in the datasets rather than developing multimodal reasoning, resulting
in limited generalization. In this paper, we propose a novel approach of
Compositional Counterfactual Contrastive Learning ($C^3$) to develop
contrastive training between factual and counterfactual samples in
video-grounded dialogues. Specifically, we design factual/counterfactual
sampling based on the temporal steps in videos and tokens in dialogues and
propose contrastive loss functions that exploit object-level or action-level
variance. Different from prior approaches, we focus on contrastive hidden state
representations among compositional output tokens to optimize the
representation space in a generation setting. We achieved promising performance
gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the
benefits of our approach in grounding video and dialogue context.
","[{'version': 'v1', 'created': 'Wed, 16 Jun 2021 16:05:27 GMT'}, {'version': 'v2', 'created': 'Sat, 5 Aug 2023 08:04:15 GMT'}]",2023-08-08,"[['Le', 'Hung', ''], ['Chen', 'Nancy F.', ''], ['Hoi', 'Steven C. H.', '']]"
2103.16289,Md Rashad Al Hasan Rony,"Debanjan Chaudhuri, Md Rashad Al Hasan Rony, Jens Lehmann","Grounding Dialogue Systems via Knowledge Graph Aware Decoding with
  Pre-trained Transformers","16 pages, 3 figures, accepted at ESWC 2021",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Generating knowledge grounded responses in both goal and non-goal oriented
dialogue systems is an important research challenge. Knowledge Graphs (KG) can
be viewed as an abstraction of the real world, which can potentially facilitate
a dialogue system to produce knowledge grounded responses. However, integrating
KGs into the dialogue generation process in an end-to-end manner is a
non-trivial task. This paper proposes a novel architecture for integrating KGs
into the response generation process by training a BERT model that learns to
answer using the elements of the KG (entities and relations) in a multi-task,
end-to-end setting. The k-hop subgraph of the KG is incorporated into the model
during training and inference using Graph Laplacian. Empirical evaluation
suggests that the model achieves better knowledge groundedness (measured via
Entity F1 score) compared to other state-of-the-art models for both goal and
non-goal oriented dialogues.
","[{'version': 'v1', 'created': 'Tue, 30 Mar 2021 12:36:00 GMT'}]",2021-03-31,"[['Chaudhuri', 'Debanjan', ''], ['Rony', 'Md Rashad Al Hasan', ''], ['Lehmann', 'Jens', '']]"
2402.14830,Arindam Mitra,"Arindam Mitra, Hamed Khanpour, Corby Rosset, Ahmed Awadallah",Orca-Math: Unlocking the potential of SLMs in Grade School Math,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Mathematical word problem-solving has long been recognized as a complex task
for small language models (SLMs). A recent study hypothesized that the smallest
model size, needed to achieve over 80% accuracy on the GSM8K benchmark, is 34
billion parameters. To reach this level of performance with smaller models,
researcher often train SLMs to generate Python code or use tools to help avoid
calculation errors. Additionally, they employ ensembling, where outputs of up
to 100 model runs are combined to arrive at a more accurate result. Result
selection is done using consensus, majority vote or a separate a verifier model
used in conjunction with the SLM. Ensembling provides a substantial boost in
accuracy but at a significant cost increase with multiple calls to the model
(e.g., Phi-GSM uses top-48 to boost the performance from 68.2 to 81.5).
  In this work, we present Orca-Math, a 7-billion-parameter SLM based on the
Mistral-7B, which achieves 86.81% on GSM8k without the need for multiple model
calls or the use of verifiers, code execution or any other external tools. Our
approach has the following key elements: (1) A high quality synthetic dataset
of 200K math problems created using a multi-agent setup where agents
collaborate to create the data, (2) An iterative learning techniques that
enables the SLM to practice solving problems, receive feedback on its solutions
and learn from preference pairs incorporating the SLM solutions and the
feedback. When trained with Supervised Fine-Tuning alone, Orca-Math achieves
81.50% on GSM8k pass@1 metric. With iterative preference learning, Orca-Math
achieves 86.81% pass@1. Orca-Math surpasses the performance of significantly
larger models such as LLAMA-2-70B, WizardMath-70B, Gemini-Pro, ChatGPT-3.5. It
also significantly outperforms other smaller models while using much smaller
data (hundreds of thousands vs. millions of problems).
","[{'version': 'v1', 'created': 'Fri, 16 Feb 2024 23:44:38 GMT'}]",2024-02-26,"[['Mitra', 'Arindam', ''], ['Khanpour', 'Hamed', ''], ['Rosset', 'Corby', ''], ['Awadallah', 'Ahmed', '']]"
2003.06094,Xiaoyuan Yi,"Xiaoyuan Yi, Ruoyu Li, Cheng Yang, Wenhao Li, Maosong Sun","MixPoet: Diverse Poetry Generation via Learning Controllable Mixed
  Latent Space","8 pages, 5 figures, published in AAAI 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As an essential step towards computer creativity, automatic poetry generation
has gained increasing attention these years. Though recent neural models make
prominent progress in some criteria of poetry quality, generated poems still
suffer from the problem of poor diversity. Related literature researches show
that different factors, such as life experience, historical background, etc.,
would influence composition styles of poets, which considerably contributes to
the high diversity of human-authored poetry. Inspired by this, we propose
MixPoet, a novel model that absorbs multiple factors to create various styles
and promote diversity. Based on a semi-supervised variational autoencoder, our
model disentangles the latent space into some subspaces, with each conditioned
on one influence factor by adversarial training. In this way, the model learns
a controllable latent variable to capture and mix generalized factor-related
properties. Different factor mixtures lead to diverse styles and hence further
differentiate generated poems from each other. Experiment results on Chinese
poetry demonstrate that MixPoet improves both diversity and quality against
three state-of-the-art models.
","[{'version': 'v1', 'created': 'Fri, 13 Mar 2020 03:31:29 GMT'}]",2020-03-16,"[['Yi', 'Xiaoyuan', ''], ['Li', 'Ruoyu', ''], ['Yang', 'Cheng', ''], ['Li', 'Wenhao', ''], ['Sun', 'Maosong', '']]"
2302.13971,Gautier Izacard,"Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet,
  Marie-Anne Lachaux, Timoth\'ee Lacroix, Baptiste Rozi\`ere, Naman Goyal, Eric
  Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave,
  Guillaume Lample",LLaMA: Open and Efficient Foundation Language Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We introduce LLaMA, a collection of foundation language models ranging from
7B to 65B parameters. We train our models on trillions of tokens, and show that
it is possible to train state-of-the-art models using publicly available
datasets exclusively, without resorting to proprietary and inaccessible
datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks,
and LLaMA-65B is competitive with the best models, Chinchilla-70B and
PaLM-540B. We release all our models to the research community.
","[{'version': 'v1', 'created': 'Mon, 27 Feb 2023 17:11:15 GMT'}]",2023-02-28,"[['Touvron', 'Hugo', ''], ['Lavril', 'Thibaut', ''], ['Izacard', 'Gautier', ''], ['Martinet', 'Xavier', ''], ['Lachaux', 'Marie-Anne', ''], ['Lacroix', 'Timothée', ''], ['Rozière', 'Baptiste', ''], ['Goyal', 'Naman', ''], ['Hambro', 'Eric', ''], ['Azhar', 'Faisal', ''], ['Rodriguez', 'Aurelien', ''], ['Joulin', 'Armand', ''], ['Grave', 'Edouard', ''], ['Lample', 'Guillaume', '']]"
2207.10872,Nasser Ghadiri,"Hoda Memarzadeh, Nasser Ghadiri, Maryam Lotfi Shahreza","Assessing mortality prediction through different representation models
  based on concepts extracted from clinical notes",,,,,cs.CL cs.IR cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Recent years have seen particular interest in using electronic medical
records (EMRs) for secondary purposes to enhance the quality and safety of
healthcare delivery. EMRs tend to contain large amounts of valuable clinical
notes. Learning of embedding is a method for converting notes into a format
that makes them comparable. Transformer-based representation models have
recently made a great leap forward. These models are pre-trained on large
online datasets to understand natural language texts effectively. The quality
of a learning embedding is influenced by how clinical notes are used as input
to representation models. A clinical note has several sections with different
levels of information value. It is also common for healthcare providers to use
different expressions for the same concept. Existing methods use clinical notes
directly or with an initial preprocessing as input to representation models.
However, to learn a good embedding, we identified the most essential clinical
notes section. We then mapped the extracted concepts from selected sections to
the standard names in the Unified Medical Language System (UMLS). We used the
standard phrases corresponding to the unique concepts as input for clinical
models. We performed experiments to measure the usefulness of the learned
embedding vectors in the task of hospital mortality prediction on a subset of
the publicly available Medical Information Mart for Intensive Care (MIMIC-III)
dataset. According to the experiments, clinical transformer-based
representation models produced better results with getting input generated by
standard names of extracted unique concepts compared to other input formats.
The best-performing models were BioBERT, PubMedBERT, and UmlsBERT,
respectively.
","[{'version': 'v1', 'created': 'Fri, 22 Jul 2022 04:34:33 GMT'}]",2022-07-25,"[['Memarzadeh', 'Hoda', ''], ['Ghadiri', 'Nasser', ''], ['Shahreza', 'Maryam Lotfi', '']]"
2007.10534,Gullal Singh Cheema,"Gullal S. Cheema, Sherzod Hakimov, Ralph Ewerth","Check_square at CheckThat! 2020: Claim Detection in Social Media via
  Fusion of Transformer and Syntactic Features",CLEF2020-CheckThat!,,,,cs.CL cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this digital age of news consumption, a news reader has the ability to
react, express and share opinions with others in a highly interactive and fast
manner. As a consequence, fake news has made its way into our daily life
because of very limited capacity to verify news on the Internet by large
companies as well as individuals. In this paper, we focus on solving two
problems which are part of the fact-checking ecosystem that can help to
automate fact-checking of claims in an ever increasing stream of content on
social media. For the first problem, claim check-worthiness prediction, we
explore the fusion of syntactic features and deep transformer Bidirectional
Encoder Representations from Transformers (BERT) embeddings, to classify
check-worthiness of a tweet, i.e. whether it includes a claim or not. We
conduct a detailed feature analysis and present our best performing models for
English and Arabic tweets. For the second problem, claim retrieval, we explore
the pre-trained embeddings from a Siamese network transformer model
(sentence-transformers) specifically trained for semantic textual similarity,
and perform KD-search to retrieve verified claims with respect to a query
tweet.
","[{'version': 'v1', 'created': 'Tue, 21 Jul 2020 00:07:17 GMT'}, {'version': 'v2', 'created': 'Sun, 20 Sep 2020 23:51:37 GMT'}]",2020-09-22,"[['Cheema', 'Gullal S.', ''], ['Hakimov', 'Sherzod', ''], ['Ewerth', 'Ralph', '']]"
2107.02421,Inari Listenmaa,"Inari Listenmaa, Jason Morris, Alfred Ang, Maryam Hanafiah, Regina
  Cheong",An NLG pipeline for a legal expert system: a work in progress,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  We present the NLG component for L4, a prototype domain-specific language
(DSL) for drafting laws and contracts. As a concrete use case, we describe a
pipeline for a legal expert system created from L4 code. The NLG component is
used in two steps. The first step is to create an interview, whose answers are
processed into a query for an automated reasoner. The second step is to render
the answers of the reasoner in natural language.
","[{'version': 'v1', 'created': 'Tue, 6 Jul 2021 06:42:38 GMT'}]",2021-07-07,"[['Listenmaa', 'Inari', ''], ['Morris', 'Jason', ''], ['Ang', 'Alfred', ''], ['Hanafiah', 'Maryam', ''], ['Cheong', 'Regina', '']]"
1705.02395,Markus Borg,"Markus Borg, Iben Lennerstad, Rasmus Ros, Elizabeth Bjarnason","On Using Active Learning and Self-Training when Mining Performance
  Discussions on Stack Overflow","Preprint of paper accepted for the Proc. of the 21st International
  Conference on Evaluation and Assessment in Software Engineering, 2017",,,,cs.CL cs.HC cs.LG cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Abundant data is the key to successful machine learning. However, supervised
learning requires annotated data that are often hard to obtain. In a
classification task with limited resources, Active Learning (AL) promises to
guide annotators to examples that bring the most value for a classifier. AL can
be successfully combined with self-training, i.e., extending a training set
with the unlabelled examples for which a classifier is the most certain. We
report our experiences on using AL in a systematic manner to train an SVM
classifier for Stack Overflow posts discussing performance of software
components. We show that the training examples deemed as the most valuable to
the classifier are also the most difficult for humans to annotate. Despite
carefully evolved annotation criteria, we report low inter-rater agreement, but
we also propose mitigation strategies. Finally, based on one annotator's work,
we show that self-training can improve the classification accuracy. We conclude
the paper by discussing implication for future text miners aspiring to use AL
and self-training.
","[{'version': 'v1', 'created': 'Wed, 26 Apr 2017 20:47:36 GMT'}]",2017-05-09,"[['Borg', 'Markus', ''], ['Lennerstad', 'Iben', ''], ['Ros', 'Rasmus', ''], ['Bjarnason', 'Elizabeth', '']]"
2303.16537,Zichen Chen,"Zichen Chen, Ambuj K Singh, Misha Sra",LMExplainer: a Knowledge-Enhanced Explainer for Language Models,"12 pages, 1 figure, 7 tables, and 3 case studies",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) such as GPT-4 are very powerful and can process
different kinds of natural language processing (NLP) tasks. However, it can be
difficult to interpret the results due to the multi-layer nonlinear model
structure and millions of parameters. A lack of clarity and understanding of
how the language models (LMs) work can make them unreliable, difficult to
trust, and potentially dangerous for use in real-world scenarios. Most recent
works exploit attention weights to provide explanations for LM predictions.
However, pure attention-based explanations are unable to support the growing
complexity of LMs, and cannot reason about their decision-making processes. We
propose LMExplainer, a knowledge-enhanced explainer for LMs that can provide
human-understandable explanations. We use a knowledge graph (KG) and a graph
attention neural network to extract the key decision signals of the LM. We
further explore whether interpretation can also help the AI understand the task
better. Our experimental results show that LMExplainer outperforms existing
LM+KG methods on CommonsenseQA and OpenBookQA. We compare the explanation
results with generated explanation methods and human-annotated results. The
comparison shows our method can provide more comprehensive and clearer
explanations. LMExplainer demonstrates the potential to enhance model
performance and furnish explanations for the LM reasoning process in natural
language.
","[{'version': 'v1', 'created': 'Wed, 29 Mar 2023 08:59:44 GMT'}, {'version': 'v2', 'created': 'Thu, 3 Aug 2023 23:23:43 GMT'}]",2023-08-07,"[['Chen', 'Zichen', ''], ['Singh', 'Ambuj K', ''], ['Sra', 'Misha', '']]"
2107.02012,Prathmesh Pathwar,"Prathmesh Pathwar, Simran Gill",Tackling COVID-19 Infodemic using Deep Learning,"15 pages, 4 figures, Accepted in 4th International Conference on
  Computational Intelligence and Data Engineering",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Humanity is battling one of the most deleterious virus in modern history, the
COVID-19 pandemic, but along with the pandemic there's an infodemic permeating
the pupil and society with misinformation which exacerbates the current malady.
We try to detect and classify fake news on online media to detect fake
information relating to COVID-19 and coronavirus. The dataset contained fake
posts, articles and news gathered from fact checking websites like politifact
whereas real tweets were taken from verified twitter handles. We incorporated
multiple conventional classification techniques like Naive Bayes, KNN, Gradient
Boost and Random Forest along with Deep learning approaches, specifically CNN,
RNN, DNN and the ensemble model RMDL. We analyzed these approaches with two
feature extraction techniques, TF-IDF and GloVe Word Embeddings which would
provide deeper insights into the dataset containing COVID-19 info on online
media.
","[{'version': 'v1', 'created': 'Thu, 1 Jul 2021 11:07:47 GMT'}]",2021-07-06,"[['Pathwar', 'Prathmesh', ''], ['Gill', 'Simran', '']]"
cs/0408060,Docteur Francois Trouilleux,"Gabriel G. Bes (GRIL), Lionel Lamadon (GRIL), Francois Trouilleux
  (GRIL)",Verbal chunk extraction in French using limited resources,,,,,cs.CL,,"  A way of extracting French verbal chunks, inflected and infinitive, is
explored and tested on effective corpus. Declarative morphological and local
grammar rules specifying chunks and some simple contextual structures are used,
relying on limited lexical information and some simple heuristic/statistic
properties obtained from restricted corpora. The specific goals, the
architecture and the formalism of the system, the linguistic information on
which it relies and the obtained results on effective corpus are presented.
","[{'version': 'v1', 'created': 'Thu, 26 Aug 2004 12:44:15 GMT'}]",2007-05-23,"[['Bes', 'Gabriel G.', '', 'GRIL'], ['Lamadon', 'Lionel', '', 'GRIL'], ['Trouilleux', 'Francois', '', 'GRIL']]"
2201.02740,Shane Storks,"Shane Storks, Qiaozi Gao, Aishwarya Reganti, Govind Thattai","Best of Both Worlds: A Hybrid Approach for Multi-Hop Explanation with
  Declarative Facts",Accepted to CLeaR Workshop @ AAAI 2022,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language-enabled AI systems can answer complex, multi-hop questions to high
accuracy, but supporting answers with evidence is a more challenging task which
is important for the transparency and trustworthiness to users. Prior work in
this area typically makes a trade-off between efficiency and accuracy;
state-of-the-art deep neural network systems are too cumbersome to be useful in
large-scale applications, while the fastest systems lack reliability. In this
work, we integrate fast syntactic methods with powerful semantic methods for
multi-hop explanation generation based on declarative facts. Our best system,
which learns a lightweight operation to simulate multi-hop reasoning over
pieces of evidence and fine-tunes language models to re-rank generated
explanation chains, outperforms a purely syntactic baseline from prior work by
up to 7% in gold explanation retrieval rate.
","[{'version': 'v1', 'created': 'Fri, 17 Dec 2021 20:27:48 GMT'}]",2022-01-11,"[['Storks', 'Shane', ''], ['Gao', 'Qiaozi', ''], ['Reganti', 'Aishwarya', ''], ['Thattai', 'Govind', '']]"
2305.16340,Yinghan Long,"Yinghan Long, Sayeed Shafayet Chowdhury, Kaushik Roy",Segmented Recurrent Transformer: An Efficient Sequence-to-Sequence Model,EMNLP 2023 Findings,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transformers have shown dominant performance across a range of domains
including language and vision. However, their computational cost grows
quadratically with the sequence length, making their usage prohibitive for
resource-constrained applications. To counter this, our approach is to divide
the whole sequence into segments and apply attention to the individual
segments. We propose a segmented recurrent transformer (SRformer) that combines
segmented (local) attention with recurrent attention. The loss caused by
reducing the attention window length is compensated by aggregating information
across segments with recurrent attention. SRformer leverages Recurrent
Accumulate-and-Fire (RAF) neurons' inherent memory to update the cumulative
product of keys and values. The segmented attention and lightweight RAF neurons
ensure the efficiency of the proposed transformer. Such an approach leads to
models with sequential processing capability at a lower computation/memory
cost. We apply the proposed method to T5 and BART transformers. The modified
models are tested on summarization datasets including CNN-dailymail, XSUM,
ArXiv, and MediaSUM. Notably, using segmented inputs of varied sizes, the
proposed model achieves $6-22\%$ higher ROUGE1 scores than a segmented
transformer and outperforms other recurrent transformer approaches.
Furthermore, compared to full attention, the proposed model reduces the
computational complexity of cross attention by around $40\%$.
","[{'version': 'v1', 'created': 'Wed, 24 May 2023 03:47:22 GMT'}, {'version': 'v2', 'created': 'Wed, 11 Oct 2023 05:32:13 GMT'}, {'version': 'v3', 'created': 'Mon, 23 Oct 2023 01:44:58 GMT'}]",2023-10-24,"[['Long', 'Yinghan', ''], ['Chowdhury', 'Sayeed Shafayet', ''], ['Roy', 'Kaushik', '']]"
2010.04480,Marina Fomicheva,"Marina Fomicheva, Shuo Sun, Erick Fonseca, Chrysoula Zerva,
  Fr\'ed\'eric Blain, Vishrav Chaudhary, Francisco Guzm\'an, Nina Lopatina,
  Lucia Specia and Andr\'e F. T. Martins",MLQE-PE: A Multilingual Quality Estimation and Post-Editing Dataset,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present MLQE-PE, a new dataset for Machine Translation (MT) Quality
Estimation (QE) and Automatic Post-Editing (APE). The dataset contains eleven
language pairs, with human labels for up to 10,000 translations per language
pair in the following formats: sentence-level direct assessments and
post-editing effort, and word-level good/bad labels. It also contains the
post-edited sentences, as well as titles of the articles where the sentences
were extracted from, and the neural MT models used to translate the text.
","[{'version': 'v1', 'created': 'Fri, 9 Oct 2020 10:12:02 GMT'}, {'version': 'v2', 'created': 'Thu, 16 Sep 2021 07:35:16 GMT'}, {'version': 'v3', 'created': 'Mon, 11 Oct 2021 09:31:35 GMT'}]",2021-10-12,"[['Fomicheva', 'Marina', ''], ['Sun', 'Shuo', ''], ['Fonseca', 'Erick', ''], ['Zerva', 'Chrysoula', ''], ['Blain', 'Frédéric', ''], ['Chaudhary', 'Vishrav', ''], ['Guzmán', 'Francisco', ''], ['Lopatina', 'Nina', ''], ['Specia', 'Lucia', ''], ['Martins', 'André F. T.', '']]"
1908.05161,Oren Barkan,"Oren Barkan, Noam Razin, Itzik Malkiel, Ori Katz, Avi Caciularu, Noam
  Koenigstein","Scalable Attentive Sentence-Pair Modeling via Distilled Sentence
  Embedding",In Proceedings of AAAI 2020,,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent state-of-the-art natural language understanding models, such as BERT
and XLNet, score a pair of sentences (A and B) using multiple cross-attention
operations - a process in which each word in sentence A attends to all words in
sentence B and vice versa. As a result, computing the similarity between a
query sentence and a set of candidate sentences, requires the propagation of
all query-candidate sentence-pairs throughout a stack of cross-attention
layers. This exhaustive process becomes computationally prohibitive when the
number of candidate sentences is large. In contrast, sentence embedding
techniques learn a sentence-to-vector mapping and compute the similarity
between the sentence vectors via simple elementary operations. In this paper,
we introduce Distilled Sentence Embedding (DSE) - a model that is based on
knowledge distillation from cross-attentive models, focusing on sentence-pair
tasks. The outline of DSE is as follows: Given a cross-attentive teacher model
(e.g. a fine-tuned BERT), we train a sentence embedding based student model to
reconstruct the sentence-pair scores obtained by the teacher model. We
empirically demonstrate the effectiveness of DSE on five GLUE sentence-pair
tasks. DSE significantly outperforms several ELMO variants and other sentence
embedding methods, while accelerating computation of the query-candidate
sentence-pairs similarities by several orders of magnitude, with an average
relative degradation of 4.6% compared to BERT. Furthermore, we show that DSE
produces sentence embeddings that reach state-of-the-art performance on
universal sentence representation benchmarks. Our code is made publicly
available at https://github.com/microsoft/Distilled-Sentence-Embedding.
","[{'version': 'v1', 'created': 'Wed, 14 Aug 2019 15:06:48 GMT'}, {'version': 'v2', 'created': 'Tue, 10 Sep 2019 17:57:57 GMT'}, {'version': 'v3', 'created': 'Thu, 21 Nov 2019 06:38:18 GMT'}]",2019-11-22,"[['Barkan', 'Oren', ''], ['Razin', 'Noam', ''], ['Malkiel', 'Itzik', ''], ['Katz', 'Ori', ''], ['Caciularu', 'Avi', ''], ['Koenigstein', 'Noam', '']]"
1803.05566,Jinyu Li,"Jinyu Li, Guoli Ye, Amit Das, Rui Zhao, Yifan Gong",Advancing Acoustic-to-Word CTC Model,Accepted at ICASSP 2018,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The acoustic-to-word model based on the connectionist temporal classification
(CTC) criterion was shown as a natural end-to-end (E2E) model directly
targeting words as output units. However, the word-based CTC model suffers from
the out-of-vocabulary (OOV) issue as it can only model limited number of words
in the output layer and maps all the remaining words into an OOV output node.
Hence, such a word-based CTC model can only recognize the frequent words
modeled by the network output nodes. Our first attempt to improve the
acoustic-to-word model is a hybrid CTC model which consults a letter-based CTC
when the word-based CTC model emits OOV tokens during testing time. Then, we
propose a much better solution by training a mixed-unit CTC model which
decomposes all the OOV words into sequences of frequent words and multi-letter
units. Evaluated on a 3400 hours Microsoft Cortana voice assistant task, the
final acoustic-to-word solution improves the baseline word-based CTC by
relative 12.09% word error rate (WER) reduction when combined with our proposed
attention CTC. Such an E2E model without using any language model (LM) or
complex decoder outperforms the traditional context-dependent phoneme CTC which
has strong LM and decoder by relative 6.79%.
","[{'version': 'v1', 'created': 'Thu, 15 Mar 2018 01:25:17 GMT'}]",2018-03-16,"[['Li', 'Jinyu', ''], ['Ye', 'Guoli', ''], ['Das', 'Amit', ''], ['Zhao', 'Rui', ''], ['Gong', 'Yifan', '']]"
1708.01009,Stephen Merity,"Stephen Merity, Bryan McCann, Richard Socher",Revisiting Activation Regularization for Language RNNs,,,,,cs.CL cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recurrent neural networks (RNNs) serve as a fundamental building block for
many sequence tasks across natural language processing. Recent research has
focused on recurrent dropout techniques or custom RNN cells in order to improve
performance. Both of these can require substantial modifications to the machine
learning model or to the underlying RNN configurations. We revisit traditional
regularization techniques, specifically L2 regularization on RNN activations
and slowness regularization over successive hidden states, to improve the
performance of RNNs on the task of language modeling. Both of these techniques
require minimal modification to existing RNN architectures and result in
performance improvements comparable or superior to more complicated
regularization techniques or custom cell architectures. These regularization
techniques can be used without any modification on optimized LSTM
implementations such as the NVIDIA cuDNN LSTM.
","[{'version': 'v1', 'created': 'Thu, 3 Aug 2017 05:53:53 GMT'}]",2017-08-04,"[['Merity', 'Stephen', ''], ['McCann', 'Bryan', ''], ['Socher', 'Richard', '']]"
1703.07713,Zhao Meng,"Zhao Meng, Lili Mou, Zhi Jin","Hierarchical RNN with Static Sentence-Level Attention for Text-Based
  Speaker Change Detection","In Proceedings of the ACM on Conference on Information and Knowledge
  Management (CIKM), 2017",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Speaker change detection (SCD) is an important task in dialog modeling. Our
paper addresses the problem of text-based SCD, which differs from existing
audio-based studies and is useful in various scenarios, for example, processing
dialog transcripts where speaker identities are missing (e.g., OpenSubtitle),
and enhancing audio SCD with textual information. We formulate text-based SCD
as a matching problem of utterances before and after a certain decision point;
we propose a hierarchical recurrent neural network (RNN) with static
sentence-level attention. Experimental results show that neural networks
consistently achieve better performance than feature-based approaches, and that
our attention-based model significantly outperforms non-attention neural
networks.
","[{'version': 'v1', 'created': 'Wed, 22 Mar 2017 15:42:28 GMT'}, {'version': 'v2', 'created': 'Fri, 28 Sep 2018 17:56:14 GMT'}]",2018-10-01,"[['Meng', 'Zhao', ''], ['Mou', 'Lili', ''], ['Jin', 'Zhi', '']]"
2402.14778,Nadezhda Chirkova,"Nadezhda Chirkova, Vassilina Nikoulina","Zero-shot cross-lingual transfer in instruction tuning of large language
  model",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Instruction tuning (IT) is widely used to teach pretrained large language
models (LLMs) to follow arbitrary instructions, but is under-studied in
multilingual settings. In this work, we conduct a systematic study of zero-shot
cross-lingual transfer in IT, when an LLM is instruction-tuned on English-only
data and then tested on user prompts in other languages. We investigate the
influence of model configuration choices and devise a multi-facet evaluation
strategy for multilingual instruction following. We find that cross-lingual
transfer does happen successfully in IT even if all stages of model training
are English-centric, but only if multiliguality is taken into account in
hyperparameter tuning and with large enough IT data. English-trained LLMs are
capable of generating correct-language, comprehensive and helpful responses in
the other languages, but suffer from low factuality and may occasionally have
fluency errors.
","[{'version': 'v1', 'created': 'Thu, 22 Feb 2024 18:37:33 GMT'}]",2024-02-23,"[['Chirkova', 'Nadezhda', ''], ['Nikoulina', 'Vassilina', '']]"
2004.08726,Aylin Caliskan,"Autumn Toney, Akshat Pandey, Wei Guo, David Broniatowski, Aylin
  Caliskan","Automatically Characterizing Targeted Information Operations Through
  Biases Present in Discourse on Twitter","5 pages, 4 tables, 1 figure",,,,cs.CY cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This paper considers the problem of automatically characterizing overall
attitudes and biases that may be associated with emerging information
operations via artificial intelligence. Accurate analysis of these emerging
topics usually requires laborious, manual analysis by experts to annotate
millions of tweets to identify biases in new topics. We introduce extensions of
the Word Embedding Association Test from Caliskan et al. to a new domain
(Caliskan, 2017). Our practical and unsupervised method is used to quantify
biases promoted in information operations. We validate our method using known
information operation-related tweets from Twitter's Transparency Report. We
perform a case study on the COVID-19 pandemic to evaluate our method's
performance on non-labeled Twitter data, demonstrating its usability in
emerging domains.
","[{'version': 'v1', 'created': 'Sat, 18 Apr 2020 23:03:14 GMT'}, {'version': 'v2', 'created': 'Sat, 22 Aug 2020 20:16:21 GMT'}, {'version': 'v3', 'created': 'Fri, 4 Dec 2020 02:12:53 GMT'}]",2020-12-07,"[['Toney', 'Autumn', ''], ['Pandey', 'Akshat', ''], ['Guo', 'Wei', ''], ['Broniatowski', 'David', ''], ['Caliskan', 'Aylin', '']]"
2205.05730,Leshem Choshen,"Leshem Choshen, Ofir Shifman, Omri Abend","Some Grammatical Errors are Frequent, Others are Important",,,,,cs.CL cs.AI cs.CY,http://creativecommons.org/licenses/by/4.0/,"  In Grammatical Error Correction, systems are evaluated by the number of
errors they correct. However, no one has assessed whether all error types are
equally important. We provide and apply a method to quantify the importance of
different grammatical error types to humans. We show that some rare errors are
considered disturbing while other common ones are not. This affects possible
directions to improve both systems and their evaluation.
","[{'version': 'v1', 'created': 'Wed, 11 May 2022 18:59:20 GMT'}]",2022-05-13,"[['Choshen', 'Leshem', ''], ['Shifman', 'Ofir', ''], ['Abend', 'Omri', '']]"
1903.05280,Ryan Ong,Ryan Ong,Offensive Language Analysis using Deep Learning Architecture,"6 pages, 8 tables, 1 figure",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  SemEval-2019 Task 6 (Zampieri et al., 2019b) requires us to identify and
categorise offensive language in social media. In this paper we will describe
the process we took to tackle this challenge. Our process is heavily inspired
by Sosa (2017) where he proposed CNN-LSTM and LSTM-CNN models to conduct
twitter sentiment analysis. We decided to follow his approach as well as
further his work by testing out different variations of RNN models with CNN.
Specifically, we have divided the challenge into two parts: data processing and
sampling and choosing the optimal deep learning architecture. In preprocessing,
we experimented with two techniques, SMOTE and Class Weights to counter the
imbalance between classes. Once we are happy with the quality of our input
data, we proceed to choosing the optimal deep learning architecture for this
task. Given the quality and quantity of data we have been given, we found that
the addition of CNN layer provides very little to no additional improvement to
our model's performance and sometimes even lead to a decrease in our F1-score.
In the end, the deep learning architecture that gives us the highest macro
F1-score is a simple BiLSTM-CNN.
","[{'version': 'v1', 'created': 'Tue, 12 Mar 2019 09:36:25 GMT'}, {'version': 'v2', 'created': 'Fri, 15 Mar 2019 15:01:47 GMT'}, {'version': 'v3', 'created': 'Tue, 19 Mar 2019 17:23:43 GMT'}]",2019-03-20,"[['Ong', 'Ryan', '']]"
1606.03398,Lidong Bing,"Lidong Bing, Bhuwan Dhingra, Kathryn Mazaitis, Jong Hyuk Park, William
  W. Cohen","Bootstrapping Distantly Supervised IE using Joint Learning and Small
  Well-structured Corpora","10 pages, 5 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a framework to improve performance of distantly-supervised
relation extraction, by jointly learning to solve two related tasks:
concept-instance extraction and relation extraction. We combine this with a
novel use of document structure: in some small, well-structured corpora,
sections can be identified that correspond to relation arguments, and
distantly-labeled examples from such sections tend to have good precision.
Using these as seeds we extract additional relation examples by applying label
propagation on a graph composed of noisy examples extracted from a large
unstructured testing corpus. Combined with the soft constraint that concept
examples should have the same type as the second argument of the relation, we
get significant improvements over several state-of-the-art approaches to
distantly-supervised relation extraction.
","[{'version': 'v1', 'created': 'Fri, 10 Jun 2016 17:14:11 GMT'}, {'version': 'v2', 'created': 'Thu, 11 Aug 2016 01:22:30 GMT'}]",2016-08-12,"[['Bing', 'Lidong', ''], ['Dhingra', 'Bhuwan', ''], ['Mazaitis', 'Kathryn', ''], ['Park', 'Jong Hyuk', ''], ['Cohen', 'William W.', '']]"
2306.07650,Yuchen Han,"Yuchen Han, Chen Xu, Tong Xiao and Jingbo Zhu","Modality Adaption or Regularization? A Case Study on End-to-End Speech
  Translation",ACL 2023 Main Conference,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-training and fine-tuning is a paradigm for alleviating the data scarcity
problem in end-to-end speech translation (E2E ST). The commonplace ""modality
gap"" between speech and text data often leads to inconsistent inputs between
pre-training and fine-tuning. However, we observe that this gap occurs in the
early stages of fine-tuning, but does not have a major impact on the final
performance. On the other hand, we find that there has another gap, which we
call the ""capacity gap"": high resource tasks (such as ASR and MT) always
require a large model to fit, when the model is reused for a low resource task
(E2E ST), it will get a sub-optimal performance due to the over-fitting. In a
case study, we find that the regularization plays a more important role than
the well-designed modality adaption method, which achieves 29.0 for en-de and
40.3 for en-fr on the MuST-C dataset. Code and models are available at
https://github.com/hannlp/TAB.
","[{'version': 'v1', 'created': 'Tue, 13 Jun 2023 09:42:48 GMT'}]",2023-06-14,"[['Han', 'Yuchen', ''], ['Xu', 'Chen', ''], ['Xiao', 'Tong', ''], ['Zhu', 'Jingbo', '']]"
1912.00567,Tao Wang,Tao Wang and Shaohui Kuang and Deyi Xiong and Ant\'onio Branco,Merging External Bilingual Pairs into Neural Machine Translation,"7 pages, 3 figures, 5 tables",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As neural machine translation (NMT) is not easily amenable to explicit
correction of errors, incorporating pre-specified translations into NMT is
widely regarded as a non-trivial challenge. In this paper, we propose and
explore three methods to endow NMT with pre-specified bilingual pairs. Instead,
for instance, of modifying the beam search algorithm during decoding or making
complex modifications to the attention mechanism --- mainstream approaches to
tackling this challenge ---, we experiment with the training data being
appropriately pre-processed to add information about pre-specified
translations. Extra embeddings are also used to distinguish pre-specified
tokens from the other tokens. Extensive experimentation and analysis indicate
that over 99% of the pre-specified phrases are successfully translated (given a
85% baseline) and that there is also a substantive improvement in translation
quality with the methods explored here.
","[{'version': 'v1', 'created': 'Mon, 2 Dec 2019 03:05:50 GMT'}]",2019-12-03,"[['Wang', 'Tao', ''], ['Kuang', 'Shaohui', ''], ['Xiong', 'Deyi', ''], ['Branco', 'António', '']]"
2112.07327,Lei Li,"Lei Li, Yankai Lin, Xuancheng Ren, Guangxiang Zhao, Peng Li, Jie Zhou,
  Xu Sun","Model Uncertainty-Aware Knowledge Amalgamation for Pre-Trained Language
  Models",,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  As many fine-tuned pre-trained language models~(PLMs) with promising
performance are generously released, investigating better ways to reuse these
models is vital as it can greatly reduce the retraining computational cost and
the potential environmental side-effects. In this paper, we explore a novel
model reuse paradigm, Knowledge Amalgamation~(KA) for PLMs. Without human
annotations available, KA aims to merge the knowledge from different
teacher-PLMs, each of which specializes in a different classification problem,
into a versatile student model. The achieve this, we design a Model
Uncertainty--aware Knowledge Amalgamation~(MUKA) framework, which identifies
the potential adequate teacher using Monte-Carlo Dropout for approximating the
golden supervision to guide the student. Experimental results demonstrate that
MUKA achieves substantial improvements over baselines on benchmark datasets.
Further analysis shows that MUKA can generalize well under several complicate
settings with multiple teacher models, heterogeneous teachers, and even
cross-dataset teachers.
","[{'version': 'v1', 'created': 'Tue, 14 Dec 2021 12:26:24 GMT'}]",2021-12-15,"[['Li', 'Lei', ''], ['Lin', 'Yankai', ''], ['Ren', 'Xuancheng', ''], ['Zhao', 'Guangxiang', ''], ['Li', 'Peng', ''], ['Zhou', 'Jie', ''], ['Sun', 'Xu', '']]"
1907.03040,Guan-Lin Chao,"Guan-Lin Chao, Ian Lane","BERT-DST: Scalable End-to-End Dialogue State Tracking with Bidirectional
  Encoder Representations from Transformer",Published in Interspeech 2019,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  An important yet rarely tackled problem in dialogue state tracking (DST) is
scalability for dynamic ontology (e.g., movie, restaurant) and unseen slot
values. We focus on a specific condition, where the ontology is unknown to the
state tracker, but the target slot value (except for none and dontcare),
possibly unseen during training, can be found as word segment in the dialogue
context. Prior approaches often rely on candidate generation from n-gram
enumeration or slot tagger outputs, which can be inefficient or suffer from
error propagation. We propose BERT-DST, an end-to-end dialogue state tracker
which directly extracts slot values from the dialogue context. We use BERT as
dialogue context encoder whose contextualized language representations are
suitable for scalable DST to identify slot values from their semantic context.
Furthermore, we employ encoder parameter sharing across all slots with two
advantages: (1) Number of parameters does not grow linearly with the ontology.
(2) Language representation knowledge can be transferred among slots. Empirical
evaluation shows BERT-DST with cross-slot parameter sharing outperforms prior
work on the benchmark scalable DST datasets Sim-M and Sim-R, and achieves
competitive performance on the standard DSTC2 and WOZ 2.0 datasets.
","[{'version': 'v1', 'created': 'Fri, 5 Jul 2019 22:41:02 GMT'}]",2019-07-09,"[['Chao', 'Guan-Lin', ''], ['Lane', 'Ian', '']]"
2306.11825,Sidi Lu,"Sidi Lu and Wenbo Zhao and Chenyang Tao and Arpit Gupta and Shanchan
  Wu and Tagyoung Chung and Nanyun Peng",On Compositionality and Improved Training of NADO,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  NeurAlly-Decomposed Oracle (NADO) is a powerful approach for controllable
generation with large language models. Differentiating from finetuning/prompt
tuning, it has the potential to avoid catastrophic forgetting of the large base
model and achieve guaranteed convergence to an entropy-maximized closed-form
solution without significantly limiting the model capacity. Despite its
success, several challenges arise when applying NADO to more complex scenarios.
First, the best practice of using NADO for the composition of multiple control
signals is under-explored. Second, vanilla NADO suffers from gradient vanishing
for low-probability control signals and is highly reliant on the
forward-consistency regularization. In this paper, we study the aforementioned
challenges when using NADO theoretically and empirically. We show we can
achieve guaranteed compositional generalization of NADO with a certain
practice, and propose a novel alternative parameterization of NADO to perfectly
guarantee the forward-consistency. We evaluate the improved training of NADO,
i.e. NADO++, on CommonGen. Results show that NADO++ improves the effectiveness
of the algorithm in multiple aspects.
","[{'version': 'v1', 'created': 'Tue, 20 Jun 2023 18:36:52 GMT'}]",2023-06-22,"[['Lu', 'Sidi', ''], ['Zhao', 'Wenbo', ''], ['Tao', 'Chenyang', ''], ['Gupta', 'Arpit', ''], ['Wu', 'Shanchan', ''], ['Chung', 'Tagyoung', ''], ['Peng', 'Nanyun', '']]"
1906.02671,Nicholas Waytowich,"Nicholas Waytowich, Sean L. Barton, Vernon Lawhern, Ethan Stump and
  Garrett Warnell","Grounding Natural Language Commands to StarCraft II Game States for
  Narration-Guided Reinforcement Learning","10 pages, 3 figures. Published at SPIE 2019",,,,cs.MM cs.CL cs.LG cs.NE cs.RO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While deep reinforcement learning techniques have led to agents that are
successfully able to learn to perform a number of tasks that had been
previously unlearnable, these techniques are still susceptible to the
longstanding problem of {\em reward sparsity}. This is especially true for
tasks such as training an agent to play StarCraft II, a real-time strategy game
where reward is only given at the end of a game which is usually very long.
While this problem can be addressed through reward shaping, such approaches
typically require a human expert with specialized knowledge. Inspired by the
vision of enabling reward shaping through the more-accessible paradigm of
natural-language narration, we investigate to what extent we can contextualize
these narrations by grounding them to the goal-specific states. We present a
mutual-embedding model using a multi-input deep-neural network that projects a
sequence of natural language commands into the same high-dimensional
representation space as corresponding goal states. We show that using this
model we can learn an embedding space with separable and distinct clusters that
accurately maps natural-language commands to corresponding game states . We
also discuss how this model can allow for the use of narrations as a robust
form of reward shaping to improve RL performance and efficiency.
","[{'version': 'v1', 'created': 'Wed, 24 Apr 2019 17:43:40 GMT'}]",2019-06-07,"[['Waytowich', 'Nicholas', ''], ['Barton', 'Sean L.', ''], ['Lawhern', 'Vernon', ''], ['Stump', 'Ethan', ''], ['Warnell', 'Garrett', '']]"
2006.03744,Mingjie Li,"Mingjie Li, Fuyu Wang, Xiaojun Chang and Xiaodan Liang","Auxiliary Signal-Guided Knowledge Encoder-Decoder for Medical Report
  Generation","11 pages, 3 figures",,,,cs.CV cs.CL eess.IV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Beyond the common difficulties faced in the natural image captioning, medical
report generation specifically requires the model to describe a medical image
with a fine-grained and semantic-coherence paragraph that should satisfy both
medical commonsense and logic. Previous works generally extract the global
image features and attempt to generate a paragraph that is similar to
referenced reports; however, this approach has two limitations. Firstly, the
regions of primary interest to radiologists are usually located in a small area
of the global image, meaning that the remainder parts of the image could be
considered as irrelevant noise in the training procedure. Secondly, there are
many similar sentences used in each medical report to describe the normal
regions of the image, which causes serious data bias. This deviation is likely
to teach models to generate these inessential sentences on a regular basis. To
address these problems, we propose an Auxiliary Signal-Guided Knowledge
Encoder-Decoder (ASGK) to mimic radiologists' working patterns. In more detail,
ASGK integrates internal visual feature fusion and external medical linguistic
information to guide medical knowledge transfer and learning. The core
structure of ASGK consists of a medical graph encoder and a natural language
decoder, inspired by advanced Generative Pre-Training (GPT). Experiments on the
CX-CHR dataset and our COVID-19 CT Report dataset demonstrate that our proposed
ASGK is able to generate a robust and accurate report, and moreover outperforms
state-of-the-art methods on both medical terminology classification and
paragraph generation metrics.
","[{'version': 'v1', 'created': 'Sat, 6 Jun 2020 01:00:15 GMT'}]",2020-06-09,"[['Li', 'Mingjie', ''], ['Wang', 'Fuyu', ''], ['Chang', 'Xiaojun', ''], ['Liang', 'Xiaodan', '']]"
2111.05068,Jiangwei Liu,"Songqiao Han, Hailiang Huang, Jiangwei Liu",Neural News Recommendation with Event Extraction,"11 pages, 4 figures, 2 tables",,,,cs.IR cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A key challenge of online news recommendation is to help users find articles
they are interested in. Traditional news recommendation methods usually use
single news information, which is insufficient to encode news and user
representation. Recent research uses multiple channel news information, e.g.,
title, category, and body, to enhance news and user representation. However,
these methods only use various attention mechanisms to fuse multi-view
embeddings without considering deep digging higher-level information contained
in the context. These methods encode news content on the word level and jointly
train the attention parameters in the recommendation network, leading to more
corpora being required to train the model. We propose an Event Extraction-based
News Recommendation (EENR) framework to overcome these shortcomings, utilizing
event extraction to abstract higher-level information. EENR also uses a
two-stage strategy to reduce parameters in subsequent parts of the
recommendation network. We train the Event Extraction module by external
corpora in the first stage and apply the trained model to the news
recommendation dataset to predict event-level information, including event
types, roles, and arguments, in the second stage. Then we fuse multiple channel
information, including event information, news title, and category, to encode
news and users. Extensive experiments on a real-world dataset show that our
EENR method can effectively improve the performance of news recommendations.
Finally, we also explore the reasonability of utilizing higher abstract level
information to substitute news body content.
","[{'version': 'v1', 'created': 'Tue, 9 Nov 2021 11:56:38 GMT'}, {'version': 'v2', 'created': 'Fri, 17 Dec 2021 08:48:03 GMT'}]",2021-12-20,"[['Han', 'Songqiao', ''], ['Huang', 'Hailiang', ''], ['Liu', 'Jiangwei', '']]"
2402.10051,Somnath Sendhil Kumar,"Somnath Sendhil Kumar, Dhruv Jain, Eshaan Agarwal, Raunak Pandey",SwissNYF: Tool Grounded LLM Agents for Black Box Setting,,,,,cs.AI cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  While Large Language Models (LLMs) have demonstrated enhanced capabilities in
function-calling, these advancements primarily rely on accessing the functions'
responses. This methodology is practical for simpler APIs but faces scalability
issues with irreversible APIs that significantly impact the system, such as a
database deletion API. Similarly, processes requiring extensive time for each
API call and those necessitating forward planning, like automated action
pipelines, present complex challenges. Furthermore, scenarios often arise where
a generalized approach is needed because algorithms lack direct access to the
specific implementations of these functions or secrets to use them. Traditional
tool planning methods are inadequate in these cases, compelling the need to
operate within black-box environments. Unlike their performance in tool
manipulation, LLMs excel in black-box tasks, such as program synthesis.
Therefore, we harness the program synthesis capabilities of LLMs to strategize
tool usage in black-box settings, ensuring solutions are verified prior to
implementation. We introduce TOPGUN, an ingeniously crafted approach leveraging
program synthesis for black box tool planning. Accompanied by SwissNYF, a
comprehensive suite that integrates black-box algorithms for planning and
verification tasks, addressing the aforementioned challenges and enhancing the
versatility and effectiveness of LLMs in complex API interactions. The public
code for SwissNYF is available at https://github.com/iclr-dummy-user/SwissNYF.
","[{'version': 'v1', 'created': 'Thu, 15 Feb 2024 16:15:38 GMT'}]",2024-02-16,"[['Kumar', 'Somnath Sendhil', ''], ['Jain', 'Dhruv', ''], ['Agarwal', 'Eshaan', ''], ['Pandey', 'Raunak', '']]"
2002.06670,Daniel Ranti,"Daniel Ranti, Katie Hanss, Shan Zhao, Varun Arvind, Joseph Titano,
  Anthony Costa, Eric Oermann","The Utility of General Domain Transfer Learning for Medical Language
  Tasks","8 pages, 5 figures, 2 tables",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The purpose of this study is to analyze the efficacy of transfer learning
techniques and transformer-based models as applied to medical natural language
processing (NLP) tasks, specifically radiological text classification. We used
1,977 labeled head CT reports, from a corpus of 96,303 total reports, to
evaluate the efficacy of pretraining using general domain corpora and a
combined general and medical domain corpus with a bidirectional representations
from transformers (BERT) model for the purpose of radiological text
classification. Model performance was benchmarked to a logistic regression
using bag-of-words vectorization and a long short-term memory (LSTM)
multi-label multi-class classification model, and compared to the published
literature in medical text classification. The BERT models using either set of
pretrained checkpoints outperformed the logistic regression model, achieving
sample-weighted average F1-scores of 0.87 and 0.87 for the general domain model
and the combined general and biomedical-domain model. General text transfer
learning may be a viable technique to generate state-of-the-art results within
medical NLP tasks on radiological corpora, outperforming other deep models such
as LSTMs. The efficacy of pretraining and transformer-based models could serve
to facilitate the creation of groundbreaking NLP models in the uniquely
challenging data environment of medical text.
","[{'version': 'v1', 'created': 'Sun, 16 Feb 2020 20:20:38 GMT'}]",2020-02-19,"[['Ranti', 'Daniel', ''], ['Hanss', 'Katie', ''], ['Zhao', 'Shan', ''], ['Arvind', 'Varun', ''], ['Titano', 'Joseph', ''], ['Costa', 'Anthony', ''], ['Oermann', 'Eric', '']]"
2203.07828,Taichi Iki,Taichi Iki and Akiko Aizawa,"Do BERTs Learn to Use Browser User Interface? Exploring Multi-Step Tasks
  with Unified Vision-and-Language BERTs",Work in Progress,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Pre-trained Transformers are good foundations for unified multi-task models
owing to their task-agnostic representation. Pre-trained Transformers are often
combined with text-to-text framework to execute multiple tasks by a single
model. Performing a task through a graphical user interface (GUI) is another
candidate to accommodate various tasks, including multi-step tasks with vision
and language inputs. However, few papers combine pre-trained Transformers with
performing through GUI. To fill this gap, we explore a framework in which a
model performs a task by manipulating the GUI implemented with web pages in
multiple steps. We develop task pages with and without page transitions and
propose a BERT extension for the framework. We jointly trained our BERT
extension with those task pages, and made the following observations. (1) The
model learned to use both task pages with and without page transition. (2) In
four out of five tasks without page transitions, the model performs greater
than 75% of the performance of the original BERT, which does not use browsers.
(3) The model did not generalize effectively on unseen tasks. These results
suggest that we can fine-tune BERTs to multi-step tasks through GUIs, and there
is room for improvement in their generalizability. Code will be available
online.
","[{'version': 'v1', 'created': 'Tue, 15 Mar 2022 12:32:28 GMT'}]",2022-03-16,"[['Iki', 'Taichi', ''], ['Aizawa', 'Akiko', '']]"
2310.14687,Yihan Cao,"Yihan Cao, Shuyi Chen, Ryan Liu, Zhiruo Wang, Daniel Fried","API-Assisted Code Generation for Question Answering on Varied Table
  Structures","EMNLP 2023 camera ready, 13 pages, 11 figures",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  A persistent challenge to table question answering (TableQA) by generating
executable programs has been adapting to varied table structures, typically
requiring domain-specific logical forms. In response, this paper introduces a
unified TableQA framework that: (1) provides a unified representation for
structured tables as multi-index Pandas data frames, (2) uses Python as a
powerful querying language, and (3) uses few-shot prompting to translate NL
questions into Python programs, which are executable on Pandas data frames.
Furthermore, to answer complex relational questions with extended program
functionality and external knowledge, our framework allows customized APIs that
Python programs can call. We experiment with four TableQA datasets that involve
tables of different structures -- relational, multi-table, and hierarchical
matrix shapes -- and achieve prominent improvements over past state-of-the-art
systems. In ablation studies, we (1) show benefits from our multi-index
representation and APIs over baselines that use only an LLM, and (2)
demonstrate that our approach is modular and can incorporate additional APIs.
","[{'version': 'v1', 'created': 'Mon, 23 Oct 2023 08:26:28 GMT'}]",2023-10-24,"[['Cao', 'Yihan', ''], ['Chen', 'Shuyi', ''], ['Liu', 'Ryan', ''], ['Wang', 'Zhiruo', ''], ['Fried', 'Daniel', '']]"
2401.14654,Alice Kwak,"Alice Saebom Kwak, Cheonkam Jeong, Ji Weon Lim, and Byeongcheol Min",A Korean Legal Judgment Prediction Dataset for Insurance Disputes,"5 pages, 1 figure",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This paper introduces a Korean legal judgment prediction (LJP) dataset for
insurance disputes. Successful LJP models on insurance disputes can benefit
insurance companies and their customers. It can save both sides' time and money
by allowing them to predict how the result would come out if they proceed to
the dispute mediation process. As is often the case with low-resource
languages, there is a limitation on the amount of data available for this
specific task. To mitigate this issue, we investigate how one can achieve a
good performance despite the limitation in data. In our experiment, we
demonstrate that Sentence Transformer Fine-tuning (SetFit, Tunstall et al.,
2022) is a good alternative to standard fine-tuning when training data are
limited. The models fine-tuned with the SetFit approach on our data show
similar performance to the Korean LJP benchmark models (Hwang et al., 2022)
despite the much smaller data size.
","[{'version': 'v1', 'created': 'Fri, 26 Jan 2024 05:26:27 GMT'}]",2024-01-29,"[['Kwak', 'Alice Saebom', ''], ['Jeong', 'Cheonkam', ''], ['Lim', 'Ji Weon', ''], ['Min', 'Byeongcheol', '']]"
2201.05230,Daniel Bauer,"Daniel Bauer (1), Tom Longley (2), Yueen Ma (1), Tony Wilson (2) ((1)
  Department of Computer Science, Columbia University, (2) Security Force
  Monitor, Human Rights Institute, Columbia Law School)","NLP in Human Rights Research -- Extracting Knowledge Graphs About Police
  and Army Units and Their Commanders","Equal contributions. for associated text corpus see
  https://github.com/security-force-monitor/nlp_starter_dataset",,,,cs.CL cs.CY,http://creativecommons.org/licenses/by/4.0/,"  In this working paper we explore the use of an NLP system to assist the work
of Security Force Monitor (SFM). SFM creates data about the organizational
structure, command personnel and operations of police, army and other security
forces, which assists human rights researchers, journalists and litigators in
their work to help identify and bring to account specific units and personnel
alleged to have committed abuses of human rights and international criminal
law. This working paper presents an NLP system that extracts from English
language news reports the names of security force units and the biographical
details of their personnel, and infers the formal relationship between them.
Published alongside this working paper are the system's code and training
dataset. We find that the experimental NLP system performs the task at a fair
to good level. Its performance is sufficient to justify further development
into a live workflow that will give insight into whether its performance
translates into savings in time and resource that would make it an effective
technical intervention.
","[{'version': 'v1', 'created': 'Thu, 13 Jan 2022 21:57:21 GMT'}]",2022-01-17,"[['Bauer', 'Daniel', ''], ['Longley', 'Tom', ''], ['Ma', 'Yueen', ''], ['Wilson', 'Tony', '']]"
2402.01427,Georgi Karadzhov,"Georgi Karadzhov, Andreas Vlachos, Tom Stafford",The effect of diversity on group decision-making,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We explore different aspects of cognitive diversity and its effect on the
success of group deliberation. To evaluate this, we use 500 dialogues from
small, online groups discussing the Wason Card Selection task - the DeliData
corpus. Leveraging the corpus, we perform quantitative analysis evaluating
three different measures of cognitive diversity. First, we analyse the effect
of group size as a proxy measure for diversity. Second, we evaluate the effect
of the size of the initial idea pool. Finally, we look into the content of the
discussion by analysing discussed solutions, discussion patterns, and how
conversational probing can improve those characteristics.
  Despite the reputation of groups for compounding bias, we show that small
groups can, through dialogue, overcome intuitive biases and improve individual
decision-making. Across a large sample and different operationalisations, we
consistently find that greater cognitive diversity is associated with more
successful group deliberation. Code and data used for the analysis are
available in the anonymised repository: https://anonymous.4open.science/
r/cogsci24-FD6D
","[{'version': 'v1', 'created': 'Fri, 2 Feb 2024 14:15:01 GMT'}]",2024-02-05,"[['Karadzhov', 'Georgi', ''], ['Vlachos', 'Andreas', ''], ['Stafford', 'Tom', '']]"
2308.08610,Eren Unlu Ph. D.,Eren Unlu,"FootGPT : A Large Language Model Development Experiment on a Minimal
  Setting","10 pages, 3 figures",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  With recent empirical observations, it has been argued that the most
significant aspect of developing accurate language models may be the proper
dataset content and training strategy compared to the number of neural
parameters, training duration or dataset size. Following this argument, we
opted to fine tune a one billion parameter size trained general purpose causal
language model with a dataset curated on team statistics of the Italian
football league first ten game weeks, using low rank adaptation. The limited
training dataset was compiled based on a framework where a powerful commercial
large language model provides distilled paragraphs and question answer pairs as
intended. The training duration was kept relatively short to provide a basis
for our minimal setting exploration. We share our key observations on the
process related to developing a specific purpose language model which is
intended to interpret soccer data with constrained resources in this article.
","[{'version': 'v1', 'created': 'Wed, 16 Aug 2023 18:03:22 GMT'}]",2023-08-21,"[['Unlu', 'Eren', '']]"
2206.12294,Luis Miguel Botelho,"Luis Botelho, Luis Nunes, Ricardo Ribeiro, and Rui J. Lopes","Learning Rhetorical Structure Theory-based descriptions of observed
  behaviour",,,,,cs.AI cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  In a previous paper, we have proposed a set of concepts, axiom schemata and
algorithms that can be used by agents to learn to describe their behaviour,
goals, capabilities, and environment. The current paper proposes a new set of
concepts, axiom schemata and algorithms that allow the agent to learn new
descriptions of an observed behaviour (e.g., perplexing actions), of its actor
(e.g., undesired propositions or actions), and of its environment (e.g.,
incompatible propositions). Each learned description (e.g., a certain action
prevents another action from being performed in the future) is represented by a
relationship between entities (either propositions or actions) and is learned
by the agent, just by observation, using domain-independent axiom schemata and
or learning algorithms. The relations used by agents to represent the
descriptions they learn were inspired on the Theory of Rhetorical Structure
(RST). The main contribution of the paper is the relation family Although,
inspired on the RST relation Concession. The accurate definition of the
relations of the family Although involves a set of deontic concepts whose
definition and corresponding algorithms are presented. The relations of the
family Although, once extracted from the agent's observations, express surprise
at the observed behaviour and, in certain circumstances, present a
justification for it.
  The paper shows results of the presented proposals in a demonstration
scenario, using implemented software.
","[{'version': 'v1', 'created': 'Fri, 24 Jun 2022 13:47:20 GMT'}]",2022-06-27,"[['Botelho', 'Luis', ''], ['Nunes', 'Luis', ''], ['Ribeiro', 'Ricardo', ''], ['Lopes', 'Rui J.', '']]"
2304.11960,"Philipp K\""uhn","Philipp Kuehn, Mike Schmidt, Markus Bayer, Christian Reuter",ThreatCrawl: A BERT-based Focused Crawler for the Cybersecurity Domain,"11 pages, 9 figures, 5 tables",,,,cs.CR cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Publicly available information contains valuable information for Cyber Threat
Intelligence (CTI). This can be used to prevent attacks that have already taken
place on other systems. Ideally, only the initial attack succeeds and all
subsequent ones are detected and stopped. But while there are different
standards to exchange this information, a lot of it is shared in articles or
blog posts in non-standardized ways. Manually scanning through multiple online
portals and news pages to discover new threats and extracting them is a
time-consuming task. To automize parts of this scanning process, multiple
papers propose extractors that use Natural Language Processing (NLP) to extract
Indicators of Compromise (IOCs) from documents. However, while this already
solves the problem of extracting the information out of documents, the search
for these documents is rarely considered. In this paper, a new focused crawler
is proposed called ThreatCrawl, which uses Bidirectional Encoder
Representations from Transformers (BERT)-based models to classify documents and
adapt its crawling path dynamically. While ThreatCrawl has difficulties to
classify the specific type of Open Source Intelligence (OSINT) named in texts,
e.g., IOC content, it can successfully find relevant documents and modify its
path accordingly. It yields harvest rates of up to 52%, which are, to the best
of our knowledge, better than the current state of the art.
","[{'version': 'v1', 'created': 'Mon, 24 Apr 2023 09:53:33 GMT'}, {'version': 'v2', 'created': 'Wed, 26 Apr 2023 13:25:45 GMT'}]",2023-04-27,"[['Kuehn', 'Philipp', ''], ['Schmidt', 'Mike', ''], ['Bayer', 'Markus', ''], ['Reuter', 'Christian', '']]"
2107.14641,Wout S. Lamers,"Wout S. Lamers (1), Kevin Boyack (2), Vincent Larivi\`ere (3), Cassidy
  R. Sugimoto (4), Nees Jan van Eck (1), Ludo Waltman (1), Dakota Murray (4)
  ((1) Centre for Science and Technology Studies, Leiden University, Leiden,
  Netherlands, (2) SciTech Strategies, Inc., Albuquerque, NM, USA, (3) \'Ecole
  de biblioth\'economie et des sciences de l'information, Universit\'e de
  Montr\'eal, Canada, (4) School of Informatics, Computing, and Engineering,
  Indiana University Bloomington, IN, USA)",Investigating Disagreement in the Scientific Literature,"49 pages, 10 figures",,,,cs.DL cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Disagreement is essential to scientific progress. However, the extent of
disagreement in science, its evolution over time, and the fields in which it
happens, remains poorly understood. Leveraging a massive collection of
English-language scientific texts, we develop a cue-phrase based approach to
identify instances of disagreement citations across more than four million
scientific articles. Using this method, we construct an indicator of
disagreement across scientific fields over the 2000-2015 period. In contrast
with black-box text classification methods, our framework is transparent and
easily interpretable. We reveal a disciplinary spectrum of disagreement, with
higher disagreement in the social sciences and lower disagreement in physics
and mathematics. However, detailed disciplinary analysis demonstrates
heterogeneity across sub-fields, revealing the importance of local disciplinary
cultures and epistemic characteristics of disagreement. Paper-level analysis
reveals notable episodes of disagreement in science, and illustrates how
methodological artifacts can confound analyses of scientific texts. These
findings contribute to a broader understanding of disagreement and establish a
foundation for future research to understanding key processes underlying
scientific progress.
","[{'version': 'v1', 'created': 'Fri, 30 Jul 2021 14:07:34 GMT'}, {'version': 'v2', 'created': 'Wed, 27 Oct 2021 21:53:51 GMT'}]",2021-10-29,"[['Lamers', 'Wout S.', ''], ['Boyack', 'Kevin', ''], ['Larivière', 'Vincent', ''], ['Sugimoto', 'Cassidy R.', ''], ['van Eck', 'Nees Jan', ''], ['Waltman', 'Ludo', ''], ['Murray', 'Dakota', '']]"
2310.18239,Yunhao Yang,"Yunhao Yang, Neel P. Bhatt, Tyler Ingebrand, William Ward, Steven
  Carr, Zhangyang Wang, Ufuk Topcu",Fine-Tuning Language Models Using Formal Methods Feedback,,,,,cs.AI cs.CL cs.FL,http://creativecommons.org/licenses/by/4.0/,"  Although pre-trained language models encode generic knowledge beneficial for
planning and control, they may fail to generate appropriate control policies
for domain-specific tasks. Existing fine-tuning methods use human feedback to
address this limitation, however, sourcing human feedback is labor intensive
and costly. We present a fully automated approach to fine-tune pre-trained
language models for applications in autonomous systems, bridging the gap
between generic knowledge and domain-specific requirements while reducing cost.
The method synthesizes automaton-based controllers from pre-trained models
guided by natural language task descriptions. These controllers are verifiable
against independently provided specifications within a world model, which can
be abstract or obtained from a high-fidelity simulator. Controllers with high
compliance with the desired specifications receive higher ranks, guiding the
iterative fine-tuning process. We provide quantitative evidences, primarily in
autonomous driving, to demonstrate the method's effectiveness across multiple
tasks. The results indicate an improvement in percentage of specifications
satisfied by the controller from 60% to 90%.
","[{'version': 'v1', 'created': 'Fri, 27 Oct 2023 16:24:24 GMT'}]",2023-10-30,"[['Yang', 'Yunhao', ''], ['Bhatt', 'Neel P.', ''], ['Ingebrand', 'Tyler', ''], ['Ward', 'William', ''], ['Carr', 'Steven', ''], ['Wang', 'Zhangyang', ''], ['Topcu', 'Ufuk', '']]"
2307.16630,Xinyu Zhang,"Xinyu Zhang, Hanbin Hong, Yuan Hong, Peng Huang, Binghui Wang,
  Zhongjie Ba, Kui Ren","Text-CRS: A Generalized Certified Robustness Framework against Textual
  Adversarial Attacks",To appear in IEEE S&P 2024,,,,cs.CR cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The language models, especially the basic text classification models, have
been shown to be susceptible to textual adversarial attacks such as synonym
substitution and word insertion attacks. To defend against such attacks, a
growing body of research has been devoted to improving the model robustness.
However, providing provable robustness guarantees instead of empirical
robustness is still widely unexplored. In this paper, we propose Text-CRS, a
generalized certified robustness framework for natural language processing
(NLP) based on randomized smoothing. To our best knowledge, existing certified
schemes for NLP can only certify the robustness against $\ell_0$ perturbations
in synonym substitution attacks. Representing each word-level adversarial
operation (i.e., synonym substitution, word reordering, insertion, and
deletion) as a combination of permutation and embedding transformation, we
propose novel smoothing theorems to derive robustness bounds in both
permutation and embedding space against such adversarial operations. To further
improve certified accuracy and radius, we consider the numerical relationships
between discrete words and select proper noise distributions for the randomized
smoothing. Finally, we conduct substantial experiments on multiple language
models and datasets. Text-CRS can address all four different word-level
adversarial operations and achieve a significant accuracy improvement. We also
provide the first benchmark on certified accuracy and radius of four word-level
operations, besides outperforming the state-of-the-art certification against
synonym substitution attacks.
","[{'version': 'v1', 'created': 'Mon, 31 Jul 2023 13:08:16 GMT'}]",2023-08-01,"[['Zhang', 'Xinyu', ''], ['Hong', 'Hanbin', ''], ['Hong', 'Yuan', ''], ['Huang', 'Peng', ''], ['Wang', 'Binghui', ''], ['Ba', 'Zhongjie', ''], ['Ren', 'Kui', '']]"
2110.01951,Ishani Mondal,"Ishani Mondal, Procheta Sen, Debasis Ganguly",Multi-Objective Few-shot Learning for Fair Classification,Accepted as a short paper in CIKM 2021,,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we propose a general framework for mitigating the disparities
of the predicted classes with respect to secondary attributes within the data
(e.g., race, gender etc.). Our proposed method involves learning a
multi-objective function that in addition to learning the primary objective of
predicting the primary class labels from the data, also employs a
clustering-based heuristic to minimize the disparities of the class label
distribution with respect to the cluster memberships, with the assumption that
each cluster should ideally map to a distinct combination of attribute values.
Experiments demonstrate effective mitigation of cognitive biases on a benchmark
dataset without the use of annotations of secondary attribute values (the
zero-shot case) or with the use of a small number of attribute value
annotations (the few-shot case).
","[{'version': 'v1', 'created': 'Tue, 5 Oct 2021 11:28:58 GMT'}]",2021-10-06,"[['Mondal', 'Ishani', ''], ['Sen', 'Procheta', ''], ['Ganguly', 'Debasis', '']]"
2305.15605,Eran Hirsch,"Eran Hirsch, Valentina Pyatkin, Ruben Wolhandler, Avi Caciularu, Asi
  Shefer, Ido Dagan",Revisiting Sentence Union Generation as a Testbed for Text Consolidation,Findings of the Association for Computational Linguistics (ACL 2023),,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Tasks involving text generation based on multiple input texts, such as
multi-document summarization, long-form question answering and contemporary
dialogue applications, challenge models for their ability to properly
consolidate partly-overlapping multi-text information. However, these tasks
entangle the consolidation phase with the often subjective and ill-defined
content selection requirement, impeding proper assessment of models'
consolidation capabilities. In this paper, we suggest revisiting the sentence
union generation task as an effective well-defined testbed for assessing text
consolidation capabilities, decoupling the consolidation challenge from
subjective content selection. To support research on this task, we present
refined annotation methodology and tools for crowdsourcing sentence union,
create the largest union dataset to date and provide an analysis of its rich
coverage of various consolidation aspects. We then propose a comprehensive
evaluation protocol for union generation, including both human and automatic
evaluation. Finally, as baselines, we evaluate state-of-the-art language models
on the task, along with a detailed analysis of their capacity to address
multi-text consolidation challenges and their limitations.
","[{'version': 'v1', 'created': 'Wed, 24 May 2023 22:34:01 GMT'}]",2023-05-26,"[['Hirsch', 'Eran', ''], ['Pyatkin', 'Valentina', ''], ['Wolhandler', 'Ruben', ''], ['Caciularu', 'Avi', ''], ['Shefer', 'Asi', ''], ['Dagan', 'Ido', '']]"
2402.10669,Guiming Hardy Chen,"Guiming Hardy Chen, Shunian Chen, Ziche Liu, Feng Jiang, Benyou Wang",Humans or LLMs as the Judge? A Study on Judgement Biases,19 pages,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Adopting human and large language models (LLM) as judges (\textit{a.k.a}
human- and LLM-as-a-judge) for evaluating the performance of existing LLMs has
recently gained attention. Nonetheless, this approach concurrently introduces
potential biases from human and LLM judges, questioning the reliability of the
evaluation results. In this paper, we propose a novel framework for
investigating 5 types of biases for LLM and human judges. We curate a dataset
with 142 samples referring to the revised Bloom's Taxonomy and conduct
thousands of human and LLM evaluations. Results show that human and LLM judges
are vulnerable to perturbations to various degrees, and that even the most
cutting-edge judges possess considerable biases. We further exploit their
weakness and conduct attacks on LLM judges. We hope that our work can notify
the community of the vulnerability of human- and LLM-as-a-judge against
perturbations, as well as the urgency of developing robust evaluation systems.
","[{'version': 'v1', 'created': 'Fri, 16 Feb 2024 13:21:06 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Feb 2024 17:00:15 GMT'}]",2024-02-21,"[['Chen', 'Guiming Hardy', ''], ['Chen', 'Shunian', ''], ['Liu', 'Ziche', ''], ['Jiang', 'Feng', ''], ['Wang', 'Benyou', '']]"
2210.07071,Yunhua Zhou,"Yunhua Zhou, Peiju Liu, Yuxin Wang, Xipeng Qiu",An Open-World Lottery Ticket for Out-of-Domain Intent Classification,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Most existing methods of Out-of-Domain (OOD) intent classification, which
rely on extensive auxiliary OOD corpora or specific training paradigms, are
underdeveloped in the underlying principle that the models should have
differentiated confidence in In- and Out-of-domain intent. In this work, we
demonstrate that calibrated subnetworks can be uncovered by pruning the
(poor-calibrated) overparameterized model. Calibrated confidence provided by
the subnetwork can better distinguish In- and Out-of-domain. Furthermore, we
theoretically bring new insights into why temperature scaling can differentiate
In- and Out-of-Domain intent and empirically extend the Lottery Ticket
Hypothesis to the open-world setting. Extensive experiments on three real-world
datasets demonstrate our approach can establish consistent improvements
compared with a suite of competitive baselines.
","[{'version': 'v1', 'created': 'Thu, 13 Oct 2022 14:58:35 GMT'}]",2022-10-14,"[['Zhou', 'Yunhua', ''], ['Liu', 'Peiju', ''], ['Wang', 'Yuxin', ''], ['Qiu', 'Xipeng', '']]"
2309.05619,Wei Du,"Wei Du, Laksh Advani, Yashmeet Gambhir, Daniel J Perry, Prashant
  Shiralkar, Zhengzheng Xing, and Aaron Colak","Effective Proxy for Human Labeling: Ensemble Disagreement Scores in
  Large Language Models for Industrial NLP","Camera ready version for 2023 EMNLP (The Third Workshop on Natural
  Language Generation, Evaluation, and Metrics (GEM))",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have demonstrated significant capability to
generalize across a large number of NLP tasks. For industry applications, it is
imperative to assess the performance of the LLM on unlabeled production data
from time to time to validate for a real-world setting. Human labeling to
assess model error requires considerable expense and time delay. Here we
demonstrate that ensemble disagreement scores work well as a proxy for human
labeling for language models in zero-shot, few-shot, and fine-tuned settings,
per our evaluation on keyphrase extraction (KPE) task. We measure fidelity of
the results by comparing to true error measured from human labeled ground
truth. We contrast with the alternative of using another LLM as a source of
machine labels, or silver labels. Results across various languages and domains
show disagreement scores provide a better estimation of model performance with
mean average error (MAE) as low as 0.4% and on average 13.8% better than using
silver labels.
","[{'version': 'v1', 'created': 'Mon, 11 Sep 2023 17:07:01 GMT'}, {'version': 'v2', 'created': 'Mon, 20 Nov 2023 01:24:40 GMT'}]",2023-11-21,"[['Du', 'Wei', ''], ['Advani', 'Laksh', ''], ['Gambhir', 'Yashmeet', ''], ['Perry', 'Daniel J', ''], ['Shiralkar', 'Prashant', ''], ['Xing', 'Zhengzheng', ''], ['Colak', 'Aaron', '']]"
2103.17191,Pushkar Mishra,"Pushkar Mishra, Helen Yannakoudakis, Ekaterina Shutova","Modeling Users and Online Communities for Abuse Detection: A Position on
  Ethics and Explainability",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Abuse on the Internet is an important societal problem of our time. Millions
of Internet users face harassment, racism, personal attacks, and other types of
abuse across various platforms. The psychological effects of abuse on
individuals can be profound and lasting. Consequently, over the past few years,
there has been a substantial research effort towards automated abusive language
detection in the field of NLP. In this position paper, we discuss the role that
modeling of users and online communities plays in abuse detection.
Specifically, we review and analyze the state of the art methods that leverage
user or community information to enhance the understanding and detection of
abusive language. We then explore the ethical challenges of incorporating user
and community information, laying out considerations to guide future research.
Finally, we address the topic of explainability in abusive language detection,
proposing properties that an explainable method should aim to exhibit. We
describe how user and community information can facilitate the realization of
these properties and discuss the effective operationalization of explainability
in view of the properties.
","[{'version': 'v1', 'created': 'Wed, 31 Mar 2021 16:20:37 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Apr 2021 12:35:02 GMT'}]",2021-04-15,"[['Mishra', 'Pushkar', ''], ['Yannakoudakis', 'Helen', ''], ['Shutova', 'Ekaterina', '']]"
2307.10587,Anand Kumar Rai,"Anand Kumar Rai, Siddharth D Jaiswal, Animesh Mukherjee","A Deep Dive into the Disparity of Word Error Rates Across Thousands of
  NPTEL MOOC Videos",,,,,cs.CL cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic speech recognition (ASR) systems are designed to transcribe spoken
language into written text and find utility in a variety of applications
including voice assistants and transcription services. However, it has been
observed that state-of-the-art ASR systems which deliver impressive benchmark
results, struggle with speakers of certain regions or demographics due to
variation in their speech properties. In this work, we describe the curation of
a massive speech dataset of 8740 hours consisting of $\sim9.8$K technical
lectures in the English language along with their transcripts delivered by
instructors representing various parts of Indian demography. The dataset is
sourced from the very popular NPTEL MOOC platform. We use the curated dataset
to measure the existing disparity in YouTube Automatic Captions and OpenAI
Whisper model performance across the diverse demographic traits of speakers in
India. While there exists disparity due to gender, native region, age and
speech rate of speakers, disparity based on caste is non-existent. We also
observe statistically significant disparity across the disciplines of the
lectures. These results indicate the need of more inclusive and robust ASR
systems and more representational datasets for disparity evaluation in them.
","[{'version': 'v1', 'created': 'Thu, 20 Jul 2023 05:03:00 GMT'}]",2023-07-21,"[['Rai', 'Anand Kumar', ''], ['Jaiswal', 'Siddharth D', ''], ['Mukherjee', 'Animesh', '']]"
2304.14317,Terry Yue Zhuo,Terry Yue Zhuo,ICE-Score: Instructing Large Language Models to Evaluate Code,Accepted to Findings of EACL 2024,,,,cs.AI cs.CL cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Recent advancements in the field of natural language generation have
facilitated the use of large language models to assess the quality of generated
text. Although these models have shown promising results in tasks such as
machine translation and summarization, their applicability in code intelligence
tasks remains limited without human involvement. The complexity of programming
concepts required for such tasks makes it difficult to develop evaluation
metrics that align with human judgment. Token-matching-based metrics, such as
BLEU, have demonstrated weak correlations with human practitioners in code
intelligence tasks. Moreover, utilizing human-written test suites to evaluate
functional correctness can be challenging in domains with low resources. To
overcome these obstacles, we propose \texttt{ICE-Score}, a new evaluation
metric via instructing large language models (LLMs) for code assessments. Our
metric addresses the limitations of existing approaches by achieving superior
correlations with functional correctness and human preferences, without the
need for test oracles or references. We evaluate the efficacy of our metric on
two different aspects (\textit{human preference} and \textit{execution
success}) and four programming languages. Our results demonstrate that our
metric surpasses state-of-the-art metrics for code generation, delivering high
levels of accuracy and consistency across various programming languages and
tasks. We also make our evaluation metric and datasets available to the
public\footnote{\url{https://github.com/terryyz/ice-score}}, encouraging
further research in evaluating code intelligence tasks.
","[{'version': 'v1', 'created': 'Thu, 27 Apr 2023 16:38:17 GMT'}, {'version': 'v2', 'created': 'Mon, 22 Jan 2024 17:06:50 GMT'}]",2024-01-23,"[['Zhuo', 'Terry Yue', '']]"
2305.13776,Rishabh Gupta,"Rishabh Gupta, Shaily Desai, Manvi Goel, Anil Bandhakavi, Tanmoy
  Chakraborty and Md. Shad Akhtar","Counterspeeches up my sleeve! Intent Distribution Learning and
  Persistent Fusion for Intent-Conditioned Counterspeech Generation",ACL 2023,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Counterspeech has been demonstrated to be an efficacious approach for
combating hate speech. While various conventional and controlled approaches
have been studied in recent years to generate counterspeech, a counterspeech
with a certain intent may not be sufficient in every scenario. Due to the
complex and multifaceted nature of hate speech, utilizing multiple forms of
counter-narratives with varying intents may be advantageous in different
circumstances. In this paper, we explore intent-conditioned counterspeech
generation. At first, we develop IntentCONAN, a diversified intent-specific
counterspeech dataset with 6831 counterspeeches conditioned on five intents,
i.e., informative, denouncing, question, positive, and humour. Subsequently, we
propose QUARC, a two-stage framework for intent-conditioned counterspeech
generation. QUARC leverages vector-quantized representations learned for each
intent category along with PerFuMe, a novel fusion module to incorporate
intent-specific information into the model. Our evaluation demonstrates that
QUARC outperforms several baselines by an average of 10% across evaluation
metrics. An extensive human evaluation supplements our hypothesis of better and
more appropriate responses than comparative systems.
","[{'version': 'v1', 'created': 'Tue, 23 May 2023 07:45:17 GMT'}]",2023-05-24,"[['Gupta', 'Rishabh', ''], ['Desai', 'Shaily', ''], ['Goel', 'Manvi', ''], ['Bandhakavi', 'Anil', ''], ['Chakraborty', 'Tanmoy', ''], ['Akhtar', 'Md. Shad', '']]"
2402.12058,Xuanyu Lei,"Xuanyu Lei, Zonghan Yang, Xinrui Chen, Peng Li and Yang Liu","Scaffolding Coordinates to Promote Vision-Language Coordination in Large
  Multi-Modal Models",,,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  State-of-the-art Large Multi-Modal Models (LMMs) have demonstrated
exceptional capabilities in vision-language tasks. Despite their advanced
functionalities, the performances of LMMs are still limited in challenging
scenarios that require complex reasoning with multiple levels of visual
information. Existing prompting techniques for LMMs focus on either improving
textual reasoning or leveraging tools for image preprocessing, lacking a simple
and general visual prompting scheme to promote vision-language coordination in
LMMs. In this work, we propose Scaffold prompting that scaffolds coordinates to
promote vision-language coordination. Specifically, Scaffold overlays a dot
matrix within the image as visual information anchors and leverages
multi-dimensional coordinates as textual positional references. Extensive
experiments on a wide range of challenging vision-language tasks demonstrate
the superiority of Scaffold over GPT-4V with the textual CoT prompting. Our
code is released in https://github.com/leixy20/Scaffold.
","[{'version': 'v1', 'created': 'Mon, 19 Feb 2024 11:23:53 GMT'}]",2024-02-20,"[['Lei', 'Xuanyu', ''], ['Yang', 'Zonghan', ''], ['Chen', 'Xinrui', ''], ['Li', 'Peng', ''], ['Liu', 'Yang', '']]"
2310.14541,Duzhen Zhang,"Duzhen Zhang, Wei Cong, Jiahua Dong, Yahan Yu, Xiuyi Chen, Yonggang
  Zhang, Zhen Fang",Continual Named Entity Recognition without Catastrophic Forgetting,Accepted by EMNLP2023 main conference as a long paper,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Continual Named Entity Recognition (CNER) is a burgeoning area, which
involves updating an existing model by incorporating new entity types
sequentially. Nevertheless, continual learning approaches are often severely
afflicted by catastrophic forgetting. This issue is intensified in CNER due to
the consolidation of old entity types from previous steps into the non-entity
type at each step, leading to what is known as the semantic shift problem of
the non-entity type. In this paper, we introduce a pooled feature distillation
loss that skillfully navigates the trade-off between retaining knowledge of old
entity types and acquiring new ones, thereby more effectively mitigating the
problem of catastrophic forgetting. Additionally, we develop a confidence-based
pseudo-labeling for the non-entity type, \emph{i.e.,} predicting entity types
using the old model to handle the semantic shift of the non-entity type.
Following the pseudo-labeling process, we suggest an adaptive re-weighting
type-balanced learning strategy to handle the issue of biased type
distribution. We carried out comprehensive experiments on ten CNER settings
using three different datasets. The results illustrate that our method
significantly outperforms prior state-of-the-art approaches, registering an
average improvement of $6.3$\% and $8.0$\% in Micro and Macro F1 scores,
respectively.
","[{'version': 'v1', 'created': 'Mon, 23 Oct 2023 03:45:30 GMT'}]",2023-10-24,"[['Zhang', 'Duzhen', ''], ['Cong', 'Wei', ''], ['Dong', 'Jiahua', ''], ['Yu', 'Yahan', ''], ['Chen', 'Xiuyi', ''], ['Zhang', 'Yonggang', ''], ['Fang', 'Zhen', '']]"
1408.5427,Carl Meyer Dr.,"Daniel Godfrey, Caley Johns, Carl Meyer, Shaina Race, Carol Sadek","A Case Study in Text Mining: Interpreting Twitter Data From World Cup
  Tweets",,,,,stat.ML cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Cluster analysis is a field of data analysis that extracts underlying
patterns in data. One application of cluster analysis is in text-mining, the
analysis of large collections of text to find similarities between documents.
We used a collection of about 30,000 tweets extracted from Twitter just before
the World Cup started. A common problem with real world text data is the
presence of linguistic noise. In our case it would be extraneous tweets that
are unrelated to dominant themes. To combat this problem, we created an
algorithm that combined the DBSCAN algorithm and a consensus matrix. This way
we are left with the tweets that are related to those dominant themes. We then
used cluster analysis to find those topics that the tweets describe. We
clustered the tweets using k-means, a commonly used clustering algorithm, and
Non-Negative Matrix Factorization (NMF) and compared the results. The two
algorithms gave similar results, but NMF proved to be faster and provided more
easily interpreted results. We explored our results using two visualization
tools, Gephi and Wordle.
","[{'version': 'v1', 'created': 'Thu, 21 Aug 2014 17:58:33 GMT'}]",2014-08-26,"[['Godfrey', 'Daniel', ''], ['Johns', 'Caley', ''], ['Meyer', 'Carl', ''], ['Race', 'Shaina', ''], ['Sadek', 'Carol', '']]"
2303.13988,Thilo Hagendorff,Thilo Hagendorff,"Machine Psychology: Investigating Emergent Capabilities and Behavior in
  Large Language Models Using Psychological Methods",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) are currently at the forefront of intertwining
AI systems with human communication and everyday life. Due to rapid
technological advances and their extreme versatility, LLMs nowadays have
millions of users and are at the cusp of being the main go-to technology for
information retrieval, content generation, problem-solving, etc. Therefore, it
is of great importance to thoroughly assess and scrutinize their capabilities.
Due to increasingly complex and novel behavioral patterns in current LLMs, this
can be done by treating them as participants in psychology experiments that
were originally designed to test humans. For this purpose, the paper introduces
a new field of research called ""machine psychology"". The paper outlines how
different subfields of psychology can inform behavioral tests for LLMs. It
defines methodological standards for machine psychology research, especially by
focusing on policies for prompt designs. Additionally, it describes how
behavioral patterns discovered in LLMs are to be interpreted. In sum, machine
psychology aims to discover emergent abilities in LLMs that cannot be detected
by most traditional natural language processing benchmarks.
","[{'version': 'v1', 'created': 'Fri, 24 Mar 2023 13:24:41 GMT'}, {'version': 'v2', 'created': 'Tue, 11 Apr 2023 08:45:59 GMT'}, {'version': 'v3', 'created': 'Wed, 5 Jul 2023 07:48:00 GMT'}, {'version': 'v4', 'created': 'Mon, 23 Oct 2023 20:39:23 GMT'}]",2023-10-25,"[['Hagendorff', 'Thilo', '']]"
2305.08283,Shangbin Feng,"Shangbin Feng, Chan Young Park, Yuhan Liu, Yulia Tsvetkov","From Pretraining Data to Language Models to Downstream Tasks: Tracking
  the Trails of Political Biases Leading to Unfair NLP Models",ACL 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Language models (LMs) are pretrained on diverse data sources, including news,
discussion forums, books, and online encyclopedias. A significant portion of
this data includes opinions and perspectives which, on one hand, celebrate
democracy and diversity of ideas, and on the other hand are inherently socially
biased. Our work develops new methods to (1) measure political biases in LMs
trained on such corpora, along social and economic axes, and (2) measure the
fairness of downstream NLP models trained on top of politically biased LMs. We
focus on hate speech and misinformation detection, aiming to empirically
quantify the effects of political (social, economic) biases in pretraining data
on the fairness of high-stakes social-oriented tasks. Our findings reveal that
pretrained LMs do have political leanings that reinforce the polarization
present in pretraining corpora, propagating social biases into hate speech
predictions and misinformation detectors. We discuss the implications of our
findings for NLP research and propose future directions to mitigate unfairness.
","[{'version': 'v1', 'created': 'Mon, 15 May 2023 00:06:30 GMT'}, {'version': 'v2', 'created': 'Sat, 27 May 2023 03:43:51 GMT'}, {'version': 'v3', 'created': 'Thu, 6 Jul 2023 00:40:53 GMT'}]",2023-07-07,"[['Feng', 'Shangbin', ''], ['Park', 'Chan Young', ''], ['Liu', 'Yuhan', ''], ['Tsvetkov', 'Yulia', '']]"
2401.01326,Urchade Zaratiana,"Urchade Zaratiana, Nadi Tomeh, Pierre Holat, Thierry Charnois","An Autoregressive Text-to-Graph Framework for Joint Entity and Relation
  Extraction",AAAI 2024 (camera ready version),,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we propose a novel method for joint entity and relation
extraction from unstructured text by framing it as a conditional sequence
generation problem. In contrast to conventional generative information
extraction models that are left-to-right token-level generators, our approach
is \textit{span-based}. It generates a linearized graph where nodes represent
text spans and edges represent relation triplets. Our method employs a
transformer encoder-decoder architecture with pointing mechanism on a dynamic
vocabulary of spans and relation types. Our model can capture the structural
characteristics and boundaries of entities and relations through span
representations while simultaneously grounding the generated output in the
original text thanks to the pointing mechanism. Evaluation on benchmark
datasets validates the effectiveness of our approach, demonstrating competitive
results. Code is available at https://github.com/urchade/ATG.
","[{'version': 'v1', 'created': 'Tue, 2 Jan 2024 18:32:14 GMT'}, {'version': 'v2', 'created': 'Mon, 15 Jan 2024 13:39:38 GMT'}]",2024-01-17,"[['Zaratiana', 'Urchade', ''], ['Tomeh', 'Nadi', ''], ['Holat', 'Pierre', ''], ['Charnois', 'Thierry', '']]"
1912.05238,Patrick Schramowski,"Patrick Schramowski, Cigdem Turan, Sophie Jentzsch, Constantin
  Rothkopf and Kristian Kersting","BERT has a Moral Compass: Improvements of ethical and moral values of
  machines",,,,,cs.CL cs.AI cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Allowing machines to choose whether to kill humans would be devastating for
world peace and security. But how do we equip machines with the ability to
learn ethical or even moral choices? Jentzsch et al.(2019) showed that applying
machine learning to human texts can extract deontological ethical reasoning
about ""right"" and ""wrong"" conduct by calculating a moral bias score on a
sentence level using sentence embeddings. The machine learned that it is
objectionable to kill living beings, but it is fine to kill time; It is
essential to eat, yet one might not eat dirt; it is important to spread
information, yet one should not spread misinformation. However, the evaluated
moral bias was restricted to simple actions -- one verb -- and a ranking of
actions with surrounding context. Recently BERT ---and variants such as RoBERTa
and SBERT--- has set a new state-of-the-art performance for a wide range of NLP
tasks. But has BERT also a better moral compass? In this paper, we discuss and
show that this is indeed the case. Thus, recent improvements of language
representations also improve the representation of the underlying ethical and
moral values of the machine. We argue that through an advanced semantic
representation of text, BERT allows one to get better insights of moral and
ethical values implicitly represented in text. This enables the Moral Choice
Machine (MCM) to extract more accurate imprints of moral choices and ethical
values.
","[{'version': 'v1', 'created': 'Wed, 11 Dec 2019 11:27:06 GMT'}]",2019-12-12,"[['Schramowski', 'Patrick', ''], ['Turan', 'Cigdem', ''], ['Jentzsch', 'Sophie', ''], ['Rothkopf', 'Constantin', ''], ['Kersting', 'Kristian', '']]"
2206.04659,Safa Zaid Malik,"Safa Zaid, Aswah Malik, Kisa Fatima",Jewelry Shop Conversational Chatbot,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Since the advent of chatbots in the commercial sector, they have been widely
employed in the customer service department. Typically, these commercial
chatbots are retrieval-based, so they are unable to respond to queries absent
in the provided dataset. On the contrary, generative chatbots try to create the
most appropriate response, but are mostly unable to create a smooth flow in the
customer-bot dialog. Since the client has few options left for continuing after
receiving a response, the dialog becomes short. Through our work, we try to
maximize the intelligence of a simple conversational agent so it can answer
unseen queries, and generate follow-up questions or remarks. We have built a
chatbot for a jewelry shop that finds the underlying objective of the
customer's query by finding similarity of the input to patterns in the corpus.
Our system features an audio input interface for clients, so they may speak to
it in natural language. After converting the audio to text, we trained the
model to extract the intent of the query, to find an appropriate response and
to speak to the client in a natural human voice. To gauge the system's
performance, we used performance metrics such as Recall, Precision and F1
score.
","[{'version': 'v1', 'created': 'Thu, 9 Jun 2022 17:56:51 GMT'}]",2022-06-10,"[['Zaid', 'Safa', ''], ['Malik', 'Aswah', ''], ['Fatima', 'Kisa', '']]"
2108.12575,Ruotian Luo,Ruotian Luo,Goal-driven text descriptions for images,Ph.D. thesis,,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A big part of achieving Artificial General Intelligence(AGI) is to build a
machine that can see and listen like humans. Much work has focused on designing
models for image classification, video classification, object detection, pose
estimation, speech recognition, etc., and has achieved significant progress in
recent years thanks to deep learning. However, understanding the world is not
enough. An AI agent also needs to know how to talk, especially how to
communicate with a human. While perception (vision, for example) is more common
across animal species, the use of complicated language is unique to humans and
is one of the most important aspects of intelligence.
  In this thesis, we focus on generating textual output given visual input. In
Chapter 3, we focus on generating the referring expression, a text description
for an object in the image so that a receiver can infer which object is being
described. We use a comprehension machine to directly guide the generated
referring expressions to be more discriminative. In Chapter 4, we introduce a
method that encourages discriminability in image caption generation. We show
that more discriminative captioning models generate more descriptive captions.
In Chapter 5, we study how training objectives and sampling methods affect the
models' ability to generate diverse captions. We find that a popular captioning
training strategy will be detrimental to the diversity of generated captions.
In Chapter 6, we propose a model that can control the length of generated
captions. By changing the desired length, one can influence the style and
descriptiveness of the captions. Finally, in Chapter 7, we rank/generate
informative image tags according to their information utility. The proposed
method better matches what humans think are the most important tags for the
images.
","[{'version': 'v1', 'created': 'Sat, 28 Aug 2021 05:10:38 GMT'}]",2021-08-31,"[['Luo', 'Ruotian', '']]"
2402.10614,Ming Li,"Ming Li, Jiuhai Chen, Lichang Chen, Tianyi Zhou","Can LLMs Speak For Diverse People? Tuning LLMs via Debate to Generate
  Controllable Controversial Statements",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Making LLMs speak for different, especially minority groups of people, and
generate statements supporting their diverse or even controversial perspectives
is critical to creating an inclusive environment. However, existing LLMs lack
sufficient controllability to the stance of their generated content, which
often contains inconsistent, neutral, or biased statements. In this paper, we
improve the controllability of LLMs in generating statements supporting an
argument the user defined in the prompt. We find that multi-round debates
between two LLMs with opposite stances generate higher-quality and more salient
statements for each, which are important training data to improve the
controllability of LLMs. Motivated by this, we develop a novel debate & tuning
(""DEBATunE"") pipeline finetuning LLMs to generate the statements obtained via
debate. To examine DEBATunE, we curate the largest dataset of debate topics so
far, which covers 710 controversial topics and corresponding arguments for each
topic. Evaluations by the GPT-4 judge with a novel controversy controllability
metric show that LLMs' capability of expressing diverse perspectives is
significantly improved by DEBATunE. Moreover, such controllability can be
generalized to unseen topics, generating high-quality statements supporting
controversial arguments. Our codes, models, and data will be released at
https://github.com/tianyi-lab/DEBATunE.
","[{'version': 'v1', 'created': 'Fri, 16 Feb 2024 12:00:34 GMT'}]",2024-02-19,"[['Li', 'Ming', ''], ['Chen', 'Jiuhai', ''], ['Chen', 'Lichang', ''], ['Zhou', 'Tianyi', '']]"
2311.08838,Ivan Vykopal,"Ivan Vykopal, Mat\'u\v{s} Pikuliak, Ivan Srba, Robert Moro, Dominik
  Macko, Maria Bielikova",Disinformation Capabilities of Large Language Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Automated disinformation generation is often listed as an important risk
associated with large language models (LLMs). The theoretical ability to flood
the information space with disinformation content might have dramatic
consequences for societies around the world. This paper presents a
comprehensive study of the disinformation capabilities of the current
generation of LLMs to generate false news articles in the English language. In
our study, we evaluated the capabilities of 10 LLMs using 20 disinformation
narratives. We evaluated several aspects of the LLMs: how good they are at
generating news articles, how strongly they tend to agree or disagree with the
disinformation narratives, how often they generate safety warnings, etc. We
also evaluated the abilities of detection models to detect these articles as
LLM-generated. We conclude that LLMs are able to generate convincing news
articles that agree with dangerous disinformation narratives.
","[{'version': 'v1', 'created': 'Wed, 15 Nov 2023 10:25:30 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Feb 2024 10:44:18 GMT'}]",2024-02-26,"[['Vykopal', 'Ivan', ''], ['Pikuliak', 'Matúš', ''], ['Srba', 'Ivan', ''], ['Moro', 'Robert', ''], ['Macko', 'Dominik', ''], ['Bielikova', 'Maria', '']]"
2309.01456,Michael Aubertin,"Thibault Chanus (ENS Rennes), Michael Aubertin",LLM and Infrastructure as a Code use case,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Cloud computing and the evolution of management methodologies such as Lean
Management or Agile entail a profound transformation in both system
construction and maintenance approaches. These practices are encompassed within
the term ""DevOps."" This descriptive approach to an information system or
application, alongside the configuration of its constituent components, has
necessitated the development of descriptive languages paired with specialized
engines for automating systems administration tasks. Among these, the tandem of
Ansible (engine) and YAML (descriptive language) stands out as the two most
prevalent tools in the market, facing notable competition mainly from
Terraform. The current document presents an inquiry into a solution for
generating and managing Ansible YAML roles and playbooks, utilizing Generative
LLMs (Language Models) to translate human descriptions into code. Our efforts
are focused on identifying plausible directions and outlining the potential
industrial applications. Note: For the purpose of this experiment, we have
opted against the use of Ansible Lightspeed. This is due to its reliance on an
IBM Watson model, for which we have not found any publicly available
references. Comprehensive information regarding this remarkable technology can
be found [1] directly on our partner's website, RedHat.
","[{'version': 'v1', 'created': 'Mon, 4 Sep 2023 09:05:17 GMT'}, {'version': 'v2', 'created': 'Thu, 2 Nov 2023 09:00:49 GMT'}]",2023-11-03,"[['Chanus', 'Thibault', '', 'ENS Rennes'], ['Aubertin', 'Michael', '']]"
1502.03671,R\'emi Lebret,"R\'emi Lebret, Pedro O. Pinheiro, Ronan Collobert",Phrase-based Image Captioning,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generating a novel textual description of an image is an interesting problem
that connects computer vision and natural language processing. In this paper,
we present a simple model that is able to generate descriptive sentences given
a sample image. This model has a strong focus on the syntax of the
descriptions. We train a purely bilinear model that learns a metric between an
image representation (generated from a previously trained Convolutional Neural
Network) and phrases that are used to described them. The system is then able
to infer phrases from a given image sample. Based on caption syntax statistics,
we propose a simple language model that can produce relevant descriptions for a
given test image using the phrases inferred. Our approach, which is
considerably simpler than state-of-the-art models, achieves comparable results
in two popular datasets for the task: Flickr30k and the recently proposed
Microsoft COCO.
","[{'version': 'v1', 'created': 'Thu, 12 Feb 2015 14:17:15 GMT'}, {'version': 'v2', 'created': 'Thu, 9 Apr 2015 09:48:52 GMT'}]",2015-04-10,"[['Lebret', 'Rémi', ''], ['Pinheiro', 'Pedro O.', ''], ['Collobert', 'Ronan', '']]"
1705.03645,Shantanu Kumar,Shantanu Kumar,A Survey of Deep Learning Methods for Relation Extraction,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Relation Extraction is an important sub-task of Information Extraction which
has the potential of employing deep learning (DL) models with the creation of
large datasets using distant supervision. In this review, we compare the
contributions and pitfalls of the various DL models that have been used for the
task, to help guide the path ahead.
","[{'version': 'v1', 'created': 'Wed, 10 May 2017 08:05:44 GMT'}]",2017-05-11,"[['Kumar', 'Shantanu', '']]"
2204.08975,Daryna Dementieva,"Daryna Dementieva, Nikolay Babakov and Alexander Panchenko",Detecting Text Formality: A Study of Text Classification Approaches,Published at RANLP2023,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Formality is one of the important characteristics of text documents. The
automatic detection of the formality level of a text is potentially beneficial
for various natural language processing tasks. Before, two large-scale datasets
were introduced for multiple languages featuring formality annotation -- GYAFC
and X-FORMAL. However, they were primarily used for the training of style
transfer models. At the same time, the detection of text formality on its own
may also be a useful application. This work proposes the first to our knowledge
systematic study of formality detection methods based on statistical,
neural-based, and Transformer-based machine learning methods and delivers the
best-performing models for public usage. We conducted three types of
experiments -- monolingual, multilingual, and cross-lingual. The study shows
the overcome of Char BiLSTM model over Transformer-based ones for the
monolingual and multilingual formality classification task, while
Transformer-based classifiers are more stable to cross-lingual knowledge
transfer.
","[{'version': 'v1', 'created': 'Tue, 19 Apr 2022 16:23:07 GMT'}, {'version': 'v2', 'created': 'Fri, 8 Sep 2023 09:11:02 GMT'}]",2023-09-11,"[['Dementieva', 'Daryna', ''], ['Babakov', 'Nikolay', ''], ['Panchenko', 'Alexander', '']]"
1604.03136,Piyush Bansal,"Arnav Sharma, Sakshi Gupta, Raveesh Motlani, Piyush Bansal, Manish
  Srivastava, Radhika Mamidi, Dipti M. Sharma",Shallow Parsing Pipeline for Hindi-English Code-Mixed Social Media Text,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this study, the problem of shallow parsing of Hindi-English code-mixed
social media text (CSMT) has been addressed. We have annotated the data,
developed a language identifier, a normalizer, a part-of-speech tagger and a
shallow parser. To the best of our knowledge, we are the first to attempt
shallow parsing on CSMT. The pipeline developed has been made available to the
research community with the goal of enabling better text analysis of Hindi
English CSMT. The pipeline is accessible at http://bit.ly/csmt-parser-api .
","[{'version': 'v1', 'created': 'Mon, 11 Apr 2016 20:24:52 GMT'}]",2016-04-13,"[['Sharma', 'Arnav', ''], ['Gupta', 'Sakshi', ''], ['Motlani', 'Raveesh', ''], ['Bansal', 'Piyush', ''], ['Srivastava', 'Manish', ''], ['Mamidi', 'Radhika', ''], ['Sharma', 'Dipti M.', '']]"
1712.01818,Chung-Cheng Chiu,"Rohit Prabhavalkar, Tara N. Sainath, Yonghui Wu, Patrick Nguyen,
  Zhifeng Chen, Chung-Cheng Chiu, Anjuli Kannan","Minimum Word Error Rate Training for Attention-based
  Sequence-to-Sequence Models",,,,,cs.CL eess.AS stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sequence-to-sequence models, such as attention-based models in automatic
speech recognition (ASR), are typically trained to optimize the cross-entropy
criterion which corresponds to improving the log-likelihood of the data.
However, system performance is usually measured in terms of word error rate
(WER), not log-likelihood. Traditional ASR systems benefit from discriminative
sequence training which optimizes criteria such as the state-level minimum
Bayes risk (sMBR) which are more closely related to WER. In the present work,
we explore techniques to train attention-based models to directly minimize
expected word error rate. We consider two loss functions which approximate the
expected number of word errors: either by sampling from the model, or by using
N-best lists of decoded hypotheses, which we find to be more effective than the
sampling-based method. In experimental evaluations, we find that the proposed
training procedure improves performance by up to 8.2% relative to the baseline
system. This allows us to train grapheme-based, uni-directional attention-based
models which match the performance of a traditional, state-of-the-art,
discriminative sequence-trained system on a mobile voice-search task.
","[{'version': 'v1', 'created': 'Tue, 5 Dec 2017 18:52:18 GMT'}]",2017-12-06,"[['Prabhavalkar', 'Rohit', ''], ['Sainath', 'Tara N.', ''], ['Wu', 'Yonghui', ''], ['Nguyen', 'Patrick', ''], ['Chen', 'Zhifeng', ''], ['Chiu', 'Chung-Cheng', ''], ['Kannan', 'Anjuli', '']]"
2002.10665,Sumant Pushp,"Sumant Pushp, Pragya Kashmira, Shyamanta M Hazarika",Declarative Memory-based Structure for the Representation of Text Data,21 pages,,,,cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In the era of intelligent computing, computational progress in text
processing is an essential consideration. Many systems have been developed to
process text over different languages. Though, there is considerable
development, they still lack in understanding of the text, i.e., instead of
keeping text as knowledge, many treat text as a data. In this work we introduce
a text representation scheme which is influenced by human memory
infrastructure. Since texts are declarative in nature, a structural
organization would foster efficient computation over text. We exploit long term
episodic memory to keep text information observed over time. This not only keep
fragments of text in an organized fashion but also reduces redundancy and
stores the temporal relation among them. Wordnet has been used to imitate
semantic memory, which works at word level to facilitate the understanding
about individual words within text. Experimental results of various operation
performed over episodic memory and growth of knowledge infrastructure over time
is reported.
","[{'version': 'v1', 'created': 'Tue, 25 Feb 2020 04:56:47 GMT'}]",2020-02-26,"[['Pushp', 'Sumant', ''], ['Kashmira', 'Pragya', ''], ['Hazarika', 'Shyamanta M', '']]"
1804.10080,Sergey Novoselov,"Sergey Novoselov, Andrey Shulipa, Ivan Kremnev, Alexandr Kozlov, Vadim
  Shchemelinin",On deep speaker embeddings for text-independent speaker recognition,Submitted to Odyssey 2018,,,,cs.SD cs.CL eess.AS stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigate deep neural network performance in the textindependent speaker
recognition task. We demonstrate that using angular softmax activation at the
last classification layer of a classification neural network instead of a
simple softmax activation allows to train a more generalized discriminative
speaker embedding extractor. Cosine similarity is an effective metric for
speaker verification in this embedding space. We also address the problem of
choosing an architecture for the extractor. We found that deep networks with
residual frame level connections outperform wide but relatively shallow
architectures. This paper also proposes several improvements for previous
DNN-based extractor systems to increase the speaker recognition accuracy. We
show that the discriminatively trained similarity metric learning approach
outperforms the standard LDA-PLDA method as an embedding backend. The results
obtained on Speakers in the Wild and NIST SRE 2016 evaluation sets demonstrate
robustness of the proposed systems when dealing with close to real-life
conditions.
","[{'version': 'v1', 'created': 'Thu, 26 Apr 2018 14:22:01 GMT'}]",2018-04-27,"[['Novoselov', 'Sergey', ''], ['Shulipa', 'Andrey', ''], ['Kremnev', 'Ivan', ''], ['Kozlov', 'Alexandr', ''], ['Shchemelinin', 'Vadim', '']]"
1905.13464,"Tommi Gr\""ondahl","Tommi Gr\""ondahl and N. Asokan",Effective writing style imitation via combinatorial paraphrasing,"16 pages, 1 figure, Accepted for publication in Privacy Enhancing
  Technologies (PETS2020)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Stylometry can be used to profile or deanonymize authors against their will
based on writing style. Style transfer provides a defence. Current techniques
typically use either encoder-decoder architectures or rule-based algorithms.
Crucially, style transfer must reliably retain original semantic content to be
actually deployable. We conduct a multifaceted evaluation of three
state-of-the-art encoder-decoder style transfer techniques, and show that all
fail at semantic retainment. In particular, they do not produce appropriate
paraphrases, but only retain original content in the trivial case of exactly
reproducing the text. To mitigate this problem we propose ParChoice: a
technique based on the combinatorial application of multiple paraphrasing
algorithms. ParChoice strongly outperforms the encoder-decoder baselines in
semantic retainment. Additionally, compared to baselines that achieve
non-negligible semantic retainment, ParChoice has superior style transfer
performance. We also apply ParChoice to multi-author style imitation (not
considered by prior work), where we achieve up to 75% imitation success among
five authors. Furthermore, when compared to two state-of-the-art rule-based
style transfer techniques, ParChoice has markedly better semantic retainment.
Combining ParChoice with the best performing rule-based baseline (Mutant-X)
also reaches the highest style transfer success on the Brennan-Greenstadt and
Extended-Brennan-Greenstadt corpora, with much less impact on original meaning
than when using the rule-based baseline techniques alone. Finally, we highlight
a critical problem that afflicts all current style transfer techniques: the
adversary can use the same technique for thwarting style transfer via
adversarial training. We show that adding randomness to style transfer helps to
mitigate the effectiveness of adversarial training.
","[{'version': 'v1', 'created': 'Fri, 31 May 2019 08:42:27 GMT'}, {'version': 'v2', 'created': 'Tue, 16 Jun 2020 14:02:31 GMT'}, {'version': 'v3', 'created': 'Fri, 3 Jul 2020 12:36:28 GMT'}]",2020-07-06,"[['Gröndahl', 'Tommi', ''], ['Asokan', 'N.', '']]"
2403.14221,Yukun Zhao,"Zhao Yukun, Yan Lingyong, Sun Weiwei, Xing Guoliang, Wang Shuaiqiang,
  Meng Chong, Cheng Zhicong, Ren Zhaochun, Yin Dawei","Improving the Robustness of Large Language Models via Consistency
  Alignment",Accepted by LREC-COLING 2024,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Large language models (LLMs) have shown tremendous success in following user
instructions and generating helpful responses. Nevertheless, their robustness
is still far from optimal, as they may generate significantly inconsistent
responses due to minor changes in the verbalized instructions. Recent
literature has explored this inconsistency issue, highlighting the importance
of continued improvement in the robustness of response generation. However,
systematic analysis and solutions are still lacking. In this paper, we
quantitatively define the inconsistency problem and propose a two-stage
training framework consisting of instruction-augmented supervised fine-tuning
and consistency alignment training. The first stage helps a model generalize on
following instructions via similar instruction augmentations. In the second
stage, we improve the diversity and help the model understand which responses
are more aligned with human expectations by differentiating subtle differences
in similar responses. The training process is accomplished by self-rewards
inferred from the trained model at the first stage without referring to
external human preference resources. We conduct extensive experiments on recent
publicly available LLMs on instruction-following tasks and demonstrate the
effectiveness of our training framework.
","[{'version': 'v1', 'created': 'Thu, 21 Mar 2024 08:21:12 GMT'}]",2024-03-22,"[['Yukun', 'Zhao', ''], ['Lingyong', 'Yan', ''], ['Weiwei', 'Sun', ''], ['Guoliang', 'Xing', ''], ['Shuaiqiang', 'Wang', ''], ['Chong', 'Meng', ''], ['Zhicong', 'Cheng', ''], ['Zhaochun', 'Ren', ''], ['Dawei', 'Yin', '']]"
1411.5595,Tianze Shi,"Tianze Shi, Zhiyuan Liu",Linking GloVe with word2vec,"5 pages, 2 figures",,,,cs.CL cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Global Vectors for word representation (GloVe), introduced by Jeffrey
Pennington et al. is reported to be an efficient and effective method for
learning vector representations of words. State-of-the-art performance is also
provided by skip-gram with negative-sampling (SGNS) implemented in the word2vec
tool. In this note, we explain the similarities between the training objectives
of the two models, and show that the objective of SGNS is similar to the
objective of a specialized form of GloVe, though their cost functions are
defined differently.
","[{'version': 'v1', 'created': 'Thu, 20 Nov 2014 16:39:28 GMT'}, {'version': 'v2', 'created': 'Wed, 26 Nov 2014 06:46:18 GMT'}]",2014-11-27,"[['Shi', 'Tianze', ''], ['Liu', 'Zhiyuan', '']]"
2212.09603,Qintong Li,"Qintong Li, Zhiyong Wu, Lingpeng Kong, Wei Bi",Explanation Regeneration via Information Bottleneck,Accepted in ACL2023 Findings,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Explaining the black-box predictions of NLP models naturally and accurately
is an important open problem in natural language generation. These free-text
explanations are expected to contain sufficient and carefully-selected evidence
to form supportive arguments for predictions. Due to the superior generative
capacity of large pretrained language models, recent work built on prompt
engineering enables explanation generation without specific training. However,
explanation generated through single-pass prompting often lacks sufficiency and
conciseness. To address this problem, we develop an information bottleneck
method EIB to produce refined explanations that are sufficient and concise. Our
approach regenerates the free-text explanation by polishing the single-pass
output from the pretrained language model but retaining the information that
supports the contents being explained. Experiments on two out-of-domain tasks
verify the effectiveness of EIB through automatic evaluation and
thoroughly-conducted human evaluation.
","[{'version': 'v1', 'created': 'Mon, 19 Dec 2022 16:41:19 GMT'}, {'version': 'v2', 'created': 'Tue, 11 Jul 2023 05:17:19 GMT'}]",2023-07-12,"[['Li', 'Qintong', ''], ['Wu', 'Zhiyong', ''], ['Kong', 'Lingpeng', ''], ['Bi', 'Wei', '']]"
2106.09572,Xiangpeng Wan,"Xiangpeng Wan, Michael C. Lucic, Hakim Ghazzai, Yehia Massoud","Topic Modeling and Progression of American Digital News Media During the
  Onset of the COVID-19 Pandemic",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Currently, the world is in the midst of a severe global pandemic, which has
affected all aspects of people's lives. As a result, there is a deluge of
COVID-related digital media articles published in the United States, due to the
disparate effects of the pandemic. This large volume of information is
difficult to consume by the audience in a reasonable amount of time. In this
paper, we develop a Natural Language Processing (NLP) pipeline that is capable
of automatically distilling various digital articles into manageable pieces of
information, while also modelling the progression topics discussed over time in
order to aid readers in rapidly gaining holistic perspectives on pressing
issues (i.e., the COVID-19 pandemic) from a diverse array of sources. We
achieve these goals by first collecting a large corpus of COVID-related
articles during the onset of the pandemic. After, we apply unsupervised and
semi-supervised learning procedures to summarize articles, then cluster them
based on their similarities using the community detection methods. Next, we
identify the topic of each cluster of articles using the BART algorithm.
Finally, we provide a detailed digital media analysis based on the NLP-pipeline
outputs and show how the conversation surrounding COVID-19 evolved over time.
","[{'version': 'v1', 'created': 'Tue, 25 May 2021 14:27:47 GMT'}]",2021-06-18,"[['Wan', 'Xiangpeng', ''], ['Lucic', 'Michael C.', ''], ['Ghazzai', 'Hakim', ''], ['Massoud', 'Yehia', '']]"
2402.05123,Jiahao Wang,"Jiahao Wang, Bolin Zhang, Qianlong Du, Jiajun Zhang, Dianhui Chu",A Survey on Data Selection for LLM Instruction Tuning,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Instruction tuning is a vital step of training large language models (LLM),
so how to enhance the effect of instruction tuning has received increased
attention. Existing works indicate that the quality of the dataset is more
crucial than the quantity during instruction tuning of LLM. Therefore, recently
a lot of studies focus on exploring the methods of selecting high-quality
subset from instruction datasets, aiming to reduce training costs and enhance
the instruction-following capabilities of LLMs. This paper presents a
comprehensive survey on data selection for LLM instruction tuning. Firstly, we
introduce the wildly used instruction datasets. Then, we propose a new taxonomy
of the data selection methods and provide a detailed introduction of recent
advances,and the evaluation strategies and results of data selection methods
are also elaborated in detail. Finally, we emphasize the open challenges and
present new frontiers of this task.
","[{'version': 'v1', 'created': 'Sun, 4 Feb 2024 13:32:01 GMT'}]",2024-02-09,"[['Wang', 'Jiahao', ''], ['Zhang', 'Bolin', ''], ['Du', 'Qianlong', ''], ['Zhang', 'Jiajun', ''], ['Chu', 'Dianhui', '']]"
2210.13076,Duo Zheng,"Duo Zheng, Tao Kong, Ya Jing, Jiaan Wang, Xiaojie Wang",Towards Unifying Reference Expression Generation and Comprehension,Accepted to EMNLP 2022 (main conference),,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Reference Expression Generation (REG) and Comprehension (REC) are two highly
correlated tasks. Modeling REG and REC simultaneously for utilizing the
relation between them is a promising way to improve both. However, the problem
of distinct inputs, as well as building connections between them in a single
model, brings challenges to the design and training of the joint model. To
address the problems, we propose a unified model for REG and REC, named UniRef.
It unifies these two tasks with the carefully-designed Image-Region-Text Fusion
layer (IRTF), which fuses the image, region and text via the image
cross-attention and region cross-attention. Additionally, IRTF could generate
pseudo input regions for the REC task to enable a uniform way for sharing the
identical representation space across the REC and REG. We further propose
Vision-conditioned Masked Language Modeling (VMLM) and Text-Conditioned Region
Prediction (TRP) to pre-train UniRef model on multi-granular corpora. The VMLM
and TRP are directly related to REG and REC, respectively, but could help each
other. We conduct extensive experiments on three benchmark datasets, RefCOCO,
RefCOCO+ and RefCOCOg. Experimental results show that our model outperforms
previous state-of-the-art methods on both REG and REC.
","[{'version': 'v1', 'created': 'Mon, 24 Oct 2022 09:53:41 GMT'}]",2022-10-25,"[['Zheng', 'Duo', ''], ['Kong', 'Tao', ''], ['Jing', 'Ya', ''], ['Wang', 'Jiaan', ''], ['Wang', 'Xiaojie', '']]"
2209.05301,Matthew Shardlow,"Sanja Stajner, Daniel Ferres, Matthew Shardlow, Kai North, Marcos
  Zampieri, Horacio Saggion","Lexical Simplification Benchmarks for English, Portuguese, and Spanish",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Even in highly-developed countries, as many as 15-30\% of the population can
only understand texts written using a basic vocabulary. Their understanding of
everyday texts is limited, which prevents them from taking an active role in
society and making informed decisions regarding healthcare, legal
representation, or democratic choice. Lexical simplification is a natural
language processing task that aims to make text understandable to everyone by
replacing complex vocabulary and expressions with simpler ones, while
preserving the original meaning. It has attracted considerable attention in the
last 20 years, and fully automatic lexical simplification systems have been
proposed for various languages. The main obstacle for the progress of the field
is the absence of high-quality datasets for building and evaluating lexical
simplification systems. We present a new benchmark dataset for lexical
simplification in English, Spanish, and (Brazilian) Portuguese, and provide
details about data selection and annotation procedures. This is the first
dataset that offers a direct comparison of lexical simplification systems for
three languages. To showcase the usability of the dataset, we adapt two
state-of-the-art lexical simplification systems with differing architectures
(neural vs.\ non-neural) to all three languages (English, Spanish, and
Brazilian Portuguese) and evaluate their performances on our new dataset. For a
fairer comparison, we use several evaluation measures which capture varied
aspects of the systems' efficacy, and discuss their strengths and weaknesses.
We find a state-of-the-art neural lexical simplification system outperforms a
state-of-the-art non-neural lexical simplification system in all three
languages. More importantly, we find that the state-of-the-art neural lexical
simplification systems perform significantly better for English than for
Spanish and Portuguese.
","[{'version': 'v1', 'created': 'Mon, 12 Sep 2022 15:06:26 GMT'}]",2022-09-13,"[['Stajner', 'Sanja', ''], ['Ferres', 'Daniel', ''], ['Shardlow', 'Matthew', ''], ['North', 'Kai', ''], ['Zampieri', 'Marcos', ''], ['Saggion', 'Horacio', '']]"
1909.04157,Liang Lu,"Liang Lu, Eric Sun and Yifan Gong",Self-Teaching Networks,"5 pages, Interspeech 2019",,,,eess.AS cs.CL cs.LG cs.SD stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose self-teaching networks to improve the generalization capacity of
deep neural networks. The idea is to generate soft supervision labels using the
output layer for training the lower layers of the network. During the network
training, we seek an auxiliary loss that drives the lower layer to mimic the
behavior of the output layer. The connection between the two network layers
through the auxiliary loss can help the gradient flow, which works similar to
the residual networks. Furthermore, the auxiliary loss also works as a
regularizer, which improves the generalization capacity of the network. We
evaluated the self-teaching network with deep recurrent neural networks on
speech recognition tasks, where we trained the acoustic model using 30 thousand
hours of data. We tested the acoustic model using data collected from 4
scenarios. We show that the self-teaching network can achieve consistent
improvements and outperform existing methods such as label smoothing and
confidence penalization.
","[{'version': 'v1', 'created': 'Mon, 9 Sep 2019 21:11:35 GMT'}]",2019-09-11,"[['Lu', 'Liang', ''], ['Sun', 'Eric', ''], ['Gong', 'Yifan', '']]"
2310.01846,Xiang Lisa Li,"Xiang Lisa Li, Vaishnavi Shrivastava, Siyan Li, Tatsunori Hashimoto,
  Percy Liang","Benchmarking and Improving Generator-Validator Consistency of Language
  Models",preprint,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  As of September 2023, ChatGPT correctly answers ""what is 7+8"" with 15, but
when asked ""7+8=15, True or False"" it responds with ""False"". This inconsistency
between generating and validating an answer is prevalent in language models
(LMs) and erodes trust. In this paper, we propose a framework for measuring the
consistency between generation and validation (which we call
generator-validator consistency, or GV-consistency), finding that even GPT-4, a
state-of-the-art LM, is GV-consistent only 76% of the time. To improve the
consistency of LMs, we propose to finetune on the filtered generator and
validator responses that are GV-consistent, and call this approach consistency
fine-tuning. We find that this approach improves GV-consistency of Alpaca-30B
from 60% to 93%, and the improvement extrapolates to unseen tasks and domains
(e.g., GV-consistency for positive style transfers extrapolates to unseen
styles like humor). In addition to improving consistency, consistency
fine-tuning improves both generator quality and validator accuracy without
using any labeled data. Evaluated across 6 tasks, including math questions,
knowledge-intensive QA, and instruction following, our method improves the
generator quality by 16% and the validator accuracy by 6.3% across all tasks.
","[{'version': 'v1', 'created': 'Tue, 3 Oct 2023 07:23:22 GMT'}]",2023-10-04,"[['Li', 'Xiang Lisa', ''], ['Shrivastava', 'Vaishnavi', ''], ['Li', 'Siyan', ''], ['Hashimoto', 'Tatsunori', ''], ['Liang', 'Percy', '']]"
2206.08288,Hiroaki Funayama,"Hiroaki Funayama, Tasuku Sato, Yuichiroh Matsubayashi, Tomoya
  Mizumoto, Jun Suzuki and Kentaro Inui","Balancing Cost and Quality: An Exploration of Human-in-the-loop
  Frameworks for Automated Short Answer Scoring","12pages, To be published in proceedings of AIED2022",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Short answer scoring (SAS) is the task of grading short text written by a
learner. In recent years, deep-learning-based approaches have substantially
improved the performance of SAS models, but how to guarantee high-quality
predictions still remains a critical issue when applying such models to the
education field. Towards guaranteeing high-quality predictions, we present the
first study of exploring the use of human-in-the-loop framework for minimizing
the grading cost while guaranteeing the grading quality by allowing a SAS model
to share the grading task with a human grader. Specifically, by introducing a
confidence estimation method for indicating the reliability of the model
predictions, one can guarantee the scoring quality by utilizing only
predictions with high reliability for the scoring results and casting
predictions with low reliability to human graders. In our experiments, we
investigate the feasibility of the proposed framework using multiple confidence
estimation methods and multiple SAS datasets. We find that our
human-in-the-loop framework allows automatic scoring models and human graders
to achieve the target scoring quality.
","[{'version': 'v1', 'created': 'Thu, 16 Jun 2022 16:43:18 GMT'}]",2022-06-17,"[['Funayama', 'Hiroaki', ''], ['Sato', 'Tasuku', ''], ['Matsubayashi', 'Yuichiroh', ''], ['Mizumoto', 'Tomoya', ''], ['Suzuki', 'Jun', ''], ['Inui', 'Kentaro', '']]"
1506.02078,Andrej Karpathy,"Andrej Karpathy, Justin Johnson, Li Fei-Fei",Visualizing and Understanding Recurrent Networks,"changing style, adding references, minor changes to text",,,,cs.LG cs.CL cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recurrent Neural Networks (RNNs), and specifically a variant with Long
Short-Term Memory (LSTM), are enjoying renewed interest as a result of
successful applications in a wide range of machine learning problems that
involve sequential data. However, while LSTMs provide exceptional results in
practice, the source of their performance and their limitations remain rather
poorly understood. Using character-level language models as an interpretable
testbed, we aim to bridge this gap by providing an analysis of their
representations, predictions and error types. In particular, our experiments
reveal the existence of interpretable cells that keep track of long-range
dependencies such as line lengths, quotes and brackets. Moreover, our
comparative analysis with finite horizon n-gram models traces the source of the
LSTM improvements to long-range structural dependencies. Finally, we provide
analysis of the remaining errors and suggests areas for further study.
","[{'version': 'v1', 'created': 'Fri, 5 Jun 2015 22:33:04 GMT'}, {'version': 'v2', 'created': 'Tue, 17 Nov 2015 02:42:24 GMT'}]",2015-11-18,"[['Karpathy', 'Andrej', ''], ['Johnson', 'Justin', ''], ['Fei-Fei', 'Li', '']]"
2311.04498,Ao Zhang,"Ao Zhang, Yuan Yao, Wei Ji, Zhiyuan Liu, Tat-Seng Chua","NExT-Chat: An LMM for Chat, Detection and Segmentation",Technical Report (https://next-chatv.github.io/),,,,cs.CV cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The development of large language models (LLMs) has greatly advanced the
field of multimodal understanding, leading to the emergence of large multimodal
models (LMMs). In order to enhance the level of visual comprehension, recent
studies have equipped LMMs with region-level understanding capabilities by
representing object bounding box coordinates as a series of text sequences
(pix2seq). In this paper, we introduce a novel paradigm for object location
modeling called pix2emb method, where we ask the LMM to output the location
embeddings and then decode them with different decoders. This paradigm allows
us to use different location formats (such as bounding boxes and masks) in
multimodal conversations. Leveraging the proposed pix2emb method, we train an
LMM named NExT-Chat and demonstrate its capability of handling multiple tasks
like visual grounding, region captioning, and grounded reasoning. Comprehensive
experiments show the effectiveness of our NExT-Chat on various tasks, e.g.,
NExT-Chat (87.7) vs. Shikra (86.9) on POPE-Random, NExT-Chat (68.9) vs. LISA
(67.9) on referring expression segmentation task, and NExT-Chat (79.6) vs.
Kosmos-2 (62.3) on region caption task. The code and model are released at
https://github.com/NExT-ChatV/NExT-Chat.
","[{'version': 'v1', 'created': 'Wed, 8 Nov 2023 07:15:05 GMT'}, {'version': 'v2', 'created': 'Fri, 10 Nov 2023 08:46:23 GMT'}, {'version': 'v3', 'created': 'Mon, 13 Nov 2023 03:35:23 GMT'}, {'version': 'v4', 'created': 'Mon, 18 Dec 2023 12:15:26 GMT'}]",2023-12-19,"[['Zhang', 'Ao', ''], ['Yao', 'Yuan', ''], ['Ji', 'Wei', ''], ['Liu', 'Zhiyuan', ''], ['Chua', 'Tat-Seng', '']]"
1910.00795,Andros Tjandra,"Andros Tjandra, Sakriani Sakti, Satoshi Nakamura",Speech-to-speech Translation between Untranscribed Unknown Languages,"Accepted in IEEE ASRU 2019. Web-page for more samples & details:
  https://sp2code-translation-v1.netlify.com/",,,,cs.CL cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we explore a method for training speech-to-speech translation
tasks without any transcription or linguistic supervision. Our proposed method
consists of two steps: First, we train and generate discrete representation
with unsupervised term discovery with a discrete quantized autoencoder. Second,
we train a sequence-to-sequence model that directly maps the source language
speech to the target language's discrete representation. Our proposed method
can directly generate target speech without any auxiliary or pre-training steps
with a source or target transcription. To the best of our knowledge, this is
the first work that performed pure speech-to-speech translation between
untranscribed unknown languages.
","[{'version': 'v1', 'created': 'Wed, 2 Oct 2019 06:42:57 GMT'}, {'version': 'v2', 'created': 'Sat, 5 Oct 2019 08:03:25 GMT'}]",2019-10-08,"[['Tjandra', 'Andros', ''], ['Sakti', 'Sakriani', ''], ['Nakamura', 'Satoshi', '']]"
2212.09674,Chester Palen-Michel,Chester Palen-Michel and Constantine Lignos,LR-Sum: Summarization for Less-Resourced Languages,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This preprint describes work in progress on LR-Sum, a new
permissively-licensed dataset created with the goal of enabling further
research in automatic summarization for less-resourced languages. LR-Sum
contains human-written summaries for 40 languages, many of which are
less-resourced. We describe our process for extracting and filtering the
dataset from the Multilingual Open Text corpus (Palen-Michel et al., 2022). The
source data is public domain newswire collected from from Voice of America
websites, and LR-Sum is released under a Creative Commons license (CC BY 4.0),
making it one of the most openly-licensed multilingual summarization datasets.
We describe how we plan to use the data for modeling experiments and discuss
limitations of the dataset.
","[{'version': 'v1', 'created': 'Mon, 19 Dec 2022 18:00:09 GMT'}, {'version': 'v2', 'created': 'Thu, 26 Oct 2023 19:50:29 GMT'}]",2023-10-30,"[['Palen-Michel', 'Chester', ''], ['Lignos', 'Constantine', '']]"
2110.03111,Louis Castricato,"Shahbuland Matiana, JR Smith, Ryan Teehan, Louis Castricato, Stella
  Biderman, Leo Gao, Spencer Frazier",Cut the CARP: Fishing for zero-shot story evaluation,"9 pages, 4 figures",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Recent advances in large-scale language models (Raffel et al., 2019; Brown et
al., 2020) have brought significant qualitative and quantitative improvements
in machine-driven text generation. Despite this, generation and evaluation of
machine-generated narrative text remains a challenging problem. Objective
evaluation of computationally-generated stories may be prohibitively expensive,
require meticulously annotated datasets, or may not adequately measure the
logical coherence of a generated story's narratological structure.
  Informed by recent advances in contrastive learning (Radford et al., 2021),
we present Contrastive Authoring and Reviewing Pairing (CARP): a scalable,
efficient method for performing qualitatively superior, zero-shot evaluation of
stories. We show a strong correlation between human evaluation of stories and
those of CARP. Model outputs more significantly correlate with corresponding
human input than those language-model based methods which utilize finetuning or
prompt engineering approaches. We also present and analyze the Story-Critique
Dataset, a new corpora composed of 1.3 million aligned story-critique pairs
derived from over 80,000 stories. We expect this corpus to be of interest to
NLP researchers.
","[{'version': 'v1', 'created': 'Wed, 6 Oct 2021 23:50:46 GMT'}, {'version': 'v2', 'created': 'Fri, 8 Oct 2021 17:27:35 GMT'}, {'version': 'v3', 'created': 'Tue, 26 Oct 2021 16:37:30 GMT'}]",2021-10-27,"[['Matiana', 'Shahbuland', ''], ['Smith', 'JR', ''], ['Teehan', 'Ryan', ''], ['Castricato', 'Louis', ''], ['Biderman', 'Stella', ''], ['Gao', 'Leo', ''], ['Frazier', 'Spencer', '']]"
2208.12666,Kaushal Bhogale,"Kaushal Santosh Bhogale, Abhigyan Raman, Tahir Javed, Sumanth
  Doddapaneni, Anoop Kunchukuttan, Pratyush Kumar, Mitesh M. Khapra","Effectiveness of Mining Audio and Text Pairs from Public Data for
  Improving ASR Systems for Low-Resource Languages",,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end (E2E) models have become the default choice for state-of-the-art
speech recognition systems. Such models are trained on large amounts of
labelled data, which are often not available for low-resource languages.
Techniques such as self-supervised learning and transfer learning hold promise,
but have not yet been effective in training accurate models. On the other hand,
collecting labelled datasets on a diverse set of domains and speakers is very
expensive. In this work, we demonstrate an inexpensive and effective
alternative to these approaches by ``mining'' text and audio pairs for Indian
languages from public sources, specifically from the public archives of All
India Radio. As a key component, we adapt the Needleman-Wunsch algorithm to
align sentences with corresponding audio segments given a long audio and a PDF
of its transcript, while being robust to errors due to OCR, extraneous text,
and non-transcribed speech. We thus create Shrutilipi, a dataset which contains
over 6,400 hours of labelled audio across 12 Indian languages totalling to
4.95M sentences. On average, Shrutilipi results in a 2.3x increase over
publicly available labelled data. We establish the quality of Shrutilipi with
21 human evaluators across the 12 languages. We also establish the diversity of
Shrutilipi in terms of represented regions, speakers, and mentioned named
entities. Significantly, we show that adding Shrutilipi to the training set of
Wav2Vec models leads to an average decrease in WER of 5.8\% for 7 languages on
the IndicSUPERB benchmark. For Hindi, which has the most benchmarks (7), the
average WER falls from 18.8% to 13.5%. This improvement extends to efficient
models: We show a 2.3% drop in WER for a Conformer model (10x smaller than
Wav2Vec). Finally, we demonstrate the diversity of Shrutilipi by showing that
the model trained with it is more robust to noisy input.
","[{'version': 'v1', 'created': 'Fri, 26 Aug 2022 13:37:45 GMT'}]",2022-08-29,"[['Bhogale', 'Kaushal Santosh', ''], ['Raman', 'Abhigyan', ''], ['Javed', 'Tahir', ''], ['Doddapaneni', 'Sumanth', ''], ['Kunchukuttan', 'Anoop', ''], ['Kumar', 'Pratyush', ''], ['Khapra', 'Mitesh M.', '']]"
2302.13311,Chunpu Xu,"Chunpu Xu, Hanzhuo Tan, Jing Li, Piji Li",Understanding Social Media Cross-Modality Discourse in Linguistic Space,EMNLP 2022 Findings,,,,cs.MM cs.CL cs.SI,http://creativecommons.org/licenses/by/4.0/,"  The multimedia communications with texts and images are popular on social
media. However, limited studies concern how images are structured with texts to
form coherent meanings in human cognition. To fill in the gap, we present a
novel concept of cross-modality discourse, reflecting how human readers couple
image and text understandings. Text descriptions are first derived from images
(named as subtitles) in the multimedia contexts. Five labels -- entity-level
insertion, projection and concretization and scene-level restatement and
extension -- are further employed to shape the structure of subtitles and texts
and present their joint meanings. As a pilot study, we also build the very
first dataset containing 16K multimedia tweets with manually annotated
discourse labels. The experimental results show that the multimedia encoder
based on multi-head attention with captions is able to obtain
the-state-of-the-art results.
","[{'version': 'v1', 'created': 'Sun, 26 Feb 2023 13:04:04 GMT'}]",2023-02-28,"[['Xu', 'Chunpu', ''], ['Tan', 'Hanzhuo', ''], ['Li', 'Jing', ''], ['Li', 'Piji', '']]"
1901.08259,Qian Liu,"Qian Liu, Bei Chen, Jian-Guang Lou, Ge Jin, Dongmei Zhang",FANDA: A Novel Approach to Perform Follow-up Query Analysis,Accepted by AAAI 2019,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent work on Natural Language Interfaces to Databases (NLIDB) has attracted
considerable attention. NLIDB allow users to search databases using natural
language instead of SQL-like query languages. While saving the users from
having to learn query languages, multi-turn interaction with NLIDB usually
involves multiple queries where contextual information is vital to understand
the users' query intents. In this paper, we address a typical contextual
understanding problem, termed as follow-up query analysis. In spite of its
ubiquity, follow-up query analysis has not been well studied due to two primary
obstacles: the multifarious nature of follow-up query scenarios and the lack of
high-quality datasets. Our work summarizes typical follow-up query scenarios
and provides a new FollowUp dataset with $1000$ query triples on 120 tables.
Moreover, we propose a novel approach FANDA, which takes into account the
structures of queries and employs a ranking model with weakly supervised
max-margin learning. The experimental results on FollowUp demonstrate the
superiority of FANDA over multiple baselines across multiple metrics.
","[{'version': 'v1', 'created': 'Thu, 24 Jan 2019 07:25:16 GMT'}]",2019-01-25,"[['Liu', 'Qian', ''], ['Chen', 'Bei', ''], ['Lou', 'Jian-Guang', ''], ['Jin', 'Ge', ''], ['Zhang', 'Dongmei', '']]"
2201.03327,Sajjad Kachuee,"Sajjad Kachuee, Mohammad Sharifkhani",Latency Adjustable Transformer Encoder for Language Understanding,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Adjusting the latency, power, and accuracy of natural language understanding
models is a desirable objective of an efficient architecture. This paper
proposes an efficient Transformer architecture that adjusts the inference
computational cost adaptively with a desired inference latency speedup. In
fine-tuning phase, the proposed method detects less important hidden sequence
elements (word-vectors) and eliminates them in each encoder layer using a
proposed Attention Context Contribution (ACC) metric. After the fine-tuning
phase, with the novel offline-tuning property, the inference latency of the
model can be adjusted in a wide range of inference speedup selections without
any further training. The proposed method is applied to the BERT-base and GPT-2
models for evaluation. Extensive experiments show that most of the word-vectors
in higher Transformer layers have less contribution to the subsequent layers;
hence, they can be eliminated to improve the inference latency. Experimental
results on extensive sentiment analysis, classification, text generation tasks
and regression benchmarks like GLUE showed that the method is effective in
various datasets with minimal impact on global context. The proposed method
mathematically and experimentally improves the inference latency of BERT-base
and GPT-2 by up to 4.8 and 3.72 times with less than 0.75% accuracy drop and
passable perplexity on average. The suggested approach posits that in Large
Language Models (LLMs), although the complete network is necessary for
training, it can be truncated during the fine-tuning phase.
","[{'version': 'v1', 'created': 'Mon, 10 Jan 2022 13:04:39 GMT'}, {'version': 'v2', 'created': 'Fri, 14 Jan 2022 14:45:24 GMT'}, {'version': 'v3', 'created': 'Fri, 11 Feb 2022 07:53:45 GMT'}, {'version': 'v4', 'created': 'Thu, 17 Mar 2022 14:04:59 GMT'}, {'version': 'v5', 'created': 'Tue, 21 Jun 2022 17:27:55 GMT'}, {'version': 'v6', 'created': 'Wed, 7 Sep 2022 13:53:53 GMT'}, {'version': 'v7', 'created': 'Wed, 20 Dec 2023 17:41:51 GMT'}]",2023-12-21,"[['Kachuee', 'Sajjad', ''], ['Sharifkhani', 'Mohammad', '']]"
2310.02989,Siavash Golkar,"Siavash Golkar, Mariel Pettee, Michael Eickenberg, Alberto Bietti,
  Miles Cranmer, Geraud Krawezik, Francois Lanusse, Michael McCabe, Ruben
  Ohana, Liam Parker, Bruno R\'egaldo-Saint Blancard, Tiberiu Tesileanu,
  Kyunghyun Cho, Shirley Ho",xVal: A Continuous Number Encoding for Large Language Models,10 pages 7 figures. Supplementary: 5 pages 2 figures,,,,stat.ML cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models have not yet been broadly adapted for the analysis of
scientific datasets due in part to the unique difficulties of tokenizing
numbers. We propose xVal, a numerical encoding scheme that represents any real
number using just a single token. xVal represents a given real number by
scaling a dedicated embedding vector by the number value. Combined with a
modified number-inference approach, this strategy renders the model end-to-end
continuous when considered as a map from the numbers of the input string to
those of the output string. This leads to an inductive bias that is generally
more suitable for applications in scientific domains. We empirically evaluate
our proposal on a number of synthetic and real-world datasets. Compared with
existing number encoding schemes, we find that xVal is more token-efficient and
demonstrates improved generalization.
","[{'version': 'v1', 'created': 'Wed, 4 Oct 2023 17:26:16 GMT'}]",2023-10-05,"[['Golkar', 'Siavash', ''], ['Pettee', 'Mariel', ''], ['Eickenberg', 'Michael', ''], ['Bietti', 'Alberto', ''], ['Cranmer', 'Miles', ''], ['Krawezik', 'Geraud', ''], ['Lanusse', 'Francois', ''], ['McCabe', 'Michael', ''], ['Ohana', 'Ruben', ''], ['Parker', 'Liam', ''], ['Blancard', 'Bruno Régaldo-Saint', ''], ['Tesileanu', 'Tiberiu', ''], ['Cho', 'Kyunghyun', ''], ['Ho', 'Shirley', '']]"
2202.03354,Michael Heck,"Michael Heck, Nurul Lubis, Carel van Niekerk, Shutong Feng, Christian
  Geishauser, Hsien-Chin Lin, Milica Ga\v{s}i\'c",Robust Dialogue State Tracking with Weak Supervision and Sparse Data,"12 pages, 6 figures, pre-MIT Press publication version (author's
  final version), accepted for publication in TACL",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generalising dialogue state tracking (DST) to new data is especially
challenging due to the strong reliance on abundant and fine-grained supervision
during training. Sample sparsity, distributional shift and the occurrence of
new concepts and topics frequently lead to severe performance degradation
during inference. In this paper we propose a training strategy to build
extractive DST models without the need for fine-grained manual span labels. Two
novel input-level dropout methods mitigate the negative impact of sample
sparsity. We propose a new model architecture with a unified encoder that
supports value as well as slot independence by leveraging the attention
mechanism. We combine the strengths of triple copy strategy DST and value
matching to benefit from complementary predictions without violating the
principle of ontology independence. Our experiments demonstrate that an
extractive DST model can be trained without manual span labels. Our
architecture and training strategies improve robustness towards sample
sparsity, new concepts and topics, leading to state-of-the-art performance on a
range of benchmarks. We further highlight our model's ability to effectively
learn from non-dialogue data.
","[{'version': 'v1', 'created': 'Mon, 7 Feb 2022 16:58:12 GMT'}, {'version': 'v2', 'created': 'Tue, 9 Aug 2022 15:08:46 GMT'}]",2022-08-10,"[['Heck', 'Michael', ''], ['Lubis', 'Nurul', ''], ['van Niekerk', 'Carel', ''], ['Feng', 'Shutong', ''], ['Geishauser', 'Christian', ''], ['Lin', 'Hsien-Chin', ''], ['Gašić', 'Milica', '']]"
2304.09842,Pan Lu,"Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying
  Nian Wu, Song-Chun Zhu, Jianfeng Gao","Chameleon: Plug-and-Play Compositional Reasoning with Large Language
  Models","32 pages, 10 figures, 24 tables. Accepted to NeurIPS 2023",,,,cs.CL cs.AI cs.CV cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have achieved remarkable progress in solving
various natural language processing tasks due to emergent reasoning abilities.
However, LLMs have inherent limitations as they are incapable of accessing
up-to-date information (stored on the Web or in task-specific knowledge bases),
using external tools, and performing precise mathematical and logical
reasoning. In this paper, we present Chameleon, an AI system that mitigates
these limitations by augmenting LLMs with plug-and-play modules for
compositional reasoning. Chameleon synthesizes programs by composing various
tools (e.g., LLMs, off-the-shelf vision models, web search engines, Python
functions, and heuristic-based modules) for accomplishing complex reasoning
tasks. At the heart of Chameleon is an LLM-based planner that assembles a
sequence of tools to execute to generate the final response. We showcase the
effectiveness of Chameleon on two multi-modal knowledge-intensive reasoning
tasks: ScienceQA and TabMWP. Chameleon, powered by GPT-4, achieves an 86.54%
overall accuracy on ScienceQA, improving the best published few-shot result by
11.37%. On TabMWP, GPT-4-powered Chameleon improves the accuracy by 17.0%,
lifting the state of the art to 98.78%. Our analysis also shows that the
GPT-4-powered planner exhibits more consistent and rational tool selection via
inferring potential constraints from instructions, compared to a
ChatGPT-powered planner. The project is available at
https://chameleon-llm.github.io.
","[{'version': 'v1', 'created': 'Wed, 19 Apr 2023 17:47:47 GMT'}, {'version': 'v2', 'created': 'Wed, 24 May 2023 17:52:19 GMT'}, {'version': 'v3', 'created': 'Tue, 31 Oct 2023 17:43:39 GMT'}]",2023-11-01,"[['Lu', 'Pan', ''], ['Peng', 'Baolin', ''], ['Cheng', 'Hao', ''], ['Galley', 'Michel', ''], ['Chang', 'Kai-Wei', ''], ['Wu', 'Ying Nian', ''], ['Zhu', 'Song-Chun', ''], ['Gao', 'Jianfeng', '']]"
2312.12383,David Noever,David Noever and Samantha Elizabeth Miller Noever,"Visual AI and Linguistic Intelligence Through Steerability and
  Composability",,,,,cs.AI cs.CL cs.CV,http://creativecommons.org/licenses/by/4.0/,"  This study explores the capabilities of multimodal large language models
(LLMs) in handling challenging multistep tasks that integrate language and
vision, focusing on model steerability, composability, and the application of
long-term memory and context understanding. The problem addressed is the LLM's
ability (Nov 2023 GPT-4 Vision Preview) to manage tasks that require
synthesizing visual and textual information, especially where stepwise
instructions and sequential logic are paramount. The research presents a series
of 14 creatively and constructively diverse tasks, ranging from AI Lego
Designing to AI Satellite Image Analysis, designed to test the limits of
current LLMs in contexts that previously proved difficult without extensive
memory and contextual understanding. Key findings from evaluating 800 guided
dialogs include notable disparities in task completion difficulty. For
instance, 'Image to Ingredient AI Bartender' (Low difficulty) contrasted
sharply with 'AI Game Self-Player' (High difficulty), highlighting the LLM's
varying proficiency in processing complex visual data and generating coherent
instructions. Tasks such as 'AI Genetic Programmer' and 'AI Negotiator' showed
high completion difficulty, emphasizing challenges in maintaining context over
multiple steps. The results underscore the importance of developing LLMs that
combine long-term memory and contextual awareness to mimic human-like thought
processes in complex problem-solving scenarios.
","[{'version': 'v1', 'created': 'Sat, 18 Nov 2023 22:01:33 GMT'}]",2023-12-20,"[['Noever', 'David', ''], ['Noever', 'Samantha Elizabeth Miller', '']]"
2403.13592,Stephanie Brandl,Ilias Chalkidis and Stephanie Brandl,"Llama meets EU: Investigating the European Political Spectrum through
  the Lens of LLMs",accepted to NAACL 2024 as a short paper,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Instruction-finetuned Large Language Models inherit clear political leanings
that have been shown to influence downstream task performance. We expand this
line of research beyond the two-party system in the US and audit Llama Chat in
the context of EU politics in various settings to analyze the model's political
knowledge and its ability to reason in context. We adapt, i.e., further
fine-tune, Llama Chat on speeches of individual euro-parties from debates in
the European Parliament to reevaluate its political leaning based on the EUandI
questionnaire. Llama Chat shows considerable knowledge of national parties'
positions and is capable of reasoning in context. The adapted, party-specific,
models are substantially re-aligned towards respective positions which we see
as a starting point for using chat-based LLMs as data-driven conversational
engines to assist research in political science.
","[{'version': 'v1', 'created': 'Wed, 20 Mar 2024 13:42:57 GMT'}]",2024-03-21,"[['Chalkidis', 'Ilias', ''], ['Brandl', 'Stephanie', '']]"
2009.07489,Sufeng Duan,"Sufeng Duan, Hai Zhao and Rui Wang",Graph-to-Sequence Neural Machine Translation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural machine translation (NMT) usually works in a seq2seq learning way by
viewing either source or target sentence as a linear sequence of words, which
can be regarded as a special case of graph, taking words in the sequence as
nodes and relationships between words as edges. In the light of the current NMT
models more or less capture graph information among the sequence in a latent
way, we present a graph-to-sequence model facilitating explicit graph
information capturing. In detail, we propose a graph-based SAN-based NMT model
called Graph-Transformer by capturing information of subgraphs of different
orders in every layers. Subgraphs are put into different groups according to
their orders, and every group of subgraphs respectively reflect different
levels of dependency between words. For fusing subgraph representations, we
empirically explore three methods which weight different groups of subgraphs of
different orders. Results of experiments on WMT14 English-German and IWSLT14
German-English show that our method can effectively boost the Transformer with
an improvement of 1.1 BLEU points on WMT14 English-German dataset and 1.0 BLEU
points on IWSLT14 German-English dataset.
","[{'version': 'v1', 'created': 'Wed, 16 Sep 2020 06:28:58 GMT'}]",2020-09-17,"[['Duan', 'Sufeng', ''], ['Zhao', 'Hai', ''], ['Wang', 'Rui', '']]"
2011.00474,Zhen Wu,"Chengcan Ying and Zhen Wu and Xinyu Dai and Shujian Huang and Jiajun
  Chen","Opinion Transmission Network for Jointly Improving Aspect-oriented
  Opinion Words Extraction and Sentiment Classification",Accepted by NLPCC 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Aspect-level sentiment classification (ALSC) and aspect oriented opinion
words extraction (AOWE) are two highly relevant aspect-based sentiment analysis
(ABSA) subtasks. They respectively aim to detect the sentiment polarity and
extract the corresponding opinion words toward a given aspect in a sentence.
Previous works separate them and focus on one of them by training neural models
on small-scale labeled data, while neglecting the connections between them. In
this paper, we propose a novel joint model, Opinion Transmission Network (OTN),
to exploit the potential bridge between ALSC and AOWE to achieve the goal of
facilitating them simultaneously. Specifically, we design two tailor-made
opinion transmission mechanisms to control opinion clues flow bidirectionally,
respectively from ALSC to AOWE and AOWE to ALSC. Experiment results on two
benchmark datasets show that our joint model outperforms strong baselines on
the two tasks. Further analysis also validates the effectiveness of opinion
transmission mechanisms.
","[{'version': 'v1', 'created': 'Sun, 1 Nov 2020 11:00:19 GMT'}]",2020-11-03,"[['Ying', 'Chengcan', ''], ['Wu', 'Zhen', ''], ['Dai', 'Xinyu', ''], ['Huang', 'Shujian', ''], ['Chen', 'Jiajun', '']]"
1908.00249,Ting Yao,Jing Wang and Yingwei Pan and Ting Yao and Jinhui Tang and Tao Mei,"Convolutional Auto-encoding of Sentence Topics for Image Paragraph
  Generation",IJCAI 2019,,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Image paragraph generation is the task of producing a coherent story (usually
a paragraph) that describes the visual content of an image. The problem
nevertheless is not trivial especially when there are multiple descriptive and
diverse gists to be considered for paragraph generation, which often happens in
real images. A valid question is how to encapsulate such gists/topics that are
worthy of mention from an image, and then describe the image from one topic to
another but holistically with a coherent structure. In this paper, we present a
new design --- Convolutional Auto-Encoding (CAE) that purely employs
convolutional and deconvolutional auto-encoding framework for topic modeling on
the region-level features of an image. Furthermore, we propose an architecture,
namely CAE plus Long Short-Term Memory (dubbed as CAE-LSTM), that novelly
integrates the learnt topics in support of paragraph generation. Technically,
CAE-LSTM capitalizes on a two-level LSTM-based paragraph generation framework
with attention mechanism. The paragraph-level LSTM captures the inter-sentence
dependency in a paragraph, while sentence-level LSTM is to generate one
sentence which is conditioned on each learnt topic. Extensive experiments are
conducted on Stanford image paragraph dataset, and superior results are
reported when comparing to state-of-the-art approaches. More remarkably,
CAE-LSTM increases CIDEr performance from 20.93% to 25.15%.
","[{'version': 'v1', 'created': 'Thu, 1 Aug 2019 07:58:50 GMT'}]",2019-08-02,"[['Wang', 'Jing', ''], ['Pan', 'Yingwei', ''], ['Yao', 'Ting', ''], ['Tang', 'Jinhui', ''], ['Mei', 'Tao', '']]"
2210.06970,Martin Potthast,"Alonso Palomino, Martin Potthast, Khalid Al-Khatib and Benno Stein","Differential Bias: On the Perceptibility of Stance Imbalance in
  Argumentation","Accepted at AACL-IJCNLP 2022, Findings Volume",,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Most research on natural language processing treats bias as an absolute
concept: Based on a (probably complex) algorithmic analysis, a sentence, an
article, or a text is classified as biased or not. Given the fact that for
humans the question of whether a text is biased can be difficult to answer or
is answered contradictory, we ask whether an ""absolute bias classification"" is
a promising goal at all. We see the problem not in the complexity of
interpreting language phenomena but in the diversity of sociocultural
backgrounds of the readers, which cannot be handled uniformly: To decide
whether a text has crossed the proverbial line between non-biased and biased is
subjective. By asking ""Is text X more [less, equally] biased than text Y?"" we
propose to analyze a simpler problem, which, by its construction, is rather
independent of standpoints, views, or sociocultural aspects. In such a model,
bias becomes a preference relation that induces a partial ordering from least
biased to most biased texts without requiring a decision on where to draw the
line. A prerequisite for this kind of bias model is the ability of humans to
perceive relative bias differences in the first place. In our research, we
selected a specific type of bias in argumentation, the stance bias, and
designed a crowdsourcing study showing that differences in stance bias are
perceptible when (light) support is provided through training or visual aid.
","[{'version': 'v1', 'created': 'Thu, 13 Oct 2022 12:48:07 GMT'}]",2022-10-14,"[['Palomino', 'Alonso', ''], ['Potthast', 'Martin', ''], ['Al-Khatib', 'Khalid', ''], ['Stein', 'Benno', '']]"
2403.01528,Qizhi Pei,"Qizhi Pei, Lijun Wu, Kaiyuan Gao, Jinhua Zhu, Yue Wang, Zun Wang, Tao
  Qin, and Rui Yan","Leveraging Biomolecule and Natural Language through Multi-Modal
  Learning: A Survey","Survey Paper. 25 pages, 9 figures, and 3 tables",,,,cs.CL cs.AI q-bio.BM,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The integration of biomolecular modeling with natural language (BL) has
emerged as a promising interdisciplinary area at the intersection of artificial
intelligence, chemistry and biology. This approach leverages the rich,
multifaceted descriptions of biomolecules contained within textual data sources
to enhance our fundamental understanding and enable downstream computational
tasks such as biomolecule property prediction. The fusion of the nuanced
narratives expressed through natural language with the structural and
functional specifics of biomolecules described via various molecular modeling
techniques opens new avenues for comprehensively representing and analyzing
biomolecules. By incorporating the contextual language data that surrounds
biomolecules into their modeling, BL aims to capture a holistic view
encompassing both the symbolic qualities conveyed through language as well as
quantitative structural characteristics. In this review, we provide an
extensive analysis of recent advancements achieved through cross modeling of
biomolecules and natural language. (1) We begin by outlining the technical
representations of biomolecules employed, including sequences, 2D graphs, and
3D structures. (2) We then examine in depth the rationale and key objectives
underlying effective multi-modal integration of language and molecular data
sources. (3) We subsequently survey the practical applications enabled to date
in this developing research area. (4) We also compile and summarize the
available resources and datasets to facilitate future work. (5) Looking ahead,
we identify several promising research directions worthy of further exploration
and investment to continue advancing the field. The related resources and
contents are updating in
\url{https://github.com/QizhiPei/Awesome-Biomolecule-Language-Cross-Modeling}.
","[{'version': 'v1', 'created': 'Sun, 3 Mar 2024 14:59:47 GMT'}, {'version': 'v2', 'created': 'Tue, 5 Mar 2024 11:12:47 GMT'}]",2024-03-06,"[['Pei', 'Qizhi', ''], ['Wu', 'Lijun', ''], ['Gao', 'Kaiyuan', ''], ['Zhu', 'Jinhua', ''], ['Wang', 'Yue', ''], ['Wang', 'Zun', ''], ['Qin', 'Tao', ''], ['Yan', 'Rui', '']]"
2311.16075,Francois Remy,Fran\c{c}ois Remy and Kris Demuynck and Thomas Demeester,"BioLORD-2023: Semantic Textual Representations Fusing LLM and Clinical
  Knowledge Graph Insights",Preprint of upcoming journal article,,,,cs.CL cs.AI cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this study, we investigate the potential of Large Language Models to
complement biomedical knowledge graphs in the training of semantic models for
the biomedical and clinical domains. Drawing on the wealth of the UMLS
knowledge graph and harnessing cutting-edge Large Language Models, we propose a
new state-of-the-art approach for obtaining high-fidelity representations of
biomedical concepts and sentences, consisting of three steps: an improved
contrastive learning phase, a novel self-distillation phase, and a weight
averaging phase. Through rigorous evaluations via the extensive BioLORD testing
suite and diverse downstream tasks, we demonstrate consistent and substantial
performance improvements over the previous state of the art (e.g. +2pts on
MedSTS, +2.5pts on MedNLI-S, +6.1pts on EHR-Rel-B). Besides our new
state-of-the-art biomedical model for English, we also distill and release a
multilingual model compatible with 50+ languages and finetuned on 7 European
languages. Many clinical pipelines can benefit from our latest models. Our new
multilingual model enables a range of languages to benefit from our
advancements in biomedical semantic representation learning, opening a new
avenue for bioinformatics researchers around the world. As a result, we hope to
see BioLORD-2023 becoming a precious tool for future biomedical applications.
","[{'version': 'v1', 'created': 'Mon, 27 Nov 2023 18:46:17 GMT'}]",2023-11-28,"[['Remy', 'François', ''], ['Demuynck', 'Kris', ''], ['Demeester', 'Thomas', '']]"
1707.04242,Christophe Van Gysel,"Tom Kenter, Alexey Borisov, Christophe Van Gysel, Mostafa Dehghani,
  Maarten de Rijke, Bhaskar Mitra",Neural Networks for Information Retrieval,Overview of full-day tutorial at SIGIR 2017,,,,cs.IR cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Machine learning plays a role in many aspects of modern IR systems, and deep
learning is applied in all of them. The fast pace of modern-day research has
given rise to many different approaches for many different IR problems. The
amount of information available can be overwhelming both for junior students
and for experienced researchers looking for new research topics and directions.
Additionally, it is interesting to see what key insights into IR problems the
new technologies are able to give us. The aim of this full-day tutorial is to
give a clear overview of current tried-and-trusted neural methods in IR and how
they benefit IR research. It covers key architectures, as well as the most
promising future directions.
","[{'version': 'v1', 'created': 'Thu, 13 Jul 2017 17:46:59 GMT'}]",2017-07-14,"[['Kenter', 'Tom', ''], ['Borisov', 'Alexey', ''], ['Van Gysel', 'Christophe', ''], ['Dehghani', 'Mostafa', ''], ['de Rijke', 'Maarten', ''], ['Mitra', 'Bhaskar', '']]"
1909.06091,Alham Fikri Aji,"Alham Fikri Aji, Kenneth Heafield",Neural Machine Translation with 4-Bit Precision and Beyond,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural Machine Translation (NMT) is resource intensive. We design a
quantization procedure to compress NMT models better for devices with limited
hardware capability. Because most neural network parameters are near zero, we
employ logarithmic quantization in lieu of fixed-point quantization. However,
we find bias terms are less amenable to log quantization but note they comprise
a tiny fraction of the model, so we leave them uncompressed. We also propose to
use an error-feedback mechanism during retraining, to preserve the compressed
model as a stale gradient. We empirically show that NMT models based on
Transformer or RNN architecture can be compressed up to 4-bit precision without
any noticeable quality degradation. Models can be compressed up to binary
precision, albeit with lower quality. The RNN architecture seems to be more
robust to quantization, compared to the Transformer.
","[{'version': 'v1', 'created': 'Fri, 13 Sep 2019 08:55:08 GMT'}, {'version': 'v2', 'created': 'Fri, 20 Sep 2019 17:26:10 GMT'}]",2019-09-23,"[['Aji', 'Alham Fikri', ''], ['Heafield', 'Kenneth', '']]"
1810.13097,Kim Anh Nguyen,Kim Anh Nguyen and Ngan Dong and Cam-Tu Nguyen,Attentive Neural Network for Named Entity Recognition in Vietnamese,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose an attentive neural network for the task of named entity
recognition in Vietnamese. The proposed attentive neural model makes use of
character-based language models and word embeddings to encode words as vector
representations. A neural network architecture of encoder, attention, and
decoder layers is then utilized to encode knowledge of input sentences and to
label entity tags. The experimental results show that the proposed attentive
neural network achieves the state-of-the-art results on the benchmark named
entity recognition datasets in Vietnamese in comparison to both hand-crafted
features based models and neural models.
","[{'version': 'v1', 'created': 'Wed, 31 Oct 2018 04:05:05 GMT'}, {'version': 'v2', 'created': 'Sun, 9 Jun 2019 11:40:02 GMT'}]",2019-06-11,"[['Nguyen', 'Kim Anh', ''], ['Dong', 'Ngan', ''], ['Nguyen', 'Cam-Tu', '']]"
2210.11399,Yi Tay,"Yi Tay, Jason Wei, Hyung Won Chung, Vinh Q. Tran, David R. So, Siamak
  Shakeri, Xavier Garcia, Huaixiu Steven Zheng, Jinfeng Rao, Aakanksha
  Chowdhery, Denny Zhou, Donald Metzler, Slav Petrov, Neil Houlsby, Quoc V. Le,
  Mostafa Dehghani",Transcending Scaling Laws with 0.1% Extra Compute,V2 has updated references/related work,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Scaling language models improves performance but comes with significant
computational costs. This paper proposes UL2R, a method that substantially
improves existing language models and their scaling curves with a relatively
tiny amount of extra compute. The key idea is to continue training a
state-of-the-art large language model (e.g., PaLM) on a few more steps with
UL2's mixture-of-denoiser objective. We show that, with almost negligible extra
computational costs and no new sources of data, we are able to substantially
improve the scaling properties of large language models on downstream metrics.
In this paper, we continue training PaLM with UL2R, introducing a new set of
models at 8B, 62B, and 540B scale which we call U-PaLM. Impressively, at 540B
scale, we show an approximately 2x computational savings rate where U-PaLM
achieves the same performance as the final PaLM 540B model at around half its
computational budget (i.e., saving $\sim$4.4 million TPUv4 hours). We further
show that this improved scaling curve leads to 'emergent abilities' on
challenging BIG-Bench tasks -- for instance, U-PaLM does much better than PaLM
on some tasks or demonstrates better quality at much smaller scale (62B as
opposed to 540B). Overall, we show that U-PaLM outperforms PaLM on many
few-shot setups, i.e., English NLP tasks (e.g., commonsense reasoning, question
answering), reasoning tasks with chain-of-thought (e.g., GSM8K), multilingual
tasks (MGSM, TydiQA), MMLU and challenging BIG-Bench tasks. Finally, we provide
qualitative examples showing the new capabilities of U-PaLM for single and
multi-span infilling.
","[{'version': 'v1', 'created': 'Thu, 20 Oct 2022 16:46:41 GMT'}, {'version': 'v2', 'created': 'Wed, 16 Nov 2022 12:32:52 GMT'}]",2022-11-17,"[['Tay', 'Yi', ''], ['Wei', 'Jason', ''], ['Chung', 'Hyung Won', ''], ['Tran', 'Vinh Q.', ''], ['So', 'David R.', ''], ['Shakeri', 'Siamak', ''], ['Garcia', 'Xavier', ''], ['Zheng', 'Huaixiu Steven', ''], ['Rao', 'Jinfeng', ''], ['Chowdhery', 'Aakanksha', ''], ['Zhou', 'Denny', ''], ['Metzler', 'Donald', ''], ['Petrov', 'Slav', ''], ['Houlsby', 'Neil', ''], ['Le', 'Quoc V.', ''], ['Dehghani', 'Mostafa', '']]"
2012.11468,Yunmo Chen,"Yunmo Chen, Sixing Lu, Fan Yang, Xiaojiang Huang, Xing Fan, Chenlei
  Guo","Pattern-aware Data Augmentation for Query Rewriting in Voice Assistant
  Systems",Accepted to DEEP-DIAL 2021 workshop at AAAI,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Query rewriting (QR) systems are widely used to reduce the friction caused by
errors in a spoken language understanding pipeline. However, the underlying
supervised models require a large number of labeled pairs, and these pairs are
hard and costly to be collected. Therefore, We propose an augmentation
framework that learns patterns from existing training pairs and generates
rewrite candidates from rewrite labels inversely to compensate for insufficient
QR training data. The proposed framework casts the augmentation problem as a
sequence-to-sequence generation task and enforces the optimization process with
a policy gradient technique for controllable rewarding. This approach goes
beyond the traditional heuristics or rule-based augmentation methods and is not
constrained to generate predefined patterns of swapping/replacing words. Our
experimental results show its effectiveness compared with a fully trained QR
baseline and demonstrate its potential application in boosting the QR
performance on low-resource domains or locales.
","[{'version': 'v1', 'created': 'Mon, 21 Dec 2020 16:36:32 GMT'}]",2020-12-22,"[['Chen', 'Yunmo', ''], ['Lu', 'Sixing', ''], ['Yang', 'Fan', ''], ['Huang', 'Xiaojiang', ''], ['Fan', 'Xing', ''], ['Guo', 'Chenlei', '']]"
2102.04610,Pengfei Wei,"Pengfei Wei, Bi Zeng and Wenxiong Liao","Joint Intent Detection and Slot Filling with Wheel-Graph Attention
  Networks",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Intent detection and slot filling are two fundamental tasks for building a
spoken language understanding (SLU) system. Multiple deep learning-based joint
models have demonstrated excellent results on the two tasks. In this paper, we
propose a new joint model with a wheel-graph attention network (Wheel-GAT)
which is able to model interrelated connections directly for intent detection
and slot filling. To construct a graph structure for utterances, we create
intent nodes, slot nodes, and directed edges. Intent nodes can provide
utterance-level semantic information for slot filling, while slot nodes can
also provide local keyword information for intent. Experiments show that our
model outperforms multiple baselines on two public datasets. Besides, we also
demonstrate that using Bidirectional Encoder Representation from Transformer
(BERT) model further boosts the performance in the SLU task.
","[{'version': 'v1', 'created': 'Tue, 9 Feb 2021 02:37:56 GMT'}]",2021-02-10,"[['Wei', 'Pengfei', ''], ['Zeng', 'Bi', ''], ['Liao', 'Wenxiong', '']]"
2310.12902,Nina Begus,Nina Begus,"Experimental Narratives: A Comparison of Human Crowdsourced Storytelling
  and AI Storytelling",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The paper proposes a framework that combines behavioral and computational
experiments employing fictional prompts as a novel tool for investigating
cultural artifacts and social biases in storytelling both by humans and
generative AI. The study analyzes 250 stories authored by crowdworkers in June
2019 and 80 stories generated by GPT-3.5 and GPT-4 in March 2023 by merging
methods from narratology and inferential statistics. Both crowdworkers and
large language models responded to identical prompts about creating and falling
in love with an artificial human. The proposed experimental paradigm allows a
direct comparison between human and LLM-generated storytelling. Responses to
the Pygmalionesque prompts confirm the pervasive presence of the Pygmalion myth
in the collective imaginary of both humans and large language models. All
solicited narratives present a scientific or technological pursuit. The
analysis reveals that narratives from GPT-3.5 and particularly GPT-4 are more
more progressive in terms of gender roles and sexuality than those written by
humans. While AI narratives can occasionally provide innovative plot twists,
they offer less imaginative scenarios and rhetoric than human-authored texts.
The proposed framework argues that fiction can be used as a window into human
and AI-based collective imaginary and social dimensions.
","[{'version': 'v1', 'created': 'Thu, 19 Oct 2023 16:54:38 GMT'}]",2023-10-20,"[['Begus', 'Nina', '']]"
2112.01640,David Wadden,"David Wadden, Kyle Lo, Lucy Lu Wang, Arman Cohan, Iz Beltagy, Hannaneh
  Hajishirzi","MultiVerS: Improving scientific claim verification with weak supervision
  and full-document context",NAACL Findings 2022. Github: https://github.com/dwadden/multivers,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The scientific claim verification task requires an NLP system to label
scientific documents which Support or Refute an input claim, and to select
evidentiary sentences (or rationales) justifying each predicted label. In this
work, we present MultiVerS, which predicts a fact-checking label and identifies
rationales in a multitask fashion based on a shared encoding of the claim and
full document context. This approach accomplishes two key modeling goals.
First, it ensures that all relevant contextual information is incorporated into
each labeling decision. Second, it enables the model to learn from instances
annotated with a document-level fact-checking label, but lacking sentence-level
rationales. This allows MultiVerS to perform weakly-supervised domain
adaptation by training on scientific documents labeled using high-precision
heuristics. Our approach outperforms two competitive baselines on three
scientific claim verification datasets, with particularly strong performance in
zero / few-shot domain adaptation experiments. Our code and data are available
at https://github.com/dwadden/multivers.
","[{'version': 'v1', 'created': 'Thu, 2 Dec 2021 23:37:16 GMT'}, {'version': 'v2', 'created': 'Mon, 9 May 2022 21:53:41 GMT'}]",2022-05-11,"[['Wadden', 'David', ''], ['Lo', 'Kyle', ''], ['Wang', 'Lucy Lu', ''], ['Cohan', 'Arman', ''], ['Beltagy', 'Iz', ''], ['Hajishirzi', 'Hannaneh', '']]"
2005.07818,Yanpei Shi,"Yanpei Shi, Qiang Huang, Thomas Hain",Speaker Re-identification with Speaker Dependent Speech Enhancement,Acceptted for presentation at Interspeech2020,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While the use of deep neural networks has significantly boosted speaker
recognition performance, it is still challenging to separate speakers in poor
acoustic environments. Here speech enhancement methods have traditionally
allowed improved performance. The recent works have shown that adapting speech
enhancement can lead to further gains. This paper introduces a novel approach
that cascades speech enhancement and speaker recognition. In the first step, a
speaker embedding vector is generated , which is used in the second step to
enhance the speech quality and re-identify the speakers. Models are trained in
an integrated framework with joint optimisation. The proposed approach is
evaluated using the Voxceleb1 dataset, which aims to assess speaker recognition
in real world situations. In addition three types of noise at different
signal-noise-ratios were added for this work. The obtained results show that
the proposed approach using speaker dependent speech enhancement can yield
better speaker recognition and speech enhancement performances than two
baselines in various noise conditions.
","[{'version': 'v1', 'created': 'Fri, 15 May 2020 23:02:10 GMT'}, {'version': 'v2', 'created': 'Fri, 7 Aug 2020 15:54:03 GMT'}, {'version': 'v3', 'created': 'Thu, 27 Aug 2020 07:36:12 GMT'}]",2020-08-28,"[['Shi', 'Yanpei', ''], ['Huang', 'Qiang', ''], ['Hain', 'Thomas', '']]"
1803.08652,Ikuya Yamada,"Ikuya Yamada, Ryuji Tamaki, Hiroyuki Shindo, Yoshiyasu Takefuji",Studio Ousia's Quiz Bowl Question Answering System,"This is a preprint of a springer book chapter from NIPS 2017
  Competitions proceedings",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this chapter, we describe our question answering system, which was the
winning system at the Human-Computer Question Answering (HCQA) Competition at
the Thirty-first Annual Conference on Neural Information Processing Systems
(NIPS). The competition requires participants to address a factoid question
answering task referred to as quiz bowl. To address this task, we use two novel
neural network models and combine these models with conventional information
retrieval models using a supervised machine learning model. Our system achieved
the best performance among the systems submitted in the competition and won a
match against six top human quiz experts by a wide margin.
","[{'version': 'v1', 'created': 'Fri, 23 Mar 2018 04:15:07 GMT'}]",2018-03-26,"[['Yamada', 'Ikuya', ''], ['Tamaki', 'Ryuji', ''], ['Shindo', 'Hiroyuki', ''], ['Takefuji', 'Yoshiyasu', '']]"
2107.11879,Marco Valentino,"Marco Valentino, Mokanarangan Thayaparan, Deborah Ferreira, Andr\'e
  Freitas","Hybrid Autoregressive Inference for Scalable Multi-hop Explanation
  Regeneration","To appear at the 36th AAAI Conference on Artificial Intelligence
  (AAAI-22)",,,,cs.CL cs.AI cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Regenerating natural language explanations in the scientific domain has been
proposed as a benchmark to evaluate complex multi-hop and explainable
inference. In this context, large language models can achieve state-of-the-art
performance when employed as cross-encoder architectures and fine-tuned on
human-annotated explanations. However, while much attention has been devoted to
the quality of the explanations, the problem of performing inference
efficiently is largely under-studied. Cross-encoders, in fact, are
intrinsically not scalable, possessing limited applicability to real-world
scenarios that require inference on massive facts banks. To enable complex
multi-hop reasoning at scale, this paper focuses on bi-encoder architectures,
investigating the problem of scientific explanation regeneration at the
intersection of dense and sparse models. Specifically, we present SCAR (for
Scalable Autoregressive Inference), a hybrid framework that iteratively
combines a Transformer-based bi-encoder with a sparse model of explanatory
power, designed to leverage explicit inference patterns in the explanations.
Our experiments demonstrate that the hybrid framework significantly outperforms
previous sparse models, achieving performance comparable with that of
state-of-the-art cross-encoders while being approx 50 times faster and scalable
to corpora of millions of facts. Further analyses on semantic drift and
multi-hop question answering reveal that the proposed hybridisation boosts the
quality of the most challenging explanations, contributing to improved
performance on downstream inference tasks.
","[{'version': 'v1', 'created': 'Sun, 25 Jul 2021 19:29:53 GMT'}, {'version': 'v2', 'created': 'Mon, 6 Dec 2021 17:03:57 GMT'}]",2021-12-07,"[['Valentino', 'Marco', ''], ['Thayaparan', 'Mokanarangan', ''], ['Ferreira', 'Deborah', ''], ['Freitas', 'André', '']]"
2402.14579,Nicolas Lell,"Hye Jin Kim, Nicolas Lell, Ansgar Scherp","Text Role Classification in Scientific Charts Using Multimodal
  Transformers",,,,,cs.CV cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text role classification involves classifying the semantic role of textual
elements within scientific charts. For this task, we propose to finetune two
pretrained multimodal document layout analysis models, LayoutLMv3 and UDOP, on
chart datasets. The transformers utilize the three modalities of text, image,
and layout as input. We further investigate whether data augmentation and
balancing methods help the performance of the models. The models are evaluated
on various chart datasets, and results show that LayoutLMv3 outperforms UDOP in
all experiments. LayoutLMv3 achieves the highest F1-macro score of 82.87 on the
ICPR22 test dataset, beating the best-performing model from the ICPR22
CHART-Infographics challenge. Moreover, the robustness of the models is tested
on a synthetic noisy dataset ICPR22-N. Finally, the generalizability of the
models is evaluated on three chart datasets, CHIME-R, DeGruyter, and EconBiz,
for which we added labels for the text roles. Findings indicate that even in
cases where there is limited training data, transformers can be used with the
help of data augmentation and balancing methods. The source code and datasets
are available on GitHub under
https://github.com/hjkimk/text-role-classification
","[{'version': 'v1', 'created': 'Thu, 8 Feb 2024 13:21:44 GMT'}]",2024-02-23,"[['Kim', 'Hye Jin', ''], ['Lell', 'Nicolas', ''], ['Scherp', 'Ansgar', '']]"
2211.15833,Bing Liu,"Bing Liu, Harrisen Scells, Wen Hua, Guido Zuccon, Genghong Zhao, Xia
  Zhang",Guiding Neural Entity Alignment with Compatibility,EMNLP 2022,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Entity Alignment (EA) aims to find equivalent entities between two Knowledge
Graphs (KGs). While numerous neural EA models have been devised, they are
mainly learned using labelled data only. In this work, we argue that different
entities within one KG should have compatible counterparts in the other KG due
to the potential dependencies among the entities. Making compatible predictions
thus should be one of the goals of training an EA model along with fitting the
labelled data: this aspect however is neglected in current methods. To power
neural EA models with compatibility, we devise a training framework by
addressing three problems: (1) how to measure the compatibility of an EA model;
(2) how to inject the property of being compatible into an EA model; (3) how to
optimise parameters of the compatibility model. Extensive experiments on
widely-used datasets demonstrate the advantages of integrating compatibility
within EA models. In fact, state-of-the-art neural EA models trained within our
framework using just 5\% of the labelled data can achieve comparable
effectiveness with supervised training using 20\% of the labelled data.
","[{'version': 'v1', 'created': 'Tue, 29 Nov 2022 00:05:08 GMT'}]",2022-11-30,"[['Liu', 'Bing', ''], ['Scells', 'Harrisen', ''], ['Hua', 'Wen', ''], ['Zuccon', 'Guido', ''], ['Zhao', 'Genghong', ''], ['Zhang', 'Xia', '']]"
2401.03512,Chengyue Yu,"Chengyue Yu, Lei Zang, Jiaotuan Wang, Chenyi Zhuang, Jinjie Gu","CharPoet: A Chinese Classical Poetry Generation System Based on
  Token-free LLM",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic Chinese classical poetry generation has attracted much research
interest, but achieving effective control over format and content
simultaneously remains challenging. Traditional systems usually accept keywords
as user inputs, resulting in limited control over content. Large language
models (LLMs) improve content control by allowing unrestricted user
instructions, but the token-by-token generation process frequently makes format
errors. Motivated by this, we propose CharPoet, a Chinese classical poetry
generation system based on token-free LLM, which provides effective control
over both format and content. Our token-free architecture generates in a
character-by-character manner, enabling precise control over the number of
characters. Pruned from existing token-based LLMs, CharPoet inherits their
pretrained capabilities and can generate poetry following instructions like
""Write me a poem for my mother's birthday."" CharPoet achieves format accuracy
above 0.96, outperforming Jiuge-GPT-2 (0.91) and GPT-4 (0.38). In terms of
content quality, CharPoet surpasses traditional systems including Jiuge, and is
comparable to other LLMs. Our system is open source and available at
https://modelscope.cn/models/CharPoet/CharPoet. A video demonstration of
CharPoet is available at https://youtu.be/voZ25qEp3Dc.
","[{'version': 'v1', 'created': 'Sun, 7 Jan 2024 15:00:36 GMT'}, {'version': 'v2', 'created': 'Tue, 9 Jan 2024 03:52:12 GMT'}, {'version': 'v3', 'created': 'Wed, 20 Mar 2024 07:39:48 GMT'}]",2024-03-21,"[['Yu', 'Chengyue', ''], ['Zang', 'Lei', ''], ['Wang', 'Jiaotuan', ''], ['Zhuang', 'Chenyi', ''], ['Gu', 'Jinjie', '']]"
2402.05224,Berk Atil,"Berk Atil, Mahsa Sheikhi Karizaki, Rebecca J. Passonneau",VerAs: Verify then Assess STEM Lab Reports,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  With an increasing focus in STEM education on critical thinking skills,
science writing plays an ever more important role in curricula that stress
inquiry skills. A recently published dataset of two sets of college level lab
reports from an inquiry-based physics curriculum relies on analytic assessment
rubrics that utilize multiple dimensions, specifying subject matter knowledge
and general components of good explanations. Each analytic dimension is
assessed on a 6-point scale, to provide detailed feedback to students that can
help them improve their science writing skills. Manual assessment can be slow,
and difficult to calibrate for consistency across all students in large
classes. While much work exists on automated assessment of open-ended questions
in STEM subjects, there has been far less work on long-form writing such as lab
reports. We present an end-to-end neural architecture that has separate
verifier and assessment modules, inspired by approaches to Open Domain Question
Answering (OpenQA). VerAs first verifies whether a report contains any content
relevant to a given rubric dimension, and if so, assesses the relevant
sentences. On the lab reports, VerAs outperforms multiple baselines based on
OpenQA systems or Automated Essay Scoring (AES). VerAs also performs well on an
analytic rubric for middle school physics essays.
","[{'version': 'v1', 'created': 'Wed, 7 Feb 2024 20:02:09 GMT'}]",2024-02-09,"[['Atil', 'Berk', ''], ['Karizaki', 'Mahsa Sheikhi', ''], ['Passonneau', 'Rebecca J.', '']]"
2311.07978,Jessica Ojo,"Jessica Ojo, Kelechi Ogueji, Pontus Stenetorp, David I. Adelani",How good are Large Language Models on African Languages?,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Recent advancements in natural language processing have led to the
proliferation of large language models (LLMs). These models have been shown to
yield good performance, using in-context learning, even on unseen tasks and
languages. Additionally, they have been widely adopted as
language-model-as-a-service commercial APIs like GPT-4 API. However, their
performance on African languages is largely unknown. We present an analysis of
three popular large language models (mT0, LLaMa 2, and GPT-4) on five tasks
(news topic classification, sentiment classification, machine translation,
question answering, and named entity recognition) across 30 African languages,
spanning different language families and geographical regions. Our results
suggest that all LLMs produce below-par performance on African languages, and
there is a large gap in performance compared to high-resource languages like
English most tasks. We find that GPT-4 has an average or impressive performance
on classification tasks but very poor results on generative tasks like machine
translation. Surprisingly, we find that mT0 had the best overall on
cross-lingual QA, better than the state-of-the-art supervised model (i.e.
fine-tuned mT5) and GPT-4 on African languages. Overall, LLaMa 2 records the
worst performance due to its limited multilingual capabilities and
English-centric pre-training corpus. In general, our findings present a
call-to-action to ensure African languages are well represented in large
language models, given their growing popularity.
","[{'version': 'v1', 'created': 'Tue, 14 Nov 2023 08:10:14 GMT'}]",2023-11-15,"[['Ojo', 'Jessica', ''], ['Ogueji', 'Kelechi', ''], ['Stenetorp', 'Pontus', ''], ['Adelani', 'David I.', '']]"
2001.05295,Ethan Steinberg,"Ethan Steinberg, Ken Jung, Jason A. Fries, Conor K. Corbin, Stephen R.
  Pfohl, Nigam H. Shah","Language Models Are An Effective Patient Representation Learning
  Technique For Electronic Health Record Data",,,,,cs.CL cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Widespread adoption of electronic health records (EHRs) has fueled the
development of using machine learning to build prediction models for various
clinical outcomes. This process is often constrained by having a relatively
small number of patient records for training the model. We demonstrate that
using patient representation schemes inspired from techniques in natural
language processing can increase the accuracy of clinical prediction models by
transferring information learned from the entire patient population to the task
of training a specific model, where only a subset of the population is
relevant. Such patient representation schemes enable a 3.5% mean improvement in
AUROC on five prediction tasks compared to standard baselines, with the average
improvement rising to 19% when only a small number of patient records are
available for training the clinical prediction model.
","[{'version': 'v1', 'created': 'Mon, 6 Jan 2020 22:24:59 GMT'}, {'version': 'v2', 'created': 'Tue, 12 May 2020 20:58:31 GMT'}]",2020-05-14,"[['Steinberg', 'Ethan', ''], ['Jung', 'Ken', ''], ['Fries', 'Jason A.', ''], ['Corbin', 'Conor K.', ''], ['Pfohl', 'Stephen R.', ''], ['Shah', 'Nigam H.', '']]"
2206.12759,Qingcheng Zeng,"Qingcheng Zeng, Dading Chong, Peilin Zhou, Jie Yang","Low-resource Accent Classification in Geographically-proximate Settings:
  A Forensic and Sociophonetics Perspective",INTERSPEECH 2022,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Accented speech recognition and accent classification are relatively
under-explored research areas in speech technology. Recently, deep
learning-based methods and Transformer-based pretrained models have achieved
superb performances in both areas. However, most accent classification tasks
focused on classifying different kinds of English accents and little attention
was paid to geographically-proximate accent classification, especially under a
low-resource setting where forensic speech science tasks usually encounter. In
this paper, we explored three main accent modelling methods combined with two
different classifiers based on 105 speaker recordings retrieved from five urban
varieties in Northern England. Although speech representations generated from
pretrained models generally have better performances in downstream
classification, traditional methods like Mel Frequency Cepstral Coefficients
(MFCCs) and formant measurements are equipped with specific strengths. These
results suggest that in forensic phonetics scenario where data are relatively
scarce, a simple modelling method and classifier could be competitive with
state-of-the-art pretrained speech models as feature extractors, which could
enhance a sooner estimation for the accent information in practices. Besides,
our findings also cross-validated a new methodology in quantifying
sociophonetic changes.
","[{'version': 'v1', 'created': 'Sun, 26 Jun 2022 01:25:17 GMT'}, {'version': 'v2', 'created': 'Wed, 29 Jun 2022 03:11:05 GMT'}]",2022-06-30,"[['Zeng', 'Qingcheng', ''], ['Chong', 'Dading', ''], ['Zhou', 'Peilin', ''], ['Yang', 'Jie', '']]"
2309.12361,Yeganeh Madadi,"Yeganeh Madadi, Mohammad Delsoz, Priscilla A. Lao, Joseph W. Fong, TJ
  Hollingsworth, Malik Y. Kahook, Siamak Yousefi","ChatGPT Assisting Diagnosis of Neuro-ophthalmology Diseases Based on
  Case Reports",,,,,cs.CY cs.AI cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Objective: To evaluate the efficiency of large language models (LLMs) such as
ChatGPT to assist in diagnosing neuro-ophthalmic diseases based on detailed
case descriptions. Methods: We selected 22 different case reports of
neuro-ophthalmic diseases from a publicly available online database. These
cases included a wide range of chronic and acute diseases that are commonly
seen by neuro-ophthalmic sub-specialists. We inserted the text from each case
as a new prompt into both ChatGPT v3.5 and ChatGPT Plus v4.0 and asked for the
most probable diagnosis. We then presented the exact information to two
neuro-ophthalmologists and recorded their diagnoses followed by comparison to
responses from both versions of ChatGPT. Results: ChatGPT v3.5, ChatGPT Plus
v4.0, and the two neuro-ophthalmologists were correct in 13 (59%), 18 (82%), 19
(86%), and 19 (86%) out of 22 cases, respectively. The agreement between the
various diagnostic sources were as follows: ChatGPT v3.5 and ChatGPT Plus v4.0,
13 (59%); ChatGPT v3.5 and the first neuro-ophthalmologist, 12 (55%); ChatGPT
v3.5 and the second neuro-ophthalmologist, 12 (55%); ChatGPT Plus v4.0 and the
first neuro-ophthalmologist, 17 (77%); ChatGPT Plus v4.0 and the second
neuro-ophthalmologist, 16 (73%); and first and second neuro-ophthalmologists 17
(17%). Conclusions: The accuracy of ChatGPT v3.5 and ChatGPT Plus v4.0 in
diagnosing patients with neuro-ophthalmic diseases was 59% and 82%,
respectively. With further development, ChatGPT Plus v4.0 may have potential to
be used in clinical care settings to assist clinicians in providing quick,
accurate diagnoses of patients in neuro-ophthalmology. The applicability of
using LLMs like ChatGPT in clinical settings that lack access to subspeciality
trained neuro-ophthalmologists deserves further research.
","[{'version': 'v1', 'created': 'Tue, 5 Sep 2023 00:44:23 GMT'}]",2023-09-25,"[['Madadi', 'Yeganeh', ''], ['Delsoz', 'Mohammad', ''], ['Lao', 'Priscilla A.', ''], ['Fong', 'Joseph W.', ''], ['Hollingsworth', 'TJ', ''], ['Kahook', 'Malik Y.', ''], ['Yousefi', 'Siamak', '']]"
2008.09105,Mingkui Tan,"Deng Huang, Peihao Chen, Runhao Zeng, Qing Du, Mingkui Tan, Chuang Gan",Location-aware Graph Convolutional Networks for Video Question Answering,,,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We addressed the challenging task of video question answering, which requires
machines to answer questions about videos in a natural language form. Previous
state-of-the-art methods attempt to apply spatio-temporal attention mechanism
on video frame features without explicitly modeling the location and relations
among object interaction occurred in videos. However, the relations between
object interaction and their location information are very critical for both
action recognition and question reasoning. In this work, we propose to
represent the contents in the video as a location-aware graph by incorporating
the location information of an object into the graph construction. Here, each
node is associated with an object represented by its appearance and location
features. Based on the constructed graph, we propose to use graph convolution
to infer both the category and temporal locations of an action. As the graph is
built on objects, our method is able to focus on the foreground action contents
for better video question answering. Lastly, we leverage an attention mechanism
to combine the output of graph convolution and encoded question features for
final answer reasoning. Extensive experiments demonstrate the effectiveness of
the proposed methods. Specifically, our method significantly outperforms
state-of-the-art methods on TGIF-QA, Youtube2Text-QA, and MSVD-QA datasets.
Code and pre-trained models are publicly available at:
https://github.com/SunDoge/L-GCN
","[{'version': 'v1', 'created': 'Fri, 7 Aug 2020 02:12:56 GMT'}]",2020-08-21,"[['Huang', 'Deng', ''], ['Chen', 'Peihao', ''], ['Zeng', 'Runhao', ''], ['Du', 'Qing', ''], ['Tan', 'Mingkui', ''], ['Gan', 'Chuang', '']]"
1304.3432,Stephen Jose Hanson,"Stephen Jose Hanson, Malcolm Bauer","Machine Learning, Clustering, and Polymorphy","Appears in Proceedings of the First Conference on Uncertainty in
  Artificial Intelligence (UAI1985)",,,UAI-P-1985-PG-117-128,cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes a machine induction program (WITT) that attempts to
model human categorization. Properties of categories to which human subjects
are sensitive includes best or prototypical members, relative contrasts between
putative categories, and polymorphy (neither necessary or sufficient features).
This approach represents an alternative to usual Artificial Intelligence
approaches to generalization and conceptual clustering which tend to focus on
necessary and sufficient feature rules, equivalence classes, and simple search
and match schemes. WITT is shown to be more consistent with human
categorization while potentially including results produced by more traditional
clustering schemes. Applications of this approach in the domains of expert
systems and information retrieval are also discussed.
","[{'version': 'v1', 'created': 'Wed, 27 Mar 2013 19:56:55 GMT'}]",2013-04-15,"[['Hanson', 'Stephen Jose', ''], ['Bauer', 'Malcolm', '']]"
2106.14720,Curt Kohler,Curt Kohler and Ron Daniel Jr,What's in a Measurement? Using GPT-3 on SemEval 2021 Task 8 -- MeasEval,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In the summer of 2020 OpenAI released its GPT-3 autoregressive language model
to much fanfare. While the model has shown promise on tasks in several areas,
it has not always been clear when the results were cherry-picked or when they
were the unvarnished output. We were particularly interested in what benefits
GPT-3 could bring to the SemEval 2021 MeasEval task - identifying measurements
and their associated attributes in scientific literature. We had already
experimented with multi-turn questions answering as a solution to this task. We
wanted to see if we could use GPT-3's few-shot learning capabilities to more
easily develop a solution that would have better performance than our prior
work. Unfortunately, we have not been successful in that effort. This paper
discusses the approach we used, challenges we encountered, and results we
observed. Some of the problems we encountered were simply due to the state of
the art. For example, the limits on the size of the prompt and answer limited
the amount of the training signal that could be offered. Others are more
fundamental. We are unaware of generative models that excel in retaining
factual information. Also, the impact of changes in the prompts is
unpredictable, making it hard to reliably improve performance.
","[{'version': 'v1', 'created': 'Mon, 28 Jun 2021 13:48:25 GMT'}]",2021-06-29,"[['Kohler', 'Curt', ''], ['Daniel', 'Ron', 'Jr']]"
2311.18765,Yanqing Liu,"Yanqing Liu, Kai Wang, Wenqi Shao, Ping Luo, Yu Qiao, Mike Zheng Shou,
  Kaipeng Zhang and Yang You",MLLMs-Augmented Visual-Language Representation Learning,,,,,cs.CV cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Visual-language pre-training has achieved remarkable success in many
multi-modal tasks, largely attributed to the availability of large-scale
image-text datasets. In this work, we demonstrate that Multi-modal Large
Language Models (MLLMs) can enhance visual-language representation learning by
establishing richer image-text associations for image-text datasets. Our
approach is simple, utilizing MLLMs to extend multiple diverse captions for
each image. To prevent the bias introduced by MLLMs' hallucinations and
monotonous language styles, we propose ""text shearing"" to maintain the quality
and availability of extended captions. In image-text retrieval, without
introducing additional training cost, our method consistently obtains 5.6 ~
35.0 and 16.8 ~ 46.1 improvement on Recall@1 under the fine-tuning and
zero-shot settings, respectively. Notably, we obtain zero-shot results that are
comparable to fine-tuning on target datasets, which encourages more exploration
of the versatile use of MLLMs.
","[{'version': 'v1', 'created': 'Thu, 30 Nov 2023 18:05:52 GMT'}, {'version': 'v2', 'created': 'Fri, 1 Dec 2023 15:38:31 GMT'}, {'version': 'v3', 'created': 'Wed, 13 Mar 2024 08:47:32 GMT'}]",2024-03-14,"[['Liu', 'Yanqing', ''], ['Wang', 'Kai', ''], ['Shao', 'Wenqi', ''], ['Luo', 'Ping', ''], ['Qiao', 'Yu', ''], ['Shou', 'Mike Zheng', ''], ['Zhang', 'Kaipeng', ''], ['You', 'Yang', '']]"
2205.02340,Yuri Kuratov,"Alina Kolesnikova, Yuri Kuratov, Vasily Konovalov, Mikhail Burtsev","Knowledge Distillation of Russian Language Models with Reduction of
  Vocabulary",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Today, transformer language models serve as a core component for majority of
natural language processing tasks. Industrial application of such models
requires minimization of computation time and memory footprint. Knowledge
distillation is one of approaches to address this goal. Existing methods in
this field are mainly focused on reducing the number of layers or dimension of
embeddings/hidden representations. Alternative option is to reduce the number
of tokens in vocabulary and therefore the embeddings matrix of the student
model. The main problem with vocabulary minimization is mismatch between input
sequences and output class distributions of a teacher and a student models. As
a result, it is impossible to directly apply KL-based knowledge distillation.
We propose two simple yet effective alignment techniques to make knowledge
distillation to the students with reduced vocabulary. Evaluation of distilled
models on a number of common benchmarks for Russian such as Russian SuperGLUE,
SberQuAD, RuSentiment, ParaPhaser, Collection-3 demonstrated that our
techniques allow to achieve compression from $17\times$ to $49\times$, while
maintaining quality of $1.7\times$ compressed student with the full-sized
vocabulary, but reduced number of Transformer layers only. We make our code and
distilled models available.
","[{'version': 'v1', 'created': 'Wed, 4 May 2022 21:56:57 GMT'}]",2022-05-06,"[['Kolesnikova', 'Alina', ''], ['Kuratov', 'Yuri', ''], ['Konovalov', 'Vasily', ''], ['Burtsev', 'Mikhail', '']]"
2110.05376,Suyoun Kim,"Suyoun Kim, Duc Le, Weiyi Zheng, Tarun Singh, Abhinav Arora, Xiaoyu
  Zhai, Christian Fuegen, Ozlem Kalinli, Michael L. Seltzer","Evaluating User Perception of Speech Recognition System Quality with
  Semantic Distance Metric",INTERSPEECH 2022,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Measuring automatic speech recognition (ASR) system quality is critical for
creating user-satisfying voice-driven applications. Word Error Rate (WER) has
been traditionally used to evaluate ASR system quality; however, it sometimes
correlates poorly with user perception/judgement of transcription quality. This
is because WER weighs every word equally and does not consider semantic
correctness which has a higher impact on user perception. In this work, we
propose evaluating ASR output hypotheses quality with SemDist that can measure
semantic correctness by using the distance between the semantic vectors of the
reference and hypothesis extracted from a pre-trained language model. Our
experimental results of 71K and 36K user annotated ASR output quality show that
SemDist achieves higher correlation with user perception than WER. We also show
that SemDist has higher correlation with downstream Natural Language
Understanding (NLU) tasks than WER.
","[{'version': 'v1', 'created': 'Mon, 11 Oct 2021 16:09:01 GMT'}, {'version': 'v2', 'created': 'Tue, 5 Jul 2022 20:24:08 GMT'}]",2022-07-07,"[['Kim', 'Suyoun', ''], ['Le', 'Duc', ''], ['Zheng', 'Weiyi', ''], ['Singh', 'Tarun', ''], ['Arora', 'Abhinav', ''], ['Zhai', 'Xiaoyu', ''], ['Fuegen', 'Christian', ''], ['Kalinli', 'Ozlem', ''], ['Seltzer', 'Michael L.', '']]"
2101.03778,Ekaterina Artemova,"Alexander Podolskiy and Dmitry Lipin and Andrey Bout and Ekaterina
  Artemova and Irina Piontkovskaya","Revisiting Mahalanobis Distance for Transformer-Based Out-of-Domain
  Detection",AAAI 2021,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Real-life applications, heavily relying on machine learning, such as dialog
systems, demand out-of-domain detection methods. Intent classification models
should be equipped with a mechanism to distinguish seen intents from unseen
ones so that the dialog agent is capable of rejecting the latter and avoiding
undesired behavior. However, despite increasing attention paid to the task, the
best practices for out-of-domain intent detection have not yet been fully
established.
  This paper conducts a thorough comparison of out-of-domain intent detection
methods. We prioritize the methods, not requiring access to out-of-domain data
during training, gathering of which is extremely time- and labor-consuming due
to lexical and stylistic variation of user utterances. We evaluate multiple
contextual encoders and methods, proven to be efficient, on three standard
datasets for intent classification, expanded with out-of-domain utterances. Our
main findings show that fine-tuning Transformer-based encoders on in-domain
data leads to superior results. Mahalanobis distance, together with utterance
representations, derived from Transformer-based encoders, outperforms other
methods by a wide margin and establishes new state-of-the-art results for all
datasets.
  The broader analysis shows that the reason for success lies in the fact that
the fine-tuned Transformer is capable of constructing homogeneous
representations of in-domain utterances, revealing geometrical disparity to out
of domain utterances. In turn, the Mahalanobis distance captures this disparity
easily.
  The code is available in our GitHub repo:
https://github.com/huawei-noah/noah-research/tree/master/Maha_OOD .
","[{'version': 'v1', 'created': 'Mon, 11 Jan 2021 09:10:58 GMT'}, {'version': 'v2', 'created': 'Mon, 23 May 2022 13:23:20 GMT'}]",2022-05-24,"[['Podolskiy', 'Alexander', ''], ['Lipin', 'Dmitry', ''], ['Bout', 'Andrey', ''], ['Artemova', 'Ekaterina', ''], ['Piontkovskaya', 'Irina', '']]"
2205.11308,Zhiling Zhang,"Zhiling Zhang, Siyuan Chen, Mengyue Wu, Kenny Q. Zhu","Symptom Identification for Interpretable Detection of Multiple Mental
  Disorders",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Mental disease detection (MDD) from social media has suffered from poor
generalizability and interpretability, due to lack of symptom modeling. This
paper introduces PsySym, the first annotated symptom identification corpus of
multiple psychiatric disorders, to facilitate further research progress. PsySym
is annotated according to a knowledge graph of the 38 symptom classes related
to 7 mental diseases complied from established clinical manuals and scales, and
a novel annotation framework for diversity and quality. Experiments show that
symptom-assisted MDD enabled by PsySym can outperform strong pure-text
baselines. We also exhibit the convincing MDD explanations provided by symptom
predictions with case studies, and point to their further potential
applications.
","[{'version': 'v1', 'created': 'Mon, 23 May 2022 13:51:48 GMT'}]",2022-05-24,"[['Zhang', 'Zhiling', ''], ['Chen', 'Siyuan', ''], ['Wu', 'Mengyue', ''], ['Zhu', 'Kenny Q.', '']]"
2304.11340,Sakae Mizuki,Sakae Mizuki and Naoaki Okazaki,Semantic Specialization for Knowledge-based Word Sense Disambiguation,Accepted by EACL 2023. 14 pages,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  A promising approach for knowledge-based Word Sense Disambiguation (WSD) is
to select the sense whose contextualized embeddings computed for its definition
sentence are closest to those computed for a target word in a given sentence.
This approach relies on the similarity of the \textit{sense} and
\textit{context} embeddings computed by a pre-trained language model. We
propose a semantic specialization for WSD where contextualized embeddings are
adapted to the WSD task using solely lexical knowledge. The key idea is, for a
given sense, to bring semantically related senses and contexts closer and send
different/unrelated senses farther away. We realize this idea as the joint
optimization of the Attract-Repel objective for sense pairs and the
self-training objective for context-sense pairs while controlling deviations
from the original embeddings. The proposed method outperformed previous studies
that adapt contextualized embeddings. It achieved state-of-the-art performance
on knowledge-based WSD when combined with the reranking heuristic that uses the
sense inventory. We found that the similarity characteristics of specialized
embeddings conform to the key idea. We also found that the (dis)similarity of
embeddings between the related/different/unrelated senses correlates well with
the performance of WSD.
","[{'version': 'v1', 'created': 'Sat, 22 Apr 2023 07:40:23 GMT'}]",2023-04-25,"[['Mizuki', 'Sakae', ''], ['Okazaki', 'Naoaki', '']]"
2110.15797,Brandon Trabucco,"Xuanlin Li, Brandon Trabucco, Dong Huk Park, Michael Luo, Sheng Shen,
  Trevor Darrell, Yang Gao","Discovering Non-monotonic Autoregressive Orderings with Variational
  Inference","updated from ICLR 2021, first two authors contributed equally",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The predominant approach for language modeling is to process sequences from
left to right, but this eliminates a source of information: the order by which
the sequence was generated. One strategy to recover this information is to
decode both the content and ordering of tokens. Existing approaches supervise
content and ordering by designing problem-specific loss functions and
pre-training with an ordering pre-selected. Other recent works use iterative
search to discover problem-specific orderings for training, but suffer from
high time complexity and cannot be efficiently parallelized. We address these
limitations with an unsupervised parallelizable learner that discovers
high-quality generation orders purely from training data -- no domain knowledge
required. The learner contains an encoder network and decoder language model
that perform variational inference with autoregressive orders (represented as
permutation matrices) as latent variables. The corresponding ELBO is not
differentiable, so we develop a practical algorithm for end-to-end optimization
using policy gradients. We implement the encoder as a Transformer with
non-causal attention that outputs permutations in one forward pass.
Permutations then serve as target generation orders for training an
insertion-based Transformer language model. Empirical results in language
modeling tasks demonstrate that our method is context-aware and discovers
orderings that are competitive with or even better than fixed orders.
","[{'version': 'v1', 'created': 'Wed, 27 Oct 2021 16:08:09 GMT'}]",2021-11-01,"[['Li', 'Xuanlin', ''], ['Trabucco', 'Brandon', ''], ['Park', 'Dong Huk', ''], ['Luo', 'Michael', ''], ['Shen', 'Sheng', ''], ['Darrell', 'Trevor', ''], ['Gao', 'Yang', '']]"
2207.04447,Kiril Gashteovski,"Bhushan Kotnis, Kiril Gashteovski, Julia Gastinger, Giuseppe Serra,
  Francesco Alesiani, Timo Sztyler, Ammar Shaker, Na Gong, Carolin Lawrence,
  Zhao Xu","Human-Centric Research for NLP: Towards a Definition and Guiding
  Questions",,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  With Human-Centric Research (HCR) we can steer research activities so that
the research outcome is beneficial for human stakeholders, such as end users.
But what exactly makes research human-centric? We address this question by
providing a working definition and define how a research pipeline can be split
into different stages in which human-centric components can be added.
Additionally, we discuss existing NLP with HCR components and define a series
of guiding questions, which can serve as starting points for researchers
interested in exploring human-centric research approaches. We hope that this
work would inspire researchers to refine the proposed definition and to pose
other questions that might be meaningful for achieving HCR.
","[{'version': 'v1', 'created': 'Sun, 10 Jul 2022 12:02:27 GMT'}]",2022-07-12,"[['Kotnis', 'Bhushan', ''], ['Gashteovski', 'Kiril', ''], ['Gastinger', 'Julia', ''], ['Serra', 'Giuseppe', ''], ['Alesiani', 'Francesco', ''], ['Sztyler', 'Timo', ''], ['Shaker', 'Ammar', ''], ['Gong', 'Na', ''], ['Lawrence', 'Carolin', ''], ['Xu', 'Zhao', '']]"
2403.04656,Lin Xu,"Lin Xu, Ningxin Peng, Daquan Zhou, See-Kiong Ng, Jinlan Fu",Chain of Thought Explanation for Dialogue State Tracking,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Dialogue state tracking (DST) aims to record user queries and goals during a
conversational interaction achieved by maintaining a predefined set of slots
and their corresponding values. Current approaches decide slot values opaquely,
while humans usually adopt a more deliberate approach by collecting information
from relevant dialogue turns and then reasoning the appropriate values. In this
work, we focus on the steps needed to figure out slot values by proposing a
model named Chain-of-Thought-Explanation (CoTE) for the DST task. CoTE, which
is built on the generative DST framework, is designed to create detailed
explanations step by step after determining the slot values. This process leads
to more accurate and reliable slot values. More-over, to improve the reasoning
ability of the CoTE, we further construct more fluent and high-quality
explanations with automatic paraphrasing, leading the method CoTE-refined.
Experimental results on three widely recognized DST benchmarks-MultiWOZ 2.2,
WoZ 2.0, and M2M-demonstrate the remarkable effectiveness of the CoTE.
Furthermore, through a meticulous fine-grained analysis, we observe significant
benefits of our CoTE on samples characterized by longer dialogue turns, user
responses, and reasoning steps.
","[{'version': 'v1', 'created': 'Thu, 7 Mar 2024 16:59:55 GMT'}, {'version': 'v2', 'created': 'Sat, 9 Mar 2024 15:37:36 GMT'}]",2024-03-12,"[['Xu', 'Lin', ''], ['Peng', 'Ningxin', ''], ['Zhou', 'Daquan', ''], ['Ng', 'See-Kiong', ''], ['Fu', 'Jinlan', '']]"
2004.01549,Manikandan Ravikiran,Manikandan Ravikiran,"Finding Black Cat in a Coal Cellar -- Keyphrase Extraction &
  Keyphrase-Rubric Relationship Classification from Complex Assignments","v1 preprint. Working paper. More results to be added. Text overlap
  with arXiv:2003.07019",,,,cs.CL cs.CY cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Diversity in content and open-ended questions are inherent in complex
assignments across online graduate programs. The natural scale of these
programs poses a variety of challenges across both peer and expert feedback
including rogue reviews. While the identification of relevant content and
associating it to predefined rubrics would simplify and improve the grading
process, the research to date is still in a nascent stage. As such in this
paper we aim to quantify the effectiveness of supervised and unsupervised
approaches for the task for keyphrase extraction and generic/specific
keyphrase-rubric relationship extraction. Through this study, we find that (i)
unsupervised MultiPartiteRank produces the best result for keyphrase extraction
(ii) supervised SVM classifier with BERT features that offer the best
performance for both generic and specific keyphrase-rubric relationship
classification. We finally present a comprehensive analysis and derive useful
observations for those interested in these tasks for the future. The source
code is released in \url{https://github.com/manikandan-ravikiran/cs6460-proj}.
","[{'version': 'v1', 'created': 'Fri, 3 Apr 2020 13:18:02 GMT'}, {'version': 'v2', 'created': 'Mon, 6 Apr 2020 12:09:54 GMT'}, {'version': 'v3', 'created': 'Fri, 24 Apr 2020 13:17:19 GMT'}]",2020-04-27,"[['Ravikiran', 'Manikandan', '']]"
2401.12086,Aliz\'ee Pace,"Aliz\'ee Pace, Jonathan Mallinson, Eric Malmi, Sebastian Krause,
  Aliaksei Severyn",West-of-N: Synthetic Preference Generation for Improved Reward Modeling,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The success of reinforcement learning from human feedback (RLHF) in language
model alignment is strongly dependent on the quality of the underlying reward
model. In this paper, we present a novel approach to improve reward model
quality by generating synthetic preference data, thereby augmenting the
training dataset with on-policy, high-quality preference pairs. Motivated by
the promising results of Best-of-N sampling strategies in language model
training, we extend their application to reward model training. This results in
a self-training strategy to generate preference pairs by selecting the best and
worst candidates in a pool of responses to a given query. Empirically, we find
that this approach improves the performance of any reward model, with an effect
comparable to the addition of a similar quantity of human preference data. This
work opens up new avenues of research for improving RLHF for language model
alignment, by offering synthetic preference generation as a solution to reward
modeling challenges.
","[{'version': 'v1', 'created': 'Mon, 22 Jan 2024 16:24:43 GMT'}]",2024-01-23,"[['Pace', 'Alizée', ''], ['Mallinson', 'Jonathan', ''], ['Malmi', 'Eric', ''], ['Krause', 'Sebastian', ''], ['Severyn', 'Aliaksei', '']]"
2308.13534,Arsalan Shahid,"Ahtsham Zafar, Venkatesh Balavadhani Parthasarathy, Chan Le Van, Saad
  Shahid, Aafaq Iqbal khan, Arsalan Shahid","Building Trust in Conversational AI: A Comprehensive Review and Solution
  Architecture for Explainable, Privacy-Aware Systems using LLMs and Knowledge
  Graph",,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Conversational AI systems have emerged as key enablers of human-like
interactions across diverse sectors. Nevertheless, the balance between
linguistic nuance and factual accuracy has proven elusive. In this paper, we
first introduce LLMXplorer, a comprehensive tool that provides an in-depth
review of over 150 Large Language Models (LLMs), elucidating their myriad
implications ranging from social and ethical to regulatory, as well as their
applicability across industries. Building on this foundation, we propose a
novel functional architecture that seamlessly integrates the structured
dynamics of Knowledge Graphs with the linguistic capabilities of LLMs.
Validated using real-world AI news data, our architecture adeptly blends
linguistic sophistication with factual rigour and further strengthens data
security through Role-Based Access Control. This research provides insights
into the evolving landscape of conversational AI, emphasizing the imperative
for systems that are efficient, transparent, and trustworthy.
","[{'version': 'v1', 'created': 'Sun, 13 Aug 2023 22:47:51 GMT'}]",2023-08-29,"[['Zafar', 'Ahtsham', ''], ['Parthasarathy', 'Venkatesh Balavadhani', ''], ['Van', 'Chan Le', ''], ['Shahid', 'Saad', ''], ['khan', 'Aafaq Iqbal', ''], ['Shahid', 'Arsalan', '']]"
2302.11042,Tai Nguyen,Tai Nguyen and Eric Wong,In-context Example Selection with Influences,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In-context learning (ICL) is a powerful paradigm emerged from large language
models (LLMs). Despite its promises, ICL performance is known to be highly
sensitive to input examples. In this work, we use $\textit{in-context
influences}$ to analyze few-shot ICL performance directly from the in-context
examples. Our proposed influence-based example selection method can identify
both positive and negative examples, outperforming several baselines when
evaluated on 9 SuperGLUE tasks. Our analysis uncovers up to a $16.3\%$
performance gap between using the most negative in-context examples compared to
the most positive. In a case study, we apply our influence-based framework to
quantify the phenomena of recency bias in example ordering for few-shot ICL.
","[{'version': 'v1', 'created': 'Tue, 21 Feb 2023 22:47:45 GMT'}, {'version': 'v2', 'created': 'Mon, 5 Jun 2023 17:49:58 GMT'}]",2023-06-06,"[['Nguyen', 'Tai', ''], ['Wong', 'Eric', '']]"
2305.15507,Antonio Valerio Miceli Barone,"Antonio Valerio Miceli-Barone, Fazl Barez, Ioannis Konstas, Shay B.
  Cohen","The Larger They Are, the Harder They Fail: Language Models do not
  Recognize Identifier Swaps in Python","17 pages, 5 figure, ACL 2023",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) have successfully been applied to code
generation tasks, raising the question of how well these models understand
programming. Typical programming languages have invariances and equivariances
in their semantics that human programmers intuitively understand and exploit,
such as the (near) invariance to the renaming of identifiers. We show that LLMs
not only fail to properly generate correct Python code when default function
names are swapped, but some of them even become more confident in their
incorrect predictions as the model size increases, an instance of the recently
discovered phenomenon of Inverse Scaling, which runs contrary to the commonly
observed trend of increasing prediction quality with increasing model size. Our
findings indicate that, despite their astonishing typical-case performance,
LLMs still lack a deep, abstract understanding of the content they manipulate,
making them unsuitable for tasks that statistically deviate from their training
data, and that mere scaling is not enough to achieve such capability.
","[{'version': 'v1', 'created': 'Wed, 24 May 2023 18:54:39 GMT'}]",2023-05-26,"[['Miceli-Barone', 'Antonio Valerio', ''], ['Barez', 'Fazl', ''], ['Konstas', 'Ioannis', ''], ['Cohen', 'Shay B.', '']]"
2112.12444,Muhammad Bilal Zafar,"Muhammad Bilal Zafar, Philipp Schmidt, Michele Donini, C\'edric
  Archambeau, Felix Biessmann, Sanjiv Ranjan Das, Krishnaram Kenthapadi","More Than Words: Towards Better Quality Interpretations of Text
  Classifiers",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The large size and complex decision mechanisms of state-of-the-art text
classifiers make it difficult for humans to understand their predictions,
leading to a potential lack of trust by the users. These issues have led to the
adoption of methods like SHAP and Integrated Gradients to explain
classification decisions by assigning importance scores to input tokens.
However, prior work, using different randomization tests, has shown that
interpretations generated by these methods may not be robust. For instance,
models making the same predictions on the test set may still lead to different
feature importance rankings. In order to address the lack of robustness of
token-based interpretability, we explore explanations at higher semantic levels
like sentences. We use computational metrics and human subject studies to
compare the quality of sentence-based interpretations against token-based ones.
Our experiments show that higher-level feature attributions offer several
advantages: 1) they are more robust as measured by the randomization tests, 2)
they lead to lower variability when using approximation-based methods like
SHAP, and 3) they are more intelligible to humans in situations where the
linguistic coherence resides at a higher granularity level. Based on these
findings, we show that token-based interpretability, while being a convenient
first choice given the input interfaces of the ML models, is not the most
effective one in all situations.
","[{'version': 'v1', 'created': 'Thu, 23 Dec 2021 10:18:50 GMT'}]",2021-12-24,"[['Zafar', 'Muhammad Bilal', ''], ['Schmidt', 'Philipp', ''], ['Donini', 'Michele', ''], ['Archambeau', 'Cédric', ''], ['Biessmann', 'Felix', ''], ['Das', 'Sanjiv Ranjan', ''], ['Kenthapadi', 'Krishnaram', '']]"
2306.09306,Shankar Padmanabhan,"Shankar Padmanabhan, Yasumasa Onoe, Michael J.Q. Zhang, Greg Durrett,
  Eunsol Choi",Propagating Knowledge Updates to LMs Through Distillation,NeurIPS 2023 Camera Ready,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Modern language models have the capacity to store and use immense amounts of
knowledge about real-world entities, but it remains unclear how to update such
knowledge stored in model parameters. While prior methods for updating
knowledge in LMs successfully inject atomic facts, updated LMs fail to make
inferences based on injected facts. In this work, we demonstrate that a context
distillation-based approach can both impart knowledge about entities and
propagate that knowledge to enable broader inferences. Our approach consists of
two stages: transfer set generation and distillation on the transfer set. We
first generate a transfer set by prompting a language model to generate
continuations from the entity definition. Then, we update the model parameters
so that the distribution of the LM (the student) matches the distribution of
the LM conditioned on the definition (the teacher) on the transfer set. Our
experiments demonstrate that this approach is more effective at propagating
knowledge updates than fine-tuning and other gradient-based knowledge-editing
methods. Moreover, it does not compromise performance in other contexts, even
when injecting the definitions of up to 150 entities at once.
","[{'version': 'v1', 'created': 'Thu, 15 Jun 2023 17:39:50 GMT'}, {'version': 'v2', 'created': 'Tue, 31 Oct 2023 00:29:12 GMT'}]",2023-11-01,"[['Padmanabhan', 'Shankar', ''], ['Onoe', 'Yasumasa', ''], ['Zhang', 'Michael J. Q.', ''], ['Durrett', 'Greg', ''], ['Choi', 'Eunsol', '']]"
2108.03502,Arina Puchkova,"Alexandr Nikolich, Arina Puchkova",Fine-tuning GPT-3 for Russian Text Summarization,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Automatic summarization techniques aim to shorten and generalize information
given in the text while preserving its core message and the most relevant
ideas. This task can be approached and treated with a variety of methods,
however, not many attempts have been made to produce solutions specifically for
the Russian language despite existing localizations of the state-of-the-art
models. In this paper, we aim to showcase ruGPT3 ability to summarize texts,
fine-tuning it on the corpora of Russian news with their corresponding
human-generated summaries. Additionally, we employ hyperparameter tuning so
that the model's output becomes less random and more tied to the original text.
We evaluate the resulting texts with a set of metrics, showing that our
solution can surpass the state-of-the-art model's performance without
additional changes in architecture or loss function. Despite being able to
produce sensible summaries, our model still suffers from a number of flaws,
namely, it is prone to altering Named Entities present in the original text
(such as surnames, places, dates), deviating from facts stated in the given
document, and repeating the information in the summary.
","[{'version': 'v1', 'created': 'Sat, 7 Aug 2021 19:01:40 GMT'}]",2021-08-10,"[['Nikolich', 'Alexandr', ''], ['Puchkova', 'Arina', '']]"
2005.10232,Anil Ramakrishna,"Anil Ramakrishna, Shrikanth Narayanan","Sentence level estimation of psycholinguistic norms using joint
  multidimensional annotations","5 pages, 4 figures, submitted to Interspeech 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Psycholinguistic normatives represent various affective and mental constructs
using numeric scores and are used in a variety of applications in natural
language processing. They are commonly used at the sentence level, the scores
of which are estimated by extrapolating word level scores using simple
aggregation strategies, which may not always be optimal. In this work, we
present a novel approach to estimate the psycholinguistic norms at sentence
level. We apply a multidimensional annotation fusion model on annotations at
the word level to estimate a parameter which captures relationships between
different norms. We then use this parameter at sentence level to estimate the
norms. We evaluate our approach by predicting sentence level scores for various
normative dimensions and compare with standard word aggregation schemes.
","[{'version': 'v1', 'created': 'Wed, 20 May 2020 17:47:56 GMT'}]",2020-05-21,"[['Ramakrishna', 'Anil', ''], ['Narayanan', 'Shrikanth', '']]"
2302.04985,Xingwei Tan,"Xingwei Tan, Gabriele Pergola, Yulan He",Event Temporal Relation Extraction with Bayesian Translational Model,9 pages + 2,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Existing models to extract temporal relations between events lack a
principled method to incorporate external knowledge. In this study, we
introduce Bayesian-Trans, a Bayesian learning-based method that models the
temporal relation representations as latent variables and infers their values
via Bayesian inference and translational functions. Compared to conventional
neural approaches, instead of performing point estimation to find the best set
parameters, the proposed model infers the parameters' posterior distribution
directly, enhancing the model's capability to encode and express uncertainty
about the predictions. Experimental results on the three widely used datasets
show that Bayesian-Trans outperforms existing approaches for event temporal
relation extraction. We additionally present detailed analyses on uncertainty
quantification, comparison of priors, and ablation studies, illustrating the
benefits of the proposed approach.
","[{'version': 'v1', 'created': 'Fri, 10 Feb 2023 00:11:19 GMT'}]",2023-02-13,"[['Tan', 'Xingwei', ''], ['Pergola', 'Gabriele', ''], ['He', 'Yulan', '']]"
2110.09454,Jon Chun,Jon Chun,"SentimentArcs: A Novel Method for Self-Supervised Sentiment Analysis of
  Time Series Shows SOTA Transformers Can Struggle Finding Narrative Arcs","87 pages, 97 figures",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  SOTA Transformer and DNN short text sentiment classifiers report over 97%
accuracy on narrow domains like IMDB movie reviews. Real-world performance is
significantly lower because traditional models overfit benchmarks and
generalize poorly to different or more open domain texts. This paper introduces
SentimentArcs, a new self-supervised time series sentiment analysis methodology
that addresses the two main limitations of traditional supervised sentiment
analysis: limited labeled training datasets and poor generalization. A large
ensemble of diverse models provides a synthetic ground truth for
self-supervised learning. Novel metrics jointly optimize an exhaustive search
across every possible corpus:model combination. The joint optimization over
both the corpus and model solves the generalization problem. Simple
visualizations exploit the temporal structure in narratives so domain experts
can quickly spot trends, identify key features, and note anomalies over
hundreds of arcs and millions of data points. To our knowledge, this is the
first self-supervised method for time series sentiment analysis and the largest
survey directly comparing real-world model performance on long-form narratives.
","[{'version': 'v1', 'created': 'Mon, 18 Oct 2021 16:45:31 GMT'}]",2021-10-19,"[['Chun', 'Jon', '']]"
2402.03616,Chin-Chia Hsu,"Yujin Kim, Chin-Chia Hsu",Leveraging Large Language Models for Hybrid Workplace Decision Support,,,,,cs.CL cs.AI cs.HC cs.IR,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Large Language Models (LLMs) hold the potential to perform a variety of text
processing tasks and provide textual explanations for proposed actions or
decisions. In the era of hybrid work, LLMs can provide intelligent decision
support for workers who are designing their hybrid work plans. In particular,
they can offer suggestions and explanations to workers balancing numerous
decision factors, thereby enhancing their work experience. In this paper, we
present a decision support model for workspaces in hybrid work environments,
leveraging the reasoning skill of LLMs. We first examine LLM's capability of
making suitable workspace suggestions. We find that its reasoning extends
beyond the guidelines in the prompt and the LLM can manage the trade-off among
the available resources in the workspaces. We conduct an extensive user study
to understand workers' decision process for workspace choices and evaluate the
effectiveness of the system. We observe that a worker's decision could be
influenced by the LLM's suggestions and explanations. The participants in our
study find the system to be convenient, regardless of whether reasons are
provided or not. Our results show that employees can benefit from the
LLM-empowered system for their workspace selection in hybrid workplace.
","[{'version': 'v1', 'created': 'Tue, 6 Feb 2024 01:05:14 GMT'}]",2024-02-07,"[['Kim', 'Yujin', ''], ['Hsu', 'Chin-Chia', '']]"
2310.09623,Dimitris Gkoumas,"Dimitris Gkoumas, Adam Tsakalidis and Maria Liakata",A Digital Language Coherence Marker for Monitoring Dementia,It has been accepted to appear at EMNLP23,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The use of spontaneous language to derive appropriate digital markers has
become an emergent, promising and non-intrusive method to diagnose and monitor
dementia. Here we propose methods to capture language coherence as a
cost-effective, human-interpretable digital marker for monitoring cognitive
changes in people with dementia. We introduce a novel task to learn the
temporal logical consistency of utterances in short transcribed narratives and
investigate a range of neural approaches. We compare such language coherence
patterns between people with dementia and healthy controls and conduct a
longitudinal evaluation against three clinical bio-markers to investigate the
reliability of our proposed digital coherence marker. The coherence marker
shows a significant difference between people with mild cognitive impairment,
those with Alzheimer's Disease and healthy controls. Moreover our analysis
shows high association between the coherence marker and the clinical
bio-markers as well as generalisability potential to other related conditions.
","[{'version': 'v1', 'created': 'Sat, 14 Oct 2023 17:10:19 GMT'}]",2023-10-17,"[['Gkoumas', 'Dimitris', ''], ['Tsakalidis', 'Adam', ''], ['Liakata', 'Maria', '']]"
2212.10773,Ying Shen,"Zhiyang Xu, Ying Shen, Lifu Huang","MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction
  Tuning","ACL 2023, dataset url: https://github.com/VT-NLP/MultiInstruct",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Instruction tuning, a new learning paradigm that fine-tunes pre-trained
language models on tasks specified through instructions, has shown promising
zero-shot performance on various natural language processing tasks. However, it
has yet to be explored for vision and multimodal tasks. In this work, we
introduce MUL-TIINSTRUCT, the first multimodal instruction tuning benchmark
dataset that consists of 62 diverse multimodal tasks in a unified seq-to-seq
format covering 10 broad categories. The tasks are derived from 21 existing
open-source datasets and each task is equipped with 5 expert-written
instructions. We take OFA as the base pre-trained model for multimodal
instruction tuning, and to further improve its zero-shot performance, we
explore multiple transfer learning strategies to leverage the large-scale
NATURAL INSTRUCTIONS dataset. Experimental results demonstrate strong zero-shot
performance on various unseen multimodal tasks and the benefit of transfer
learning from a text-only instruction dataset. We also design a new evaluation
metric - Sensitivity, to evaluate how sensitive the model is to the variety of
instructions. Our results indicate that fine-tuning the model on a diverse set
of tasks and instructions leads to a reduced sensitivity to variations in
instructions for each task.
","[{'version': 'v1', 'created': 'Wed, 21 Dec 2022 05:17:06 GMT'}, {'version': 'v2', 'created': 'Wed, 7 Jun 2023 23:05:26 GMT'}, {'version': 'v3', 'created': 'Sat, 10 Jun 2023 18:33:21 GMT'}]",2023-06-13,"[['Xu', 'Zhiyang', ''], ['Shen', 'Ying', ''], ['Huang', 'Lifu', '']]"
2006.07968,Christopher Potts,"Atticus Geiger, Alexandra Carstensen, Michael C. Frank, and
  Christopher Potts","Relational reasoning and generalization using non-symbolic neural
  networks",,,,,cs.LG cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The notion of equality (identity) is simple and ubiquitous, making it a key
case study for broader questions about the representations supporting abstract
relational reasoning. Previous work suggested that neural networks were not
suitable models of human relational reasoning because they could not represent
mathematically identity, the most basic form of equality. We revisit this
question. In our experiments, we assess out-of-sample generalization of
equality using both arbitrary representations and representations that have
been pretrained on separate tasks to imbue them with structure. We find neural
networks are able to learn (1) basic equality (mathematical identity), (2)
sequential equality problems (learning ABA-patterned sequences) with only
positive training instances, and (3) a complex, hierarchical equality problem
with only basic equality training instances (""zero-shot'"" generalization). In
the two latter cases, our models perform tasks proposed in previous work to
demarcate human-unique symbolic abilities. These results suggest that essential
aspects of symbolic reasoning can emerge from data-driven, non-symbolic
learning processes.
","[{'version': 'v1', 'created': 'Sun, 14 Jun 2020 18:25:42 GMT'}, {'version': 'v2', 'created': 'Tue, 16 Jun 2020 04:34:22 GMT'}, {'version': 'v3', 'created': 'Sun, 1 May 2022 19:39:54 GMT'}]",2022-05-03,"[['Geiger', 'Atticus', ''], ['Carstensen', 'Alexandra', ''], ['Frank', 'Michael C.', ''], ['Potts', 'Christopher', '']]"
2301.05149,Khanh Nguyen,Lingjun Zhao and Khanh Nguyen and Hal Daum\'e III,"Define, Evaluate, and Improve Task-Oriented Cognitive Capabilities for
  Instruction Generation Models",Findings of ACL 2023,,,,cs.CL cs.AI cs.HC cs.LG cs.RO,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Recent work studies the cognitive capabilities of language models through
psychological tests designed for humans. While these studies are helpful for
understanding the general capabilities of these models, there is no guarantee
that a model possessing sufficient capabilities to pass those tests would
actually use those capabilities in performing real-life tasks. In this work, we
formulate task-oriented cognitive capabilities, which are human-like cognitive
capabilities that language models leverage to perform tasks. These capabilities
are (i) the ability to quickly generate good candidate utterances (the search
capability) (ii) the ability to predict how a listener interprets those
utterances and choose the most appropriate one (the pragmatic capability). We
design an evaluation scheme for comparing these capabilities of a language
model with those of a human. Applying this scheme to examine various models in
a navigation instruction generation problem, we find that their pragmatic
capability is severely lacking. This insight leads us to augment them with
better models of the listener and obtain a significant boost of 11% in success
rate in guiding real humans. Our work advocates for having a principled
procedure for aligning language models with humans that involves (i)
formulating task-oriented capabilities, (ii) devising a method to quantify
their deficiency, and (iii) iteratively improving them.
","[{'version': 'v1', 'created': 'Wed, 21 Dec 2022 04:43:19 GMT'}, {'version': 'v2', 'created': 'Sun, 28 May 2023 14:34:54 GMT'}]",2023-05-30,"[['Zhao', 'Lingjun', ''], ['Nguyen', 'Khanh', ''], ['Daumé', 'Hal', 'III']]"
2108.13873,Qiongkai Xu,"Qiongkai Xu, Xuanli He, Lingjuan Lyu, Lizhen Qu, Gholamreza Haffari",Student Surpasses Teacher: Imitation Attack for Black-Box NLP APIs,COLING 2022 (oral),,,,cs.CR cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Machine-learning-as-a-service (MLaaS) has attracted millions of users to
their splendid large-scale models. Although published as black-box APIs, the
valuable models behind these services are still vulnerable to imitation
attacks. Recently, a series of works have demonstrated that attackers manage to
steal or extract the victim models. Nonetheless, none of the previous stolen
models can outperform the original black-box APIs. In this work, we conduct
unsupervised domain adaptation and multi-victim ensemble to showing that
attackers could potentially surpass victims, which is beyond previous
understanding of model extraction. Extensive experiments on both benchmark
datasets and real-world APIs validate that the imitators can succeed in
outperforming the original black-box models on transferred domains. We consider
our work as a milestone in the research of imitation attack, especially on NLP
APIs, as the superior performance could influence the defense or even
publishing strategy of API providers.
","[{'version': 'v1', 'created': 'Sun, 29 Aug 2021 10:52:04 GMT'}, {'version': 'v2', 'created': 'Sun, 4 Sep 2022 12:42:05 GMT'}]",2022-09-07,"[['Xu', 'Qiongkai', ''], ['He', 'Xuanli', ''], ['Lyu', 'Lingjuan', ''], ['Qu', 'Lizhen', ''], ['Haffari', 'Gholamreza', '']]"
1601.07435,Torsten Timm,Torsten Timm,Co-Occurrence Patterns in the Voynich Manuscript,"19 pages; tables for sections of the VMS added; 'The Towneley plays'
  as example for English poetry added; revised version",,,,cs.CL cs.CR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Voynich Manuscript is a medieval book written in an unknown script. This
paper studies the distribution of similarly spelled words in the Voynich
Manuscript. It shows that the distribution of words within the manuscript is
not compatible with natural languages.
","[{'version': 'v1', 'created': 'Wed, 27 Jan 2016 16:37:08 GMT'}, {'version': 'v2', 'created': 'Mon, 8 Feb 2016 08:18:24 GMT'}]",2016-02-09,"[['Timm', 'Torsten', '']]"
2104.06973,Sugam Garg,"Haswanth Aekula, Sugam Garg, Animesh Gupta","[RE] Double-Hard Debias: Tailoring Word Embeddings for Gender Bias
  Mitigation",Under review at ML Reproducibility Challenge 2020,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Despite widespread use in natural language processing (NLP) tasks, word
embeddings have been criticized for inheriting unintended gender bias from
training corpora. programmer is more closely associated with man and homemaker
is more closely associated with woman. Such gender bias has also been shown to
propagate in downstream tasks.
","[{'version': 'v1', 'created': 'Wed, 14 Apr 2021 16:56:14 GMT'}]",2021-04-15,"[['Aekula', 'Haswanth', ''], ['Garg', 'Sugam', ''], ['Gupta', 'Animesh', '']]"
2310.16147,Wookje Han,"Wookje Han, Jinsol Park, Kyungjae Lee","PreWoMe: Exploiting Presuppositions as Working Memory for Long Form
  Question Answering","11 pages 3 figures, Accepted to EMNLP 2023 (short)",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Information-seeking questions in long-form question answering (LFQA) often
prove misleading due to ambiguity or false presupposition in the question.
While many existing approaches handle misleading questions, they are tailored
to limited questions, which are insufficient in a real-world setting with
unpredictable input characteristics. In this work, we propose PreWoMe, a
unified approach capable of handling any type of information-seeking question.
The key idea of PreWoMe involves extracting presuppositions in the question and
exploiting them as working memory to generate feedback and action about the
question. Our experiment shows that PreWoMe is effective not only in tackling
misleading questions but also in handling normal ones, thereby demonstrating
the effectiveness of leveraging presuppositions, feedback, and action for
real-world QA settings.
","[{'version': 'v1', 'created': 'Tue, 24 Oct 2023 19:47:26 GMT'}, {'version': 'v2', 'created': 'Tue, 14 Nov 2023 02:46:32 GMT'}]",2023-11-15,"[['Han', 'Wookje', ''], ['Park', 'Jinsol', ''], ['Lee', 'Kyungjae', '']]"
2003.03235,Bernhard Kratzwald,"Bernhard Kratzwald, Xiang Yue, Huan Sun, Stefan Feuerriegel",Practical Annotation Strategies for Question Answering Datasets,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Annotating datasets for question answering (QA) tasks is very costly, as it
requires intensive manual labor and often domain-specific knowledge. Yet
strategies for annotating QA datasets in a cost-effective manner are scarce. To
provide a remedy for practitioners, our objective is to develop heuristic rules
for annotating a subset of questions, so that the annotation cost is reduced
while maintaining both in- and out-of-domain performance. For this, we conduct
a large-scale analysis in order to derive practical recommendations. First, we
demonstrate experimentally that more training samples contribute often only to
a higher in-domain test-set performance, but do not help the model in
generalizing to unseen datasets. Second, we develop a model-guided annotation
strategy: it makes a recommendation with regard to which subset of samples
should be annotated. Its effectiveness is demonstrated in a case study based on
domain customization of QA to a clinical setting. Here, remarkably, annotating
a stratified subset with only 1.2% of the original training set achieves 97.7%
of the performance as if the complete dataset was annotated. Hence, the
labeling effort can be reduced immensely. Altogether, our work fulfills a
demand in practice when labeling budgets are limited and where thus
recommendations are needed for annotating QA datasets more cost-effectively.
","[{'version': 'v1', 'created': 'Fri, 6 Mar 2020 14:25:50 GMT'}]",2020-03-09,"[['Kratzwald', 'Bernhard', ''], ['Yue', 'Xiang', ''], ['Sun', 'Huan', ''], ['Feuerriegel', 'Stefan', '']]"
2310.04910,Weihe Zhai,"Weihe Zhai, Arkaitz Zubiaga, Bingquan Liu, Chengjie Sun, Yalong Zhao",Faithful Knowledge Graph Explanations for Commonsense Reasoning,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  While fusing language models and knowledge graphs has become common in
commonsense question answering research, enabling faithful chain-of-thought
explanations in these models remains an open problem. Our analysis reveals that
one major weakness of current KG-based explanation methodologies lies in
overlooking the faithfulness of path decoding during evaluation. This oversight
leads to the distribution of the graph encoder often diverging from the
original model predictions. To address this gap, we present two main
contributions: (1) We propose and validate Text-GNN Fidelity in this specific
context, to assess the reliability of the graph representation. (2) We
introduce TeGDA (Text-Graph Distribution-aware Alignment), a novel algorithm
that aligns the graph encoder with the target model to improve the faithfulness
of subsequent explanations and that can be easily integrated into existing
approaches. Our experiments and analysis show its potential to produce more
faithful systems. Concretely, our work emphasises the neglected distributional
misalignment problem in LM-KG reasoning models, which has been a latent source
of spurious explanations.
","[{'version': 'v1', 'created': 'Sat, 7 Oct 2023 20:29:45 GMT'}, {'version': 'v2', 'created': 'Sun, 11 Feb 2024 08:13:39 GMT'}, {'version': 'v3', 'created': 'Sat, 17 Feb 2024 14:35:59 GMT'}]",2024-02-20,"[['Zhai', 'Weihe', ''], ['Zubiaga', 'Arkaitz', ''], ['Liu', 'Bingquan', ''], ['Sun', 'Chengjie', ''], ['Zhao', 'Yalong', '']]"
1910.03833,Yubei Chen,"Juexiao Zhang, Yubei Chen, Brian Cheung, Bruno A Olshausen",Word Embedding Visualization Via Dictionary Learning,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Co-occurrence statistics based word embedding techniques have proved to be
very useful in extracting the semantic and syntactic representation of words as
low dimensional continuous vectors. In this work, we discovered that dictionary
learning can open up these word vectors as a linear combination of more
elementary word factors. We demonstrate many of the learned factors have
surprisingly strong semantic or syntactic meaning corresponding to the factors
previously identified manually by human inspection. Thus dictionary learning
provides a powerful visualization tool for understanding word embedding
representations. Furthermore, we show that the word factors can help in
identifying key semantic and syntactic differences in word analogy tasks and
improve upon the state-of-the-art word embedding techniques in these tasks by a
large margin.
","[{'version': 'v1', 'created': 'Wed, 9 Oct 2019 08:14:48 GMT'}, {'version': 'v2', 'created': 'Mon, 15 Mar 2021 09:57:44 GMT'}]",2021-03-16,"[['Zhang', 'Juexiao', ''], ['Chen', 'Yubei', ''], ['Cheung', 'Brian', ''], ['Olshausen', 'Bruno A', '']]"
1605.04122,Richard Moot,"Richard Moot (LaBRI), Christian Retor\'e (TEXTE)",Natural Language Semantics and Computability,,,,,cs.CL cs.AI cs.CC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper is a reflexion on the computability of natural language semantics.
It does not contain a new model or new results in the formal semantics of
natural language: it is rather a computational analysis of the logical models
and algorithms currently used in natural language semantics, defined as the
mapping of a statement to logical formulas - formulas, because a statement can
be ambiguous. We argue that as long as possible world semantics is left out,
one can compute the semantic representation(s) of a given statement, including
aspects of lexical meaning. We also discuss the algorithmic complexity of this
process.
","[{'version': 'v1', 'created': 'Fri, 13 May 2016 10:46:22 GMT'}]",2016-05-16,"[['Moot', 'Richard', '', 'LaBRI'], ['Retoré', 'Christian', '', 'TEXTE']]"
2102.03662,Francis Tyers,Anastasia Kuznetsova and Anurag Kumar and Francis M. Tyers,"A bandit approach to curriculum generation for automatic speech
  recognition",,,,,cs.CL cs.SD eess.AS,http://creativecommons.org/licenses/by-sa/4.0/,"  The Automated Speech Recognition (ASR) task has been a challenging domain
especially for low data scenarios with few audio examples. This is the main
problem in training ASR systems on the data from low-resource or marginalized
languages. In this paper we present an approach to mitigate the lack of
training data by employing Automated Curriculum Learning in combination with an
adversarial bandit approach inspired by Reinforcement learning. The goal of the
approach is to optimize the training sequence of mini-batches ranked by the
level of difficulty and compare the ASR performance metrics against the random
training sequence and discrete curriculum. We test our approach on a truly
low-resource language and show that the bandit framework has a good improvement
over the baseline transfer-learning model.
","[{'version': 'v1', 'created': 'Sat, 6 Feb 2021 20:32:10 GMT'}]",2021-02-09,"[['Kuznetsova', 'Anastasia', ''], ['Kumar', 'Anurag', ''], ['Tyers', 'Francis M.', '']]"
2302.14708,Daisuke Bekki,Daisuke Bekki and Hitomi Yanaka,"Is Japanese CCGBank empirically correct? A case study of passive and
  causative constructions","To appear in Proceedings of Treebanks and Linguistic Theories (TLT)
  2023, the workshop in the Georgetown University Round Table on Linguistics
  2023 (GURT2023)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Japanese CCGBank serves as training and evaluation data for developing
Japanese CCG parsers. However, since it is automatically generated from the
Kyoto Corpus, a dependency treebank, its linguistic validity still needs to be
sufficiently verified. In this paper, we focus on the analysis of
passive/causative constructions in the Japanese CCGBank and show that, together
with the compositional semantics of ccg2lambda, a semantic parsing system, it
yields empirically wrong predictions for the nested construction of passives
and causatives.
","[{'version': 'v1', 'created': 'Tue, 28 Feb 2023 16:19:24 GMT'}]",2023-03-01,"[['Bekki', 'Daisuke', ''], ['Yanaka', 'Hitomi', '']]"
2208.12608,Elwin Huaman,Elwin Huaman and Jorge Luis Huaman and Wendi Huaman,Getting Quechua Closer to Final Users through Knowledge Graphs,"9 pages, 4 figures, 1 table, submitted to The 9th International
  Conference on Information Management and Big Data (SIMBig 2022)",,,,cs.CY cs.AI cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Quechua language and Quechua knowledge gather millions of people around the
world, especially in several countries in South America. Unfortunately, there
are only a few resources available to Quechua communities, and they are mainly
stored in PDF format. In this paper, the Quechua Knowledge Graph is envisioned
and generated as an effort to get Quechua closer to the Quechua communities,
researchers, and technology developers. Currently, there are 553636 triples
stored in the Quechua Knowledge Graph, which is accessible on the Web,
retrievable by machines, and curated by users. To showcase the deployment of
the Quechua Knowledge Graph, use cases and future work are described.
","[{'version': 'v1', 'created': 'Wed, 17 Aug 2022 21:21:26 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Sep 2022 14:55:08 GMT'}]",2022-09-23,"[['Huaman', 'Elwin', ''], ['Huaman', 'Jorge Luis', ''], ['Huaman', 'Wendi', '']]"
2211.05414,Ke Yang,"Ke Yang, Charles Yu, Yi Fung, Manling Li, Heng Ji",ADEPT: A DEbiasing PrompT Framework,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Several works have proven that finetuning is an applicable approach for
debiasing contextualized word embeddings. Similarly, discrete prompts with
semantic meanings have shown to be effective in debiasing tasks. With unfixed
mathematical representation at the token level, continuous prompts usually
surpass discrete ones at providing a pre-trained language model (PLM) with
additional task-specific information. Despite this, relatively few efforts have
been made to debias PLMs by prompt tuning with continuous prompts compared to
its discrete counterpart. Furthermore, for most debiasing methods that alter a
PLM's original parameters, a major problem is the need to not only decrease the
bias in the PLM but also to ensure that the PLM does not lose its
representation ability. Finetuning methods typically have a hard time
maintaining this balance, as they tend to violently remove meanings of
attribute words. In this paper, we propose ADEPT, a method to debias PLMs using
prompt tuning while maintaining the delicate balance between removing biases
and ensuring representation ability. To achieve this, we propose a new training
criterion inspired by manifold learning and equip it with an explicit debiasing
term to optimize prompt tuning. In addition, we conduct several experiments
with regard to the reliability, quality, and quantity of a previously proposed
attribute training corpus in order to obtain a clearer prototype of a certain
attribute, which indicates the attribute's position and relative distances to
other words on the manifold. We evaluate ADEPT on several widely acknowledged
debiasing benchmarks and downstream tasks, and find that it achieves
competitive results while maintaining (and in some cases even improving) the
PLM's representation ability. We further visualize words' correlation before
and after debiasing a PLM, and give some possible explanations for the visible
effects.
","[{'version': 'v1', 'created': 'Thu, 10 Nov 2022 08:41:40 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Dec 2022 15:06:38 GMT'}]",2022-12-26,"[['Yang', 'Ke', ''], ['Yu', 'Charles', ''], ['Fung', 'Yi', ''], ['Li', 'Manling', ''], ['Ji', 'Heng', '']]"
2102.01847,Yasufumi Taniguchi,"Yasufumi Taniguchi, Hiroki Nakayama, Kubo Takahiro, Jun Suzuki",An Investigation Between Schema Linking and Text-to-SQL Performance,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text-to-SQL is a crucial task toward developing methods for understanding
natural language by computers. Recent neural approaches deliver excellent
performance; however, models that are difficult to interpret inhibit future
developments. Hence, this study aims to provide a better approach toward the
interpretation of neural models. We hypothesize that the internal behavior of
models at hand becomes much easier to analyze if we identify the detailed
performance of schema linking simultaneously as the additional information of
the text-to-SQL performance. We provide the ground-truth annotation of schema
linking information onto the Spider dataset. We demonstrate the usefulness of
the annotated data and how to analyze the current state-of-the-art neural
models.
","[{'version': 'v1', 'created': 'Wed, 3 Feb 2021 02:50:10 GMT'}]",2021-02-04,"[['Taniguchi', 'Yasufumi', ''], ['Nakayama', 'Hiroki', ''], ['Takahiro', 'Kubo', ''], ['Suzuki', 'Jun', '']]"
2207.13243,Stephen Casper,"Tilman R\""auker, Anson Ho, Stephen Casper, Dylan Hadfield-Menell","Toward Transparent AI: A Survey on Interpreting the Inner Structures of
  Deep Neural Networks",,,,,cs.LG cs.AI cs.CL cs.CV,http://creativecommons.org/licenses/by/4.0/,"  The last decade of machine learning has seen drastic increases in scale and
capabilities. Deep neural networks (DNNs) are increasingly being deployed in
the real world. However, they are difficult to analyze, raising concerns about
using them without a rigorous understanding of how they function. Effective
tools for interpreting them will be important for building more trustworthy AI
by helping to identify problems, fix bugs, and improve basic understanding. In
particular, ""inner"" interpretability techniques, which focus on explaining the
internal components of DNNs, are well-suited for developing a mechanistic
understanding, guiding manual modifications, and reverse engineering solutions.
  Much recent work has focused on DNN interpretability, and rapid progress has
thus far made a thorough systematization of methods difficult. In this survey,
we review over 300 works with a focus on inner interpretability tools. We
introduce a taxonomy that classifies methods by what part of the network they
help to explain (weights, neurons, subnetworks, or latent representations) and
whether they are implemented during (intrinsic) or after (post hoc) training.
To our knowledge, we are also the first to survey a number of connections
between interpretability research and work in adversarial robustness, continual
learning, modularity, network compression, and studying the human visual
system. We discuss key challenges and argue that the status quo in
interpretability research is largely unproductive. Finally, we highlight the
importance of future work that emphasizes diagnostics, debugging, adversaries,
and benchmarking in order to make interpretability tools more useful to
engineers in practical applications.
","[{'version': 'v1', 'created': 'Wed, 27 Jul 2022 01:59:13 GMT'}, {'version': 'v2', 'created': 'Thu, 28 Jul 2022 07:06:44 GMT'}, {'version': 'v3', 'created': 'Mon, 5 Sep 2022 18:35:00 GMT'}, {'version': 'v4', 'created': 'Tue, 27 Dec 2022 22:06:28 GMT'}, {'version': 'v5', 'created': 'Fri, 27 Jan 2023 20:15:54 GMT'}, {'version': 'v6', 'created': 'Fri, 18 Aug 2023 21:14:43 GMT'}]",2023-08-22,"[['Räuker', 'Tilman', ''], ['Ho', 'Anson', ''], ['Casper', 'Stephen', ''], ['Hadfield-Menell', 'Dylan', '']]"
1810.05102,Pankaj Gupta,"Pankaj Gupta and Subburam Rajaram and Hinrich Sch\""utze and Bernt
  Andrassy and Thomas Runkler",Neural Relation Extraction Within and Across Sentence Boundaries,AAAI2019,,,,cs.CL cs.AI cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Past work in relation extraction mostly focuses on binary relation between
entity pairs within single sentence. Recently, the NLP community has gained
interest in relation extraction in entity pairs spanning multiple sentences. In
this paper, we propose a novel architecture for this task: inter-sentential
dependency-based neural networks (iDepNN). iDepNN models the shortest and
augmented dependency paths via recurrent and recursive neural networks to
extract relationships within (intra-) and across (inter-) sentence boundaries.
Compared to SVM and neural network baselines, iDepNN is more robust to false
positives in relationships spanning sentences.
  We evaluate our models on four datasets from newswire (MUC6) and medical
(BioNLP shared task) domains that achieve state-of-the-art performance and show
a better balance in precision and recall for inter-sentential relationships. We
perform better than 11 teams participating in the BioNLP shared task 2016 and
achieve a gain of 5.2% (0.587 vs 0.558) in F1 over the winning team. We also
release the crosssentence annotations for MUC6.
","[{'version': 'v1', 'created': 'Thu, 11 Oct 2018 16:07:20 GMT'}, {'version': 'v2', 'created': 'Mon, 14 Jan 2019 16:56:53 GMT'}]",2019-01-15,"[['Gupta', 'Pankaj', ''], ['Rajaram', 'Subburam', ''], ['Schütze', 'Hinrich', ''], ['Andrassy', 'Bernt', ''], ['Runkler', 'Thomas', '']]"
2302.06541,Maximilian Mozes,"Maximilian Mozes, Jessica Hoffmann, Katrin Tomanek, Muhamed Kouate,
  Nithum Thain, Ann Yuan, Tolga Bolukbasi, Lucas Dixon",Towards Agile Text Classifiers for Everyone,Findings of EMNLP 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Text-based safety classifiers are widely used for content moderation and
increasingly to tune generative language model behavior - a topic of growing
concern for the safety of digital assistants and chatbots. However, different
policies require different classifiers, and safety policies themselves improve
from iteration and adaptation. This paper introduces and evaluates methods for
agile text classification, whereby classifiers are trained using small,
targeted datasets that can be quickly developed for a particular policy.
Experimenting with 7 datasets from three safety-related domains, comprising 15
annotation schemes, led to our key finding: prompt-tuning large language
models, like PaLM 62B, with a labeled dataset of as few as 80 examples can
achieve state-of-the-art performance. We argue that this enables a paradigm
shift for text classification, especially for models supporting safer online
discourse. Instead of collecting millions of examples to attempt to create
universal safety classifiers over months or years, classifiers could be tuned
using small datasets, created by individuals or small organizations, tailored
for specific use cases, and iterated on and adapted in the time-span of a day.
","[{'version': 'v1', 'created': 'Mon, 13 Feb 2023 17:34:13 GMT'}, {'version': 'v2', 'created': 'Sat, 21 Oct 2023 11:49:09 GMT'}]",2023-10-24,"[['Mozes', 'Maximilian', ''], ['Hoffmann', 'Jessica', ''], ['Tomanek', 'Katrin', ''], ['Kouate', 'Muhamed', ''], ['Thain', 'Nithum', ''], ['Yuan', 'Ann', ''], ['Bolukbasi', 'Tolga', ''], ['Dixon', 'Lucas', '']]"
2403.02694,Waris Gill,"Waris Gill (1), Mohamed Elidrisi (2), Pallavi Kalapatapu (2), Ali
  Anwar (3), Muhammad Ali Gulzar (1) ((1) Virginia Tech, USA, (2) Cisco, USA
  (3) University of Minnesota, Minneapolis, USA)",Privacy-Aware Semantic Cache for Large Language Models,"This study presents the first privacy aware semantic cache for LLMs
  based on Federated Learning. Total pages 12",,,,cs.LG cs.AI cs.CL cs.CR cs.DC,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) like ChatGPT, Google Bard, Claude, and Llama 2
have revolutionized natural language processing and search engine dynamics.
However, these models incur exceptionally high computational costs. For
instance, GPT-3 consists of 175 billion parameters and inference on these
models also demands billions of floating-point operations. Caching is a natural
solution to reduce LLM inference costs on repeated queries. However, existing
caching methods are incapable of finding semantic similarities among LLM
queries, leading to unacceptable false hit-and-miss rates.
  This paper introduces MeanCache, a semantic cache for LLMs that identifies
semantically similar queries to determine cache hit or miss. Using MeanCache,
the response to a user's semantically similar query can be retrieved from a
local cache rather than re-querying the LLM, thus reducing costs, service
provider load, and environmental impact. MeanCache leverages Federated Learning
(FL) to collaboratively train a query similarity model in a distributed manner
across numerous users without violating privacy. By placing a local cache in
each user's device and using FL, MeanCache reduces the latency and costs and
enhances model performance, resulting in lower cache false hit rates. Our
experiments, benchmarked against the GPTCache, reveal that MeanCache attains an
approximately 17% higher F-score and a 20% increase in precision during
semantic cache hit-and-miss decisions. Furthermore, MeanCache reduces the
storage requirement by 83% and accelerates semantic cache hit-and-miss
decisions by 11%, while still surpassing GPTCache.
","[{'version': 'v1', 'created': 'Tue, 5 Mar 2024 06:23:50 GMT'}]",2024-03-06,"[['Gill', 'Waris', ''], ['Elidrisi', 'Mohamed', ''], ['Kalapatapu', 'Pallavi', ''], ['Anwar', 'Ali', ''], ['Gulzar', 'Muhammad Ali', '']]"
2401.18034,Mitodru Niyogi,Mitodru Niyogi and Arnab Bhattacharya,"Paramanu: A Family of Novel Efficient Indic Generative Foundation
  Language Models",,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  We present Gyan AI Paramanu (""atom""), a family of novel language models for
Indian languages. It is a collection of auto-regressive monolingual, bilingual,
and multilingual Indic language models pretrained from scratch on a single GPU
for 10 Indian languages (Assamese, Bangla, Hindi, Konkani, Maithili, Marathi,
Odia, Sanskrit, Tamil, Telugu) across 5 scripts (Bangla, Devanagari, Odia,
Tamil, Telugu) of varying sizes ranging from 13.29M to 367.5M.The models are
pretrained with a context size of 1024 on a single GPU. The models are very
efficient, small, fast, and powerful. We have also developed an efficient most
advanced Indic tokenizer that can even tokenize unseen languages. In order to
avoid the ""curse of multi-linguality"" in our multilingual mParamanu model, we
pretrained on comparable corpora by typological grouping using the same script.
We performed human evaluation of our pretrained models for open end text
generation on grammar, coherence, creativity, and factuality metrics for
Bangla, Hindi, and Sanskrit. Our Bangla, Hindi, and Sanskrit models
outperformed GPT-3.5-Turbo (ChatGPT), Bloom 7B, LLaMa-2 7B, OPT 6.7B, GPT-J 6B,
GPTNeo 1.3B, GPT2-XL large language models (LLMs) by a large margin despite
being smaller in size by 66 to 20 times compared to standard 7B LLMs. To run
inference on our pretrained models, CPU is enough, and GPU is not needed. We
also instruction-tuned our pretrained Bangla, Hindi, Marathi, Tamil, and Telugu
models on 23k instructions in respective languages. Our pretrained and
instruction-tuned models which are first of its kind, most powerful efficient
small generative language models ever developed for Indic languages, and the
various results lead to the conclusion that high quality generative language
models are possible without high amount of compute power and humongous number
of parameters. We plan to release our models at https://www.bharatgpts.com.
","[{'version': 'v1', 'created': 'Wed, 31 Jan 2024 17:58:10 GMT'}]",2024-02-01,"[['Niyogi', 'Mitodru', ''], ['Bhattacharya', 'Arnab', '']]"
1912.08777,Jingqing Zhang,"Jingqing Zhang, Yao Zhao, Mohammad Saleh, Peter J. Liu","PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive
  Summarization","Added results from mixed+stochastic model, test-set overlapping
  analysis; Code link added; Accepted for ICML 2020. arXiv admin note: text
  overlap with arXiv:1605.06560, arXiv:1205.2395, arXiv:0902.4351,
  arXiv:1610.09932, arXiv:nucl-ex/0512029 by other authors",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent work pre-training Transformers with self-supervised objectives on
large text corpora has shown great success when fine-tuned on downstream NLP
tasks including text summarization. However, pre-training objectives tailored
for abstractive text summarization have not been explored. Furthermore there is
a lack of systematic evaluation across diverse domains. In this work, we
propose pre-training large Transformer-based encoder-decoder models on massive
text corpora with a new self-supervised objective. In PEGASUS, important
sentences are removed/masked from an input document and are generated together
as one output sequence from the remaining sentences, similar to an extractive
summary. We evaluated our best PEGASUS model on 12 downstream summarization
tasks spanning news, science, stories, instructions, emails, patents, and
legislative bills. Experiments demonstrate it achieves state-of-the-art
performance on all 12 downstream datasets measured by ROUGE scores. Our model
also shows surprising performance on low-resource summarization, surpassing
previous state-of-the-art results on 6 datasets with only 1000 examples.
Finally we validated our results using human evaluation and show that our model
summaries achieve human performance on multiple datasets.
","[{'version': 'v1', 'created': 'Wed, 18 Dec 2019 18:16:20 GMT'}, {'version': 'v2', 'created': 'Tue, 2 Jun 2020 17:24:23 GMT'}, {'version': 'v3', 'created': 'Fri, 10 Jul 2020 11:07:21 GMT'}]",2020-07-21,"[['Zhang', 'Jingqing', ''], ['Zhao', 'Yao', ''], ['Saleh', 'Mohammad', ''], ['Liu', 'Peter J.', '']]"
2311.04922,Lucas Druart,"Lucas Druart (LIA), L\'eo Jacqmin (LIS), Beno\^it Favre (LIS), Lina
  Maria Rojas-Barahona, Valentin Vielzeuf","Are cascade dialogue state tracking models speaking out of turn in
  spoken dialogues?","Submitted to IEEE ICASSP 2024{\copyright} 2023 IEEE. Personal use of
  this material is permitted. Permission from IEEE must be obtained for all
  other uses, in any current or future media, including reprinting/republishing
  this material for advertising or promotional purposes, creating new
  collective works, for resale or redistribution to servers or lists, or reuse
  of any copyrighted component of this work in other works",,,,cs.CL cs.AI eess.AS eess.SP,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In Task-Oriented Dialogue (TOD) systems, correctly updating the system's
understanding of the user's needs is key to a smooth interaction. Traditionally
TOD systems are composed of several modules that interact with one another.
While each of these components is the focus of active research communities,
their behavior in interaction can be overlooked. This paper proposes a
comprehensive analysis of the errors of state of the art systems in complex
settings such as Dialogue State Tracking which highly depends on the dialogue
context. Based on spoken MultiWoz, we identify that errors on non-categorical
slots' values are essential to address in order to bridge the gap between
spoken and chat-based dialogue systems. We explore potential solutions to
improve transcriptions and help dialogue state tracking generative models
correct such errors.
","[{'version': 'v1', 'created': 'Fri, 3 Nov 2023 08:45:22 GMT'}]",2023-11-21,"[['Druart', 'Lucas', '', 'LIA'], ['Jacqmin', 'Léo', '', 'LIS'], ['Favre', 'Benoît', '', 'LIS'], ['Rojas-Barahona', 'Lina Maria', ''], ['Vielzeuf', 'Valentin', '']]"
2312.09781,Min-Han Shih,"Min-Han Shih, Ho-Lam Chung, Yu-Chi Pai, Ming-Hao Hsu, Guan-Ting Lin,
  Shang-Wen Li, Hung-yi Lee",GSQA: An End-to-End Model for Generative Spoken Question Answering,"5 pages, 2 figures, submitted to ICASSP 2024",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In recent advancements in spoken question answering (QA), end-to-end models
have made significant strides. However, previous research has primarily focused
on extractive span selection. While this extractive-based approach is effective
when answers are present directly within the input, it falls short in
addressing abstractive questions, where answers are not directly extracted but
inferred from the given information. To bridge this gap, we introduce the first
end-to-end Generative Spoken Question Answering (GSQA) model that empowers the
system to engage in abstractive reasoning. The challenge in training our GSQA
model lies in the absence of a spoken abstractive QA dataset. We propose using
text models for initialization and leveraging the extractive QA dataset to
transfer knowledge from the text generative model to the spoken generative
model. Experimental results indicate that our model surpasses the previous
extractive model by 3% on extractive QA datasets. Furthermore, the GSQA model
has only been fine-tuned on the spoken extractive QA dataset. Despite not
having seen any spoken abstractive QA data, it can still closely match the
performance of the cascade model. In conclusion, our GSQA model shows the
potential to generalize to a broad spectrum of questions, thus further
expanding the spoken question answering capabilities of abstractive QA. Our
code is available at https://voidful.github.io/GSQA
","[{'version': 'v1', 'created': 'Fri, 15 Dec 2023 13:33:18 GMT'}, {'version': 'v2', 'created': 'Mon, 25 Dec 2023 18:43:58 GMT'}]",2023-12-27,"[['Shih', 'Min-Han', ''], ['Chung', 'Ho-Lam', ''], ['Pai', 'Yu-Chi', ''], ['Hsu', 'Ming-Hao', ''], ['Lin', 'Guan-Ting', ''], ['Li', 'Shang-Wen', ''], ['Lee', 'Hung-yi', '']]"
2204.04833,Hosein Rezaei,Hosein Rezaei,Word Embeddings Are Capable of Capturing Rhythmic Similarity of Words,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Word embedding systems such as Word2Vec and GloVe are well-known in deep
learning approaches to NLP. This is largely due to their ability to capture
semantic relationships between words. In this work we investigated their
usefulness in capturing rhythmic similarity of words instead. The results show
that vectors these embeddings assign to rhyming words are more similar to each
other, compared to the other words. It is also revealed that GloVe performs
relatively better than Word2Vec in this regard. We also proposed a first of its
kind metric for quantifying rhythmic similarity of a pair of words.
","[{'version': 'v1', 'created': 'Mon, 11 Apr 2022 02:33:23 GMT'}, {'version': 'v2', 'created': 'Thu, 14 Apr 2022 07:28:15 GMT'}]",2022-04-15,"[['Rezaei', 'Hosein', '']]"
2201.09012,Momchil Hardalov,"Kristiyan Vachev, Momchil Hardalov, Georgi Karadzhov, Georgi Georgiev,
  Ivan Koychev, Preslav Nakov",Leaf: Multiple-Choice Question Generation,Accepted to ECIR 2022 (Demo),,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Testing with quiz questions has proven to be an effective way to assess and
improve the educational process. However, manually creating quizzes is tedious
and time-consuming. To address this challenge, we present Leaf, a system for
generating multiple-choice questions from factual text. In addition to being
very well suited for the classroom, Leaf could also be used in an industrial
setting, e.g., to facilitate onboarding and knowledge sharing, or as a
component of chatbots, question answering systems, or Massive Open Online
Courses (MOOCs). The code and the demo are available on
https://github.com/KristiyanVachev/Leaf-Question-Generation.
","[{'version': 'v1', 'created': 'Sat, 22 Jan 2022 10:17:53 GMT'}]",2022-01-25,"[['Vachev', 'Kristiyan', ''], ['Hardalov', 'Momchil', ''], ['Karadzhov', 'Georgi', ''], ['Georgiev', 'Georgi', ''], ['Koychev', 'Ivan', ''], ['Nakov', 'Preslav', '']]"
2004.04270,Sravana Reddy,"Ann Clifton, Aasish Pappu, Sravana Reddy, Yongze Yu, Jussi Karlgren,
  Ben Carterette, Rosie Jones",The Spotify Podcast Dataset,"4 pages, 3 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Podcasts are a relatively new form of audio media. Episodes appear on a
regular cadence, and come in many different formats and levels of formality.
They can be formal news journalism or conversational chat; fiction or
non-fiction. They are rapidly growing in popularity and yet have been
relatively little studied. As an audio format, podcasts are more varied in
style and production types than, say, broadcast news, and contain many more
genres than typically studied in video research. The medium is therefore a rich
domain with many research avenues for the IR and NLP communities. We present
the Spotify Podcast Dataset, a set of approximately 100K podcast episodes
comprised of raw audio files along with accompanying ASR transcripts. This
represents over 47,000 hours of transcribed audio, and is an order of magnitude
larger than previous speech-to-text corpora.
","[{'version': 'v1', 'created': 'Wed, 8 Apr 2020 21:25:00 GMT'}, {'version': 'v2', 'created': 'Fri, 30 Oct 2020 17:58:57 GMT'}, {'version': 'v3', 'created': 'Sat, 5 Dec 2020 05:50:48 GMT'}]",2020-12-08,"[['Clifton', 'Ann', ''], ['Pappu', 'Aasish', ''], ['Reddy', 'Sravana', ''], ['Yu', 'Yongze', ''], ['Karlgren', 'Jussi', ''], ['Carterette', 'Ben', ''], ['Jones', 'Rosie', '']]"
2304.07869,Vakul Goyle,"Vakul Goyle, Parvathy Krishnaswamy, Kannan Girija Ravikumar, Utsa
  Chattopadhyay, Kartikay Goyle",Neural Machine Translation For Low Resource Languages,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural Machine translation is a challenging task due to the inherent complex
nature and the fluidity that natural languages bring. Nonetheless, in recent
years, it has achieved state-of-the-art performance in several language pairs.
Although, a lot of traction can be seen in the areas of multilingual neural
machine translation (MNMT) in the recent years, there are no comprehensive
survey done to identify what approaches work well. The goal of this paper is to
investigate the realm of low resource languages and build a Neural Machine
Translation model to achieve state-of-the-art results. The paper looks to build
upon the mBART language model and explore strategies to augment it with various
NLP and Deep Learning techniques like back translation and transfer learning.
This implementation tries to unpack the architecture of the NMT application and
determine the different components which offers us opportunities to amend the
said application within the purview of the low resource languages problem
space.
","[{'version': 'v1', 'created': 'Sun, 16 Apr 2023 19:27:48 GMT'}, {'version': 'v2', 'created': 'Tue, 18 Apr 2023 01:36:29 GMT'}]",2023-04-19,"[['Goyle', 'Vakul', ''], ['Krishnaswamy', 'Parvathy', ''], ['Ravikumar', 'Kannan Girija', ''], ['Chattopadhyay', 'Utsa', ''], ['Goyle', 'Kartikay', '']]"
2402.12264,Hampus Linander,"Oleksandr Balabanov, Hampus Linander",Uncertainty quantification in fine-tuned LLMs using LoRA ensembles,"8 pages, 4 figures",,,,cs.LG cs.AI cs.CL stat.ML,http://creativecommons.org/licenses/by/4.0/,"  Fine-tuning large language models can improve task specific performance,
although a general understanding of what the fine-tuned model has learned,
forgotten and how to trust its predictions is still missing. We derive
principled uncertainty quantification for fine-tuned LLMs with posterior
approximations using computationally efficient low-rank adaptation ensembles.
We analyze three common multiple-choice datasets using low-rank adaptation
ensembles based on Mistral-7b, and draw quantitative and qualitative
conclusions on their perceived complexity and model efficacy on the different
target domains during and after fine-tuning. In particular, backed by the
numerical experiments, we hypothesise about signals from entropic uncertainty
measures for data domains that are inherently difficult for a given
architecture to learn.
","[{'version': 'v1', 'created': 'Mon, 19 Feb 2024 16:26:00 GMT'}]",2024-02-20,"[['Balabanov', 'Oleksandr', ''], ['Linander', 'Hampus', '']]"
1912.05156,Lambert Schomaker,Lambert Schomaker,"Lifelong learning for text retrieval and recognition in historical
  handwritten document collections","To appear as chapter in book: Handwritten Historical Document
  Analysis, Recognition, and Retrieval -- State of the Art and Future Trends,
  in the book series: Series in Machine Perception and Artificial Intelligence
  World Scientific, ISSN (print): 1793-0839 Original version deposited at
  Zenodo: https://zenodo.org/record/2346885#.XfCfsq5ytpg on December 17, 2018",,,,cs.CV cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This chapter provides an overview of the problems that need to be dealt with
when constructing a lifelong-learning retrieval, recognition and indexing
engine for large historical document collections in multiple scripts and
languages, the Monk system. This application is highly variable over time,
since the continuous labeling by end users changes the concept of what a
'ground truth' constitutes. Although current advances in deep learning provide
a huge potential in this application domain, the scale of the problem, i.e.,
more than 520 hugely diverse books, documents and manuscripts precludes the
current meticulous and painstaking human effort which is required in designing
and developing successful deep-learning systems. The ball-park principle is
introduced, which describes the evolution from the sparsely-labeled stage that
can only be addressed by traditional methods or nearest-neighbor methods on
embedded vectors of pre-trained neural networks, up to the other end of the
spectrum where massive labeling allows reliable training of deep-learning
methods. Contents: Introduction, Expectation management, Deep learning, The
ball-park principle, Technical realization, Work flow, Quality and quantity of
material, Industrialization and scalability, Human effort, Algorithms, Object
of recognition, Processing pipeline, Performance,Compositionality, Conclusion.
","[{'version': 'v1', 'created': 'Wed, 11 Dec 2019 07:56:31 GMT'}]",2019-12-12,"[['Schomaker', 'Lambert', '']]"
2109.12683,Aakriti Budhraja,"Aakriti Budhraja, Madhura Pande, Pratyush Kumar, Mitesh M. Khapra",On the Prunability of Attention Heads in Multilingual BERT,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large multilingual models, such as mBERT, have shown promise in crosslingual
transfer. In this work, we employ pruning to quantify the robustness and
interpret layer-wise importance of mBERT. On four GLUE tasks, the relative
drops in accuracy due to pruning have almost identical results on mBERT and
BERT suggesting that the reduced attention capacity of the multilingual models
does not affect robustness to pruning. For the crosslingual task XNLI, we
report higher drops in accuracy with pruning indicating lower robustness in
crosslingual transfer. Also, the importance of the encoder layers sensitively
depends on the language family and the pre-training corpus size. The top
layers, which are relatively more influenced by fine-tuning, encode important
information for languages similar to English (SVO) while the bottom layers,
which are relatively less influenced by fine-tuning, are particularly important
for agglutinative and low-resource languages.
","[{'version': 'v1', 'created': 'Sun, 26 Sep 2021 19:45:44 GMT'}]",2021-09-28,"[['Budhraja', 'Aakriti', ''], ['Pande', 'Madhura', ''], ['Kumar', 'Pratyush', ''], ['Khapra', 'Mitesh M.', '']]"
2303.05958,Mohammad Zeineldeen,"Mohammad Zeineldeen, Kartik Audhkhasi, Murali Karthick Baskar, Bhuvana
  Ramabhadran","Robust Knowledge Distillation from RNN-T Models With Noisy Training
  Labels Using Full-Sum Loss",Accepted at ICASSP 2023,,,,cs.CL cs.SD eess.AS stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This work studies knowledge distillation (KD) and addresses its constraints
for recurrent neural network transducer (RNN-T) models. In hard distillation, a
teacher model transcribes large amounts of unlabelled speech to train a student
model. Soft distillation is another popular KD method that distills the output
logits of the teacher model. Due to the nature of RNN-T alignments, applying
soft distillation between RNN-T architectures having different posterior
distributions is challenging. In addition, bad teachers having high
word-error-rate (WER) reduce the efficacy of KD. We investigate how to
effectively distill knowledge from variable quality ASR teachers, which has not
been studied before to the best of our knowledge. We show that a sequence-level
KD, full-sum distillation, outperforms other distillation methods for RNN-T
models, especially for bad teachers. We also propose a variant of full-sum
distillation that distills the sequence discriminative knowledge of the teacher
leading to further improvement in WER. We conduct experiments on public
datasets namely SpeechStew and LibriSpeech, and on in-house production data.
","[{'version': 'v1', 'created': 'Fri, 10 Mar 2023 14:46:23 GMT'}]",2023-03-13,"[['Zeineldeen', 'Mohammad', ''], ['Audhkhasi', 'Kartik', ''], ['Baskar', 'Murali Karthick', ''], ['Ramabhadran', 'Bhuvana', '']]"
2305.18887,Kenji Kawaguchi,"Kenji Kawaguchi, Zhun Deng, Xu Ji, Jiaoyang Huang",How Does Information Bottleneck Help Deep Learning?,"Accepted at ICML 2023. Code is available at
  https://github.com/xu-ji/information-bottleneck",,,,cs.LG cs.AI cs.CL cs.CV cs.IT math.IT,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Numerous deep learning algorithms have been inspired by and understood via
the notion of information bottleneck, where unnecessary information is (often
implicitly) minimized while task-relevant information is maximized. However, a
rigorous argument for justifying why it is desirable to control information
bottlenecks has been elusive. In this paper, we provide the first rigorous
learning theory for justifying the benefit of information bottleneck in deep
learning by mathematically relating information bottleneck to generalization
errors. Our theory proves that controlling information bottleneck is one way to
control generalization errors in deep learning, although it is not the only or
necessary way. We investigate the merit of our new mathematical findings with
experiments across a range of architectures and learning settings. In many
cases, generalization errors are shown to correlate with the degree of
information bottleneck: i.e., the amount of the unnecessary information at
hidden layers. This paper provides a theoretical foundation for current and
future methods through the lens of information bottleneck. Our new
generalization bounds scale with the degree of information bottleneck, unlike
the previous bounds that scale with the number of parameters, VC dimension,
Rademacher complexity, stability or robustness. Our code is publicly available
at: https://github.com/xu-ji/information-bottleneck
","[{'version': 'v1', 'created': 'Tue, 30 May 2023 09:28:25 GMT'}]",2023-05-31,"[['Kawaguchi', 'Kenji', ''], ['Deng', 'Zhun', ''], ['Ji', 'Xu', ''], ['Huang', 'Jiaoyang', '']]"
2402.11282,Qihang Yang,"Qihang Yang, Caimei Yang, Yu Liao, Ziman Zhuang","Grammaticality illusion or ambiguous interpretation? Event-related
  potentials reveal the nature of the missing-NP effect in Mandarin
  centre-embedded structures",,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  In several languages, omitting a verb phrase (VP) in double centre-embedded
structures creates a grammaticality illusion. Similar illusion also exhibited
in Mandarin missing-NP double centre-embedded structures. However, there is no
consensus on its very nature. Instead of treating it as grammaticality
illusion, we argue that ambiguous interpretations of verbs can best account for
this phenomenon in Mandarin. To further support this hypothesis, we conducted
two electroencephalography (EEG) experiments on quasi double centre-embedded
structures whose complexity is reduced by placing the self-embedding relative
clauses into the sentence's subject position. Experiment 1 showed that similar
phenomenon even exhibited in this structure, evidenced by an absence of P600
effect and a presence of N400 effect. In Experiment 2, providing semantic cues
to reduce ambiguity dispelled this illusion, as evidenced by a P600 effect. We
interpret the results under garden-path theory and propose that word-order
difference may account for this cross-linguistic variation.
","[{'version': 'v1', 'created': 'Sat, 17 Feb 2024 13:43:39 GMT'}]",2024-02-20,"[['Yang', 'Qihang', ''], ['Yang', 'Caimei', ''], ['Liao', 'Yu', ''], ['Zhuang', 'Ziman', '']]"
1808.09502,Lucy H. Lin,"Lucy H. Lin, Scott Miles, Noah A. Smith",Semantic Matching Against a Corpus: New Applications and Methods,"18 pages, 5 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We consider the case of a domain expert who wishes to explore the extent to
which a particular idea is expressed in a text collection. We propose the task
of semantically matching the idea, expressed as a natural language proposition,
against a corpus. We create two preliminary tasks derived from existing
datasets, and then introduce a more realistic one on disaster recovery designed
for emergency managers, whom we engaged in a user study. On the latter, we find
that a new model built from natural language entailment data produces
higher-quality matches than simple word-vector averaging, both on
expert-crafted queries and on ones produced by the subjects themselves. This
work provides a proof-of-concept for such applications of semantic matching and
illustrates key challenges.
","[{'version': 'v1', 'created': 'Tue, 28 Aug 2018 19:15:57 GMT'}]",2018-08-30,"[['Lin', 'Lucy H.', ''], ['Miles', 'Scott', ''], ['Smith', 'Noah A.', '']]"
2109.12573,Xiaoze Jiang,"Xiaoze Jiang, Yaobo Liang, Weizhu Chen, Nan Duan","XLM-K: Improving Cross-Lingual Language Model Pre-training with
  Multilingual Knowledge",AAAI-2022,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Cross-lingual pre-training has achieved great successes using monolingual and
bilingual plain text corpora. However, most pre-trained models neglect
multilingual knowledge, which is language agnostic but comprises abundant
cross-lingual structure alignment. In this paper, we propose XLM-K, a
cross-lingual language model incorporating multilingual knowledge in
pre-training. XLM-K augments existing multilingual pre-training with two
knowledge tasks, namely Masked Entity Prediction Task and Object Entailment
Task. We evaluate XLM-K on MLQA, NER and XNLI. Experimental results clearly
demonstrate significant improvements over existing multilingual language
models. The results on MLQA and NER exhibit the superiority of XLM-K in
knowledge related tasks. The success in XNLI shows a better cross-lingual
transferability obtained in XLM-K. What is more, we provide a detailed probing
analysis to confirm the desired knowledge captured in our pre-training regimen.
The code is available at
https://github.com/microsoft/Unicoder/tree/master/pretraining/xlmk.
","[{'version': 'v1', 'created': 'Sun, 26 Sep 2021 11:46:20 GMT'}, {'version': 'v2', 'created': 'Sun, 26 Dec 2021 05:59:59 GMT'}, {'version': 'v3', 'created': 'Sun, 24 Apr 2022 07:31:25 GMT'}]",2022-04-26,"[['Jiang', 'Xiaoze', ''], ['Liang', 'Yaobo', ''], ['Chen', 'Weizhu', ''], ['Duan', 'Nan', '']]"
2303.02601,Maria Lymperaiou,"Theodoti Stoikou, Maria Lymperaiou, Giorgos Stamou",Knowledge-Based Counterfactual Queries for Visual Question Answering,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Visual Question Answering (VQA) has been a popular task that combines vision
and language, with numerous relevant implementations in literature. Even though
there are some attempts that approach explainability and robustness issues in
VQA models, very few of them employ counterfactuals as a means of probing such
challenges in a model-agnostic way. In this work, we propose a systematic
method for explaining the behavior and investigating the robustness of VQA
models through counterfactual perturbations. For this reason, we exploit
structured knowledge bases to perform deterministic, optimal and controllable
word-level replacements targeting the linguistic modality, and we then evaluate
the model's response against such counterfactual inputs. Finally, we
qualitatively extract local and global explanations based on counterfactual
responses, which are ultimately proven insightful towards interpreting VQA
model behaviors. By performing a variety of perturbation types, targeting
different parts of speech of the input question, we gain insights to the
reasoning of the model, through the comparison of its responses in different
adversarial circumstances. Overall, we reveal possible biases in the
decision-making process of the model, as well as expected and unexpected
patterns, which impact its performance quantitatively and qualitatively, as
indicated by our analysis.
","[{'version': 'v1', 'created': 'Sun, 5 Mar 2023 08:00:30 GMT'}]",2023-03-07,"[['Stoikou', 'Theodoti', ''], ['Lymperaiou', 'Maria', ''], ['Stamou', 'Giorgos', '']]"
2302.01588,Li Fang,"Li Fang, Qingyu Chen, Chih-Hsuan Wei, Zhiyong Lu, Kai Wang","Bioformer: an efficient transformer language model for biomedical text
  mining",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Pretrained language models such as Bidirectional Encoder Representations from
Transformers (BERT) have achieved state-of-the-art performance in natural
language processing (NLP) tasks. Recently, BERT has been adapted to the
biomedical domain. Despite the effectiveness, these models have hundreds of
millions of parameters and are computationally expensive when applied to
large-scale NLP applications. We hypothesized that the number of parameters of
the original BERT can be dramatically reduced with minor impact on performance.
In this study, we present Bioformer, a compact BERT model for biomedical text
mining. We pretrained two Bioformer models (named Bioformer8L and Bioformer16L)
which reduced the model size by 60% compared to BERTBase. Bioformer uses a
biomedical vocabulary and was pre-trained from scratch on PubMed abstracts and
PubMed Central full-text articles. We thoroughly evaluated the performance of
Bioformer as well as existing biomedical BERT models including BioBERT and
PubMedBERT on 15 benchmark datasets of four different biomedical NLP tasks:
named entity recognition, relation extraction, question answering and document
classification. The results show that with 60% fewer parameters, Bioformer16L
is only 0.1% less accurate than PubMedBERT while Bioformer8L is 0.9% less
accurate than PubMedBERT. Both Bioformer16L and Bioformer8L outperformed
BioBERTBase-v1.1. In addition, Bioformer16L and Bioformer8L are 2-3 fold as
fast as PubMedBERT/BioBERTBase-v1.1. Bioformer has been successfully deployed
to PubTator Central providing gene annotations over 35 million PubMed abstracts
and 5 million PubMed Central full-text articles. We make Bioformer publicly
available via https://github.com/WGLab/bioformer, including pre-trained models,
datasets, and instructions for downstream use.
","[{'version': 'v1', 'created': 'Fri, 3 Feb 2023 08:04:59 GMT'}]",2023-02-06,"[['Fang', 'Li', ''], ['Chen', 'Qingyu', ''], ['Wei', 'Chih-Hsuan', ''], ['Lu', 'Zhiyong', ''], ['Wang', 'Kai', '']]"
2308.07124,Niklas Muennighoff,"Niklas Muennighoff, Qian Liu, Armel Zebaze, Qinkai Zheng, Binyuan Hui,
  Terry Yue Zhuo, Swayam Singh, Xiangru Tang, Leandro von Werra, Shayne Longpre",OctoPack: Instruction Tuning Code Large Language Models,"60 pages (9 main), 40 figures, 19 tables",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Finetuning large language models (LLMs) on instructions leads to vast
performance improvements on natural language tasks. We apply instruction tuning
using code, leveraging the natural structure of Git commits, which pair code
changes with human instructions. We compile CommitPack: 4 terabytes of Git
commits across 350 programming languages. We benchmark CommitPack against other
natural and synthetic code instructions (xP3x, Self-Instruct, OASST) on the 16B
parameter StarCoder model, and achieve state-of-the-art performance among
models not trained on OpenAI outputs, on the HumanEval Python benchmark (46.2%
pass@1). We further introduce HumanEvalPack, expanding the HumanEval benchmark
to a total of 3 coding tasks (Code Repair, Code Explanation, Code Synthesis)
across 6 languages (Python, JavaScript, Java, Go, C++, Rust). Our models,
OctoCoder and OctoGeeX, achieve the best performance across HumanEvalPack among
all permissive models, demonstrating CommitPack's benefits in generalizing to a
wider set of languages and natural coding tasks. Code, models and data are
freely available at https://github.com/bigcode-project/octopack.
","[{'version': 'v1', 'created': 'Mon, 14 Aug 2023 13:53:54 GMT'}, {'version': 'v2', 'created': 'Sun, 18 Feb 2024 09:46:06 GMT'}]",2024-02-20,"[['Muennighoff', 'Niklas', ''], ['Liu', 'Qian', ''], ['Zebaze', 'Armel', ''], ['Zheng', 'Qinkai', ''], ['Hui', 'Binyuan', ''], ['Zhuo', 'Terry Yue', ''], ['Singh', 'Swayam', ''], ['Tang', 'Xiangru', ''], ['von Werra', 'Leandro', ''], ['Longpre', 'Shayne', '']]"
2210.02595,Yuanchao Li,"Yuanchao Li, Yumnah Mohamied, Peter Bell, Catherine Lai","Exploration of A Self-Supervised Speech Model: A Study on Emotional
  Corpora",Accepted to SLT 2022,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Self-supervised speech models have grown fast during the past few years and
have proven feasible for use in various downstream tasks. Some recent work has
started to look at the characteristics of these models, yet many concerns have
not been fully addressed. In this work, we conduct a study on emotional corpora
to explore a popular self-supervised model -- wav2vec 2.0. Via a set of
quantitative analysis, we mainly demonstrate that: 1) wav2vec 2.0 appears to
discard paralinguistic information that is less useful for word recognition
purposes; 2) for emotion recognition, representations from the middle layer
alone perform as well as those derived from layer averaging, while the final
layer results in the worst performance in some cases; 3) current
self-supervised models may not be the optimal solution for downstream tasks
that make use of non-lexical features. Our work provides novel findings that
will aid future research in this area and theoretical basis for the use of
existing models.
","[{'version': 'v1', 'created': 'Wed, 5 Oct 2022 23:01:36 GMT'}, {'version': 'v2', 'created': 'Thu, 20 Oct 2022 16:45:07 GMT'}, {'version': 'v3', 'created': 'Mon, 12 Dec 2022 16:52:03 GMT'}]",2022-12-13,"[['Li', 'Yuanchao', ''], ['Mohamied', 'Yumnah', ''], ['Bell', 'Peter', ''], ['Lai', 'Catherine', '']]"
2311.03228,Ekapol Chuangsuwanich,"Peerat Limkonchotiwat, Wuttikorn Ponwitayarat, Lalita Lowphansirikul,
  Can Udomcharoenchaikit, Ekapol Chuangsuwanich, Sarana Nutanong",An Efficient Self-Supervised Cross-View Training For Sentence Embedding,"Accepted to TACL. The code and pre-trained models are available at
  https://github.com/mrpeerat/SCT",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Self-supervised sentence representation learning is the task of constructing
an embedding space for sentences without relying on human annotation efforts.
One straightforward approach is to finetune a pretrained language model (PLM)
with a representation learning method such as contrastive learning. While this
approach achieves impressive performance on larger PLMs, the performance
rapidly degrades as the number of parameters decreases. In this paper, we
propose a framework called Self-supervised Cross-View Training (SCT) to narrow
the performance gap between large and small PLMs. To evaluate the effectiveness
of SCT, we compare it to 5 baseline and state-of-the-art competitors on seven
Semantic Textual Similarity (STS) benchmarks using 5 PLMs with the number of
parameters ranging from 4M to 340M. The experimental results show that STC
outperforms the competitors for PLMs with less than 100M parameters in 18 of 21
cases.
","[{'version': 'v1', 'created': 'Mon, 6 Nov 2023 16:12:25 GMT'}]",2023-11-07,"[['Limkonchotiwat', 'Peerat', ''], ['Ponwitayarat', 'Wuttikorn', ''], ['Lowphansirikul', 'Lalita', ''], ['Udomcharoenchaikit', 'Can', ''], ['Chuangsuwanich', 'Ekapol', ''], ['Nutanong', 'Sarana', '']]"
2305.16799,Gabriella Skitalinskaya,Gabriella Skitalinskaya and Henning Wachsmuth,"To Revise or Not to Revise: Learning to Detect Improvable Claims for
  Argumentative Writing Support",Accepted as a long paper at ACL 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Optimizing the phrasing of argumentative text is crucial in higher education
and professional development. However, assessing whether and how the different
claims in a text should be revised is a hard task, especially for novice
writers. In this work, we explore the main challenges to identifying
argumentative claims in need of specific revisions. By learning from
collaborative editing behaviors in online debates, we seek to capture implicit
revision patterns in order to develop approaches aimed at guiding writers in
how to further improve their arguments. We systematically compare the ability
of common word embedding models to capture the differences between different
versions of the same text, and we analyze their impact on various types of
writing issues. To deal with the noisy nature of revision-based corpora, we
propose a new sampling strategy based on revision distance. Opposed to
approaches from prior work, such sampling can be done without employing
additional annotations and judgments. Moreover, we provide evidence that using
contextual information and domain knowledge can further improve prediction
results. How useful a certain type of context is, depends on the issue the
claim is suffering from, though.
","[{'version': 'v1', 'created': 'Fri, 26 May 2023 10:19:54 GMT'}]",2023-05-29,"[['Skitalinskaya', 'Gabriella', ''], ['Wachsmuth', 'Henning', '']]"
2303.14286,Phillip Schneider,"Phillip Schneider, Nils Rehtanz, Kristiina Jokinen and Florian Matthes","Voice-Based Conversational Agents and Knowledge Graphs for Improving
  News Search in Assisted Living","10 pages, submitted to PETRA 2023",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As the healthcare sector is facing major challenges, such as aging
populations, staff shortages, and common chronic diseases, delivering
high-quality care to individuals has become very difficult. Conversational
agents have shown to be a promising technology to alleviate some of these
issues. In the form of digital health assistants, they have the potential to
improve the everyday life of the elderly and chronically ill people. This
includes, for example, medication reminders, routine checks, or social
chit-chat. In addition, conversational agents can satisfy the fundamental need
of having access to information about daily news or local events, which enables
individuals to stay informed and connected with the world around them. However,
finding relevant news sources and navigating the plethora of news articles
available online can be overwhelming, particularly for those who may have
limited technological literacy or health-related impairments. To address this
challenge, we propose an innovative solution that combines knowledge graphs and
conversational agents for news search in assisted living. By leveraging graph
databases to semantically structure news data and implementing an intuitive
voice-based interface, our system can help care-dependent people to easily
discover relevant news articles and give personalized recommendations. We
explain our design choices, provide a system architecture, share insights of an
initial user test, and give an outlook on planned future work.
","[{'version': 'v1', 'created': 'Fri, 24 Mar 2023 21:49:27 GMT'}]",2023-03-28,"[['Schneider', 'Phillip', ''], ['Rehtanz', 'Nils', ''], ['Jokinen', 'Kristiina', ''], ['Matthes', 'Florian', '']]"
2306.11816,Jonathan Chang,"Jonathan D. Chang, Kiante Brantley, Rajkumar Ramamurthy, Dipendra
  Misra, Wen Sun",Learning to Generate Better Than Your LLM,"23 pages, 5 figures, 7 tables, 4 algorithms",,,,cs.LG cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Reinforcement learning (RL) has emerged as a powerful paradigm for
fine-tuning Large Language Models (LLMs) for text generation. In particular,
recent LLMs such as ChatGPT and GPT-4 can engage in fluent conversations with
users after finetuning with RL. Capitalizing on key properties of text
generation, we seek to investigate RL algorithms beyond general purpose
algorithms like Proximal Policy Optimization (PPO). In particular, we extend RL
algorithms to allow them to interact with a dynamic black-box guide LLM and
propose RL with guided feedback (RLGF), a suite of RL algorithms for LLM
fine-tuning. We provide two ways for the guide LLM to interact with the LLM to
be optimized for maximizing rewards. The guide LLM can generate text which
serves as additional starting states for the RL optimization procedure. The
guide LLM can also be used to complete the partial sentences generated by the
LLM that is being optimized, treating the guide LLM as an expert to imitate and
surpass eventually. We experiment on the IMDB positive sentiment, CommonGen,
and TL;DR summarization tasks. We show that our RL algorithms achieve higher
performance than supervised learning (SL) and the RL baseline PPO,
demonstrating the benefit of interaction with the guide LLM. On both CommonGen
and TL;DR, we not only outperform our SL baselines but also improve upon PPO
across a variety of metrics beyond the one we optimized for. Our code can be
found at https://github.com/Cornell-RL/tril.
","[{'version': 'v1', 'created': 'Tue, 20 Jun 2023 18:19:17 GMT'}, {'version': 'v2', 'created': 'Mon, 13 Nov 2023 18:51:42 GMT'}]",2023-11-14,"[['Chang', 'Jonathan D.', ''], ['Brantley', 'Kiante', ''], ['Ramamurthy', 'Rajkumar', ''], ['Misra', 'Dipendra', ''], ['Sun', 'Wen', '']]"
2204.08582,Jack FitzGerald,"Jack FitzGerald, Christopher Hench, Charith Peris, Scott Mackie, Kay
  Rottmann, Ana Sanchez, Aaron Nash, Liam Urbach, Vishesh Kakarala, Richa
  Singh, Swetha Ranganath, Laurie Crist, Misha Britan, Wouter Leeuwis, Gokhan
  Tur, Prem Natarajan","MASSIVE: A 1M-Example Multilingual Natural Language Understanding
  Dataset with 51 Typologically-Diverse Languages",Preprint; 8 pages,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present the MASSIVE dataset--Multilingual Amazon Slu resource package
(SLURP) for Slot-filling, Intent classification, and Virtual assistant
Evaluation. MASSIVE contains 1M realistic, parallel, labeled virtual assistant
utterances spanning 51 languages, 18 domains, 60 intents, and 55 slots. MASSIVE
was created by tasking professional translators to localize the English-only
SLURP dataset into 50 typologically diverse languages from 29 genera. We also
present modeling results on XLM-R and mT5, including exact match accuracy,
intent classification accuracy, and slot-filling F1 score. We have released our
dataset, modeling code, and models publicly.
","[{'version': 'v1', 'created': 'Mon, 18 Apr 2022 22:40:52 GMT'}, {'version': 'v2', 'created': 'Fri, 17 Jun 2022 17:19:15 GMT'}]",2022-06-20,"[['FitzGerald', 'Jack', ''], ['Hench', 'Christopher', ''], ['Peris', 'Charith', ''], ['Mackie', 'Scott', ''], ['Rottmann', 'Kay', ''], ['Sanchez', 'Ana', ''], ['Nash', 'Aaron', ''], ['Urbach', 'Liam', ''], ['Kakarala', 'Vishesh', ''], ['Singh', 'Richa', ''], ['Ranganath', 'Swetha', ''], ['Crist', 'Laurie', ''], ['Britan', 'Misha', ''], ['Leeuwis', 'Wouter', ''], ['Tur', 'Gokhan', ''], ['Natarajan', 'Prem', '']]"
2104.10259,Philip Feldman,"Philip Feldman, Sim Tiwari, Charissa S. L. Cheah, James R. Foulds,
  Shimei Pan",Analyzing COVID-19 Tweets with Transformer-based Language Models,"Six pages, six tables, four figures",,,,cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes a method for using Transformer-based Language Models
(TLMs) to understand public opinion from social media posts. In this approach,
we train a set of GPT models on several COVID-19 tweet corpora that reflect
populations of users with distinctive views. We then use prompt-based queries
to probe these models to reveal insights into the biases and opinions of the
users. We demonstrate how this approach can be used to produce results which
resemble polling the public on diverse social, political and public health
issues. The results on the COVID-19 tweet data show that transformer language
models are promising tools that can help us understand public opinions on
social media at scale.
","[{'version': 'v1', 'created': 'Tue, 20 Apr 2021 21:45:33 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Apr 2021 17:06:00 GMT'}, {'version': 'v3', 'created': 'Thu, 6 May 2021 01:03:18 GMT'}]",2021-05-07,"[['Feldman', 'Philip', ''], ['Tiwari', 'Sim', ''], ['Cheah', 'Charissa S. L.', ''], ['Foulds', 'James R.', ''], ['Pan', 'Shimei', '']]"
2311.11142,Mukaffi Bin Moin,"Fatema Tuj Johora Faria, Mukaffi Bin Moin, Ahmed Al Wase, Mehidi
  Ahmmed, Md. Rabius Sani, Tashreef Muhammad","Vashantor: A Large-scale Multilingual Benchmark Dataset for Automated
  Translation of Bangla Regional Dialects to Bangla Language",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The Bangla linguistic variety is a fascinating mix of regional dialects that
adds to the cultural diversity of the Bangla-speaking community. Despite
extensive study into translating Bangla to English, English to Bangla, and
Banglish to Bangla in the past, there has been a noticeable gap in translating
Bangla regional dialects into standard Bangla. In this study, we set out to
fill this gap by creating a collection of 32,500 sentences, encompassing
Bangla, Banglish, and English, representing five regional Bangla dialects. Our
aim is to translate these regional dialects into standard Bangla and detect
regions accurately. To achieve this, we proposed models known as mT5 and
BanglaT5 for translating regional dialects into standard Bangla. Additionally,
we employed mBERT and Bangla-bert-base to determine the specific regions from
where these dialects originated. Our experimental results showed the highest
BLEU score of 69.06 for Mymensingh regional dialects and the lowest BLEU score
of 36.75 for Chittagong regional dialects. We also observed the lowest average
word error rate of 0.1548 for Mymensingh regional dialects and the highest of
0.3385 for Chittagong regional dialects. For region detection, we achieved an
accuracy of 85.86% for Bangla-bert-base and 84.36% for mBERT. This is the first
large-scale investigation of Bangla regional dialects to Bangla machine
translation. We believe our findings will not only pave the way for future work
on Bangla regional dialects to Bangla machine translation, but will also be
useful in solving similar language-related challenges in low-resource language
conditions.
","[{'version': 'v1', 'created': 'Sat, 18 Nov 2023 18:36:16 GMT'}]",2023-11-21,"[['Faria', 'Fatema Tuj Johora', ''], ['Moin', 'Mukaffi Bin', ''], ['Wase', 'Ahmed Al', ''], ['Ahmmed', 'Mehidi', ''], ['Sani', 'Md. Rabius', ''], ['Muhammad', 'Tashreef', '']]"
2306.02377,Brielen Madureira,Brielen Madureira and David Schlangen,"""Are you telling me to put glasses on the dog?'' Content-Grounded
  Annotation of Instruction Clarification Requests in the CoDraw Dataset",A 2-page version will appear at SemDial 2023 as a poster,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Instruction Clarification Requests are a mechanism to solve communication
problems, which is very functional in instruction-following interactions.
Recent work has argued that the CoDraw dataset is a valuable source of
naturally occurring iCRs. Beyond identifying when iCRs should be made, dialogue
models should also be able to generate them with suitable form and content. In
this work, we introduce CoDraw-iCR (v2), extending the existing iCR identifiers
with fine-grained information grounded in the underlying dialogue game items
and possible actions. Our annotation can serve to model and evaluate repair
capabilities of dialogue agents.
","[{'version': 'v1', 'created': 'Sun, 4 Jun 2023 15:23:16 GMT'}, {'version': 'v2', 'created': 'Wed, 26 Jul 2023 08:54:03 GMT'}]",2023-07-27,"[['Madureira', 'Brielen', ''], ['Schlangen', 'David', '']]"
2106.01960,Gaurav Sahu,"Olga Vechtomova, Gaurav Sahu, Dhruv Kumar",LyricJam: A system for generating lyrics for live instrumental music,"Accepted to International Conference on Computational Creativity
  (ICCC) 2021 [Oral]",,,,cs.SD cs.AI cs.CL cs.LG eess.AS,http://creativecommons.org/licenses/by/4.0/,"  We describe a real-time system that receives a live audio stream from a jam
session and generates lyric lines that are congruent with the live music being
played. Two novel approaches are proposed to align the learned latent spaces of
audio and text representations that allow the system to generate novel lyric
lines matching live instrumental music. One approach is based on adversarial
alignment of latent representations of audio and lyrics, while the other
approach learns to transfer the topology from the music latent space to the
lyric latent space. A user study with music artists using the system showed
that the system was useful not only in lyric composition, but also encouraged
the artists to improvise and find new musical expressions. Another user study
demonstrated that users preferred the lines generated using the proposed
methods to the lines generated by a baseline model.
","[{'version': 'v1', 'created': 'Thu, 3 Jun 2021 16:06:46 GMT'}]",2021-06-04,"[['Vechtomova', 'Olga', ''], ['Sahu', 'Gaurav', ''], ['Kumar', 'Dhruv', '']]"
2001.00623,Kai Shu,"Kai Shu, Suhang Wang, Dongwon Lee, and Huan Liu","Mining Disinformation and Fake News: Concepts, Methods, and Recent
  Advancements","Submitted as an introductory chapter for the edited book on ""Fake
  News, Disinformation, and Misinformation in Social Media- Emerging Research
  Challenges and Opportunities"", Springer Press",,,,cs.SI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In recent years, disinformation including fake news, has became a global
phenomenon due to its explosive growth, particularly on social media. The wide
spread of disinformation and fake news can cause detrimental societal effects.
Despite the recent progress in detecting disinformation and fake news, it is
still non-trivial due to its complexity, diversity, multi-modality, and costs
of fact-checking or annotation. The goal of this chapter is to pave the way for
appreciating the challenges and advancements via: (1) introducing the types of
information disorder on social media and examine their differences and
connections; (2) describing important and emerging tasks to combat
disinformation for characterization, detection and attribution; and (3)
discussing a weak supervision approach to detect disinformation with limited
labeled data. We then provide an overview of the chapters in this book that
represent the recent advancements in three related parts: (1) user engagements
in the dissemination of information disorder; (2) techniques on detecting and
mitigating disinformation; and (3) trending issues such as ethics, blockchain,
clickbaits, etc. We hope this book to be a convenient entry point for
researchers, practitioners, and students to understand the problems and
challenges, learn state-of-the-art solutions for their specific needs, and
quickly identify new research problems in their domains.
","[{'version': 'v1', 'created': 'Thu, 2 Jan 2020 21:01:02 GMT'}]",2020-01-06,"[['Shu', 'Kai', ''], ['Wang', 'Suhang', ''], ['Lee', 'Dongwon', ''], ['Liu', 'Huan', '']]"
2309.09652,Peter Ochieng,Peter Ochieng,"Speeding Up Speech Synthesis In Diffusion Models By Reducing Data
  Distribution Recovery Steps Via Content Transfer",10 pages,,,,cs.SD cs.CL eess.AS,http://creativecommons.org/licenses/by/4.0/,"  Diffusion based vocoders have been criticised for being slow due to the many
steps required during sampling. Moreover, the model's loss function that is
popularly implemented is designed such that the target is the original input
$x_0$ or error $\epsilon_0$. For early time steps of the reverse process, this
results in large prediction errors, which can lead to speech distortions and
increase the learning time. We propose a setup where the targets are the
different outputs of forward process time steps with a goal to reduce the
magnitude of prediction errors and reduce the training time. We use the
different layers of a neural network (NN) to perform denoising by training them
to learn to generate representations similar to the noised outputs in the
forward process of the diffusion. The NN layers learn to progressively denoise
the input in the reverse process until finally the final layer estimates the
clean speech. To avoid 1:1 mapping between layers of the neural network and the
forward process steps, we define a skip parameter $\tau>1$ such that an NN
layer is trained to cumulatively remove the noise injected in the $\tau$ steps
in the forward process. This significantly reduces the number of data
distribution recovery steps and, consequently, the time to generate speech. We
show through extensive evaluation that the proposed technique generates
high-fidelity speech in competitive time that outperforms current
state-of-the-art tools. The proposed technique is also able to generalize well
to unseen speech.
","[{'version': 'v1', 'created': 'Mon, 18 Sep 2023 10:35:27 GMT'}]",2023-09-19,"[['Ochieng', 'Peter', '']]"
2004.02393,Yufei Feng,"Yufei Feng, Mo Yu, Wenhan Xiong, Xiaoxiao Guo, Junjie Huang, Shiyu
  Chang, Murray Campbell, Michael Greenspan and Xiaodan Zhu","Learning to Recover Reasoning Chains for Multi-Hop Question Answering
  via Cooperative Games",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose the new problem of learning to recover reasoning chains from
weakly supervised signals, i.e., the question-answer pairs. We propose a
cooperative game approach to deal with this problem, in which how the evidence
passages are selected and how the selected passages are connected are handled
by two models that cooperate to select the most confident chains from a large
set of candidates (from distant supervision). For evaluation, we created
benchmarks based on two multi-hop QA datasets, HotpotQA and MedHop; and
hand-labeled reasoning chains for the latter. The experimental results
demonstrate the effectiveness of our proposed approach.
","[{'version': 'v1', 'created': 'Mon, 6 Apr 2020 03:54:38 GMT'}]",2020-04-07,"[['Feng', 'Yufei', ''], ['Yu', 'Mo', ''], ['Xiong', 'Wenhan', ''], ['Guo', 'Xiaoxiao', ''], ['Huang', 'Junjie', ''], ['Chang', 'Shiyu', ''], ['Campbell', 'Murray', ''], ['Greenspan', 'Michael', ''], ['Zhu', 'Xiaodan', '']]"
2403.12469,Sanghyun Hong,"Ojas Nimase, Sanghyun Hong","When Do ""More Contexts"" Help with Sarcasm Recognition?",Accepted to LREC-COLING 2024 [Short],,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sarcasm recognition is challenging because it needs an understanding of the
true intention, which is opposite to or different from the literal meaning of
the words. Prior work has addressed this challenge by developing a series of
methods that provide richer $contexts$, e.g., sentiment or cultural nuances, to
models. While shown to be effective individually, no study has systematically
evaluated their collective effectiveness. As a result, it remains unclear to
what extent additional contexts can improve sarcasm recognition. In this work,
we explore the improvements that existing methods bring by incorporating more
contexts into a model. To this end, we develop a framework where we can
integrate multiple contextual cues and test different approaches. In evaluation
with four approaches on three sarcasm recognition benchmarks, we achieve
existing state-of-the-art performances and also demonstrate the benefits of
sequentially adding more contexts. We also identify inherent drawbacks of using
more contexts, highlighting that in the pursuit of even better results, the
model may need to adopt societal biases.
","[{'version': 'v1', 'created': 'Tue, 19 Mar 2024 06:01:02 GMT'}]",2024-03-20,"[['Nimase', 'Ojas', ''], ['Hong', 'Sanghyun', '']]"
2206.06888,Daoguang Zan,"Daoguang Zan, Bei Chen, Dejian Yang, Zeqi Lin, Minsu Kim, Bei Guan,
  Yongji Wang, Weizhu Chen, Jian-Guang Lou","CERT: Continual Pre-Training on Sketches for Library-Oriented Code
  Generation",Accepted for publication at IJCAI-ECAI 2022,,,,cs.SE cs.CL cs.PL,http://creativecommons.org/licenses/by/4.0/,"  Code generation is a longstanding challenge, aiming to generate a code
snippet based on a natural language description. Usually, expensive text-code
paired data is essential for training a code generation model. Recently, thanks
to the success of pre-training techniques, large language models are trained on
large-scale unlabelled code corpora and perform well in code generation. In
this paper, we investigate how to leverage an unlabelled code corpus to train a
model for library-oriented code generation. Since it is a common practice for
programmers to reuse third-party libraries, in which case the text-code paired
data are harder to obtain due to the huge number of libraries. We observe that
library-oriented code snippets are more likely to share similar code sketches.
Hence, we present CERT with two steps: a sketcher generates the sketch, then a
generator fills the details in the sketch. Both the sketcher and the generator
are continually pre-trained upon a base model using unlabelled data.
Furthermore, we craft two benchmarks named PandasEval and NumpyEval to evaluate
library-oriented code generation. Experimental results demonstrate the
impressive performance of CERT. For example, it surpasses the base model by an
absolute 15.67% improvement in terms of pass@1 on PandasEval. Our work is
available at https://github.com/microsoft/PyCodeGPT.
","[{'version': 'v1', 'created': 'Tue, 14 Jun 2022 14:44:34 GMT'}]",2022-06-15,"[['Zan', 'Daoguang', ''], ['Chen', 'Bei', ''], ['Yang', 'Dejian', ''], ['Lin', 'Zeqi', ''], ['Kim', 'Minsu', ''], ['Guan', 'Bei', ''], ['Wang', 'Yongji', ''], ['Chen', 'Weizhu', ''], ['Lou', 'Jian-Guang', '']]"
2403.00632,Qian Wan,"Qian Wan, Xin Feng, Yining Bei, Zhiqi Gao, Zhicong Lu","Metamorpheus: Interactive, Affective, and Creative Dream Narration
  Through Metaphorical Visual Storytelling",Accepted by CHI 2024,,,,cs.HC cs.AI cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Human emotions are essentially molded by lived experiences, from which we
construct personalised meaning. The engagement in such meaning-making process
has been practiced as an intervention in various psychotherapies to promote
wellness. Nevertheless, to support recollecting and recounting lived
experiences in everyday life remains under explored in HCI. It also remains
unknown how technologies such as generative AI models can facilitate the
meaning making process, and ultimately support affective mindfulness. In this
paper we present Metamorpheus, an affective interface that engages users in a
creative visual storytelling of emotional experiences during dreams.
Metamorpheus arranges the storyline based on a dream's emotional arc, and
provokes self-reflection through the creation of metaphorical images and text
depictions. The system provides metaphor suggestions, and generates visual
metaphors and text depictions using generative AI models, while users can apply
generations to recolour and re-arrange the interface to be visually affective.
Our experience-centred evaluation manifests that, by interacting with
Metamorpheus, users can recall their dreams in vivid detail, through which they
relive and reflect upon their experiences in a meaningful way.
","[{'version': 'v1', 'created': 'Fri, 1 Mar 2024 16:09:32 GMT'}]",2024-03-06,"[['Wan', 'Qian', ''], ['Feng', 'Xin', ''], ['Bei', 'Yining', ''], ['Gao', 'Zhiqi', ''], ['Lu', 'Zhicong', '']]"
1708.04134,Biplav Srivastava,"Q Vera Liao, Biplav Srivastava, Pavan Kapanipathi","A Measure for Dialog Complexity and its Application in Streamlining
  Service Operations",11 pages,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Dialog is a natural modality for interaction between customers and businesses
in the service industry. As customers call up the service provider, their
interactions may be routine or extraordinary. We believe that these
interactions, when seen as dialogs, can be analyzed to obtain a better
understanding of customer needs and how to efficiently address them. We
introduce the idea of a dialog complexity measure to characterize multi-party
interactions, propose a general data-driven method to calculate it, use it to
discover insights in public and enterprise dialog datasets, and demonstrate its
beneficial usage in facilitating better handling of customer requests and
evaluating service agents.
","[{'version': 'v1', 'created': 'Fri, 4 Aug 2017 03:44:35 GMT'}]",2017-08-15,"[['Liao', 'Q Vera', ''], ['Srivastava', 'Biplav', ''], ['Kapanipathi', 'Pavan', '']]"
2002.08795,Prithviraj Ammanabrolu,"Prithviraj Ammanabrolu, Ethan Tien, Zhaochen Luo, Mark O. Riedl","How To Avoid Being Eaten By a Grue: Exploration Strategies for
  Text-Adventure Agents",,,,,cs.LG cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text-based games -- in which an agent interacts with the world through
textual natural language -- present us with the problem of
combinatorially-sized action-spaces. Most current reinforcement learning
algorithms are not capable of effectively handling such a large number of
possible actions per turn. Poor sample efficiency, consequently, results in
agents that are unable to pass bottleneck states, where they are unable to
proceed because they do not see the right action sequence to pass the
bottleneck enough times to be sufficiently reinforced. Building on prior work
using knowledge graphs in reinforcement learning, we introduce two new game
state exploration strategies. We compare our exploration strategies against
strong baselines on the classic text-adventure game, Zork1, where prior agent
have been unable to get past a bottleneck where the agent is eaten by a Grue.
","[{'version': 'v1', 'created': 'Wed, 19 Feb 2020 17:18:20 GMT'}]",2020-02-21,"[['Ammanabrolu', 'Prithviraj', ''], ['Tien', 'Ethan', ''], ['Luo', 'Zhaochen', ''], ['Riedl', 'Mark O.', '']]"
1712.03133,Kartik Audhkhasi,"Kartik Audhkhasi, Brian Kingsbury, Bhuvana Ramabhadran, George Saon,
  Michael Picheny","Building competitive direct acoustics-to-word models for English
  conversational speech recognition","Submitted to IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP), 2018",,,,cs.CL cs.AI cs.NE stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Direct acoustics-to-word (A2W) models in the end-to-end paradigm have
received increasing attention compared to conventional sub-word based automatic
speech recognition models using phones, characters, or context-dependent hidden
Markov model states. This is because A2W models recognize words from speech
without any decoder, pronunciation lexicon, or externally-trained language
model, making training and decoding with such models simple. Prior work has
shown that A2W models require orders of magnitude more training data in order
to perform comparably to conventional models. Our work also showed this
accuracy gap when using the English Switchboard-Fisher data set. This paper
describes a recipe to train an A2W model that closes this gap and is at-par
with state-of-the-art sub-word based models. We achieve a word error rate of
8.8%/13.9% on the Hub5-2000 Switchboard/CallHome test sets without any decoder
or language model. We find that model initialization, training data order, and
regularization have the most impact on the A2W model performance. Next, we
present a joint word-character A2W model that learns to first spell the word
and then recognize it. This model provides a rich output to the user instead of
simple word hypotheses, making it especially useful in the case of words unseen
or rarely-seen during training.
","[{'version': 'v1', 'created': 'Fri, 8 Dec 2017 15:43:21 GMT'}]",2017-12-11,"[['Audhkhasi', 'Kartik', ''], ['Kingsbury', 'Brian', ''], ['Ramabhadran', 'Bhuvana', ''], ['Saon', 'George', ''], ['Picheny', 'Michael', '']]"
1911.10235,Yiren Wang,"Yiren Wang, Hongzhao Huang, Zhe Liu, Yutong Pang, Yongqiang Wang,
  ChengXiang Zhai, Fuchun Peng",Improving N-gram Language Models with Pre-trained Deep Transformer,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Although n-gram language models (LMs) have been outperformed by the
state-of-the-art neural LMs, they are still widely used in speech recognition
due to its high efficiency in inference. In this paper, we demonstrate that
n-gram LM can be improved by neural LMs through a text generation based data
augmentation method. In contrast to previous approaches, we employ a
large-scale general domain pre-training followed by in-domain fine-tuning
strategy to construct deep Transformer based neural LMs. Large amount of
in-domain text data is generated with the well trained deep Transformer to
construct new n-gram LMs, which are then interpolated with baseline n-gram
systems. Empirical studies on different speech recognition tasks show that the
proposed approach can effectively improve recognition accuracy. In particular,
our proposed approach brings significant relative word error rate reduction up
to 6.0% for domains with limited in-domain data.
","[{'version': 'v1', 'created': 'Fri, 22 Nov 2019 20:11:40 GMT'}]",2019-12-03,"[['Wang', 'Yiren', ''], ['Huang', 'Hongzhao', ''], ['Liu', 'Zhe', ''], ['Pang', 'Yutong', ''], ['Wang', 'Yongqiang', ''], ['Zhai', 'ChengXiang', ''], ['Peng', 'Fuchun', '']]"
2311.06243,Weiyang Liu,"Weiyang Liu, Zeju Qiu, Yao Feng, Yuliang Xiu, Yuxuan Xue, Longhui Yu,
  Haiwen Feng, Zhen Liu, Juyeon Heo, Songyou Peng, Yandong Wen, Michael J.
  Black, Adrian Weller, Bernhard Sch\""olkopf",Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization,"Technical Report (33 pages, 18 figures)",,,,cs.LG cs.AI cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large foundation models are becoming ubiquitous, but training them from
scratch is prohibitively expensive. Thus, efficiently adapting these powerful
models to downstream tasks is increasingly important. In this paper, we study a
principled finetuning paradigm -- Orthogonal Finetuning (OFT) -- for downstream
task adaptation. Despite demonstrating good generalizability, OFT still uses a
fairly large number of trainable parameters due to the high dimensionality of
orthogonal matrices. To address this, we start by examining OFT from an
information transmission perspective, and then identify a few key desiderata
that enable better parameter-efficiency. Inspired by how the Cooley-Tukey fast
Fourier transform algorithm enables efficient information transmission, we
propose an efficient orthogonal parameterization using butterfly structures. We
apply this parameterization to OFT, creating a novel parameter-efficient
finetuning method, called Orthogonal Butterfly (BOFT). By subsuming OFT as a
special case, BOFT introduces a generalized orthogonal finetuning framework.
Finally, we conduct an extensive empirical study of adapting large vision
transformers, large language models, and text-to-image diffusion models to
various downstream tasks in vision and language.
","[{'version': 'v1', 'created': 'Fri, 10 Nov 2023 18:59:54 GMT'}]",2023-11-13,"[['Liu', 'Weiyang', ''], ['Qiu', 'Zeju', ''], ['Feng', 'Yao', ''], ['Xiu', 'Yuliang', ''], ['Xue', 'Yuxuan', ''], ['Yu', 'Longhui', ''], ['Feng', 'Haiwen', ''], ['Liu', 'Zhen', ''], ['Heo', 'Juyeon', ''], ['Peng', 'Songyou', ''], ['Wen', 'Yandong', ''], ['Black', 'Michael J.', ''], ['Weller', 'Adrian', ''], ['Schölkopf', 'Bernhard', '']]"
cmp-lg/9807007,Thorsten Brants,"Wojciech Skut and Thorsten Brants (Computational Linguistics,
  Universitity of the Saarland, Germany)",Chunk Tagger - Statistical Recognition of Noun Phrases,"7 pages, LaTeX",,,,cmp-lg cs.CL,,"  We describe a stochastic approach to partial parsing, i.e., the recognition
of syntactic structures of limited depth. The technique utilises Markov Models,
but goes beyond usual bracketing approaches, since it is capable of recognising
not only the boundaries, but also the internal structure and syntactic category
of simple as well as complex NP's, PP's, AP's and adverbials. We compare
tagging accuracy for different applications and encoding schemes.
","[{'version': 'v1', 'created': 'Fri, 17 Jul 1998 14:23:10 GMT'}]",2007-05-23,"[['Skut', 'Wojciech', '', 'Computational Linguistics,\n  Universitity of the Saarland, Germany'], ['Brants', 'Thorsten', '', 'Computational Linguistics,\n  Universitity of the Saarland, Germany']]"
2310.20470,A. Seza Dogruoz,"A. Seza Do\u{g}ru\""oz, Sunayana Sitaram, Zheng-Xin Yong","Representativeness as a Forgotten Lesson for Multilingual and
  Code-switched Data Collection and Preparation",Accepted for EMNLP'23 Findings (to appear on EMNLP'23 Proceedings),,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Multilingualism is widespread around the world and code-switching (CSW) is a
common practice among different language pairs/tuples across locations and
regions. However, there is still not much progress in building successful CSW
systems, despite the recent advances in Massive Multilingual Language Models
(MMLMs). We investigate the reasons behind this setback through a critical
study about the existing CSW data sets (68) across language pairs in terms of
the collection and preparation (e.g. transcription and annotation) stages. This
in-depth analysis reveals that \textbf{a)} most CSW data involves English
ignoring other language pairs/tuples \textbf{b)} there are flaws in terms of
representativeness in data collection and preparation stages due to ignoring
the location based, socio-demographic and register variation in CSW. In
addition, lack of clarity on the data selection and filtering stages shadow the
representativeness of CSW data sets. We conclude by providing a short
check-list to improve the representativeness for forthcoming studies involving
CSW data collection and preparation.
","[{'version': 'v1', 'created': 'Tue, 31 Oct 2023 14:04:07 GMT'}]",2023-11-01,"[['Doğruöz', 'A. Seza', ''], ['Sitaram', 'Sunayana', ''], ['Yong', 'Zheng-Xin', '']]"
2310.00637,Paul Groth,Bradley P. Allen and Lise Stork and Paul Groth,Knowledge Engineering using Large Language Models,"19 pages, 2 figures, accepted in Transactions on Graph Data and
  Knowledge",,,,cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Knowledge engineering is a discipline that focuses on the creation and
maintenance of processes that generate and apply knowledge. Traditionally,
knowledge engineering approaches have focused on knowledge expressed in formal
languages. The emergence of large language models and their capabilities to
effectively work with natural language, in its broadest sense, raises questions
about the foundations and practice of knowledge engineering. Here, we outline
the potential role of LLMs in knowledge engineering, identifying two central
directions: 1) creating hybrid neuro-symbolic knowledge systems; and 2)
enabling knowledge engineering in natural language. Additionally, we formulate
key open research questions to tackle these directions.
","[{'version': 'v1', 'created': 'Sun, 1 Oct 2023 10:26:25 GMT'}]",2023-10-03,"[['Allen', 'Bradley P.', ''], ['Stork', 'Lise', ''], ['Groth', 'Paul', '']]"
1804.04059,Stefano M. Iacus,"A. Ceron, L. Curini, S.M. Iacus","ISIS at its apogee: the Arabic discourse on Twitter and what we can
  learn from that about ISIS support and Foreign Fighters",,,,,cs.CL cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We analyze 26.2 million comments published in Arabic language on Twitter,
from July 2014 to January 2015, when ISIS' strength reached its peak and the
group was prominently expanding the territorial area under its control. By
doing that, we are able to measure the share of support and aversion toward the
Islamic State within the online Arab communities. We then investigate two
specific topics. First, by exploiting the time-granularity of the tweets, we
link the opinions with daily events to understand the main determinants of the
changing trend in support toward ISIS. Second, by taking advantage of the
geographical locations of tweets, we explore the relationship between online
opinions across countries and the number of foreign fighters joining ISIS.
","[{'version': 'v1', 'created': 'Wed, 14 Mar 2018 05:29:30 GMT'}, {'version': 'v2', 'created': 'Tue, 24 Apr 2018 14:39:59 GMT'}]",2018-04-25,"[['Ceron', 'A.', ''], ['Curini', 'L.', ''], ['Iacus', 'S. M.', '']]"
2003.12738,Zhaojiang Lin,"Zhaojiang Lin, Genta Indra Winata, Peng Xu, Zihan Liu, Pascale Fung",Variational Transformers for Diverse Response Generation,open domain dialogue,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the great promise of Transformers in many sequence modeling tasks
(e.g., machine translation), their deterministic nature hinders them from
generalizing to high entropy tasks such as dialogue response generation.
Previous work proposes to capture the variability of dialogue responses with a
recurrent neural network (RNN)-based conditional variational autoencoder
(CVAE). However, the autoregressive computation of the RNN limits the training
efficiency. Therefore, we propose the Variational Transformer (VT), a
variational self-attentive feed-forward sequence model. The VT combines the
parallelizability and global receptive field of the Transformer with the
variational nature of the CVAE by incorporating stochastic latent variables
into Transformers. We explore two types of the VT: 1) modeling the
discourse-level diversity with a global latent variable; and 2) augmenting the
Transformer decoder with a sequence of fine-grained latent variables. Then, the
proposed models are evaluated on three conversational datasets with both
automatic metric and human evaluation. The experimental results show that our
models improve standard Transformers and other baselines in terms of diversity,
semantic relevance, and human judgment.
","[{'version': 'v1', 'created': 'Sat, 28 Mar 2020 07:48:02 GMT'}]",2020-03-31,"[['Lin', 'Zhaojiang', ''], ['Winata', 'Genta Indra', ''], ['Xu', 'Peng', ''], ['Liu', 'Zihan', ''], ['Fung', 'Pascale', '']]"
2306.04933,Zhao Song,"Junda Wu, Tong Yu, Rui Wang, Zhao Song, Ruiyi Zhang, Handong Zhao,
  Chaochao Lu, Shuai Li, Ricardo Henao","InfoPrompt: Information-Theoretic Soft Prompt Tuning for Natural
  Language Understanding",,,,,cs.CL cs.LG stat.ML,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Soft prompt tuning achieves superior performances across a wide range of
few-shot tasks. However, the performances of prompt tuning can be highly
sensitive to the initialization of the prompts. We also empirically observe
that conventional prompt tuning methods cannot encode and learn sufficient
task-relevant information from prompt tokens. In this work, we develop an
information-theoretic framework that formulates soft prompt tuning as
maximizing mutual information between prompts and other model parameters (or
encoded representations). This novel view helps us to develop a more efficient,
accurate and robust soft prompt tuning method InfoPrompt. With this framework,
we develop two novel mutual information based loss functions, to (i) discover
proper prompt initialization for the downstream tasks and learn sufficient
task-relevant information from prompt tokens and (ii) encourage the output
representation from the pretrained language model to be more aware of the
task-relevant information captured in the learnt prompt. Extensive experiments
validate that InfoPrompt can significantly accelerate the convergence of the
prompt tuning and outperform traditional prompt tuning methods. Finally, we
provide a formal theoretical result for showing to show that gradient descent
type algorithm can be used to train our mutual information loss.
","[{'version': 'v1', 'created': 'Thu, 8 Jun 2023 04:31:48 GMT'}]",2023-06-09,"[['Wu', 'Junda', ''], ['Yu', 'Tong', ''], ['Wang', 'Rui', ''], ['Song', 'Zhao', ''], ['Zhang', 'Ruiyi', ''], ['Zhao', 'Handong', ''], ['Lu', 'Chaochao', ''], ['Li', 'Shuai', ''], ['Henao', 'Ricardo', '']]"
2401.00676,Gelei Deng,"Haodong Li, Gelei Deng, Yi Liu, Kailong Wang, Yuekang Li, Tianwei
  Zhang, Yang Liu, Guoai Xu, Guosheng Xu, Haoyu Wang","Digger: Detecting Copyright Content Mis-usage in Large Language Model
  Training",,,,,cs.CR cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-training, which utilizes extensive and varied datasets, is a critical
factor in the success of Large Language Models (LLMs) across numerous
applications. However, the detailed makeup of these datasets is often not
disclosed, leading to concerns about data security and potential misuse. This
is particularly relevant when copyrighted material, still under legal
protection, is used inappropriately, either intentionally or unintentionally,
infringing on the rights of the authors.
  In this paper, we introduce a detailed framework designed to detect and
assess the presence of content from potentially copyrighted books within the
training datasets of LLMs. This framework also provides a confidence estimation
for the likelihood of each content sample's inclusion. To validate our
approach, we conduct a series of simulated experiments, the results of which
affirm the framework's effectiveness in identifying and addressing instances of
content misuse in LLM training processes. Furthermore, we investigate the
presence of recognizable quotes from famous literary works within these
datasets. The outcomes of our study have significant implications for ensuring
the ethical use of copyrighted materials in the development of LLMs,
highlighting the need for more transparent and responsible data management
practices in this field.
","[{'version': 'v1', 'created': 'Mon, 1 Jan 2024 06:04:52 GMT'}]",2024-01-02,"[['Li', 'Haodong', ''], ['Deng', 'Gelei', ''], ['Liu', 'Yi', ''], ['Wang', 'Kailong', ''], ['Li', 'Yuekang', ''], ['Zhang', 'Tianwei', ''], ['Liu', 'Yang', ''], ['Xu', 'Guoai', ''], ['Xu', 'Guosheng', ''], ['Wang', 'Haoyu', '']]"
2402.09664,Changshu Liu,"Changshu Liu, Shizhuo Dylan Zhang, Reyhaneh Jabbarvand","CodeMind: A Framework to Challenge Large Language Models for Code
  Reasoning",,,,,cs.SE cs.AI cs.CL cs.PL,http://creativecommons.org/licenses/by/4.0/,"  Solely relying on test passing to evaluate Large Language Models (LLMs) for
code synthesis may result in unfair assessment or promoting models with data
leakage. As an alternative, we introduce CodeMind, a framework designed to
gauge the code reasoning abilities of LLMs. CodeMind currently supports three
code reasoning tasks: Independent Execution Reasoning (IER), Dependent
Execution Reasoning (DER), and Specification Reasoning (SR). The first two
evaluate models to predict the execution output of an arbitrary code or code
the model could correctly synthesize. The third one evaluates the extent to
which LLMs implement the specified expected behavior.
  Our extensive evaluation of nine LLMs across five benchmarks in two different
programming languages using CodeMind shows that LLMs fairly follow control flow
constructs and, in general, explain how inputs evolve to output, specifically
for simple programs and the ones they can correctly synthesize. However, their
performance drops for code with higher complexity, non-trivial logical and
arithmetic operators, non-primitive types, and API calls. Furthermore, we
observe that, while correlated, specification reasoning (essential for code
synthesis) does not imply execution reasoning (essential for broader
programming tasks such as testing and debugging): ranking LLMs based on test
passing can be different compared to code reasoning.
","[{'version': 'v1', 'created': 'Thu, 15 Feb 2024 02:24:46 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Feb 2024 18:35:22 GMT'}, {'version': 'v3', 'created': 'Wed, 21 Feb 2024 20:23:08 GMT'}]",2024-02-23,"[['Liu', 'Changshu', ''], ['Zhang', 'Shizhuo Dylan', ''], ['Jabbarvand', 'Reyhaneh', '']]"
1803.03667,Irina Legchenkova,"Evgeny Shulzinger, Irina Legchenkova and Edward Bormashenko","Co-occurrence of the Benford-like and Zipf Laws Arising from the Texts
  Representing Human and Artificial Languages","23 pages, 8 figures, 4 tables",,,,cs.CL physics.soc-ph stat.OT,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We demonstrate that large texts, representing human (English, Russian,
Ukrainian) and artificial (C++, Java) languages, display quantitative patterns
characterized by the Benford-like and Zipf laws. The frequency of a word
following the Zipf law is inversely proportional to its rank, whereas the total
numbers of a certain word appearing in the text generate the uneven
Benford-like distribution of leading numbers. Excluding the most popular words
essentially improves the correlation of actual textual data with the Zipfian
distribution, whereas the Benford distribution of leading numbers (arising from
the overall amount of a certain word) is insensitive to the same elimination
procedure. The calculated values of the moduli of slopes of double
logarithmical plots for artificial languages (C++, Java) are markedly larger
than those for human ones.
","[{'version': 'v1', 'created': 'Tue, 6 Mar 2018 12:24:42 GMT'}]",2018-03-13,"[['Shulzinger', 'Evgeny', ''], ['Legchenkova', 'Irina', ''], ['Bormashenko', 'Edward', '']]"
2008.06176,Ye Bi,"Ye Bi, Shuo Wang, Zhongrui Fan","A Hybrid BERT and LightGBM based Model for Predicting Emotion GIF
  Categories on Twitter","4 pages, ACL 2020 EmotionGIF Challenge Technical Report",,,,cs.IR cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The animated Graphical Interchange Format (GIF) images have been widely used
on social media as an intuitive way of expression emotion. Given their
expressiveness, GIFs offer a more nuanced and precise way to convey emotions.
In this paper, we present our solution for the EmotionGIF 2020 challenge, the
shared task of SocialNLP 2020. To recommend GIF categories for unlabeled
tweets, we regarded this problem as a kind of matching tasks and proposed a
learning to rank framework based on Bidirectional Encoder Representations from
Transformer (BERT) and LightGBM. Our team won the 4th place with a Mean Average
Precision @ 6 (MAP@6) score of 0.5394 on the round 1 leaderboard.
","[{'version': 'v1', 'created': 'Fri, 14 Aug 2020 03:23:09 GMT'}]",2020-08-17,"[['Bi', 'Ye', ''], ['Wang', 'Shuo', ''], ['Fan', 'Zhongrui', '']]"
1506.06442,Fandong Meng,"Fandong Meng, Zhengdong Lu, Zhaopeng Tu, Hang Li, and Qun Liu",A Deep Memory-based Architecture for Sequence-to-Sequence Learning,"13 pages, Under review as a conference paper at ICLR 2016",,,,cs.CL cs.LG cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose DEEPMEMORY, a novel deep architecture for sequence-to-sequence
learning, which performs the task through a series of nonlinear transformations
from the representation of the input sequence (e.g., a Chinese sentence) to the
final output sequence (e.g., translation to English). Inspired by the recently
proposed Neural Turing Machine (Graves et al., 2014), we store the intermediate
representations in stacked layers of memories, and use read-write operations on
the memories to realize the nonlinear transformations between the
representations. The types of transformations are designed in advance but the
parameters are learned from data. Through layer-by-layer transformations,
DEEPMEMORY can model complicated relations between sequences necessary for
applications such as machine translation between distant languages. The
architecture can be trained with normal back-propagation on sequenceto-sequence
data, and the learning can be easily scaled up to a large corpus. DEEPMEMORY is
broad enough to subsume the state-of-the-art neural translation model in
(Bahdanau et al., 2015) as its special case, while significantly improving upon
the model with its deeper architecture. Remarkably, DEEPMEMORY, being purely
neural network-based, can achieve performance comparable to the traditional
phrase-based machine translation system Moses with a small vocabulary and a
modest parameter size.
","[{'version': 'v1', 'created': 'Mon, 22 Jun 2015 02:12:54 GMT'}, {'version': 'v2', 'created': 'Wed, 18 Nov 2015 13:55:44 GMT'}, {'version': 'v3', 'created': 'Thu, 19 Nov 2015 14:23:34 GMT'}, {'version': 'v4', 'created': 'Thu, 7 Jan 2016 08:14:08 GMT'}]",2016-01-08,"[['Meng', 'Fandong', ''], ['Lu', 'Zhengdong', ''], ['Tu', 'Zhaopeng', ''], ['Li', 'Hang', ''], ['Liu', 'Qun', '']]"
2402.05785,Jonathan Thomm,"Jonathan Thomm, Aleksandar Terzic, Geethan Karunaratne, Giacomo
  Camposampiero, Bernhard Sch\""olkopf, Abbas Rahimi","Limits of Transformer Language Models on Learning Algorithmic
  Compositions",,,,,cs.LG cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We analyze the capabilities of Transformer language models on learning
discrete algorithms. To this end, we introduce two new tasks demanding the
composition of several discrete sub-tasks. On both training LLaMA models from
scratch and prompting on GPT-4 and Gemini we measure learning compositions of
learned primitives. We observe that the compositional capabilities of
state-of-the-art Transformer language models are very limited and sample-wise
scale worse than relearning all sub-tasks for a new algorithmic composition. We
also present a theorem in complexity theory, showing that gradient descent on
memorizing feedforward models can be exponentially data inefficient.
","[{'version': 'v1', 'created': 'Thu, 8 Feb 2024 16:23:29 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Feb 2024 07:36:40 GMT'}]",2024-02-14,"[['Thomm', 'Jonathan', ''], ['Terzic', 'Aleksandar', ''], ['Karunaratne', 'Geethan', ''], ['Camposampiero', 'Giacomo', ''], ['Schölkopf', 'Bernhard', ''], ['Rahimi', 'Abbas', '']]"
2312.02337,Bashir Rastegarpanah,"Gyandev Gupta, Bashir Rastegarpanah, Amalendu Iyer, Joshua Rubin,
  Krishnaram Kenthapadi","Measuring Distributional Shifts in Text: The Advantage of Language
  Model-Based Embeddings",,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  An essential part of monitoring machine learning models in production is
measuring input and output data drift. In this paper, we present a system for
measuring distributional shifts in natural language data and highlight and
investigate the potential advantage of using large language models (LLMs) for
this problem. Recent advancements in LLMs and their successful adoption in
different domains indicate their effectiveness in capturing semantic
relationships for solving various natural language processing problems. The
power of LLMs comes largely from the encodings (embeddings) generated in the
hidden layers of the corresponding neural network. First we propose a
clustering-based algorithm for measuring distributional shifts in text data by
exploiting such embeddings. Then we study the effectiveness of our approach
when applied to text embeddings generated by both LLMs and classical embedding
algorithms. Our experiments show that general-purpose LLM-based embeddings
provide a high sensitivity to data drift compared to other embedding methods.
We propose drift sensitivity as an important evaluation metric to consider when
comparing language models. Finally, we present insights and lessons learned
from deploying our framework as part of the Fiddler ML Monitoring platform over
a period of 18 months.
","[{'version': 'v1', 'created': 'Mon, 4 Dec 2023 20:46:48 GMT'}]",2023-12-06,"[['Gupta', 'Gyandev', ''], ['Rastegarpanah', 'Bashir', ''], ['Iyer', 'Amalendu', ''], ['Rubin', 'Joshua', ''], ['Kenthapadi', 'Krishnaram', '']]"
1910.06393,Zachary Kaden,"Zachary Kaden, Teven Le Scao, Raphael Olivier","In-training Matrix Factorization for Parameter-frugal Neural Machine
  Translation",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we propose the use of in-training matrix factorization to
reduce the model size for neural machine translation. Using in-training matrix
factorization, parameter matrices may be decomposed into the products of
smaller matrices, which can compress large machine translation architectures by
vastly reducing the number of learnable parameters. We apply in-training matrix
factorization to different layers of standard neural architectures and show
that in-training factorization is capable of reducing nearly 50% of learnable
parameters without any associated loss in BLEU score. Further, we find that
in-training matrix factorization is especially powerful on embedding layers,
providing a simple and effective method to curtail the number of parameters
with minimal impact on model performance, and, at times, an increase in
performance.
","[{'version': 'v1', 'created': 'Fri, 27 Sep 2019 08:58:55 GMT'}, {'version': 'v2', 'created': 'Mon, 23 Mar 2020 18:17:20 GMT'}]",2020-03-25,"[['Kaden', 'Zachary', ''], ['Scao', 'Teven Le', ''], ['Olivier', 'Raphael', '']]"
2211.14620,Ramon Ferrer-i-Cancho,Sonia Petrini and Ramon Ferrer-i-Cancho,The distribution of syntactic dependency distances,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The syntactic structure of a sentence can be represented as a graph where
vertices are words and edges indicate syntactic dependencies between them. In
this setting, the distance between two syntactically linked words can be
defined as the difference between their positions. Here we want to contribute
to the characterization of the actual distribution of syntactic dependency
distances, and unveil its relationship with short-term memory limitations. We
propose a new double-exponential model in which decay in probability is allowed
to change after a break-point. This transition could mirror the transition from
the processing of words chunks to higher-level structures. We find that a
two-regime model -- where the first regime follows either an exponential or a
power-law decay -- is the most likely one in all 20 languages we considered,
independently of sentence length and annotation style. Moreover, the
break-point is fairly stable across languages and averages values of 4-5 words,
suggesting that the amount of words that can be simultaneously processed
abstracts from the specific language to a high degree. Finally, we give an
account of the relation between the best estimated model and the closeness of
syntactic dependencies, as measured by a recently introduced optimality score.
","[{'version': 'v1', 'created': 'Sat, 26 Nov 2022 17:31:25 GMT'}]",2022-11-29,"[['Petrini', 'Sonia', ''], ['Ferrer-i-Cancho', 'Ramon', '']]"
1801.09893,Hongzhi Zhang,"Hongzhi Zhang, Guandong Xu, Xiao Liang, Tinglei Huang and Kun fu","An Attention-Based Word-Level Interaction Model: Relation Detection for
  Knowledge Base Question Answering",Paper submitted to Neurocomputing at 11.12.2017,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Relation detection plays a crucial role in Knowledge Base Question Answering
(KBQA) because of the high variance of relation expression in the question.
Traditional deep learning methods follow an encoding-comparing paradigm, where
the question and the candidate relation are represented as vectors to compare
their semantic similarity. Max- or average- pooling operation, which compresses
the sequence of words into fixed-dimensional vectors, becomes the bottleneck of
information. In this paper, we propose to learn attention-based word-level
interactions between questions and relations to alleviate the bottleneck issue.
Similar to the traditional models, the question and relation are firstly
represented as sequences of vectors. Then, instead of merging the sequence into
a single vector with pooling operation, soft alignments between words from the
question and the relation are learned. The aligned words are subsequently
compared with the convolutional neural network (CNN) and the comparison results
are merged finally. Through performing the comparison on low-level
representations, the attention-based word-level interaction model (ABWIM)
relieves the information loss issue caused by merging the sequence into a
fixed-dimensional vector before the comparison. The experimental results of
relation detection on both SimpleQuestions and WebQuestions datasets show that
ABWIM achieves state-of-the-art accuracy, demonstrating its effectiveness.
","[{'version': 'v1', 'created': 'Tue, 30 Jan 2018 08:44:19 GMT'}]",2018-01-31,"[['Zhang', 'Hongzhi', ''], ['Xu', 'Guandong', ''], ['Liang', 'Xiao', ''], ['Huang', 'Tinglei', ''], ['fu', 'Kun', '']]"
2009.02035,Brooke Stephenson,"Brooke Stephenson, Laurent Besacier, Laurent Girin, Thomas Hueber","What the Future Brings: Investigating the Impact of Lookahead for
  Incremental Neural TTS","5 pages, 4 figures",,,,eess.AS cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In incremental text to speech synthesis (iTTS), the synthesizer produces an
audio output before it has access to the entire input sentence. In this paper,
we study the behavior of a neural sequence-to-sequence TTS system when used in
an incremental mode, i.e. when generating speech output for token n, the system
has access to n + k tokens from the text sequence. We first analyze the impact
of this incremental policy on the evolution of the encoder representations of
token n for different values of k (the lookahead parameter). The results show
that, on average, tokens travel 88% of the way to their full context
representation with a one-word lookahead and 94% after 2 words. We then
investigate which text features are the most influential on the evolution
towards the final representation using a random forest analysis. The results
show that the most salient factors are related to token length. We finally
evaluate the effects of lookahead k at the decoder level, using a MUSHRA
listening test. This test shows results that contrast with the above high
figures: speech synthesis quality obtained with 2 word-lookahead is
significantly lower than the one obtained with the full sentence.
","[{'version': 'v1', 'created': 'Fri, 4 Sep 2020 07:30:57 GMT'}]",2020-09-16,"[['Stephenson', 'Brooke', ''], ['Besacier', 'Laurent', ''], ['Girin', 'Laurent', ''], ['Hueber', 'Thomas', '']]"
2112.01810,Daniel Stancl,"Mat\v{e}j Koci\'an, Jakub N\'aplava, Daniel \v{S}tancl, Vladim\'ir
  Kadlec","Siamese BERT-based Model for Web Search Relevance Ranking Evaluated on a
  New Czech Dataset","Accepted at the Thirty-Fourth Annual Conference on Innovative
  Applications of Artificial Intelligence (IAAI-22). IAAI Innovative
  Application Award. 9 pages, 3 figures, 8 tables",,,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Web search engines focus on serving highly relevant results within hundreds
of milliseconds. Pre-trained language transformer models such as BERT are
therefore hard to use in this scenario due to their high computational demands.
We present our real-time approach to the document ranking problem leveraging a
BERT-based siamese architecture. The model is already deployed in a commercial
search engine and it improves production performance by more than 3%. For
further research and evaluation, we release DaReCzech, a unique data set of 1.6
million Czech user query-document pairs with manually assigned relevance
levels. We also release Small-E-Czech, an Electra-small language model
pre-trained on a large Czech corpus. We believe this data will support
endeavours both of search relevance and multilingual-focused research
communities.
","[{'version': 'v1', 'created': 'Fri, 3 Dec 2021 09:45:18 GMT'}]",2021-12-06,"[['Kocián', 'Matěj', ''], ['Náplava', 'Jakub', ''], ['Štancl', 'Daniel', ''], ['Kadlec', 'Vladimír', '']]"
1812.09836,Cong Duy Vu Hoang Mr,"Cong Duy Vu Hoang, Ioan Calapodescu and Marc Dymetman","Moment Matching Training for Neural Machine Translation: A Preliminary
  Study",A preliminary study,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In previous works, neural sequence models have been shown to improve
significantly if external prior knowledge can be provided, for instance by
allowing the model to access the embeddings of explicit features during both
training and inference. In this work, we propose a different point of view on
how to incorporate prior knowledge in a principled way, using a moment matching
framework. In this approach, the standard local cross-entropy training of the
sequential model is combined with a moment matching training mode that
encourages the equality of the expectations of certain predefined features
between the model distribution and the empirical distribution. In particular,
we show how to derive unbiased estimates of some stochastic gradients that are
central to the training, and compare our framework with a formally related one:
policy gradient training in reinforcement learning, pointing out some important
differences in terms of the kinds of prior assumptions in both approaches. Our
initial results are promising, showing the effectiveness of our proposed
framework.
","[{'version': 'v1', 'created': 'Mon, 24 Dec 2018 05:29:19 GMT'}, {'version': 'v2', 'created': 'Fri, 28 Dec 2018 01:01:56 GMT'}]",2018-12-31,"[['Hoang', 'Cong Duy Vu', ''], ['Calapodescu', 'Ioan', ''], ['Dymetman', 'Marc', '']]"
1410.0210,Mateusz Malinowski,Mateusz Malinowski and Mario Fritz,"A Multi-World Approach to Question Answering about Real-World Scenes
  based on Uncertain Input",Published in NIPS 2014,,,,cs.AI cs.CL cs.CV cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a method for automatically answering questions about images by
bringing together recent advances from natural language processing and computer
vision. We combine discrete reasoning with uncertain predictions by a
multi-world approach that represents uncertainty about the perceived world in a
bayesian framework. Our approach can handle human questions of high complexity
about realistic scenes and replies with range of answer like counts, object
classes, instances and lists of them. The system is directly trained from
question-answer pairs. We establish a first benchmark for this task that can be
seen as a modern attempt at a visual turing test.
","[{'version': 'v1', 'created': 'Wed, 1 Oct 2014 12:59:16 GMT'}, {'version': 'v2', 'created': 'Wed, 29 Oct 2014 16:29:44 GMT'}, {'version': 'v3', 'created': 'Tue, 11 Nov 2014 12:13:18 GMT'}, {'version': 'v4', 'created': 'Tue, 5 May 2015 17:39:10 GMT'}]",2015-05-06,"[['Malinowski', 'Mateusz', ''], ['Fritz', 'Mario', '']]"
1505.01072,Arun Maiya,"Arun S. Maiya, Dale Visser, Andrew Wan",Mining Measured Information from Text,"4 pages; 38th International ACM SIGIR Conference on Research and
  Development in Information Retrieval (SIGIR '15)",,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present an approach to extract measured information from text (e.g., a
1370 degrees C melting point, a BMI greater than 29.9 kg/m^2 ). Such
extractions are critically important across a wide range of domains -
especially those involving search and exploration of scientific and technical
documents. We first propose a rule-based entity extractor to mine measured
quantities (i.e., a numeric value paired with a measurement unit), which
supports a vast and comprehensive set of both common and obscure measurement
units. Our method is highly robust and can correctly recover valid measured
quantities even when significant errors are introduced through the process of
converting document formats like PDF to plain text. Next, we describe an
approach to extracting the properties being measured (e.g., the property ""pixel
pitch"" in the phrase ""a pixel pitch as high as 352 {\mu}m""). Finally, we
present MQSearch: the realization of a search engine with full support for
measured information.
","[{'version': 'v1', 'created': 'Tue, 5 May 2015 16:36:27 GMT'}]",2015-05-06,"[['Maiya', 'Arun S.', ''], ['Visser', 'Dale', ''], ['Wan', 'Andrew', '']]"
2311.08105,Arthur Douillard,"Arthur Douillard, Qixuan Feng, Andrei A. Rusu, Rachita Chhaparia, Yani
  Donchev, Adhiguna Kuncoro, Marc'Aurelio Ranzato, Arthur Szlam, Jiajun Shen",DiLoCo: Distributed Low-Communication Training of Language Models,,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLM) have become a critical component in many
applications of machine learning. However, standard approaches to training LLM
require a large number of tightly interconnected accelerators, with devices
exchanging gradients and other intermediate states at each optimization step.
While it is difficult to build and maintain a single computing cluster hosting
many accelerators, it might be easier to find several computing clusters each
hosting a smaller number of devices. In this work, we propose a distributed
optimization algorithm, Distributed Low-Communication (DiLoCo), that enables
training of language models on islands of devices that are poorly connected.
The approach is a variant of federated averaging, where the number of inner
steps is large, the inner optimizer is AdamW, and the outer optimizer is
Nesterov momentum. On the widely used C4 dataset, we show that DiLoCo on 8
workers performs as well as fully synchronous optimization while communicating
500 times less. DiLoCo exhibits great robustness to the data distribution of
each worker. It is also robust to resources becoming unavailable over time, and
vice versa, it can seamlessly leverage resources that become available during
training.
","[{'version': 'v1', 'created': 'Tue, 14 Nov 2023 12:05:45 GMT'}, {'version': 'v2', 'created': 'Sat, 2 Dec 2023 14:10:14 GMT'}]",2023-12-05,"[['Douillard', 'Arthur', ''], ['Feng', 'Qixuan', ''], ['Rusu', 'Andrei A.', ''], ['Chhaparia', 'Rachita', ''], ['Donchev', 'Yani', ''], ['Kuncoro', 'Adhiguna', ''], ['Ranzato', ""Marc'Aurelio"", ''], ['Szlam', 'Arthur', ''], ['Shen', 'Jiajun', '']]"
2403.02715,Duc Nguyen,"Sang T. Truong, Duc Q. Nguyen, Toan Nguyen, Dong D. Le, Nhi N. Truong,
  Tho Quan, Sanmi Koyejo","Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of
  Vietnamese Large Language Models",33 pages,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Recent advancements in large language models (LLMs) have underscored their
importance in the evolution of artificial intelligence. However, despite
extensive pretraining on multilingual datasets, available open-sourced LLMs
exhibit limited effectiveness in processing Vietnamese. The challenge is
exacerbated by the absence of systematic benchmark datasets and metrics
tailored for Vietnamese LLM evaluation. To mitigate these issues, we have
finetuned LLMs specifically for Vietnamese and developed a comprehensive
evaluation framework encompassing 10 common tasks and 31 metrics. Our
evaluation results reveal that the fine-tuned LLMs exhibit enhanced
comprehension and generative capabilities in Vietnamese. Moreover, our analysis
indicates that models with more parameters can introduce more biases and
uncalibrated outputs and the key factor influencing LLM performance is the
quality of the training or fine-tuning datasets. These insights underscore the
significance of meticulous fine-tuning with high-quality datasets in enhancing
LLM performance.
","[{'version': 'v1', 'created': 'Tue, 5 Mar 2024 07:13:28 GMT'}]",2024-03-06,"[['Truong', 'Sang T.', ''], ['Nguyen', 'Duc Q.', ''], ['Nguyen', 'Toan', ''], ['Le', 'Dong D.', ''], ['Truong', 'Nhi N.', ''], ['Quan', 'Tho', ''], ['Koyejo', 'Sanmi', '']]"
2207.01718,Brooke Stephenson,"Brooke Stephenson, Laurent Besacier, Laurent Girin, Thomas Hueber","BERT, can HE predict contrastive focus? Predicting and controlling
  prominence in neural TTS using a language model",5 pages,,,,cs.CL eess.AS,http://creativecommons.org/licenses/by/4.0/,"  Several recent studies have tested the use of transformer language model
representations to infer prosodic features for text-to-speech synthesis (TTS).
While these studies have explored prosody in general, in this work, we look
specifically at the prediction of contrastive focus on personal pronouns. This
is a particularly challenging task as it often requires semantic, discursive
and/or pragmatic knowledge to predict correctly. We collect a corpus of
utterances containing contrastive focus and we evaluate the accuracy of a BERT
model, finetuned to predict quantized acoustic prominence features, on these
samples. We also investigate how past utterances can provide relevant
information for this prediction. Furthermore, we evaluate the controllability
of pronoun prominence in a TTS model conditioned on acoustic prominence
features.
","[{'version': 'v1', 'created': 'Mon, 4 Jul 2022 20:43:41 GMT'}]",2022-07-06,"[['Stephenson', 'Brooke', ''], ['Besacier', 'Laurent', ''], ['Girin', 'Laurent', ''], ['Hueber', 'Thomas', '']]"
2210.10817,Darcey Riley,"Darcey Riley, David Chiang","A Continuum of Generation Tasks for Investigating Length Bias and
  Degenerate Repetition",Accepted for publication at BlackboxNLP 2022,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language models suffer from various degenerate behaviors. These differ
between tasks: machine translation (MT) exhibits length bias, while tasks like
story generation exhibit excessive repetition. Recent work has attributed the
difference to task constrainedness, but evidence for this claim has always
involved many confounding variables. To study this question directly, we
introduce a new experimental framework that allows us to smoothly vary task
constrainedness, from MT at one end to fully open-ended generation at the
other, while keeping all other aspects fixed. We find that: (1) repetition
decreases smoothly with constrainedness, explaining the difference in
repetition across tasks; (2) length bias surprisingly also decreases with
constrainedness, suggesting some other cause for the difference in length bias;
(3) across the board, these problems affect the mode, not the whole
distribution; (4) the differences cannot be attributed to a change in the
entropy of the distribution, since another method of changing the entropy,
label smoothing, does not produce the same effect.
","[{'version': 'v1', 'created': 'Wed, 19 Oct 2022 18:09:51 GMT'}]",2022-10-21,"[['Riley', 'Darcey', ''], ['Chiang', 'David', '']]"
2402.07817,Anna Mosolova,"Anna Mosolova, Marie Candito, Carlos Ramisch","Injecting Wiktionary to improve token-level contextual representations
  using contrastive learning",Accepted to EACL 2024 (Main),,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  While static word embeddings are blind to context, for lexical semantics
tasks context is rather too present in contextual word embeddings, vectors of
same-meaning occurrences being too different (Ethayarajh, 2019). Fine-tuning
pre-trained language models (PLMs) using contrastive learning was proposed,
leveraging automatically self-augmented examples (Liu et al., 2021b). In this
paper, we investigate how to inject a lexicon as an alternative source of
supervision, using the English Wiktionary. We also test how dimensionality
reduction impacts the resulting contextual word embeddings. We evaluate our
approach on the Word-In-Context (WiC) task, in the unsupervised setting (not
using the training set). We achieve new SoTA result on the original WiC test
set. We also propose two new WiC test sets for which we show that our
fine-tuning method achieves substantial improvements. We also observe
improvements, although modest, for the semantic frame induction task. Although
we experimented on English to allow comparison with related work, our method is
adaptable to the many languages for which large Wiktionaries exist.
","[{'version': 'v1', 'created': 'Mon, 12 Feb 2024 17:22:42 GMT'}]",2024-02-13,"[['Mosolova', 'Anna', ''], ['Candito', 'Marie', ''], ['Ramisch', 'Carlos', '']]"
1808.03370,Jiahao Chen,Jeff Bezanson and Jake Bolewski and Jiahao Chen,Fast Flexible Function Dispatch in Julia,"15 pages, repository at https://github.com/jiahao/julia-type-system",,,,cs.PL cs.CL cs.MS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Technical computing is a challenging application area for programming
languages to address. This is evinced by the unusually large number of
specialized languages in the area (e.g. MATLAB, R), and the complexity of
common software stacks, often involving multiple languages and custom code
generators. We believe this is ultimately due to key characteristics of the
domain: highly complex operators, a need for extensive code specialization for
performance, and a desire for permissive high-level programming styles allowing
productive experimentation. The Julia language attempts to provide a more
effective structure for this kind of programming by allowing programmers to
express complex polymorphic behaviors using dynamic multiple dispatch over
parametric types. The forms of extension and reuse permitted by this paradigm
have proven valuable for technical computing. We report on how this approach
has allowed domain experts to express useful abstractions while simultaneously
providing a natural path to better performance for high-level technical code.
","[{'version': 'v1', 'created': 'Thu, 9 Aug 2018 23:09:16 GMT'}]",2018-08-13,"[['Bezanson', 'Jeff', ''], ['Bolewski', 'Jake', ''], ['Chen', 'Jiahao', '']]"
2311.10757,Andrei Nesterov,"Andrei Nesterov (1), Laura Hollink (1), Jacco van Ossenbruggen (2)
  ((1) Centrum Wiskunde & Informatica, (2) VU University Amsterdam)","How Contentious Terms About People and Cultures are Used in Linked Open
  Data",,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  Web resources in linked open data (LOD) are comprehensible to humans through
literal textual values attached to them, such as labels, notes, or comments.
Word choices in literals may not always be neutral. When outdated and
culturally stereotyping terminology is used in literals, they may appear as
offensive to users in interfaces and propagate stereotypes to algorithms
trained on them. We study how frequently and in which literals contentious
terms about people and cultures occur in LOD and whether there are attempts to
mark the usage of such terms. For our analysis, we reuse English and Dutch
terms from a knowledge graph that provides opinions of experts from the
cultural heritage domain about terms' contentiousness. We inspect occurrences
of these terms in four widely used datasets: Wikidata, The Getty Art &
Architecture Thesaurus, Princeton WordNet, and Open Dutch WordNet. Some terms
are ambiguous and contentious only in particular senses. Applying word sense
disambiguation, we generate a set of literals relevant to our analysis. We
found that outdated, derogatory, stereotyping terms frequently appear in
descriptive and labelling literals, such as preferred labels that are usually
displayed in interfaces and used for indexing. In some cases, LOD contributors
mark contentious terms with words and phrases in literals (implicit markers) or
properties linked to resources (explicit markers). However, such marking is
rare and non-consistent in all datasets. Our quantitative and qualitative
insights could be helpful in developing more systematic approaches to address
the propagation of stereotypes via LOD.
","[{'version': 'v1', 'created': 'Mon, 13 Nov 2023 18:25:20 GMT'}]",2023-11-21,"[['Nesterov', 'Andrei', '', 'Centrum Wiskunde & Informatica'], ['Hollink', 'Laura', '', 'Centrum Wiskunde & Informatica'], ['van Ossenbruggen', 'Jacco', '', 'VU University Amsterdam']]"
2206.00648,Yanzhao Zou,"Yanzhao Zou, Dorien Herremans","PreBit -- A multimodal model with Twitter FinBERT embeddings for extreme
  price movement prediction of Bitcoin","21 pages, submitted preprint to Elsevier Expert Systems with
  Applications",,,,q-fin.ST cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Bitcoin, with its ever-growing popularity, has demonstrated extreme price
volatility since its origin. This volatility, together with its decentralised
nature, make Bitcoin highly subjective to speculative trading as compared to
more traditional assets. In this paper, we propose a multimodal model for
predicting extreme price fluctuations. This model takes as input a variety of
correlated assets, technical indicators, as well as Twitter content. In an
in-depth study, we explore whether social media discussions from the general
public on Bitcoin have predictive power for extreme price movements. A dataset
of 5,000 tweets per day containing the keyword `Bitcoin' was collected from
2015 to 2021. This dataset, called PreBit, is made available online. In our
hybrid model, we use sentence-level FinBERT embeddings, pretrained on financial
lexicons, so as to capture the full contents of the tweets and feed it to the
model in an understandable way. By combining these embeddings with a
Convolutional Neural Network, we built a predictive model for significant
market movements. The final multimodal ensemble model includes this NLP model
together with a model based on candlestick data, technical indicators and
correlated asset prices. In an ablation study, we explore the contribution of
the individual modalities. Finally, we propose and backtest a trading strategy
based on the predictions of our models with varying prediction threshold and
show that it can used to build a profitable trading strategy with a reduced
risk over a `hold' or moving average strategy.
","[{'version': 'v1', 'created': 'Mon, 30 May 2022 19:25:12 GMT'}, {'version': 'v2', 'created': 'Sat, 21 Oct 2023 10:45:31 GMT'}]",2023-10-24,"[['Zou', 'Yanzhao', ''], ['Herremans', 'Dorien', '']]"
1510.08480,Umashanthi Pavalanathan,Umashanthi Pavalanathan and Jacob Eisenstein,Emoticons vs. Emojis on Twitter: A Causal Inference Approach,In review at AAAI Spring Symposium 2016,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Online writing lacks the non-verbal cues present in face-to-face
communication, which provide additional contextual information about the
utterance, such as the speaker's intention or affective state. To fill this
void, a number of orthographic features, such as emoticons, expressive
lengthening, and non-standard punctuation, have become popular in social media
services including Twitter and Instagram. Recently, emojis have been introduced
to social media, and are increasingly popular. This raises the question of
whether these predefined pictographic characters will come to replace earlier
orthographic methods of paralinguistic communication. In this abstract, we
attempt to shed light on this question, using a matching approach from causal
inference to test whether the adoption of emojis causes individual users to
employ fewer emoticons in their text on Twitter.
","[{'version': 'v1', 'created': 'Wed, 28 Oct 2015 20:41:30 GMT'}]",2015-10-30,"[['Pavalanathan', 'Umashanthi', ''], ['Eisenstein', 'Jacob', '']]"
2208.05623,Kexin Yang,"Kexin Yang, Dayiheng Liu, Wenqiang Lei, Baosong Yang, Qian Qu,
  Jiancheng Lv","Draft, Command, and Edit: Controllable Text Editing in E-Commerce",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Product description generation is a challenging and under-explored task. Most
such work takes a set of product attributes as inputs then generates a
description from scratch in a single pass. However, this widespread paradigm
might be limited when facing the dynamic wishes of users on constraining the
description, such as deleting or adding the content of a user-specified
attribute based on the previous version. To address this challenge, we explore
a new draft-command-edit manner in description generation, leading to the
proposed new task-controllable text editing in E-commerce. More specifically,
we allow systems to receive a command (deleting or adding) from the user and
then generate a description by flexibly modifying the content based on the
previous version. It is easier and more practical to meet the new needs by
modifying previous versions than generating from scratch. Furthermore, we
design a data augmentation method to remedy the low resource challenge in this
task, which contains a model-based and a rule-based strategy to imitate the
edit by humans. To accompany this new task, we present a human-written
draft-command-edit dataset called E-cEdits and a new metric ""Attribute Edit"".
Our experimental results show that using the new data augmentation method
outperforms baselines to a greater extent in both automatic and human
evaluations.
","[{'version': 'v1', 'created': 'Thu, 11 Aug 2022 03:48:08 GMT'}]",2022-08-12,"[['Yang', 'Kexin', ''], ['Liu', 'Dayiheng', ''], ['Lei', 'Wenqiang', ''], ['Yang', 'Baosong', ''], ['Qu', 'Qian', ''], ['Lv', 'Jiancheng', '']]"
2305.14976,Md Tawkat Islam Khondaker,"Md Tawkat Islam Khondaker, Abdul Waheed, El Moatez Billah Nagoudi,
  Muhammad Abdul-Mageed",GPTAraEval: A Comprehensive Evaluation of ChatGPT on Arabic NLP,EMNLP 2023 Main Conference,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  ChatGPT's emergence heralds a transformative phase in NLP, particularly
demonstrated through its excellent performance on many English benchmarks.
However, the model's efficacy across diverse linguistic contexts remains
largely uncharted territory. This work aims to bridge this knowledge gap, with
a primary focus on assessing ChatGPT's capabilities on Arabic languages and
dialectal varieties. Our comprehensive study conducts a large-scale automated
and human evaluation of ChatGPT, encompassing 44 distinct language
understanding and generation tasks on over 60 different datasets. To our
knowledge, this marks the first extensive performance analysis of ChatGPT's
deployment in Arabic NLP. Our findings indicate that, despite its remarkable
performance in English, ChatGPT is consistently surpassed by smaller models
that have undergone finetuning on Arabic. We further undertake a meticulous
comparison of ChatGPT and GPT-4's Modern Standard Arabic (MSA) and Dialectal
Arabic (DA), unveiling the relative shortcomings of both models in handling
Arabic dialects compared to MSA. Although we further explore and confirm the
utility of employing GPT-4 as a potential alternative for human evaluation, our
work adds to a growing body of research underscoring the limitations of
ChatGPT.
","[{'version': 'v1', 'created': 'Wed, 24 May 2023 10:12:39 GMT'}, {'version': 'v2', 'created': 'Sat, 21 Oct 2023 05:16:24 GMT'}]",2023-10-24,"[['Khondaker', 'Md Tawkat Islam', ''], ['Waheed', 'Abdul', ''], ['Nagoudi', 'El Moatez Billah', ''], ['Abdul-Mageed', 'Muhammad', '']]"
2305.07389,Emma O'Neill,Emma O'Neill and Julie Carson-Berndsen,"Investigating the Sensitivity of Automatic Speech Recognition Systems to
  Phonetic Variation in L2 Englishes",,,,,cs.CL cs.SD eess.AS,http://creativecommons.org/licenses/by/4.0/,"  Automatic Speech Recognition (ASR) systems exhibit the best performance on
speech that is similar to that on which it was trained. As such,
underrepresented varieties including regional dialects, minority-speakers, and
low-resource languages, see much higher word error rates (WERs) than those
varieties seen as 'prestigious', 'mainstream', or 'standard'. This can act as a
barrier to incorporating ASR technology into the annotation process for
large-scale linguistic research since the manual correction of the erroneous
automated transcripts can be just as time and resource consuming as manual
transcriptions. A deeper understanding of the behaviour of an ASR system is
thus beneficial from a speech technology standpoint, in terms of improving ASR
accuracy, and from an annotation standpoint, where knowing the likely errors
made by an ASR system can aid in this manual correction. This work demonstrates
a method of probing an ASR system to discover how it handles phonetic variation
across a number of L2 Englishes. Specifically, how particular phonetic
realisations which were rare or absent in the system's training data can lead
to phoneme level misrecognitions and contribute to higher WERs. It is
demonstrated that the behaviour of the ASR is systematic and consistent across
speakers with similar spoken varieties (in this case the same L1) and phoneme
substitution errors are typically in agreement with human annotators. By
identifying problematic productions specific weaknesses can be addressed by
sourcing such realisations for training and fine-tuning thus making the system
more robust to pronunciation variation.
","[{'version': 'v1', 'created': 'Fri, 12 May 2023 11:29:13 GMT'}]",2023-05-15,"[[""O'Neill"", 'Emma', ''], ['Carson-Berndsen', 'Julie', '']]"
2310.13231,Dawei Li,"Dawei Li, Hengyuan Zhang, Yanran Li, Shiping Yang","Multi-level Contrastive Learning for Script-based Character
  Understanding","Accepted by EMNLP 2023 main conference; Camera-ready version will be
  updated soon",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In this work, we tackle the scenario of understanding characters in scripts,
which aims to learn the characters' personalities and identities from their
utterances. We begin by analyzing several challenges in this scenario, and then
propose a multi-level contrastive learning framework to capture characters'
global information in a fine-grained manner. To validate the proposed
framework, we conduct extensive experiments on three character understanding
sub-tasks by comparing with strong pre-trained language models, including
SpanBERT, Longformer, BigBird and ChatGPT-3.5. Experimental results demonstrate
that our method improves the performances by a considerable margin. Through
further in-depth analysis, we show the effectiveness of our method in
addressing the challenges and provide more hints on the scenario of character
understanding. We will open-source our work on github at
https://github.com/David-Li0406/Script-based-Character-Understanding.
","[{'version': 'v1', 'created': 'Fri, 20 Oct 2023 02:40:52 GMT'}]",2023-10-23,"[['Li', 'Dawei', ''], ['Zhang', 'Hengyuan', ''], ['Li', 'Yanran', ''], ['Yang', 'Shiping', '']]"
2311.09832,Liang Chen,"Liang Chen, Yatao Bian, Yang Deng, Deng Cai, Shuaiyi Li, Peilin Zhao,
  Kam-fai Wong",WatME: Towards Lossless Watermarking Through Lexical Redundancy,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Text watermarking has emerged as an important technique for detecting
machine-generated text. However, existing methods generally use arbitrary
vocabulary partitioning during decoding, which results in the absence of
appropriate words during the response generation and disrupts the language
model's expressiveness, thus severely degrading the quality of text response.
To address these issues, we introduce a novel approach, Watermarking with
Mutual Exclusion (WatME). Specifically, by leveraging linguistic prior
knowledge of inherent lexical redundancy, WatME can dynamically optimize the
use of available vocabulary during the decoding process of language models. It
employs a mutually exclusive rule to manage this redundancy, avoiding
situations where appropriate words are unavailable and maintaining the
expressive power of large language models (LLMs). We present theoretical
analysis and empirical evidence demonstrating that WatME substantially
preserves the text generation ability of LLMs while maintaining watermark
detectability. Specifically, we investigate watermarking's impact on the
emergent abilities of LLMs, including knowledge recall and logical reasoning.
Our comprehensive experiments confirm that WatME consistently outperforms
existing methods in retaining these crucial capabilities of LLMs. Our code will
be released to facilitate future research.
","[{'version': 'v1', 'created': 'Thu, 16 Nov 2023 11:58:31 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Feb 2024 14:58:53 GMT'}]",2024-02-19,"[['Chen', 'Liang', ''], ['Bian', 'Yatao', ''], ['Deng', 'Yang', ''], ['Cai', 'Deng', ''], ['Li', 'Shuaiyi', ''], ['Zhao', 'Peilin', ''], ['Wong', 'Kam-fai', '']]"
1210.4854,Hannaneh Hajishirzi,"Hannaneh Hajishirzi, Mohammad Rastegari, Ali Farhadi, Jessica K.
  Hodgins",Semantic Understanding of Professional Soccer Commentaries,"Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty
  in Artificial Intelligence (UAI2012)",,,UAI-P-2012-PG-326-335,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents a novel approach to the problem of semantic parsing via
learning the correspondences between complex sentences and rich sets of events.
Our main intuition is that correct correspondences tend to occur more
frequently. Our model benefits from a discriminative notion of similarity to
learn the correspondence between sentence and an event and a ranking machinery
that scores the popularity of each correspondence. Our method can discover a
group of events (called macro-events) that best describes a sentence. We
evaluate our method on our novel dataset of professional soccer commentaries.
The empirical results show that our method significantly outperforms the
state-of-theart.
","[{'version': 'v1', 'created': 'Tue, 16 Oct 2012 17:37:21 GMT'}]",2012-10-19,"[['Hajishirzi', 'Hannaneh', ''], ['Rastegari', 'Mohammad', ''], ['Farhadi', 'Ali', ''], ['Hodgins', 'Jessica K.', '']]"
2310.02567,Oscar Ma\~nas,"Oscar Ma\~nas, Benno Krojer, Aishwarya Agrawal",Improving Automatic VQA Evaluation Using Large Language Models,Accepted at AAAI 2024 (main track),,,,cs.CV cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  8 years after the visual question answering (VQA) task was proposed, accuracy
remains the primary metric for automatic evaluation. VQA Accuracy has been
effective so far in the IID evaluation setting. However, our community is
undergoing a shift towards open-ended generative models and OOD evaluation. In
this new paradigm, the existing VQA Accuracy metric is overly stringent and
underestimates the performance of VQA systems. Thus, there is a need to develop
more robust automatic VQA metrics that serve as a proxy for human judgment. In
this work, we propose to leverage the in-context learning capabilities of
instruction-tuned large language models (LLMs) to build a better VQA metric. We
formulate VQA evaluation as an answer-rating task where the LLM is instructed
to score the accuracy of a candidate answer given a set of reference answers.
We demonstrate the proposed metric better correlates with human judgment
compared to existing metrics across several VQA models and benchmarks. We hope
wide adoption of our metric will contribute to better estimating the research
progress on the VQA task. We plan to release the evaluation code and collected
human judgments.
","[{'version': 'v1', 'created': 'Wed, 4 Oct 2023 03:59:57 GMT'}, {'version': 'v2', 'created': 'Wed, 10 Jan 2024 17:00:05 GMT'}]",2024-01-11,"[['Mañas', 'Oscar', ''], ['Krojer', 'Benno', ''], ['Agrawal', 'Aishwarya', '']]"
2312.01509,Vithya Yogarajan,"Vithya Yogarajan, Gillian Dobbie, Te Taka Keegan, Rostam J. Neuwirth","Tackling Bias in Pre-trained Language Models: Current Trends and
  Under-represented Societies","38 pages, 5 figures, 11 tables. arXiv admin note: text overlap with
  arXiv:2309.00770 by other authors",,,,cs.CY cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The benefits and capabilities of pre-trained language models (LLMs) in
current and future innovations are vital to any society. However, introducing
and using LLMs comes with biases and discrimination, resulting in concerns
about equality, diversity and fairness, and must be addressed. While
understanding and acknowledging bias in LLMs and developing mitigation
strategies are crucial, the generalised assumptions towards societal needs can
result in disadvantages towards under-represented societies and indigenous
populations. Furthermore, the ongoing changes to actual and proposed amendments
to regulations and laws worldwide also impact research capabilities in tackling
the bias problem. This research presents a comprehensive survey synthesising
the current trends and limitations in techniques used for identifying and
mitigating bias in LLMs, where the overview of methods for tackling bias are
grouped into metrics, benchmark datasets, and mitigation strategies. The
importance and novelty of this survey are that it explores the perspective of
under-represented societies. We argue that current practices tackling the bias
problem cannot simply be 'plugged in' to address the needs of under-represented
societies. We use examples from New Zealand to present requirements for
adopting existing techniques to under-represented societies.
","[{'version': 'v1', 'created': 'Sun, 3 Dec 2023 21:25:10 GMT'}]",2023-12-05,"[['Yogarajan', 'Vithya', ''], ['Dobbie', 'Gillian', ''], ['Keegan', 'Te Taka', ''], ['Neuwirth', 'Rostam J.', '']]"
2109.06050,Momchil Hardalov,"Momchil Hardalov, Arnav Arora, Preslav Nakov, Isabelle Augenstein","Few-Shot Cross-Lingual Stance Detection with Sentiment-Based
  Pre-Training",Accepted to AAAI 2022 (Preprint version),,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The goal of stance detection is to determine the viewpoint expressed in a
piece of text towards a target. These viewpoints or contexts are often
expressed in many different languages depending on the user and the platform,
which can be a local news outlet, a social media platform, a news forum, etc.
Most research in stance detection, however, has been limited to working with a
single language and on a few limited targets, with little work on cross-lingual
stance detection. Moreover, non-English sources of labelled data are often
scarce and present additional challenges. Recently, large multilingual language
models have substantially improved the performance on many non-English tasks,
especially such with limited numbers of examples. This highlights the
importance of model pre-training and its ability to learn from few examples. In
this paper, we present the most comprehensive study of cross-lingual stance
detection to date: we experiment with 15 diverse datasets in 12 languages from
6 language families, and with 6 low-resource evaluation settings each. For our
experiments, we build on pattern-exploiting training, proposing the addition of
a novel label encoder to simplify the verbalisation procedure. We further
propose sentiment-based generation of stance data for pre-training, which shows
sizeable improvement of more than 6% F1 absolute in low-shot settings compared
to several strong baselines.
","[{'version': 'v1', 'created': 'Mon, 13 Sep 2021 15:20:06 GMT'}, {'version': 'v2', 'created': 'Tue, 21 Dec 2021 09:03:27 GMT'}]",2021-12-22,"[['Hardalov', 'Momchil', ''], ['Arora', 'Arnav', ''], ['Nakov', 'Preslav', ''], ['Augenstein', 'Isabelle', '']]"
2210.12694,Sungjin Park,"Sungjin Park, Seungwoo Ryu, Edward Choi",Do Language Models Understand Measurements?,Findings of EMNLP 2022,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Recent success of pre-trained language models (PLMs) has stimulated interest
in their ability to understand and work with numbers. Yet, the numerical
reasoning over measurements has not been formally studied despite their
importance. In this study, we show that PLMs lack the capability required for
reasoning over measurements. Furthermore, we find that a language model trained
on a measurement-rich corpus shows better performance on understanding
measurements. We propose a simple embedding strategy to better distinguish
between numbers and units, which leads to a significant improvement in the
probing tasks.
","[{'version': 'v1', 'created': 'Sun, 23 Oct 2022 10:52:52 GMT'}]",2022-10-25,"[['Park', 'Sungjin', ''], ['Ryu', 'Seungwoo', ''], ['Choi', 'Edward', '']]"
2306.03203,Hantian Ding,"Hantian Ding, Varun Kumar, Yuchen Tian, Zijian Wang, Rob Kwiatkowski,
  Xiaopeng Li, Murali Krishna Ramanathan, Baishakhi Ray, Parminder Bhatia,
  Sudipta Sengupta, Dan Roth, Bing Xiang",A Static Evaluation of Code Completion by Large Language Models,Accepted by ACL 2023 industry track,,,,cs.CL cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Large language models trained on code have shown great potential to increase
productivity of software developers. Several execution-based benchmarks have
been proposed to evaluate functional correctness of model-generated code on
simple programming problems. Nevertheless, it is expensive to perform the same
evaluation on complex real-world projects considering the execution cost. On
the contrary, static analysis tools such as linters, which can detect errors
without running the program, haven't been well explored for evaluating code
generation models. In this work, we propose a static evaluation framework to
quantify static errors in Python code completions, by leveraging Abstract
Syntax Trees. Compared with execution-based evaluation, our method is not only
more efficient, but also applicable to code in the wild. For experiments, we
collect code context from open source repos to generate one million function
bodies using public models. Our static analysis reveals that Undefined Name and
Unused Variable are the most common errors among others made by language
models. Through extensive studies, we also show the impact of sampling
temperature, model size, and context on static errors in code completions.
","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 19:23:34 GMT'}]",2023-06-07,"[['Ding', 'Hantian', ''], ['Kumar', 'Varun', ''], ['Tian', 'Yuchen', ''], ['Wang', 'Zijian', ''], ['Kwiatkowski', 'Rob', ''], ['Li', 'Xiaopeng', ''], ['Ramanathan', 'Murali Krishna', ''], ['Ray', 'Baishakhi', ''], ['Bhatia', 'Parminder', ''], ['Sengupta', 'Sudipta', ''], ['Roth', 'Dan', ''], ['Xiang', 'Bing', '']]"
2205.03966,Parsa Kavehzadeh,"Enamul Hoque, Parsa Kavehzadeh and Ahmed Masry",Chart Question Answering: State of the Art and Future Directions,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Information visualizations such as bar charts and line charts are very common
for analyzing data and discovering critical insights. Often people analyze
charts to answer questions that they have in mind. Answering such questions can
be challenging as they often require a significant amount of perceptual and
cognitive effort. Chart Question Answering (CQA) systems typically take a chart
and a natural language question as input and automatically generate the answer
to facilitate visual data analysis. Over the last few years, there has been a
growing body of literature on the task of CQA. In this survey, we
systematically review the current state-of-the-art research focusing on the
problem of chart question answering. We provide a taxonomy by identifying
several important dimensions of the problem domain including possible inputs
and outputs of the task and discuss the advantages and limitations of proposed
solutions. We then summarize various evaluation techniques used in the surveyed
papers. Finally, we outline the open challenges and future research
opportunities related to chart question answering.
","[{'version': 'v1', 'created': 'Sun, 8 May 2022 22:54:28 GMT'}, {'version': 'v2', 'created': 'Sat, 21 May 2022 22:47:37 GMT'}]",2022-05-24,"[['Hoque', 'Enamul', ''], ['Kavehzadeh', 'Parsa', ''], ['Masry', 'Ahmed', '']]"
2301.04871,Ruijun Chen,"Ruijun Chen, Jin Wang, Liang-Chih Yu and Xuejie Zhang","Learning to Memorize Entailment and Discourse Relations for
  Persona-Consistent Dialogues",Accepted by AAAI2023,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Maintaining engagement and consistency is particularly important in dialogue
systems. Existing works have improved the performance of dialogue systems by
intentionally learning interlocutor personas with sophisticated network
structures. One issue with this approach is that it requires more personal
corpora with annotations. Additionally, these models typically perform the next
utterance prediction to generate a response but neglect the discourse coherence
in the entire conversation. To address these issues, this study proposes a
method of learning to memorize entailment and discourse relations for
persona-consistent dialogue tasks. Entailment text pairs in natural language
inference dataset were applied to learn latent entailment relations as external
memories by premise-to-hypothesis generation task. Furthermore, an internal
memory with a similar architecture was applied to the discourse information in
the dialogue. Placing orthogonality restrictions on these two memory spaces
ensures that the latent entailment relations remain dialogue-independent. Both
memories collaborate to obtain entailment and discourse representation for the
generation, allowing a deeper understanding of both consistency and coherence.
Experiments on two large public datasets, PersonaChat and DSTC7-AVSD,
demonstrated the effectiveness of the proposed method. Both automatic and human
evaluations indicate that the proposed model outperforms several strong
baselines in terms of both persona consistency and response coherence. Our
source code is available at https://github.com/Chenrj233/LMEDR.
","[{'version': 'v1', 'created': 'Thu, 12 Jan 2023 08:37:00 GMT'}, {'version': 'v2', 'created': 'Sat, 25 Feb 2023 07:41:41 GMT'}]",2023-02-28,"[['Chen', 'Ruijun', ''], ['Wang', 'Jin', ''], ['Yu', 'Liang-Chih', ''], ['Zhang', 'Xuejie', '']]"
2110.08036,Zhao Tengfei,"Tengfei Zhao, Zhaocheng Ge, Hanping Hu, Dingmeng Shi","Generating Natural Language Adversarial Examples through An Improved
  Beam Search Algorithm","9 pages, 4 figures",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The research of adversarial attacks in the text domain attracts many
interests in the last few years, and many methods with a high attack success
rate have been proposed. However, these attack methods are inefficient as they
require lots of queries for the victim model when crafting text adversarial
examples. In this paper, a novel attack model is proposed, its attack success
rate surpasses the benchmark attack methods, but more importantly, its attack
efficiency is much higher than the benchmark attack methods. The novel method
is empirically evaluated by attacking WordCNN, LSTM, BiLSTM, and BERT on four
benchmark datasets. For instance, it achieves a 100\% attack success rate
higher than the state-of-the-art method when attacking BERT and BiLSTM on IMDB,
but the number of queries for the victim models only is 1/4 and 1/6.5 of the
state-of-the-art method, respectively. Also, further experiments show the novel
method has a good transferability on the generated adversarial examples.
","[{'version': 'v1', 'created': 'Fri, 15 Oct 2021 12:09:04 GMT'}]",2021-10-18,"[['Zhao', 'Tengfei', ''], ['Ge', 'Zhaocheng', ''], ['Hu', 'Hanping', ''], ['Shi', 'Dingmeng', '']]"
2012.07019,Yinuo Guo,"Yinuo Guo, Zeqi Lin, Jian-Guang Lou, Dongmei Zhang",Iterative Utterance Segmentation for Neural Semantic Parsing,Accepted by AAAI 2021,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural semantic parsers usually fail to parse long and complex utterances
into correct meaning representations, due to the lack of exploiting the
principle of compositionality. To address this issue, we present a novel
framework for boosting neural semantic parsers via iterative utterance
segmentation. Given an input utterance, our framework iterates between two
neural modules: a segmenter for segmenting a span from the utterance, and a
parser for mapping the span into a partial meaning representation. Then, these
intermediate parsing results are composed into the final meaning
representation. One key advantage is that this framework does not require any
handcraft templates or additional labeled data for utterance segmentation: we
achieve this through proposing a novel training method, in which the parser
provides pseudo supervision for the segmenter. Experiments on Geo,
ComplexWebQuestions, and Formulas show that our framework can consistently
improve performances of neural semantic parsers in different domains. On data
splits that require compositional generalization, our framework brings
significant accuracy gains: Geo 63.1 to 81.2, Formulas 59.7 to 72.7,
ComplexWebQuestions 27.1 to 56.3.
","[{'version': 'v1', 'created': 'Sun, 13 Dec 2020 09:46:24 GMT'}]",2020-12-15,"[['Guo', 'Yinuo', ''], ['Lin', 'Zeqi', ''], ['Lou', 'Jian-Guang', ''], ['Zhang', 'Dongmei', '']]"
2307.13699,David Woo,"David James Woo, Hengky Susanto and Kai Guo","EFL Students' Attitudes and Contradictions in a Machine-in-the-loop
  Activity System","38 pages, 4 figures",,,,cs.HC cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This study applies Activity Theory and investigates the attitudes and
contradictions of 67 English as a foreign language (EFL) students from four
Hong Kong secondary schools towards machine-in-the-loop writing, where
artificial intelligence (AI) suggests ideas during composition. Students
answered an open-ended question about their feelings on writing with AI.
Results revealed mostly positive attitudes, with some negative or mixed
feelings. From a thematic analysis, contradictions or points of tension between
students and AI stemmed from AI inadequacies, students' balancing enthusiasm
with preference, and their striving for language autonomy. The research
highlights the benefits and challenges of implementing machine-in-the-loop
writing in EFL classrooms, suggesting educators align activity goals with
students' values, language abilities, and AI capabilities to enhance students'
activity systems.
","[{'version': 'v1', 'created': 'Thu, 13 Jul 2023 07:38:11 GMT'}]",2023-07-27,"[['Woo', 'David James', ''], ['Susanto', 'Hengky', ''], ['Guo', 'Kai', '']]"
2205.10970,Bowen Xing,Bowen Xing and Ivor W. Tsang,"Neural Subgraph Explorer: Reducing Noisy Information via Target-Oriented
  Syntax Graph Pruning",To appear in IJCAI 2022,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent years have witnessed the emerging success of leveraging syntax graphs
for the target sentiment classification task. However, we discover that
existing syntax-based models suffer from two issues: noisy information
aggregation and loss of distant correlations. In this paper, we propose a novel
model termed Neural Subgraph Explorer, which (1) reduces the noisy information
via pruning target-irrelevant nodes on the syntax graph; (2) introduces
beneficial first-order connections between the target and its related words
into the obtained graph. Specifically, we design a multi-hop actions score
estimator to evaluate the value of each word regarding the specific target. The
discrete action sequence is sampled through Gumble-Softmax and then used for
both of the syntax graph and the self-attention graph. To introduce the
first-order connections between the target and its relevant words, the two
pruned graphs are merged. Finally, graph convolution is conducted on the
obtained unified graph to update the hidden states. And this process is stacked
with multiple layers. To our knowledge, this is the first attempt of
target-oriented syntax graph pruning in this task. Experimental results
demonstrate the superiority of our model, which achieves new state-of-the-art
performance.
","[{'version': 'v1', 'created': 'Mon, 23 May 2022 00:29:32 GMT'}]",2022-05-24,"[['Xing', 'Bowen', ''], ['Tsang', 'Ivor W.', '']]"
2001.09727,Vineel Pratap,"Vineel Pratap, Qiantong Xu, Jacob Kahn, Gilad Avidov, Tatiana
  Likhomanenko, Awni Hannun, Vitaliy Liptchinsky, Gabriel Synnaeve, Ronan
  Collobert",Scaling Up Online Speech Recognition Using ConvNets,,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We design an online end-to-end speech recognition system based on Time-Depth
Separable (TDS) convolutions and Connectionist Temporal Classification (CTC).
We improve the core TDS architecture in order to limit the future context and
hence reduce latency while maintaining accuracy. The system has almost three
times the throughput of a well tuned hybrid ASR baseline while also having
lower latency and a better word error rate. Also important to the efficiency of
the recognizer is our highly optimized beam search decoder. To show the impact
of our design choices, we analyze throughput, latency, accuracy, and discuss
how these metrics can be tuned based on the user requirements.
","[{'version': 'v1', 'created': 'Mon, 27 Jan 2020 12:55:02 GMT'}]",2020-01-29,"[['Pratap', 'Vineel', ''], ['Xu', 'Qiantong', ''], ['Kahn', 'Jacob', ''], ['Avidov', 'Gilad', ''], ['Likhomanenko', 'Tatiana', ''], ['Hannun', 'Awni', ''], ['Liptchinsky', 'Vitaliy', ''], ['Synnaeve', 'Gabriel', ''], ['Collobert', 'Ronan', '']]"
2403.12918,Sai Ashish Somayajula,"Sai Ashish Somayajula, Youwei Liang, Abhishek Singh, Li Zhang, Pengtao
  Xie","Generalizable and Stable Finetuning of Pretrained Language Models on
  Low-Resource Texts","Accepted as a long paper to NAACL 2024 Main Conference; 18 pages, 11
  tables, 3 figures",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pretrained Language Models (PLMs) have advanced Natural Language Processing
(NLP) tasks significantly, but finetuning PLMs on low-resource datasets poses
significant challenges such as instability and overfitting. Previous methods
tackle these issues by finetuning a strategically chosen subnetwork on a
downstream task, while keeping the remaining weights fixed to the pretrained
weights. However, they rely on a suboptimal criteria for sub-network selection,
leading to suboptimal solutions. To address these limitations, we propose a
regularization method based on attention-guided weight mixup for finetuning
PLMs. Our approach represents each network weight as a mixup of task-specific
weight and pretrained weight, controlled by a learnable attention parameter,
providing finer control over sub-network selection. Furthermore, we employ a
bi-level optimization (BLO) based framework on two separate splits of the
training dataset, improving generalization and combating overfitting. We
validate the efficacy of our proposed method through extensive experiments,
demonstrating its superiority over previous methods, particularly in the
context of finetuning PLMs on low-resource datasets.
","[{'version': 'v1', 'created': 'Tue, 19 Mar 2024 17:21:29 GMT'}]",2024-03-20,"[['Somayajula', 'Sai Ashish', ''], ['Liang', 'Youwei', ''], ['Singh', 'Abhishek', ''], ['Zhang', 'Li', ''], ['Xie', 'Pengtao', '']]"
2307.04643,Zichao Wang,"Zichao Wang, Richard Baraniuk",MultiQG-TI: Towards Question Generation from Multi-modal Sources,"Accepted at BEA workshop 2023; code
  https://github.com/moonlightlane/MultiQG-TI",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  We study the new problem of automatic question generation (QG) from
multi-modal sources containing images and texts, significantly expanding the
scope of most of the existing work that focuses exclusively on QG from only
textual sources. We propose a simple solution for our new problem, called
MultiQG-TI, which enables a text-only question generator to process visual
input in addition to textual input. Specifically, we leverage an image-to-text
model and an optical character recognition model to obtain the textual
description of the image and extract any texts in the image, respectively, and
then feed them together with the input texts to the question generator. We only
fine-tune the question generator while keeping the other components fixed. On
the challenging ScienceQA dataset, we demonstrate that MultiQG-TI significantly
outperforms ChatGPT with few-shot prompting, despite having hundred-times less
trainable parameters. Additional analyses empirically confirm the necessity of
both visual and textual signals for QG and show the impact of various modeling
choices.
","[{'version': 'v1', 'created': 'Fri, 7 Jul 2023 08:14:15 GMT'}]",2023-07-11,"[['Wang', 'Zichao', ''], ['Baraniuk', 'Richard', '']]"
2304.08205,Chuanqi Tan,"Zhen-Ru Zhang, Chuanqi Tan, Songfang Huang, Fei Huang","VECO 2.0: Cross-lingual Language Model Pre-training with
  Multi-granularity Contrastive Learning","Technical Report for AliceMind's VECO 2.0 (ranked 1st on the XTREME
  leaderboard on March 17, 2023)",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Recent studies have demonstrated the potential of cross-lingual
transferability by training a unified Transformer encoder for multiple
languages. In addition to involving the masked language model objective,
existing cross-lingual pre-training works leverage sentence-level contrastive
learning or plugs in extra cross-attention module to complement the
insufficient capabilities of cross-lingual alignment. Nonetheless, synonym
pairs residing in bilingual corpus are not exploited and aligned, which is more
crucial than sentence interdependence establishment for token-level tasks. In
this work, we propose a cross-lingual pre-trained model VECO~2.0 based on
contrastive learning with multi-granularity alignments. Specifically, the
sequence-to-sequence alignment is induced to maximize the similarity of the
parallel pairs and minimize the non-parallel pairs. Then, token-to-token
alignment is integrated to bridge the gap between synonymous tokens excavated
via the thesaurus dictionary from the other unpaired tokens in a bilingual
instance. Experiments show the effectiveness of the proposed strategy for
cross-lingual model pre-training on the XTREME benchmark.
","[{'version': 'v1', 'created': 'Mon, 17 Apr 2023 12:23:41 GMT'}]",2023-04-18,"[['Zhang', 'Zhen-Ru', ''], ['Tan', 'Chuanqi', ''], ['Huang', 'Songfang', ''], ['Huang', 'Fei', '']]"
2202.02312,Andrea Burns,"Andrea Burns, Deniz Arsan, Sanjna Agrawal, Ranjitha Kumar, Kate
  Saenko, Bryan A. Plummer","A Dataset for Interactive Vision-Language Navigation with Unknown
  Command Feasibility","Accepted at the European Conference on Computer Vision (ECCV) 2022.
  This is a new version of the paper with additional experimental results and a
  few prior implementation bugs fixed",,,,cs.CL cs.CV cs.HC,http://creativecommons.org/licenses/by/4.0/,"  Vision-language navigation (VLN), in which an agent follows language
instruction in a visual environment, has been studied under the premise that
the input command is fully feasible in the environment. Yet in practice, a
request may not be possible due to language ambiguity or environment changes.
To study VLN with unknown command feasibility, we introduce a new dataset
Mobile app Tasks with Iterative Feedback (MoTIF), where the goal is to complete
a natural language command in a mobile app. Mobile apps provide a scalable
domain to study real downstream uses of VLN methods. Moreover, mobile app
commands provide instruction for interactive navigation, as they result in
action sequences with state changes via clicking, typing, or swiping. MoTIF is
the first to include feasibility annotations, containing both binary
feasibility labels and fine-grained labels for why tasks are unsatisfiable. We
further collect follow-up questions for ambiguous queries to enable research on
task uncertainty resolution. Equipped with our dataset, we propose the new
problem of feasibility prediction, in which a natural language instruction and
multimodal app environment are used to predict command feasibility. MoTIF
provides a more realistic app dataset as it contains many diverse environments,
high-level goals, and longer action sequences than prior work. We evaluate
interactive VLN methods using MoTIF, quantify the generalization ability of
current approaches to new app environments, and measure the effect of task
feasibility on navigation performance.
","[{'version': 'v1', 'created': 'Fri, 4 Feb 2022 18:51:50 GMT'}, {'version': 'v2', 'created': 'Fri, 22 Jul 2022 23:19:57 GMT'}, {'version': 'v3', 'created': 'Mon, 15 Aug 2022 00:24:24 GMT'}]",2022-08-16,"[['Burns', 'Andrea', ''], ['Arsan', 'Deniz', ''], ['Agrawal', 'Sanjna', ''], ['Kumar', 'Ranjitha', ''], ['Saenko', 'Kate', ''], ['Plummer', 'Bryan A.', '']]"
2210.05598,Long Phan,"Long Phan, Tai Dang, Hieu Tran, Trieu H. Trinh, Vy Phan, Lam D. Chau,
  and Minh-Thang Luong","Enriching Biomedical Knowledge for Low-resource Language Through
  Large-Scale Translation",,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Biomedical data and benchmarks are highly valuable yet very limited in
low-resource languages other than English such as Vietnamese. In this paper, we
make use of a state-of-the-art translation model in English-Vietnamese to
translate and produce both pretrained as well as supervised data in the
biomedical domains. Thanks to such large-scale translation, we introduce
ViPubmedT5, a pretrained Encoder-Decoder Transformer model trained on 20
million translated abstracts from the high-quality public PubMed corpus.
ViPubMedT5 demonstrates state-of-the-art results on two different biomedical
benchmarks in summarization and acronym disambiguation. Further, we release
ViMedNLI - a new NLP task in Vietnamese translated from MedNLI using the
recently public En-vi translation model and carefully refined by human experts,
with evaluations of existing methods against ViPubmedT5.
","[{'version': 'v1', 'created': 'Tue, 11 Oct 2022 16:35:10 GMT'}, {'version': 'v2', 'created': 'Wed, 26 Oct 2022 22:16:47 GMT'}, {'version': 'v3', 'created': 'Sun, 29 Jan 2023 16:32:46 GMT'}]",2023-01-31,"[['Phan', 'Long', ''], ['Dang', 'Tai', ''], ['Tran', 'Hieu', ''], ['Trinh', 'Trieu H.', ''], ['Phan', 'Vy', ''], ['Chau', 'Lam D.', ''], ['Luong', 'Minh-Thang', '']]"
1809.06559,Yilin Shen,Yilin Shen and Xiangyu Zeng and Yu Wang and Hongxia Jin,"User Information Augmented Semantic Frame Parsing using Coarse-to-Fine
  Neural Networks",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Semantic frame parsing is a crucial component in spoken language
understanding (SLU) to build spoken dialog systems. It has two main tasks:
intent detection and slot filling. Although state-of-the-art approaches showed
good results, they require large annotated training data and long training
time. In this paper, we aim to alleviate these drawbacks for semantic frame
parsing by utilizing the ubiquitous user information. We design a novel
coarse-to-fine deep neural network model to incorporate prior knowledge of user
information intermediately to better and quickly train a semantic frame parser.
Due to the lack of benchmark dataset with real user information, we synthesize
the simplest type of user information (location and time) on ATIS benchmark
data. The results show that our approach leverages such simple user information
to outperform state-of-the-art approaches by 0.25% for intent detection and
0.31% for slot filling using standard training data. When using smaller
training data, the performance improvement on intent detection and slot filling
reaches up to 1.35% and 1.20% respectively. We also show that our approach can
achieve similar performance as state-of-the-art approaches by using less than
80% annotated training data. Moreover, the training time to achieve the similar
performance is also reduced by over 60%.
","[{'version': 'v1', 'created': 'Tue, 18 Sep 2018 07:08:59 GMT'}]",2018-09-19,"[['Shen', 'Yilin', ''], ['Zeng', 'Xiangyu', ''], ['Wang', 'Yu', ''], ['Jin', 'Hongxia', '']]"
2109.13486,Bidisha Sharma,"Bidisha Sharma, Maulik Madhavi, Xuehao Zhou, Haizhou Li","Exploring Teacher-Student Learning Approach for Multi-lingual
  Speech-to-Intent Classification",,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  End-to-end speech-to-intent classification has shown its advantage in
harvesting information from both text and speech. In this paper, we study a
technique to develop such an end-to-end system that supports multiple
languages. To overcome the scarcity of multi-lingual speech corpus, we exploit
knowledge from a pre-trained multi-lingual natural language processing model.
Multi-lingual bidirectional encoder representations from transformers (mBERT)
models are trained on multiple languages and hence expected to perform well in
the multi-lingual scenario. In this work, we employ a teacher-student learning
approach to sufficiently extract information from an mBERT model to train a
multi-lingual speech model. In particular, we use synthesized speech generated
from an English-Mandarin text corpus for analysis and training of a
multi-lingual intent classification model. We also demonstrate that the
teacher-student learning approach obtains an improved performance (91.02%) over
the traditional end-to-end (89.40%) intent classification approach in a
practical multi-lingual scenario.
","[{'version': 'v1', 'created': 'Tue, 28 Sep 2021 04:43:11 GMT'}]",2021-09-29,"[['Sharma', 'Bidisha', ''], ['Madhavi', 'Maulik', ''], ['Zhou', 'Xuehao', ''], ['Li', 'Haizhou', '']]"
2304.00717,Ziqing Yang,"Xin Yao, Ziqing Yang, Yiming Cui, Shijin Wang",MiniRBT: A Two-stage Distilled Small Chinese Pre-trained Model,4 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In natural language processing, pre-trained language models have become
essential infrastructures. However, these models often suffer from issues such
as large size, long inference time, and challenging deployment. Moreover, most
mainstream pre-trained models focus on English, and there are insufficient
studies on small Chinese pre-trained models. In this paper, we introduce
MiniRBT, a small Chinese pre-trained model that aims to advance research in
Chinese natural language processing. MiniRBT employs a narrow and deep student
model and incorporates whole word masking and two-stage distillation during
pre-training to make it well-suited for most downstream tasks. Our experiments
on machine reading comprehension and text classification tasks reveal that
MiniRBT achieves 94% performance relative to RoBERTa, while providing a 6.8x
speedup, demonstrating its effectiveness and efficiency.
","[{'version': 'v1', 'created': 'Mon, 3 Apr 2023 04:45:57 GMT'}]",2023-04-04,"[['Yao', 'Xin', ''], ['Yang', 'Ziqing', ''], ['Cui', 'Yiming', ''], ['Wang', 'Shijin', '']]"
2212.09410,Zhiying Jiang,"Zhiying Jiang, Matthew Y.R. Yang, Mikhail Tsirlin, Raphael Tang, Jimmy
  Lin",Less is More: Parameter-Free Text Classification with Gzip,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Deep neural networks (DNNs) are often used for text classification tasks as
they usually achieve high levels of accuracy. However, DNNs can be
computationally intensive with billions of parameters and large amounts of
labeled data, which can make them expensive to use, to optimize and to transfer
to out-of-distribution (OOD) cases in practice. In this paper, we propose a
non-parametric alternative to DNNs that's easy, light-weight and universal in
text classification: a combination of a simple compressor like gzip with a
$k$-nearest-neighbor classifier. Without any training, pre-training or
fine-tuning, our method achieves results that are competitive with
non-pretrained deep learning methods on six in-distributed datasets. It even
outperforms BERT on all five OOD datasets, including four low-resource
languages. Our method also performs particularly well in few-shot settings
where labeled data are too scarce for DNNs to achieve a satisfying accuracy.
","[{'version': 'v1', 'created': 'Mon, 19 Dec 2022 12:40:18 GMT'}]",2022-12-20,"[['Jiang', 'Zhiying', ''], ['Yang', 'Matthew Y. R.', ''], ['Tsirlin', 'Mikhail', ''], ['Tang', 'Raphael', ''], ['Lin', 'Jimmy', '']]"
1910.10490,Janyl Jumadinova,Xingbang Liu and Janyl Jumadinova,Automated Text Summarization for the Enhancement of Public Services,"Presented at AAAI FSS-19: Artificial Intelligence in Government and
  Public Sector, Arlington, Virginia, USA",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Natural language processing and machine learning algorithms have been shown
to be effective in a variety of applications. In this work, we contribute to
the area of AI adoption in the public sector. We present an automated system
that was used to process textual information, generate important keywords, and
automatically summarize key elements of the Meadville community statements. We
also describe the process of collaboration with My Meadville administrators
during the development of our system. My Meadville, a community initiative,
supported by the city of Meadville conducted a large number of interviews with
the residents of Meadville during the community events and transcribed these
interviews into textual data files. Their goal was to uncover the issues of
importance to the Meadville residents in an attempt to enhance public services.
Our AI system cleans and pre-processes the interview data, then using machine
learning algorithms it finds important keywords and key excerpts from each
interview. It also provides searching functionality to find excerpts from
relevant interviews based on specific keywords. Our automated system allowed
the city to save over 300 hours of human labor that would have taken to read
all interviews and highlight important points. Our findings are being used by
My Meadville initiative to locate important information from the collected data
set for ongoing community enhancement projects, to highlight relevant community
assets, and to assist in identifying the steps to be taken based on the
concerns and areas of improvement identified by the community members.
","[{'version': 'v1', 'created': 'Wed, 16 Oct 2019 13:55:02 GMT'}]",2019-10-24,"[['Liu', 'Xingbang', ''], ['Jumadinova', 'Janyl', '']]"
2312.17581,Logan Golia,"Logan Golia, Jugal Kalita",Action-Item-Driven Summarization of Long Meeting Transcripts,"Accepted into the 7th International Conference on Natural Language
  Processing and Information Retrieval (NLPIR 2023)",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The increased prevalence of online meetings has significantly enhanced the
practicality of a model that can automatically generate the summary of a given
meeting. This paper introduces a novel and effective approach to automate the
generation of meeting summaries. Current approaches to this problem generate
general and basic summaries, considering the meeting simply as a long dialogue.
However, our novel algorithms can generate abstractive meeting summaries that
are driven by the action items contained in the meeting transcript. This is
done by recursively generating summaries and employing our action-item
extraction algorithm for each section of the meeting in parallel. All of these
sectional summaries are then combined and summarized together to create a
coherent and action-item-driven summary. In addition, this paper introduces
three novel methods for dividing up long transcripts into topic-based sections
to improve the time efficiency of our algorithm, as well as to resolve the
issue of large language models (LLMs) forgetting long-term dependencies. Our
pipeline achieved a BERTScore of 64.98 across the AMI corpus, which is an
approximately 4.98% increase from the current state-of-the-art result produced
by a fine-tuned BART (Bidirectional and Auto-Regressive Transformers) model.
","[{'version': 'v1', 'created': 'Fri, 29 Dec 2023 12:33:21 GMT'}, {'version': 'v2', 'created': 'Sat, 6 Jan 2024 13:33:23 GMT'}]",2024-01-09,"[['Golia', 'Logan', ''], ['Kalita', 'Jugal', '']]"
2302.01756,Ciprian-Octavian Truic\u{a},"Ciprian-Octavian Truic\u{a} and Elena-Simona Apostol and Panagiotis
  Karras","DANES: Deep Neural Network Ensemble Architecture for Social and Textual
  Context-aware Fake News Detection",,,,,cs.AI cs.CL cs.NE cs.SI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  The growing popularity of social media platforms has simplified the creation
and distribution of news articles but also creates a conduit for spreading fake
news. In consequence, the need arises for effective context-aware fake news
detection mechanisms, where the contextual information can be built either from
the textual content of posts or from available social data (e.g., information
about the users, reactions to posts, or the social network). In this paper, we
propose DANES, a Deep Neural Network Ensemble Architecture for Social and
Textual Context-aware Fake News Detection. DANES comprises a Text Branch for a
textual content-based context and a Social Branch for the social context. These
two branches are used to create a novel Network Embedding. Preliminary ablation
results on 3 real-world datasets, i.e., BuzzFace, Twitter15, and Twitter16, are
promising, with an accuracy that outperforms state-of-the-art solutions when
employing both social and textual content features.
","[{'version': 'v1', 'created': 'Wed, 1 Feb 2023 20:05:53 GMT'}]",2023-02-06,"[['Truică', 'Ciprian-Octavian', ''], ['Apostol', 'Elena-Simona', ''], ['Karras', 'Panagiotis', '']]"
cs/9906027,Gillian Callaghan,Yorick Wilks and Roberta Catizone,Human-Computer Conversation,"14 pages, 1 figure",,,CS-99-04,cs.CL cs.HC,,"  The article surveys a little of the history of the technology, sets out the
main current theoretical approaches in brief, and discusses the on-going
opposition between theoretical and empirical approaches. It illustrates the
situation with some discussion of CONVERSE, a system that won the Loebner prize
in 1997 and which displays features of both approaches.
","[{'version': 'v1', 'created': 'Fri, 25 Jun 1999 11:44:42 GMT'}]",2007-05-23,"[['Wilks', 'Yorick', ''], ['Catizone', 'Roberta', '']]"
2402.12738,Michimasa Inaba,"Michimasa Inaba, Mariko Ukiyo and Keiko Takamizo","Can Large Language Models be Used to Provide Psychological Counselling?
  An Analysis of GPT-4-Generated Responses Using Role-play Dialogues",Accepted as a conference paper at IWSDS 2024,,,,cs.CL cs.AI cs.HC,http://creativecommons.org/licenses/by/4.0/,"  Mental health care poses an increasingly serious challenge to modern
societies. In this context, there has been a surge in research that utilizes
information technologies to address mental health problems, including those
aiming to develop counseling dialogue systems. However, there is a need for
more evaluations of the performance of counseling dialogue systems that use
large language models. For this study, we collected counseling dialogue data
via role-playing scenarios involving expert counselors, and the utterances were
annotated with the intentions of the counselors. To determine the feasibility
of a dialogue system in real-world counseling scenarios, third-party counselors
evaluated the appropriateness of responses from human counselors and those
generated by GPT-4 in identical contexts in role-play dialogue data. Analysis
of the evaluation results showed that the responses generated by GPT-4 were
competitive with those of human counselors.
","[{'version': 'v1', 'created': 'Tue, 20 Feb 2024 06:05:36 GMT'}]",2024-02-21,"[['Inaba', 'Michimasa', ''], ['Ukiyo', 'Mariko', ''], ['Takamizo', 'Keiko', '']]"
2309.16705,David Noever,David Noever and Samantha Elizabeth Miller Noever,"Multimodal Analysis Of Google Bard And GPT-Vision: Experiments In Visual
  Reasoning",,,,,cs.CV cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Addressing the gap in understanding visual comprehension in Large Language
Models (LLMs), we designed a challenge-response study, subjecting Google Bard
and GPT-Vision to 64 visual tasks, spanning categories like ""Visual Situational
Reasoning"" and ""Next Scene Prediction."" Previous models, such as GPT4, leaned
heavily on optical character recognition tools like Tesseract, whereas Bard and
GPT-Vision, akin to Google Lens and Visual API, employ deep learning techniques
for visual text recognition. However, our findings spotlight both
vision-language model's limitations: while proficient in solving visual
CAPTCHAs that stump ChatGPT alone, it falters in recreating visual elements
like ASCII art or analyzing Tic Tac Toe grids, suggesting an over-reliance on
educated visual guesses. The prediction problem based on visual inputs appears
particularly challenging with no common-sense guesses for next-scene
forecasting based on current ""next-token"" multimodal models. This study
provides experimental insights into the current capacities and areas for
improvement in multimodal LLMs.
","[{'version': 'v1', 'created': 'Thu, 17 Aug 2023 03:14:00 GMT'}, {'version': 'v2', 'created': 'Sat, 14 Oct 2023 19:53:39 GMT'}]",2023-10-18,"[['Noever', 'David', ''], ['Noever', 'Samantha Elizabeth Miller', '']]"
2401.02072,Chen Zheng,"Chen Zheng, Ke Sun, Da Tang, Yukun Ma, Yuyu Zhang, Chenguang Xi, Xun
  Zhou","ICE-GRT: Instruction Context Enhancement by Generative Reinforcement
  based Transformers",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The emergence of Large Language Models (LLMs) such as ChatGPT and LLaMA
encounter limitations in domain-specific tasks, with these models often lacking
depth and accuracy in specialized areas, and exhibiting a decrease in general
capabilities when fine-tuned, particularly analysis ability in small sized
models. To address these gaps, we introduce ICE-GRT, utilizing Reinforcement
Learning from Human Feedback (RLHF) grounded in Proximal Policy Optimization
(PPO), demonstrating remarkable ability in in-domain scenarios without
compromising general task performance. Our exploration of ICE-GRT highlights
its understanding and reasoning ability to not only generate robust answers but
also to provide detailed analyses of the reasons behind the answer. This
capability marks a significant progression beyond the scope of Supervised
Fine-Tuning models. The success of ICE-GRT is dependent on several crucial
factors, including Appropriate Data, Reward Size Scaling, KL-Control, Advantage
Normalization, etc. The ICE-GRT model exhibits state-of-the-art performance in
domain-specific tasks and across 12 general Language tasks against equivalent
size and even larger size LLMs, highlighting the effectiveness of our approach.
We provide a comprehensive analysis of the ICE-GRT, underscoring the
significant advancements it brings to the field of LLM.
","[{'version': 'v1', 'created': 'Thu, 4 Jan 2024 05:47:41 GMT'}]",2024-01-05,"[['Zheng', 'Chen', ''], ['Sun', 'Ke', ''], ['Tang', 'Da', ''], ['Ma', 'Yukun', ''], ['Zhang', 'Yuyu', ''], ['Xi', 'Chenguang', ''], ['Zhou', 'Xun', '']]"
2202.04994,Ale\v{s} \v{Z}agar,"Ale\v{s} \v{Z}agar, Marko Robnik-\v{S}ikonja",Slovene SuperGLUE Benchmark: Translation and Evaluation,arXiv admin note: text overlap with arXiv:2107.10614,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We present a Slovene combined machine-human translated SuperGLUE benchmark.
We describe the translation process and problems arising due to differences in
morphology and grammar. We evaluate the translated datasets in several modes:
monolingual, cross-lingual, and multilingual, taking into account differences
between machine and human translated training sets. The results show that the
monolingual Slovene SloBERTa model is superior to massively multilingual and
trilingual BERT models, but these also show a good cross-lingual performance on
certain tasks. The performance of Slovene models still lags behind the best
English models.
","[{'version': 'v1', 'created': 'Thu, 10 Feb 2022 12:46:06 GMT'}]",2022-02-11,"[['Žagar', 'Aleš', ''], ['Robnik-Šikonja', 'Marko', '']]"
2302.14502,Zican Dong,"Zican Dong, Tianyi Tang, Lunyi Li and Wayne Xin Zhao",A Survey on Long Text Modeling with Transformers,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Modeling long texts has been an essential technique in the field of natural
language processing (NLP). With the ever-growing number of long documents, it
is important to develop effective modeling methods that can process and analyze
such texts. However, long texts pose important research challenges for existing
text models, with more complex semantics and special characteristics. In this
paper, we provide an overview of the recent advances on long texts modeling
based on Transformer models. Firstly, we introduce the formal definition of
long text modeling. Then, as the core content, we discuss how to process long
input to satisfy the length limitation and design improved Transformer
architectures to effectively extend the maximum context length. Following this,
we discuss how to adapt Transformer models to capture the special
characteristics of long texts. Finally, we describe four typical applications
involving long text modeling and conclude this paper with a discussion of
future directions. Our survey intends to provide researchers with a synthesis
and pointer to related work on long text modeling.
","[{'version': 'v1', 'created': 'Tue, 28 Feb 2023 11:34:30 GMT'}]",2023-03-01,"[['Dong', 'Zican', ''], ['Tang', 'Tianyi', ''], ['Li', 'Lunyi', ''], ['Zhao', 'Wayne Xin', '']]"
2205.13789,Gianluigi Lopardo,"Gianluigi Lopardo, Frederic Precioso, Damien Garreau",A Sea of Words: An In-Depth Analysis of Anchors for Text Data,"Accepted to AISTATS 2023. 9+2 page paper, 21-page appendix",,,,stat.ML cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Anchors (Ribeiro et al., 2018) is a post-hoc, rule-based interpretability
method. For text data, it proposes to explain a decision by highlighting a
small set of words (an anchor) such that the model to explain has similar
outputs when they are present in a document. In this paper, we present the
first theoretical analysis of Anchors, considering that the search for the best
anchor is exhaustive. After formalizing the algorithm for text classification,
we present explicit results on different classes of models when the
vectorization step is TF-IDF, and words are replaced by a fixed
out-of-dictionary token when removed. Our inquiry covers models such as
elementary if-then rules and linear classifiers. We then leverage this analysis
to gain insights on the behavior of Anchors for any differentiable classifiers.
For neural networks, we empirically show that the words corresponding to the
highest partial derivatives of the model with respect to the input, reweighted
by the inverse document frequencies, are selected by Anchors.
","[{'version': 'v1', 'created': 'Fri, 27 May 2022 06:57:32 GMT'}, {'version': 'v2', 'created': 'Sat, 25 Feb 2023 17:11:38 GMT'}]",2023-03-17,"[['Lopardo', 'Gianluigi', ''], ['Precioso', 'Frederic', ''], ['Garreau', 'Damien', '']]"
2201.06170,"Phillip Benjamin Str\""obel","Phillip Benjamin Str\""obel, Simon Clematide, Martin Volk, Raphael
  Schwitter, Tobias Hodel, David Schoch",Evaluation of HTR models without Ground Truth Material,Accepted at LREC 2022. Final version submitted to LREC 2022,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The evaluation of Handwritten Text Recognition (HTR) models during their
development is straightforward: because HTR is a supervised problem, the usual
data split into training, validation, and test data sets allows the evaluation
of models in terms of accuracy or error rates. However, the evaluation process
becomes tricky as soon as we switch from development to application. A
compilation of a new (and forcibly smaller) ground truth (GT) from a sample of
the data that we want to apply the model on and the subsequent evaluation of
models thereon only provides hints about the quality of the recognised text, as
do confidence scores (if available) the models return. Moreover, if we have
several models at hand, we face a model selection problem since we want to
obtain the best possible result during the application phase. This calls for
GT-free metrics to select the best model, which is why we (re-)introduce and
compare different metrics, from simple, lexicon-based to more elaborate ones
using standard language models and masked language models (MLM). We show that
MLM-based evaluation can compete with lexicon-based methods, with the advantage
that large and multilingual transformers are readily available, thus making
compiling lexical resources for other metrics superfluous.
","[{'version': 'v1', 'created': 'Mon, 17 Jan 2022 01:26:09 GMT'}, {'version': 'v2', 'created': 'Fri, 29 Apr 2022 09:59:29 GMT'}]",2022-05-02,"[['Ströbel', 'Phillip Benjamin', ''], ['Clematide', 'Simon', ''], ['Volk', 'Martin', ''], ['Schwitter', 'Raphael', ''], ['Hodel', 'Tobias', ''], ['Schoch', 'David', '']]"
2111.09486,Binyuan Hui,"Bowen Qin, Lihan Wang, Binyuan Hui, Ruiying Geng, Zheng Cao, Min Yang,
  Jian Sun, Yongbin Li",Linking-Enhanced Pre-Training for Table Semantic Parsing,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently pre-training models have significantly improved the performance of
various NLP tasks by leveraging large-scale text corpora to improve the
contextual representation ability of the neural network. The large pre-training
language model has also been applied in the area of table semantic parsing.
However, existing pre-training approaches have not carefully explored explicit
interaction relationships between a question and the corresponding database
schema, which is a key ingredient for uncovering their semantic and structural
correspondence. Furthermore, the question-aware representation learning in the
schema grounding context has received less attention in pre-training
objective.To alleviate these issues, this paper designs two novel pre-training
objectives to impose the desired inductive bias into the learned
representations for table pre-training. We further propose a schema-aware
curriculum learning approach to mitigate the impact of noise and learn
effectively from the pre-training data in an easy-to-hard manner. We evaluate
our pre-trained framework by fine-tuning it on two benchmarks, Spider and
SQUALL. The results demonstrate the effectiveness of our pre-training objective
and curriculum compared to a variety of baselines.
","[{'version': 'v1', 'created': 'Thu, 18 Nov 2021 02:51:04 GMT'}, {'version': 'v2', 'created': 'Fri, 10 Dec 2021 06:59:25 GMT'}, {'version': 'v3', 'created': 'Tue, 15 Feb 2022 02:23:38 GMT'}]",2022-02-16,"[['Qin', 'Bowen', ''], ['Wang', 'Lihan', ''], ['Hui', 'Binyuan', ''], ['Geng', 'Ruiying', ''], ['Cao', 'Zheng', ''], ['Yang', 'Min', ''], ['Sun', 'Jian', ''], ['Li', 'Yongbin', '']]"
2308.11891,Hengyuan Zhang,"Hengyuan Zhang, Peng Chang, Zongcheng Ji",Bridging the Gap: Deciphering Tabular Data Using Large Language Model,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In the realm of natural language processing, the understanding of tabular
data has perpetually stood as a focal point of scholarly inquiry. The emergence
of expansive language models, exemplified by the likes of ChatGPT, has ushered
in a wave of endeavors wherein researchers aim to harness these models for
tasks related to table-based question answering. Central to our investigative
pursuits is the elucidation of methodologies that amplify the aptitude of such
large language models in discerning both the structural intricacies and
inherent content of tables, ultimately facilitating their capacity to provide
informed responses to pertinent queries. To this end, we have architected a
distinctive module dedicated to the serialization of tables for seamless
integration with expansive language models. Additionally, we've instituted a
corrective mechanism within the model to rectify potential inaccuracies.
Experimental results indicate that, although our proposed method trails the
SOTA by approximately 11.7% in overall metrics, it surpasses the SOTA by about
1.2% in tests on specific datasets. This research marks the first application
of large language models to table-based question answering tasks, enhancing the
model's comprehension of both table structures and content.
","[{'version': 'v1', 'created': 'Wed, 23 Aug 2023 03:38:21 GMT'}, {'version': 'v2', 'created': 'Mon, 28 Aug 2023 14:07:12 GMT'}]",2023-08-29,"[['Zhang', 'Hengyuan', ''], ['Chang', 'Peng', ''], ['Ji', 'Zongcheng', '']]"
2306.11698,Boxin Wang,"Boxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie, Mintong Kang,
  Chenhui Zhang, Chejian Xu, Zidi Xiong, Ritik Dutta, Rylan Schaeffer, Sang T.
  Truong, Simran Arora, Mantas Mazeika, Dan Hendrycks, Zinan Lin, Yu Cheng,
  Sanmi Koyejo, Dawn Song, Bo Li","DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT
  Models",NeurIPS 2023 Outstanding Paper (Datasets and Benchmarks Track),,,,cs.CL cs.AI cs.CR,http://creativecommons.org/licenses/by-sa/4.0/,"  Generative Pre-trained Transformer (GPT) models have exhibited exciting
progress in their capabilities, capturing the interest of practitioners and the
public alike. Yet, while the literature on the trustworthiness of GPT models
remains limited, practitioners have proposed employing capable GPT models for
sensitive applications such as healthcare and finance -- where mistakes can be
costly. To this end, this work proposes a comprehensive trustworthiness
evaluation for large language models with a focus on GPT-4 and GPT-3.5,
considering diverse perspectives -- including toxicity, stereotype bias,
adversarial robustness, out-of-distribution robustness, robustness on
adversarial demonstrations, privacy, machine ethics, and fairness. Based on our
evaluations, we discover previously unpublished vulnerabilities to
trustworthiness threats. For instance, we find that GPT models can be easily
misled to generate toxic and biased outputs and leak private information in
both training data and conversation history. We also find that although GPT-4
is usually more trustworthy than GPT-3.5 on standard benchmarks, GPT-4 is more
vulnerable given jailbreaking system or user prompts, potentially because GPT-4
follows (misleading) instructions more precisely. Our work illustrates a
comprehensive trustworthiness evaluation of GPT models and sheds light on the
trustworthiness gaps. Our benchmark is publicly available at
https://decodingtrust.github.io/ ; our dataset can be previewed at
https://huggingface.co/datasets/AI-Secure/DecodingTrust ; a concise version of
this work is at https://openreview.net/pdf?id=kaHpo8OZw2 .
","[{'version': 'v1', 'created': 'Tue, 20 Jun 2023 17:24:23 GMT'}, {'version': 'v2', 'created': 'Mon, 11 Dec 2023 01:49:39 GMT'}, {'version': 'v3', 'created': 'Tue, 19 Dec 2023 19:38:39 GMT'}, {'version': 'v4', 'created': 'Fri, 5 Jan 2024 07:01:05 GMT'}, {'version': 'v5', 'created': 'Mon, 26 Feb 2024 20:41:01 GMT'}]",2024-02-28,"[['Wang', 'Boxin', ''], ['Chen', 'Weixin', ''], ['Pei', 'Hengzhi', ''], ['Xie', 'Chulin', ''], ['Kang', 'Mintong', ''], ['Zhang', 'Chenhui', ''], ['Xu', 'Chejian', ''], ['Xiong', 'Zidi', ''], ['Dutta', 'Ritik', ''], ['Schaeffer', 'Rylan', ''], ['Truong', 'Sang T.', ''], ['Arora', 'Simran', ''], ['Mazeika', 'Mantas', ''], ['Hendrycks', 'Dan', ''], ['Lin', 'Zinan', ''], ['Cheng', 'Yu', ''], ['Koyejo', 'Sanmi', ''], ['Song', 'Dawn', ''], ['Li', 'Bo', '']]"
2103.04156,Eleni Partalidou,"Eleni Partalidou, Despina Christou and Grigorios Tsoumakas","Improving Zero-Shot Entity Retrieval through Effective Dense
  Representations","8 pages, 2 figures",,,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Entity Linking (EL) seeks to align entity mentions in text to entries in a
knowledge-base and is usually comprised of two phases: candidate generation and
candidate ranking. While most methods focus on the latter, it is the candidate
generation phase that sets an upper bound to both time and accuracy performance
of the overall EL system. This work's contribution is a significant improvement
in candidate generation which thus raises the performance threshold for EL, by
generating candidates that include the gold entity in the least candidate set
(top-K). We propose a simple approach that efficiently embeds mention-entity
pairs in dense space through a BERT-based bi-encoder. Specifically, we extend
(Wu et al., 2020) by introducing a new pooling function and incorporating
entity type side-information. We achieve a new state-of-the-art 84.28% accuracy
on top-50 candidates on the Zeshel dataset, compared to the previous 82.06% on
the top-64 of (Wu et al., 2020). We report the results from extensive
experimentation using our proposed model on both seen and unseen entity
datasets. Our results suggest that our method could be a useful complement to
existing EL approaches.
","[{'version': 'v1', 'created': 'Sat, 6 Mar 2021 17:00:09 GMT'}]",2021-03-09,"[['Partalidou', 'Eleni', ''], ['Christou', 'Despina', ''], ['Tsoumakas', 'Grigorios', '']]"
2305.14232,Yu Zhang,"Yu Zhang, Hao Cheng, Zhihong Shen, Xiaodong Liu, Ye-Yi Wang, Jianfeng
  Gao","Pre-training Multi-task Contrastive Learning Models for Scientific
  Literature Understanding","17 pages; Accepted to Findings of EMNLP 2023 (Project Page:
  https://scimult.github.io/)",,,,cs.CL cs.DL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Scientific literature understanding tasks have gained significant attention
due to their potential to accelerate scientific discovery. Pre-trained language
models (LMs) have shown effectiveness in these tasks, especially when tuned via
contrastive learning. However, jointly utilizing pre-training data across
multiple heterogeneous tasks (e.g., extreme multi-label paper classification,
citation prediction, and literature search) remains largely unexplored. To
bridge this gap, we propose a multi-task contrastive learning framework,
SciMult, with a focus on facilitating common knowledge sharing across different
scientific literature understanding tasks while preventing task-specific skills
from interfering with each other. To be specific, we explore two techniques --
task-aware specialization and instruction tuning. The former adopts a
Mixture-of-Experts Transformer architecture with task-aware sub-layers; the
latter prepends task-specific instructions to the input text so as to produce
task-aware outputs. Extensive experiments on a comprehensive collection of
benchmark datasets verify the effectiveness of our task-aware specialization
strategy, where we outperform state-of-the-art scientific pre-trained LMs.
Code, datasets, and pre-trained models can be found at
https://scimult.github.io/.
","[{'version': 'v1', 'created': 'Tue, 23 May 2023 16:47:22 GMT'}, {'version': 'v2', 'created': 'Thu, 19 Oct 2023 01:18:49 GMT'}]",2023-10-24,"[['Zhang', 'Yu', ''], ['Cheng', 'Hao', ''], ['Shen', 'Zhihong', ''], ['Liu', 'Xiaodong', ''], ['Wang', 'Ye-Yi', ''], ['Gao', 'Jianfeng', '']]"
2105.00403,Koji Inoue,"Tatsuya Kawahara, Koji Inoue, Divesh Lala","Intelligent Conversational Android ERICA Applied to Attentive Listening
  and Job Interview","7 pages, 5 figures, 1 table",,,,cs.CL cs.AI cs.RO,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Following the success of spoken dialogue systems (SDS) in smartphone
assistants and smart speakers, a number of communicative robots are developed
and commercialized. Compared with the conventional SDSs designed as a
human-machine interface, interaction with robots is expected to be in a closer
manner to talking to a human because of the anthropomorphism and physical
presence. The goal or task of dialogue may not be information retrieval, but
the conversation itself. In order to realize human-level ""long and deep""
conversation, we have developed an intelligent conversational android ERICA. We
set up several social interaction tasks for ERICA, including attentive
listening, job interview, and speed dating. To allow for spontaneous,
incremental multiple utterances, a robust turn-taking model is implemented
based on TRP (transition-relevance place) prediction, and a variety of
backchannels are generated based on time frame-wise prediction instead of
IPU-based prediction. We have realized an open-domain attentive listening
system with partial repeats and elaborating questions on focus words as well as
assessment responses. It has been evaluated with 40 senior people, engaged in
conversation of 5-7 minutes without a conversation breakdown. It was also
compared against the WOZ setting. We have also realized a job interview system
with a set of base questions followed by dynamic generation of elaborating
questions. It has also been evaluated with student subjects, showing promising
results.
","[{'version': 'v1', 'created': 'Sun, 2 May 2021 06:37:23 GMT'}]",2021-05-04,"[['Kawahara', 'Tatsuya', ''], ['Inoue', 'Koji', ''], ['Lala', 'Divesh', '']]"
2008.02742,Yen-Ling Kuo,"Yen-Ling Kuo, Boris Katz, Andrei Barbu","Compositional Networks Enable Systematic Generalization for Grounded
  Language Understanding",Accepted in Findings of EMNLP 2021,,,,cs.CL cs.AI cs.RO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Humans are remarkably flexible when understanding new sentences that include
combinations of concepts they have never encountered before. Recent work has
shown that while deep networks can mimic some human language abilities when
presented with novel sentences, systematic variation uncovers the limitations
in the language-understanding abilities of networks. We demonstrate that these
limitations can be overcome by addressing the generalization challenges in the
gSCAN dataset, which explicitly measures how well an agent is able to interpret
novel linguistic commands grounded in vision, e.g., novel pairings of
adjectives and nouns. The key principle we employ is compositionality: that the
compositional structure of networks should reflect the compositional structure
of the problem domain they address, while allowing other parameters to be
learned end-to-end. We build a general-purpose mechanism that enables agents to
generalize their language understanding to compositional domains. Crucially,
our network has the same state-of-the-art performance as prior work while
generalizing its knowledge when prior work does not. Our network also provides
a level of interpretability that enables users to inspect what each part of
networks learns. Robust grounded language understanding without dramatic
failures and without corner cases is critical to building safe and fair robots;
we demonstrate the significant role that compositionality can play in achieving
that goal.
","[{'version': 'v1', 'created': 'Thu, 6 Aug 2020 16:17:35 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Apr 2021 01:02:32 GMT'}, {'version': 'v3', 'created': 'Tue, 19 Oct 2021 05:32:14 GMT'}]",2021-10-20,"[['Kuo', 'Yen-Ling', ''], ['Katz', 'Boris', ''], ['Barbu', 'Andrei', '']]"
1909.05398,Matthew Hausknecht,"Matthew Hausknecht, Prithviraj Ammanabrolu, Marc-Alexandre C\^ot\'e,
  Xingdi Yuan",Interactive Fiction Games: A Colossal Adventure,,,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A hallmark of human intelligence is the ability to understand and communicate
with language. Interactive Fiction games are fully text-based simulation
environments where a player issues text commands to effect change in the
environment and progress through the story. We argue that IF games are an
excellent testbed for studying language-based autonomous agents. In particular,
IF games combine challenges of combinatorial action spaces, language
understanding, and commonsense reasoning. To facilitate rapid development of
language-based agents, we introduce Jericho, a learning environment for
man-made IF games and conduct a comprehensive study of text-agents across a
rich set of games, highlighting directions in which agents can improve.
","[{'version': 'v1', 'created': 'Wed, 11 Sep 2019 22:41:00 GMT'}, {'version': 'v2', 'created': 'Tue, 29 Oct 2019 18:59:52 GMT'}, {'version': 'v3', 'created': 'Tue, 25 Feb 2020 19:36:33 GMT'}]",2020-02-27,"[['Hausknecht', 'Matthew', ''], ['Ammanabrolu', 'Prithviraj', ''], ['Côté', 'Marc-Alexandre', ''], ['Yuan', 'Xingdi', '']]"
2305.04166,Nghia Hieu Nguyen,"Doanh C. Bui, Nghia Hieu Nguyen, Khang Nguyen","UIT-OpenViIC: A Novel Benchmark for Evaluating Image Captioning in
  Vietnamese","10 pages, 7 figures, submitted to Elsevier",,,,cs.CV cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Image Captioning is one of the vision-language tasks that still interest the
research community worldwide in the 2020s. MS-COCO Caption benchmark is
commonly used to evaluate the performance of advanced captioning models,
although it was published in 2015. Recent captioning models trained on the
MS-COCO Caption dataset only have good performance in language patterns of
English; they do not have such good performance in contexts captured in Vietnam
or fluently caption images using Vietnamese. To contribute to the low-resources
research community as in Vietnam, we introduce a novel image captioning dataset
in Vietnamese, the Open-domain Vietnamese Image Captioning dataset
(UIT-OpenViIC). The introduced dataset includes complex scenes captured in
Vietnam and manually annotated by Vietnamese under strict rules and
supervision. In this paper, we present in more detail the dataset creation
process. From preliminary analysis, we show that our dataset is challenging to
recent state-of-the-art (SOTA) Transformer-based baselines, which performed
well on the MS COCO dataset. Then, the modest results prove that UIT-OpenViIC
has room to grow, which can be one of the standard benchmarks in Vietnamese for
the research community to evaluate their captioning models. Furthermore, we
present a CAMO approach that effectively enhances the image representation
ability by a multi-level encoder output fusion mechanism, which helps improve
the quality of generated captions compared to previous captioning models.
","[{'version': 'v1', 'created': 'Sun, 7 May 2023 02:48:47 GMT'}, {'version': 'v2', 'created': 'Tue, 9 May 2023 12:46:06 GMT'}]",2023-05-10,"[['Bui', 'Doanh C.', ''], ['Nguyen', 'Nghia Hieu', ''], ['Nguyen', 'Khang', '']]"
2104.03026,Christian Hardmeier,"Christian Hardmeier, Marta R. Costa-juss\`a, Kellie Webster, Will
  Radford and Su Lin Blodgett","How to Write a Bias Statement: Recommendations for Submissions to the
  Workshop on Gender Bias in NLP","This document was originally published as a blog post on the web site
  of GeBNLP 2020",,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  At the Workshop on Gender Bias in NLP (GeBNLP), we'd like to encourage
authors to give explicit consideration to the wider aspects of bias and its
social implications. For the 2020 edition of the workshop, we therefore
requested that all authors include an explicit bias statement in their work to
clarify how their work relates to the social context in which NLP systems are
used.
  The programme committee of the workshops included a number of reviewers with
a background in the humanities and social sciences, in addition to NLP experts
doing the bulk of the reviewing. Each paper was assigned one of those
reviewers, and they were asked to pay specific attention to the provided bias
statements in their reviews. This initiative was well received by the authors
who submitted papers to the workshop, several of whom said they received useful
suggestions and literature hints from the bias reviewers. We are therefore
planning to keep this feature of the review process in future editions of the
workshop.
","[{'version': 'v1', 'created': 'Wed, 7 Apr 2021 10:00:11 GMT'}]",2021-04-08,"[['Hardmeier', 'Christian', ''], ['Costa-jussà', 'Marta R.', ''], ['Webster', 'Kellie', ''], ['Radford', 'Will', ''], ['Blodgett', 'Su Lin', '']]"
1309.6874,Pengtao Xie,"Pengtao Xie, Eric P. Xing",Integrating Document Clustering and Topic Modeling,"Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)",,,UAI-P-2013-PG-694-703,cs.LG cs.CL cs.IR stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Document clustering and topic modeling are two closely related tasks which
can mutually benefit each other. Topic modeling can project documents into a
topic space which facilitates effective document clustering. Cluster labels
discovered by document clustering can be incorporated into topic models to
extract local topics specific to each cluster and global topics shared by all
clusters. In this paper, we propose a multi-grain clustering topic model
(MGCTM) which integrates document clustering and topic modeling into a unified
framework and jointly performs the two tasks to achieve the overall best
performance. Our model tightly couples two components: a mixture component used
for discovering latent groups in document collection and a topic model
component used for mining multi-grain topics including local topics specific to
each cluster and global topics shared across clusters.We employ variational
inference to approximate the posterior of hidden variables and learn model
parameters. Experiments on two datasets demonstrate the effectiveness of our
model.
","[{'version': 'v1', 'created': 'Thu, 26 Sep 2013 12:54:02 GMT'}]",2013-09-27,"[['Xie', 'Pengtao', ''], ['Xing', 'Eric P.', '']]"
2010.04609,Guohou Shan,"Guohou Shan, James Foulds, Shimei Pan","Causal Feature Selection with Dimension Reduction for Interpretable Text
  Classification","11 pages, 3 pages",,,,cs.LG cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text features that are correlated with class labels, but do not directly
cause them, are sometimesuseful for prediction, but they may not be insightful.
As an alternative to traditional correlation-basedfeature selection, causal
inference could reveal more principled, meaningful relationships betweentext
features and labels. To help researchers gain insight into text data, e.g. for
social scienceapplications, in this paper we investigate a class of
matching-based causal inference methods fortext feature selection. Features
used in document classification are often high dimensional, howeverexisting
causal feature selection methods use Propensity Score Matching (PSM) which is
known to beless effective in high-dimensional spaces. We propose a new causal
feature selection framework thatcombines dimension reduction with causal
inference to improve text feature selection. Experiments onboth synthetic and
real-world data demonstrate the promise of our methods in improving
classificationand enhancing interpretability.
","[{'version': 'v1', 'created': 'Fri, 9 Oct 2020 14:36:49 GMT'}]",2020-10-12,"[['Shan', 'Guohou', ''], ['Foulds', 'James', ''], ['Pan', 'Shimei', '']]"
2310.17143,Zhicheng Lin,Zhicheng Lin,Techniques for supercharging academic writing with generative AI,"14 pages, 2 figures, 1 table, 1 box",,,,cs.CY cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Academic writing is an indispensable yet laborious part of the research
enterprise. This Perspective maps out principles and methods for using
generative artificial intelligence (AI), specifically large language models
(LLMs), to elevate the quality and efficiency of academic writing. We introduce
a human-AI collaborative framework that delineates the rationale (why), process
(how), and nature (what) of AI engagement in writing. The framework pinpoints
both short-term and long-term reasons for engagement and their underlying
mechanisms (e.g., cognitive offloading and imaginative stimulation). It reveals
the role of AI throughout the writing process, conceptualized through a
two-stage model for human-AI collaborative writing, and the nature of AI
assistance in writing, represented through a model of writing-assistance types
and levels. Building on this framework, we describe effective prompting
techniques for incorporating AI into the writing routine (outlining, drafting,
and editing) as well as strategies for maintaining rigorous scholarship,
adhering to varied journal policies, and avoiding overreliance on AI.
Ultimately, the prudent integration of AI into academic writing can ease the
communication burden, empower authors, accelerate discovery, and promote
diversity in science.
","[{'version': 'v1', 'created': 'Thu, 26 Oct 2023 04:35:00 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Feb 2024 05:31:19 GMT'}]",2024-02-14,"[['Lin', 'Zhicheng', '']]"
2210.01877,Xiuying Chen,"Xiuying Chen, Mingzhe Li, Xin Gao, Xiangliang Zhang",Towards Improving Faithfulness in Abstractive Summarization,NeurIPS 2022,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Despite the success achieved in neural abstractive summarization based on
pre-trained language models, one unresolved issue is that the generated
summaries are not always faithful to the input document. There are two possible
causes of the unfaithfulness problem: (1) the summarization model fails to
understand or capture the gist of the input text, and (2) the model over-relies
on the language model to generate fluent but inadequate words. In this work, we
propose a Faithfulness Enhanced Summarization model (FES), which is designed
for addressing these two problems and improving faithfulness in abstractive
summarization. For the first problem, we propose to use question-answering (QA)
to examine whether the encoder fully grasps the input document and can answer
the questions on the key information in the input. The QA attention on the
proper input words can also be used to stipulate how the decoder should attend
to the source. For the second problem, we introduce a max-margin loss defined
on the difference between the language and the summarization model, aiming to
prevent the overconfidence of the language model. Extensive experiments on two
benchmark summarization datasets, CNN/DM and XSum, demonstrate that our model
significantly outperforms strong baselines. The evaluation of factual
consistency also shows that our model generates more faithful summaries than
baselines.
","[{'version': 'v1', 'created': 'Tue, 4 Oct 2022 19:52:09 GMT'}]",2022-10-06,"[['Chen', 'Xiuying', ''], ['Li', 'Mingzhe', ''], ['Gao', 'Xin', ''], ['Zhang', 'Xiangliang', '']]"
2309.06706,Minghan Wang,"Minghan Wang, Jinming Zhao, Thuy-Trang Vu, Fatemeh Shiri, Ehsan
  Shareghi, Gholamreza Haffari",Simultaneous Machine Translation with Large Language Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Real-world simultaneous machine translation (SimulMT) systems face more
challenges than just the quality-latency trade-off. They also need to address
issues related to robustness with noisy input, processing long contexts, and
flexibility for knowledge injection. These challenges demand models with strong
language understanding and generation capabilities which may not often equipped
by dedicated MT models. In this paper, we investigate the possibility of
applying Large Language Models (LLM) to SimulMT tasks by using existing
incremental-decoding methods with a newly proposed RALCP algorithm for latency
reduction. We conducted experiments using the \texttt{Llama2-7b-chat} model on
nine different languages from the MUST-C dataset. The results show that LLM
outperforms dedicated MT models in terms of BLEU and LAAL metrics. Further
analysis indicates that LLM has advantages in terms of tuning efficiency and
robustness. However, it is important to note that the computational cost of LLM
remains a significant obstacle to its application in SimulMT.\footnote{We will
release our code, weights, and data with publication.}
","[{'version': 'v1', 'created': 'Wed, 13 Sep 2023 04:06:47 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Feb 2024 06:50:00 GMT'}]",2024-02-16,"[['Wang', 'Minghan', ''], ['Zhao', 'Jinming', ''], ['Vu', 'Thuy-Trang', ''], ['Shiri', 'Fatemeh', ''], ['Shareghi', 'Ehsan', ''], ['Haffari', 'Gholamreza', '']]"
2310.20111,Dong-Ho Lee,"Dong-Ho Lee, Jay Pujara, Mohit Sewak, Ryen W. White, Sujay Kumar
  Jauhar",Making Large Language Models Better Data Creators,"Accepted to EMNLP 2023 main conference. 12 pages, 5 figures, 6
  tables. Code is available at https://github.com/microsoft/llm-data-creation",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Although large language models (LLMs) have advanced the state-of-the-art in
NLP significantly, deploying them for downstream applications is still
challenging due to cost, responsiveness, control, or concerns around privacy
and security. As such, trainable models are still the preferred option in some
cases. However, these models still require human-labeled data for optimal
performance, which is expensive and time-consuming to obtain. In order to
address this issue, several techniques to reduce human effort involve labeling
or generating data using LLMs. Although these methods are effective for certain
applications, in practice they encounter difficulties in real-world scenarios.
Labeling data requires careful data selection, while generating data
necessitates task-specific prompt engineering. In this paper, we propose a
unified data creation pipeline that requires only a single formatting example,
and which is applicable to a broad range of tasks, including traditionally
problematic ones with semantically devoid label spaces. In our experiments we
demonstrate that instruction-following LLMs are highly cost-effective data
creators, and that models trained with these data exhibit performance better
than those trained with human-labeled data (by up to 17.5%) on
out-of-distribution evaluation, while maintaining comparable performance on
in-distribution tasks. These results have important implications for the
robustness of NLP systems deployed in the real-world.
","[{'version': 'v1', 'created': 'Tue, 31 Oct 2023 01:08:34 GMT'}]",2023-11-01,"[['Lee', 'Dong-Ho', ''], ['Pujara', 'Jay', ''], ['Sewak', 'Mohit', ''], ['White', 'Ryen W.', ''], ['Jauhar', 'Sujay Kumar', '']]"
2109.13711,Mehar Bhatia,"Mehar Bhatia, Tenzin Singhay Bhotia, Akshat Agarwal, Prakash Ramesh,
  Shubham Gupta, Kumar Shridhar, Felix Laumann and Ayushman Dash",One to rule them all: Towards Joint Indic Language Hate Speech Detection,"submitted to FIRE 2021 in the HASOC-FIRE shared task on hate speech
  and offensive language detection",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This paper is a contribution to the Hate Speech and Offensive Content
Identification in Indo-European Languages (HASOC) 2021 shared task. Social
media today is a hotbed of toxic and hateful conversations, in various
languages. Recent news reports have shown that current models struggle to
automatically identify hate posted in minority languages. Therefore,
efficiently curbing hate speech is a critical challenge and problem of
interest. We present a multilingual architecture using state-of-the-art
transformer language models to jointly learn hate and offensive speech
detection across three languages namely, English, Hindi, and Marathi. On the
provided testing corpora, we achieve Macro F1 scores of 0.7996, 0.7748, 0.8651
for sub-task 1A and 0.6268, 0.5603 during the fine-grained classification of
sub-task 1B. These results show the efficacy of exploiting a multilingual
training scheme.
","[{'version': 'v1', 'created': 'Tue, 28 Sep 2021 13:30:00 GMT'}]",2021-09-29,"[['Bhatia', 'Mehar', ''], ['Bhotia', 'Tenzin Singhay', ''], ['Agarwal', 'Akshat', ''], ['Ramesh', 'Prakash', ''], ['Gupta', 'Shubham', ''], ['Shridhar', 'Kumar', ''], ['Laumann', 'Felix', ''], ['Dash', 'Ayushman', '']]"
1610.03120,Hussam Hamdan,Hussam Hamdan,Correlation-Based Method for Sentiment Classification,"I'm not convinced about the significance of this paper in its actual
  state",,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The classic supervised classification algorithms are efficient, but
time-consuming, complicated and not interpretable, which makes it difficult to
analyze their results that limits the possibility to improve them based on real
observations. In this paper, we propose a new and a simple classifier to
predict a sentiment label of a short text. This model keeps the capacity of
human interpret-ability and can be extended to integrate NLP techniques in a
more interpretable way. Our model is based on a correlation metric which
measures the degree of association between a sentiment label and a word. Ten
correlation metrics are proposed and evaluated intrinsically. And then a
classifier based on each metric is proposed, evaluated and compared to the
classic classification algorithms which have proved their performance in many
studies. Our model outperforms these algorithms with several correlation
metrics.
","[{'version': 'v1', 'created': 'Mon, 10 Oct 2016 22:35:21 GMT'}, {'version': 'v2', 'created': 'Thu, 1 Mar 2018 22:37:49 GMT'}]",2018-03-05,"[['Hamdan', 'Hussam', '']]"
2311.09656,Siru Ouyang,"Siru Ouyang, Zhuosheng Zhang, Bing Yan, Xuan Liu, Yejin Choi, Jiawei
  Han, Lianhui Qin",Structured Chemistry Reasoning with Large Language Models,Work in progress,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) excel in diverse areas, yet struggle with
complex scientific reasoning, especially in the field of chemistry. Different
from the simple chemistry tasks (e.g., molecule classification) addressed in
previous studies, complex chemistry problems require not only vast knowledge
and precise calculation, but also compositional reasoning about rich dynamic
interactions of different concepts (e.g., temperature changes). Our study shows
that even advanced LLMs, like GPT-4, can fail easily in different ways.
Interestingly, the errors often stem not from a lack of domain knowledge within
the LLMs, but rather from the absence of an effective reasoning structure that
guides the LLMs to elicit the right knowledge, incorporate the knowledge in
step-by-step reasoning, and iteratively refine results for further improved
quality. On this basis, we introduce StructChem, a simple yet effective
prompting strategy that offers the desired guidance and substantially boosts
the LLMs' chemical reasoning capability. Testing across four chemistry areas --
quantum chemistry, mechanics, physical chemistry, and kinetics -- StructChem
substantially enhances GPT-4's performance, with up to 30\% peak improvement.
Our analysis also underscores the unique difficulties of precise grounded
reasoning in science with LLMs, highlighting a need for more research in this
area. Code is available at \url{https://github.com/ozyyshr/StructChem}.
","[{'version': 'v1', 'created': 'Thu, 16 Nov 2023 08:20:36 GMT'}, {'version': 'v2', 'created': 'Fri, 9 Feb 2024 16:35:28 GMT'}]",2024-02-12,"[['Ouyang', 'Siru', ''], ['Zhang', 'Zhuosheng', ''], ['Yan', 'Bing', ''], ['Liu', 'Xuan', ''], ['Choi', 'Yejin', ''], ['Han', 'Jiawei', ''], ['Qin', 'Lianhui', '']]"
2311.17771,Sim\~ao Gon\c{c}alves,"Sim\~ao Gon\c{c}alves, Gon\c{c}alo Correia, Diogo Pernes, Afonso
  Mendes","Supervising the Centroid Baseline for Extractive Multi-Document
  Summarization","Accepted at ""The 4th New Frontiers in Summarization (with LLMs)
  Workshop""",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The centroid method is a simple approach for extractive multi-document
summarization and many improvements to its pipeline have been proposed. We
further refine it by adding a beam search process to the sentence selection and
also a centroid estimation attention model that leads to improved results. We
demonstrate this in several multi-document summarization datasets, including in
a multilingual scenario.
","[{'version': 'v1', 'created': 'Wed, 29 Nov 2023 16:11:45 GMT'}]",2023-11-30,"[['Gonçalves', 'Simão', ''], ['Correia', 'Gonçalo', ''], ['Pernes', 'Diogo', ''], ['Mendes', 'Afonso', '']]"
2212.10622,Shashi Narayan,"Roee Aharoni, Shashi Narayan, Joshua Maynez, Jonathan Herzig,
  Elizabeth Clark, Mirella Lapata",mFACE: Multilingual Summarization with Factual Consistency Evaluation,28 pages with links to released data,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Abstractive summarization has enjoyed renewed interest in recent years,
thanks to pre-trained language models and the availability of large-scale
datasets. Despite promising results, current models still suffer from
generating factually inconsistent summaries, reducing their utility for
real-world application. Several recent efforts attempt to address this by
devising models that automatically detect factual inconsistencies in machine
generated summaries. However, they focus exclusively on English, a language
with abundant resources. In this work, we leverage factual consistency
evaluation models to improve multilingual summarization. We explore two
intuitive approaches to mitigate hallucinations based on the signal provided by
a multilingual NLI model, namely data filtering and controlled generation.
Experimental results in the 45 languages from the XLSum dataset show gains over
strong baselines in both automatic and human evaluation.
","[{'version': 'v1', 'created': 'Tue, 20 Dec 2022 19:52:41 GMT'}, {'version': 'v2', 'created': 'Fri, 5 Jan 2024 12:13:55 GMT'}]",2024-01-08,"[['Aharoni', 'Roee', ''], ['Narayan', 'Shashi', ''], ['Maynez', 'Joshua', ''], ['Herzig', 'Jonathan', ''], ['Clark', 'Elizabeth', ''], ['Lapata', 'Mirella', '']]"
2401.04152,Jiawen Kang,"Jiawen Kang, Lingwei Meng, Mingyu Cui, Haohan Guo, Xixin Wu, Xunying
  Liu, Helen Meng",Cross-Speaker Encoding Network for Multi-Talker Speech Recognition,Accepted by ICASSP2024,,,,cs.SD cs.AI cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end multi-talker speech recognition has garnered great interest as an
effective approach to directly transcribe overlapped speech from multiple
speakers. Current methods typically adopt either 1) single-input
multiple-output (SIMO) models with a branched encoder, or 2) single-input
single-output (SISO) models based on attention-based encoder-decoder
architecture with serialized output training (SOT). In this work, we propose a
Cross-Speaker Encoding (CSE) network to address the limitations of SIMO models
by aggregating cross-speaker representations. Furthermore, the CSE model is
integrated with SOT to leverage both the advantages of SIMO and SISO while
mitigating their drawbacks. To the best of our knowledge, this work represents
an early effort to integrate SIMO and SISO for multi-talker speech recognition.
Experiments on the two-speaker LibrispeechMix dataset show that the CES model
reduces word error rate (WER) by 8% over the SIMO baseline. The CSE-SOT model
reduces WER by 10% overall and by 16% on high-overlap speech compared to the
SOT model.
","[{'version': 'v1', 'created': 'Mon, 8 Jan 2024 16:37:45 GMT'}]",2024-01-10,"[['Kang', 'Jiawen', ''], ['Meng', 'Lingwei', ''], ['Cui', 'Mingyu', ''], ['Guo', 'Haohan', ''], ['Wu', 'Xixin', ''], ['Liu', 'Xunying', ''], ['Meng', 'Helen', '']]"
2106.14574,Paula Czarnowska,"Paula Czarnowska, Yogarshi Vyas, Kashif Shah","Quantifying Social Biases in NLP: A Generalization and Empirical
  Comparison of Extrinsic Fairness Metrics","Accepted for publication in Transaction of the Association for
  Computational Linguistics (TACL), 2021. The arXiv version is a pre-MIT Press
  publication version",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Measuring bias is key for better understanding and addressing unfairness in
NLP/ML models. This is often done via fairness metrics which quantify the
differences in a model's behaviour across a range of demographic groups. In
this work, we shed more light on the differences and similarities between the
fairness metrics used in NLP. First, we unify a broad range of existing metrics
under three generalized fairness metrics, revealing the connections between
them. Next, we carry out an extensive empirical comparison of existing metrics
and demonstrate that the observed differences in bias measurement can be
systematically explained via differences in parameter choices for our
generalized metrics.
","[{'version': 'v1', 'created': 'Mon, 28 Jun 2021 11:02:33 GMT'}]",2021-06-29,"[['Czarnowska', 'Paula', ''], ['Vyas', 'Yogarshi', ''], ['Shah', 'Kashif', '']]"
2111.08546,Vinitra Swamy,"Vinitra Swamy, Angelika Romanou, Martin Jaggi",Interpreting Language Models Through Knowledge Graph Extraction,"Published at NeurIPS 2021: eXplainable AI for Debugging and Diagnosis
  Workshop",,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Transformer-based language models trained on large text corpora have enjoyed
immense popularity in the natural language processing community and are
commonly used as a starting point for downstream tasks. While these models are
undeniably useful, it is a challenge to quantify their performance beyond
traditional accuracy metrics. In this paper, we compare BERT-based language
models through snapshots of acquired knowledge at sequential stages of the
training process. Structured relationships from training corpora may be
uncovered through querying a masked language model with probing tasks. We
present a methodology to unveil a knowledge acquisition timeline by generating
knowledge graph extracts from cloze ""fill-in-the-blank"" statements at various
stages of RoBERTa's early training. We extend this analysis to a comparison of
pretrained variations of BERT models (DistilBERT, BERT-base, RoBERTa). This
work proposes a quantitative framework to compare language models through
knowledge graph extraction (GED, Graph2Vec) and showcases a part-of-speech
analysis (POSOR) to identify the linguistic strengths of each model variant.
Using these metrics, machine learning practitioners can compare models,
diagnose their models' behavioral strengths and weaknesses, and identify new
targeted datasets to improve model performance.
","[{'version': 'v1', 'created': 'Tue, 16 Nov 2021 15:18:01 GMT'}]",2021-11-17,"[['Swamy', 'Vinitra', ''], ['Romanou', 'Angelika', ''], ['Jaggi', 'Martin', '']]"
2310.03686,Anna Langedijk,"Anna Langedijk, Hosein Mohebbi, Gabriele Sarti, Willem Zuidema, Jaap
  Jumelet",DecoderLens: Layerwise Interpretation of Encoder-Decoder Transformers,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In recent years, many interpretability methods have been proposed to help
interpret the internal states of Transformer-models, at different levels of
precision and complexity. Here, to analyze encoder-decoder Transformers, we
propose a simple, new method: DecoderLens. Inspired by the LogitLens (for
decoder-only Transformers), this method involves allowing the decoder to
cross-attend representations of intermediate encoder layers instead of using
the final encoder output, as is normally done in encoder-decoder models. The
method thus maps previously uninterpretable vector representations to
human-interpretable sequences of words or symbols. We report results from the
DecoderLens applied to models trained on question answering, logical reasoning,
speech recognition and machine translation. The DecoderLens reveals several
specific subtasks that are solved at low or intermediate layers, shedding new
light on the information flow inside the encoder component of this important
class of models.
","[{'version': 'v1', 'created': 'Thu, 5 Oct 2023 17:04:59 GMT'}]",2023-10-06,"[['Langedijk', 'Anna', ''], ['Mohebbi', 'Hosein', ''], ['Sarti', 'Gabriele', ''], ['Zuidema', 'Willem', ''], ['Jumelet', 'Jaap', '']]"
2402.14200,Younghun Lee,"Younghun Lee, Dan Goldwasser, Laura Schwab Reese","Towards Understanding Counseling Conversations: Domain Knowledge and
  Large Language Models","Findings of EACL 2024, 10 pages",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Understanding the dynamics of counseling conversations is an important task,
yet it is a challenging NLP problem regardless of the recent advance of
Transformer-based pre-trained language models. This paper proposes a systematic
approach to examine the efficacy of domain knowledge and large language models
(LLMs) in better representing conversations between a crisis counselor and a
help seeker. We empirically show that state-of-the-art language models such as
Transformer-based models and GPT models fail to predict the conversation
outcome. To provide richer context to conversations, we incorporate
human-annotated domain knowledge and LLM-generated features; simple integration
of domain knowledge and LLM features improves the model performance by
approximately 15%. We argue that both domain knowledge and LLM-generated
features can be exploited to better characterize counseling conversations when
they are used as an additional context to conversations.
","[{'version': 'v1', 'created': 'Thu, 22 Feb 2024 01:02:37 GMT'}]",2024-02-23,"[['Lee', 'Younghun', ''], ['Goldwasser', 'Dan', ''], ['Reese', 'Laura Schwab', '']]"
2401.09343,Vladimir Vlasov,Vladimir Vlasov,Efficient slot labelling,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Slot labelling is an essential component of any dialogue system, aiming to
find important arguments in every user turn. Common approaches involve large
pre-trained language models (PLMs) like BERT or RoBERTa, but they face
challenges such as high computational requirements and dependence on
pre-training data. In this work, we propose a lightweight method which performs
on par or better than the state-of-the-art PLM-based methods, while having
almost 10x less trainable parameters. This makes it especially applicable for
real-life industry scenarios.
","[{'version': 'v1', 'created': 'Wed, 17 Jan 2024 17:08:36 GMT'}, {'version': 'v2', 'created': 'Fri, 19 Jan 2024 13:33:22 GMT'}]",2024-01-22,"[['Vlasov', 'Vladimir', '']]"
2303.09092,Ian Porada,"Ian Porada, Alexandra Olteanu, Kaheer Suleman, Adam Trischler, Jackie
  Chi Kit Cheung",Investigating Failures to Generalize for Coreference Resolution Models,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Coreference resolution models are often evaluated on multiple datasets.
Datasets vary, however, in how coreference is realized -- i.e., how the
theoretical concept of coreference is operationalized in the dataset -- due to
factors such as the choice of corpora and annotation guidelines. We investigate
the extent to which errors of current coreference resolution models are
associated with existing differences in operationalization across datasets
(OntoNotes, PreCo, and Winogrande). Specifically, we distinguish between and
break down model performance into categories corresponding to several types of
coreference, including coreferring generic mentions, compound modifiers, and
copula predicates, among others. This break down helps us investigate how
state-of-the-art models might vary in their ability to generalize across
different coreference types. In our experiments, for example, models trained on
OntoNotes perform poorly on generic mentions and copula predicates in PreCo.
Our findings help calibrate expectations of current coreference resolution
models; and, future work can explicitly account for those types of coreference
that are empirically associated with poor generalization when developing
models.
","[{'version': 'v1', 'created': 'Thu, 16 Mar 2023 05:32:02 GMT'}]",2023-03-17,"[['Porada', 'Ian', ''], ['Olteanu', 'Alexandra', ''], ['Suleman', 'Kaheer', ''], ['Trischler', 'Adam', ''], ['Cheung', 'Jackie Chi Kit', '']]"
1912.03627,Hossein Zeinali,"Hossein Zeinali, Luk\'a\v{s} Burget, Jan ""Honza'' \v{C}ernock\'y","A Multi Purpose and Large Scale Speech Corpus in Persian and English for
  Speaker and Speech Recognition: the DeepMine Database",,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  DeepMine is a speech database in Persian and English designed to build and
evaluate text-dependent, text-prompted, and text-independent speaker
verification, as well as Persian speech recognition systems. It contains more
than 1850 speakers and 540 thousand recordings overall, more than 480 hours of
speech are transcribed. It is the first public large-scale speaker verification
database in Persian, the largest public text-dependent and text-prompted
speaker verification database in English, and the largest public evaluation
dataset for text-independent speaker verification. It has a good coverage of
age, gender, and accents. We provide several evaluation protocols for each part
of the database to allow for research on different aspects of speaker
verification. We also provide the results of several experiments that can be
considered as baselines: HMM-based i-vectors for text-dependent speaker
verification, and HMM-based as well as state-of-the-art deep neural network
based ASR. We demonstrate that the database can serve for training robust ASR
models.
","[{'version': 'v1', 'created': 'Sun, 8 Dec 2019 07:05:36 GMT'}]",2019-12-10,"[['Zeinali', 'Hossein', ''], ['Burget', 'Lukáš', ''], ['Černocký', 'Jan ""Honza\'\'', '']]"
2103.16789,Sachin Kumar,"Lidia Kidane, Sachin Kumar, Yulia Tsvetkov","An Exploration of Data Augmentation Techniques for Improving English to
  Tigrinya Translation","Accepted at AfricaNLP Workshop, EACL 2021",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  It has been shown that the performance of neural machine translation (NMT)
drops starkly in low-resource conditions, often requiring large amounts of
auxiliary data to achieve competitive results. An effective method of
generating auxiliary data is back-translation of target language sentences. In
this work, we present a case study of Tigrinya where we investigate several
back-translation methods to generate synthetic source sentences. We find that
in low-resource conditions, back-translation by pivoting through a
higher-resource language related to the target language proves most effective
resulting in substantial improvements over baselines.
","[{'version': 'v1', 'created': 'Wed, 31 Mar 2021 03:31:09 GMT'}, {'version': 'v2', 'created': 'Sun, 4 Apr 2021 23:48:18 GMT'}]",2021-04-06,"[['Kidane', 'Lidia', ''], ['Kumar', 'Sachin', ''], ['Tsvetkov', 'Yulia', '']]"
2212.06556,Moritz Ibing,"Moritz Ibing, Isaak Lim, Leif Kobbelt",Localized Latent Updates for Fine-Tuning Vision-Language Models,,,,,cs.CV cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Although massive pre-trained vision-language models like CLIP show impressive
generalization capabilities for many tasks, still it often remains necessary to
fine-tune them for improved performance on specific datasets. When doing so, it
is desirable that updating the model is fast and that the model does not lose
its capabilities on data outside of the dataset, as is often the case with
classical fine-tuning approaches. In this work we suggest a lightweight
adapter, that only updates the models predictions close to seen datapoints. We
demonstrate the effectiveness and speed of this relatively simple approach in
the context of few-shot learning, where our results both on classes seen and
unseen during training are comparable with or improve on the state of the art.
","[{'version': 'v1', 'created': 'Tue, 13 Dec 2022 13:15:20 GMT'}]",2022-12-14,"[['Ibing', 'Moritz', ''], ['Lim', 'Isaak', ''], ['Kobbelt', 'Leif', '']]"
cmp-lg/9504002,David Elworthy,David Elworthy,Tagset Design and Inflected Languages,"EACL-94 SIGDAT paper. Includes large tables and figures, which may
  upset some version of LaTeX. Revised version to correct a minor typo!",,,,cmp-lg cs.CL,,"  An experiment designed to explore the relationship between tagging accuracy
and the nature of the tagset is described, using corpora in English, French and
Swedish. In particular, the question of internal versus external criteria for
tagset design is considered, with the general conclusion that external
(linguistic) criteria should be followed. Some problems associated with tagging
unknown words in inflected languages are briefly considered.
","[{'version': 'v1', 'created': 'Mon, 3 Apr 1995 15:47:58 GMT'}, {'version': 'v2', 'created': 'Tue, 4 Apr 1995 07:39:32 GMT'}]",2008-02-03,"[['Elworthy', 'David', '']]"
2205.10866,Paola Merlo,"Paola Merlo, Aixiu An and Maria A. Rodriguez","Blackbird's language matrices (BLMs): a new benchmark to investigate
  disentangled generalisation in neural networks","15 pages, 9 figures, 1 table",,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Current successes of machine learning architectures are based on
computationally expensive algorithms and prohibitively large amounts of data.
We need to develop tasks and data to train networks to reach more complex and
more compositional skills. In this paper, we illustrate Blackbird's language
matrices (BLMs), a novel grammatical dataset developed to test a linguistic
variant of Raven's progressive matrices, an intelligence test usually based on
visual stimuli. The dataset consists of 44800 sentences, generatively
constructed to support investigations of current models' linguistic mastery of
grammatical agreement rules and their ability to generalise them. We present
the logic of the dataset, the method to automatically construct data on a large
scale and the architecture to learn them. Through error analysis and several
experiments on variations of the dataset, we demonstrate that this language
task and the data that instantiate it provide a new challenging testbed to
understand generalisation and abstraction.
","[{'version': 'v1', 'created': 'Sun, 22 May 2022 16:51:24 GMT'}]",2022-05-24,"[['Merlo', 'Paola', ''], ['An', 'Aixiu', ''], ['Rodriguez', 'Maria A.', '']]"
2312.06337,Yuntao Shou,"Tao Meng, Yuntao Shou, Wei Ai, Nan Yin, Keqin Li","Deep Imbalanced Learning for Multimodal Emotion Recognition in
  Conversations","16 pages, 9 figures",,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The main task of Multimodal Emotion Recognition in Conversations (MERC) is to
identify the emotions in modalities, e.g., text, audio, image and video, which
is a significant development direction for realizing machine intelligence.
However, many data in MERC naturally exhibit an imbalanced distribution of
emotion categories, and researchers ignore the negative impact of imbalanced
data on emotion recognition. To tackle this problem, we systematically analyze
it from three aspects: data augmentation, loss sensitivity, and sampling
strategy, and propose the Class Boundary Enhanced Representation Learning
(CBERL) model. Concretely, we first design a multimodal generative adversarial
network to address the imbalanced distribution of {emotion} categories in raw
data. Secondly, a deep joint variational autoencoder is proposed to fuse
complementary semantic information across modalities and obtain discriminative
feature representations. Finally, we implement a multi-task graph neural
network with mask reconstruction and classification optimization to solve the
problem of overfitting and underfitting in class boundary learning, and achieve
cross-modal emotion recognition. We have conducted extensive experiments on the
IEMOCAP and MELD benchmark datasets, and the results show that CBERL has
achieved a certain performance improvement in the effectiveness of emotion
recognition. Especially on the minority class fear and disgust emotion labels,
our model improves the accuracy and F1 value by 10% to 20%.
","[{'version': 'v1', 'created': 'Mon, 11 Dec 2023 12:35:17 GMT'}]",2023-12-12,"[['Meng', 'Tao', ''], ['Shou', 'Yuntao', ''], ['Ai', 'Wei', ''], ['Yin', 'Nan', ''], ['Li', 'Keqin', '']]"
1204.6441,Daniel Gayo Avello,Daniel Gayo-Avello,"""I Wanted to Predict Elections with Twitter and all I got was this Lousy
  Paper"" -- A Balanced Survey on Election Prediction using Twitter Data","13 pages, no figures. Annotated bibliography of 25 papers regarding
  electoral prediction from Twitter data",,,,cs.CY cs.CL cs.SI physics.soc-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Predicting X from Twitter is a popular fad within the Twitter research
subculture. It seems both appealing and relatively easy. Among such kind of
studies, electoral prediction is maybe the most attractive, and at this moment
there is a growing body of literature on such a topic. This is not only an
interesting research problem but, above all, it is extremely difficult.
However, most of the authors seem to be more interested in claiming positive
results than in providing sound and reproducible methods. It is also especially
worrisome that many recent papers seem to only acknowledge those studies
supporting the idea of Twitter predicting elections, instead of conducting a
balanced literature review showing both sides of the matter. After reading many
of such papers I have decided to write such a survey myself. Hence, in this
paper, every study relevant to the matter of electoral prediction using social
media is commented. From this review it can be concluded that the predictive
power of Twitter regarding elections has been greatly exaggerated, and that
hard research problems still lie ahead.
","[{'version': 'v1', 'created': 'Sat, 28 Apr 2012 22:18:06 GMT'}]",2015-03-20,"[['Gayo-Avello', 'Daniel', '']]"
2107.04082,Andros Tjandra,"Andros Tjandra, Diptanu Gon Choudhury, Frank Zhang, Kritika Singh,
  Alexis Conneau, Alexei Baevski, Assaf Sela, Yatharth Saraf, Michael Auli","Improved Language Identification Through Cross-Lingual Self-Supervised
  Learning",,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language identification greatly impacts the success of downstream tasks such
as automatic speech recognition. Recently, self-supervised speech
representations learned by wav2vec 2.0 have been shown to be very effective for
a range of speech tasks. We extend previous self-supervised work on language
identification by experimenting with pre-trained models which were learned on
real-world unconstrained speech in multiple languages and not just on English.
We show that models pre-trained on many languages perform better and enable
language identification systems that require very little labeled data to
perform well. Results on a 26 languages setup show that with only 10 minutes of
labeled data per language, a cross-lingually pre-trained model can achieve over
89.2% accuracy.
","[{'version': 'v1', 'created': 'Thu, 8 Jul 2021 19:37:06 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Jul 2021 03:24:21 GMT'}, {'version': 'v3', 'created': 'Wed, 4 Aug 2021 20:04:24 GMT'}, {'version': 'v4', 'created': 'Mon, 18 Oct 2021 03:49:06 GMT'}]",2021-10-19,"[['Tjandra', 'Andros', ''], ['Choudhury', 'Diptanu Gon', ''], ['Zhang', 'Frank', ''], ['Singh', 'Kritika', ''], ['Conneau', 'Alexis', ''], ['Baevski', 'Alexei', ''], ['Sela', 'Assaf', ''], ['Saraf', 'Yatharth', ''], ['Auli', 'Michael', '']]"
2210.12346,Sicong Shao,"Sicong Shao, Saleem Alharir, Salim Hariri, Pratik Satam, Sonia Shiri,
  Abdessamad Mbarki",AI-based Arabic Language and Speech Tutor,"Accepted to the 19th IEEE/ACS International Conference on Computer
  Systems and Applications",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In the past decade, we have observed a growing interest in using technologies
such as artificial intelligence (AI), machine learning, and chatbots to provide
assistance to language learners, especially in second language learning. By
using AI and natural language processing (NLP) and chatbots, we can create an
intelligent self-learning environment that goes beyond multiple-choice
questions and/or fill in the blank exercises. In addition, NLP allows for
learning to be adaptive in that it offers more than an indication that an error
has occurred. It also provides a description of the error, uses linguistic
analysis to isolate the source of the error, and then suggests additional
drills to achieve optimal individualized learning outcomes. In this paper, we
present our approach for developing an Artificial Intelligence-based Arabic
Language and Speech Tutor (AI-ALST) for teaching the Moroccan Arabic dialect.
The AI-ALST system is an intelligent tutor that provides analysis and
assessment of students learning the Moroccan dialect at University of Arizona
(UA). The AI-ALST provides a self-learned environment to practice each lesson
for pronunciation training. In this paper, we present our initial experimental
evaluation of the AI-ALST that is based on MFCC (Mel frequency cepstrum
coefficient) feature extraction, bidirectional LSTM (Long Short-Term Memory),
attention mechanism, and a cost-based strategy for dealing with class-imbalance
learning. We evaluated our tutor on the word pronunciation of lesson 1 of the
Moroccan Arabic dialect class. The experimental results show that the AI-ALST
can effectively and successfully detect pronunciation errors and evaluate its
performance by using F_1-score, accuracy, precision, and recall.
","[{'version': 'v1', 'created': 'Sat, 22 Oct 2022 04:22:16 GMT'}]",2022-10-25,"[['Shao', 'Sicong', ''], ['Alharir', 'Saleem', ''], ['Hariri', 'Salim', ''], ['Satam', 'Pratik', ''], ['Shiri', 'Sonia', ''], ['Mbarki', 'Abdessamad', '']]"
1908.07590,Songwei Ge,"Songwei Ge, Curtis Xuan, Ruihua Song, Chao Zou, Wei Liu, Jin Zhou","From Text to Sound: A Preliminary Study on Retrieving Sound Effects to
  Radio Stories","In the Proceedings of the 42nd International ACM SIGIR Conference on
  Research and Development in Information Retrieval (SIGIR 2019)",,,,cs.IR cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sound effects play an essential role in producing high-quality radio stories
but require enormous labor cost to add. In this paper, we address the problem
of automatically adding sound effects to radio stories with a retrieval-based
model. However, directly implementing a tag-based retrieval model leads to high
false positives due to the ambiguity of story contents. To solve this problem,
we introduce a retrieval-based framework hybridized with a semantic inference
model which helps to achieve robust retrieval results. Our model relies on
fine-designed features extracted from the context of candidate triggers. We
collect two story dubbing datasets through crowdsourcing to analyze the setting
of adding sound effects and to train and test our proposed methods. We further
discuss the importance of each feature and introduce several heuristic rules
for the trade-off between precision and recall. Together with the
text-to-speech technology, our results reveal a promising automatic pipeline on
producing high-quality radio stories.
","[{'version': 'v1', 'created': 'Tue, 20 Aug 2019 20:10:05 GMT'}]",2019-08-22,"[['Ge', 'Songwei', ''], ['Xuan', 'Curtis', ''], ['Song', 'Ruihua', ''], ['Zou', 'Chao', ''], ['Liu', 'Wei', ''], ['Zhou', 'Jin', '']]"
2110.08214,Danni Liu,"Danni Liu, Changhan Wang, Hongyu Gong, Xutai Ma, Yun Tang, Juan Pino","From Start to Finish: Latency Reduction Strategies for Incremental
  Speech Synthesis in Simultaneous Speech-to-Speech Translation",Accepted by Interspeech 2022,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Speech-to-speech translation (S2ST) converts input speech to speech in
another language. A challenge of delivering S2ST in real time is the
accumulated delay between the translation and speech synthesis modules. While
recently incremental text-to-speech (iTTS) models have shown large quality
improvements, they typically require additional future text inputs to reach
optimal performance. In this work, we minimize the initial waiting time of iTTS
by adapting the upstream speech translator to generate high-quality pseudo
lookahead for the speech synthesizer. After mitigating the initial delay, we
demonstrate that the duration of synthesized speech also plays a crucial role
on latency. We formalize this as a latency metric and then present a simple yet
effective duration-scaling approach for latency reduction. Our approaches
consistently reduce latency by 0.2-0.5 second without sacrificing speech
translation quality.
","[{'version': 'v1', 'created': 'Fri, 15 Oct 2021 17:20:28 GMT'}, {'version': 'v2', 'created': 'Tue, 29 Mar 2022 16:51:40 GMT'}, {'version': 'v3', 'created': 'Fri, 15 Jul 2022 16:18:36 GMT'}]",2022-07-18,"[['Liu', 'Danni', ''], ['Wang', 'Changhan', ''], ['Gong', 'Hongyu', ''], ['Ma', 'Xutai', ''], ['Tang', 'Yun', ''], ['Pino', 'Juan', '']]"
2110.05115,Judicael Poumay,"Judicael Poumay, Ashwin Ittoo","A Comprehensive Comparison of Word Embeddings in Event & Entity
  Coreference Resolution","10 pages, 1 table,10 figures, to be published in Findings of EMNLP
  2021",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Coreference Resolution is an important NLP task and most state-of-the-art
methods rely on word embeddings for word representation. However, one issue
that has been largely overlooked in literature is that of comparing the
performance of different embeddings across and within families in this task.
Therefore, we frame our study in the context of Event and Entity Coreference
Resolution (EvCR & EnCR), and address two questions : 1) Is there a trade-off
between performance (predictive & run-time) and embedding size? 2) How do the
embeddings' performance compare within and across families? Our experiments
reveal several interesting findings. First, we observe diminishing returns in
performance with respect to embedding size. E.g. a model using solely a
character embedding achieves 86% of the performance of the largest model (Elmo,
GloVe, Character) while being 1.2% of its size. Second, the larger model using
multiple embeddings learns faster overall despite being slower per epoch.
However, it is still slower at test time. Finally, Elmo performs best on both
EvCR and EnCR, while GloVe and FastText perform best in EvCR and EnCR
respectively.
","[{'version': 'v1', 'created': 'Mon, 11 Oct 2021 09:46:46 GMT'}]",2021-10-12,"[['Poumay', 'Judicael', ''], ['Ittoo', 'Ashwin', '']]"
2210.06432,Wu Xing,"Xing Wu, Chaochen Gao, Zijia Lin, Jizhong Han, Zhongyuan Wang, Songlin
  Hu","InfoCSE: Information-aggregated Contrastive Learning of Sentence
  Embeddings",EMNLP 2022,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Contrastive learning has been extensively studied in sentence embedding
learning, which assumes that the embeddings of different views of the same
sentence are closer. The constraint brought by this assumption is weak, and a
good sentence representation should also be able to reconstruct the original
sentence fragments. Therefore, this paper proposes an information-aggregated
contrastive learning framework for learning unsupervised sentence embeddings,
termed InfoCSE. InfoCSE forces the representation of [CLS] positions to
aggregate denser sentence information by introducing an additional Masked
language model task and a well-designed network. We evaluate the proposed
InfoCSE on several benchmark datasets w.r.t the semantic text similarity (STS)
task. Experimental results show that InfoCSE outperforms SimCSE by an average
Spearman correlation of 2.60% on BERT-base, and 1.77% on BERT-large, achieving
state-of-the-art results among unsupervised sentence representation learning
methods. Our code are available at
https://github.com/caskcsg/sentemb/tree/main/InfoCSE.
","[{'version': 'v1', 'created': 'Sat, 8 Oct 2022 15:53:19 GMT'}, {'version': 'v2', 'created': 'Thu, 13 Oct 2022 12:06:58 GMT'}, {'version': 'v3', 'created': 'Fri, 14 Oct 2022 03:32:56 GMT'}]",2022-10-17,"[['Wu', 'Xing', ''], ['Gao', 'Chaochen', ''], ['Lin', 'Zijia', ''], ['Han', 'Jizhong', ''], ['Wang', 'Zhongyuan', ''], ['Hu', 'Songlin', '']]"
2208.05782,Georgios Karakasidis,"Georgios Karakasidis, Tam\'as Gr\'osz, Mikko Kurimo",Comparison and Analysis of New Curriculum Criteria for End-to-End ASR,"5 pages, 2 figures, in Proceedings Interspeech 2022",,,,eess.AS cs.CL cs.LG cs.SD,http://creativecommons.org/licenses/by/4.0/,"  It is common knowledge that the quantity and quality of the training data
play a significant role in the creation of a good machine learning model. In
this paper, we take it one step further and demonstrate that the way the
training examples are arranged is also of crucial importance. Curriculum
Learning is built on the observation that organized and structured assimilation
of knowledge has the ability to enable faster training and better
comprehension. When humans learn to speak, they first try to utter basic phones
and then gradually move towards more complex structures such as words and
sentences. This methodology is known as Curriculum Learning, and we employ it
in the context of Automatic Speech Recognition. We hypothesize that end-to-end
models can achieve better performance when provided with an organized training
set consisting of examples that exhibit an increasing level of difficulty (i.e.
a curriculum). To impose structure on the training set and to define the notion
of an easy example, we explored multiple scoring functions that either use
feedback from an external neural network or incorporate feedback from the model
itself. Empirical results show that with different curriculums we can balance
the training times and the network's performance.
","[{'version': 'v1', 'created': 'Wed, 10 Aug 2022 06:56:58 GMT'}]",2022-08-12,"[['Karakasidis', 'Georgios', ''], ['Grósz', 'Tamás', ''], ['Kurimo', 'Mikko', '']]"
2310.19708,Aviv Shamsian,"Daniel Eitan, Menachem Pirchi, Neta Glazer, Shai Meital, Gil Ayach,
  Gidon Krendel, Aviv Shamsian, Aviv Navon, Gil Hetz, Joseph Keshet",Combining Language Models For Specialized Domains: A Colorful Approach,Under Review,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  General purpose language models (LMs) encounter difficulties when processing
domain-specific jargon and terminology, which are frequently utilized in
specialized fields such as medicine or industrial settings. Moreover, they
often find it challenging to interpret mixed speech that blends general
language with specialized jargon. This poses a challenge for automatic speech
recognition systems operating within these specific domains. In this work, we
introduce a novel approach that integrates domain-specific or secondary LM into
general-purpose LM. This strategy involves labeling, or ""coloring"", each word
to indicate its association with either the general or the domain-specific LM.
We develop an optimized algorithm that enhances the beam search algorithm to
effectively handle inferences involving colored words. Our evaluations indicate
that this approach is highly effective in integrating jargon into language
tasks. Notably, our method substantially lowers the error rate for
domain-specific words without compromising performance in the general domain.
","[{'version': 'v1', 'created': 'Mon, 30 Oct 2023 16:35:55 GMT'}, {'version': 'v2', 'created': 'Tue, 31 Oct 2023 08:37:40 GMT'}, {'version': 'v3', 'created': 'Wed, 1 Nov 2023 07:55:28 GMT'}]",2023-11-02,"[['Eitan', 'Daniel', ''], ['Pirchi', 'Menachem', ''], ['Glazer', 'Neta', ''], ['Meital', 'Shai', ''], ['Ayach', 'Gil', ''], ['Krendel', 'Gidon', ''], ['Shamsian', 'Aviv', ''], ['Navon', 'Aviv', ''], ['Hetz', 'Gil', ''], ['Keshet', 'Joseph', '']]"
2310.03840,Zhu Wang,Zhu Wang,Contextualized Structural Self-supervised Learning for Ontology Matching,,,,,cs.LG cs.AI cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Ontology matching (OM) entails the identification of semantic relationships
between concepts within two or more knowledge graphs (KGs) and serves as a
critical step in integrating KGs from various sources. Recent advancements in
deep OM models have harnessed the power of transformer-based language models
and the advantages of knowledge graph embedding. Nevertheless, these OM models
still face persistent challenges, such as a lack of reference alignments,
runtime latency, and unexplored different graph structures within an end-to-end
framework. In this study, we introduce a novel self-supervised learning OM
framework with input ontologies, called LaKERMap. This framework capitalizes on
the contextual and structural information of concepts by integrating implicit
knowledge into transformers. Specifically, we aim to capture multiple
structural contexts, encompassing both local and global interactions, by
employing distinct training objectives. To assess our methods, we utilize the
Bio-ML datasets and tasks. The findings from our innovative approach reveal
that LaKERMap surpasses state-of-the-art systems in terms of alignment quality
and inference time. Our models and codes are available here:
https://github.com/ellenzhuwang/lakermap.
","[{'version': 'v1', 'created': 'Thu, 5 Oct 2023 18:51:33 GMT'}]",2023-10-09,"[['Wang', 'Zhu', '']]"
2211.08295,Paul K. Mandal,"Paul K. Mandal, Rakeshkumar Mahto",An FNet based Auto Encoder for Long Sequence News Story Generation,"7 pages, 6 figures",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we design an auto encoder based off of Google's FNet
Architecture in order to generate text from a subset of news stories contained
in Google's C4 dataset. We discuss previous attempts and methods to generate
text from autoencoders and non LLM Models. FNET poses multiple advantages to
BERT based encoders in the realm of efficiency which train 80% faster on GPUs
and 70% faster on TPUs. We then compare outputs of how this autencoder perfroms
on different epochs. Finally, we analyze what outputs the encoder produces with
different seed text.
","[{'version': 'v1', 'created': 'Tue, 15 Nov 2022 16:48:09 GMT'}, {'version': 'v2', 'created': 'Thu, 17 Nov 2022 13:52:14 GMT'}]",2022-11-18,"[['Mandal', 'Paul K.', ''], ['Mahto', 'Rakeshkumar', '']]"
1506.06418,Raphael Hoffmann,"Raphael Hoffmann, Luke Zettlemoyer, Daniel S. Weld",Extreme Extraction: Only One Hour per Relation,,,,,cs.CL cs.AI cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Information Extraction (IE) aims to automatically generate a large knowledge
base from natural language text, but progress remains slow. Supervised learning
requires copious human annotation, while unsupervised and weakly supervised
approaches do not deliver competitive accuracy. As a result, most fielded
applications of IE, as well as the leading TAC-KBP systems, rely on significant
amounts of manual engineering. Even ""Extreme"" methods, such as those reported
in Freedman et al. 2011, require about 10 hours of expert labor per relation.
  This paper shows how to reduce that effort by an order of magnitude. We
present a novel system, InstaRead, that streamlines authoring with an ensemble
of methods: 1) encoding extraction rules in an expressive and compositional
representation, 2) guiding the user to promising rules based on corpus
statistics and mined resources, and 3) introducing a new interactive
development cycle that provides immediate feedback --- even on large datasets.
Experiments show that experts can create quality extractors in under an hour
and even NLP novices can author good extractors. These extractors equal or
outperform ones obtained by comparably supervised and state-of-the-art
distantly supervised approaches.
","[{'version': 'v1', 'created': 'Sun, 21 Jun 2015 22:04:39 GMT'}]",2015-06-23,"[['Hoffmann', 'Raphael', ''], ['Zettlemoyer', 'Luke', ''], ['Weld', 'Daniel S.', '']]"
2302.01806,Hoang Nguyen Hung Van,Hoang Van,Mitigating Data Scarcity for Large Language Models,"155 pages, 26 tables, 11 figures",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In recent years, pretrained neural language models (PNLMs) have taken the
field of natural language processing by storm, achieving new benchmarks and
state-of-the-art performances. These models often rely heavily on annotated
data, which may not always be available. Data scarcity are commonly found in
specialized domains, such as medical, or in low-resource languages that are
underexplored by AI research. In this dissertation, we focus on mitigating data
scarcity using data augmentation and neural ensemble learning techniques for
neural language models. In both research directions, we implement neural
network algorithms and evaluate their impact on assisting neural language
models in downstream NLP tasks. Specifically, for data augmentation, we explore
two techniques: 1) creating positive training data by moving an answer span
around its original context and 2) using text simplification techniques to
introduce a variety of writing styles to the original training data. Our
results indicate that these simple and effective solutions improve the
performance of neural language models considerably in low-resource NLP domains
and tasks. For neural ensemble learning, we use a multilabel neural classifier
to select the best prediction outcome from a variety of individual pretrained
neural language models trained for a low-resource medical text simplification
task.
","[{'version': 'v1', 'created': 'Fri, 3 Feb 2023 15:17:53 GMT'}]",2023-02-06,"[['Van', 'Hoang', '']]"
1912.00991,"Samuel R\""onnqvist","Nelda Kote, Marenglen Biba, Jenna Kanerva, Samuel R\""onnqvist, Filip
  Ginter","Morphological Tagging and Lemmatization of Albanian: A Manually
  Annotated Corpus and Neural Models",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we present the first publicly available part-of-speech and
morphologically tagged corpus for the Albanian language, as well as a neural
morphological tagger and lemmatizer trained on it. There is currently a lack of
available NLP resources for Albanian, and its complex grammar and morphology
present challenges to their development. We have created an Albanian
part-of-speech corpus based on the Universal Dependencies schema for
morphological annotation, containing about 118,000 tokens of naturally occuring
text collected from different text sources, with an addition of 67,000 tokens
of artificially created simple sentences used only in training. On this corpus,
we subsequently train and evaluate segmentation, morphological tagging and
lemmatization models, using the Turku Neural Parser Pipeline. On the held-out
evaluation set, the model achieves 92.74% accuracy on part-of-speech tagging,
85.31% on morphological tagging, and 89.95% on lemmatization. The manually
annotated corpus, as well as the trained models are available under an open
license.
","[{'version': 'v1', 'created': 'Mon, 2 Dec 2019 18:50:37 GMT'}]",2019-12-03,"[['Kote', 'Nelda', ''], ['Biba', 'Marenglen', ''], ['Kanerva', 'Jenna', ''], ['Rönnqvist', 'Samuel', ''], ['Ginter', 'Filip', '']]"
2306.01128,Dan Friedman,"Dan Friedman, Alexander Wettig, Danqi Chen",Learning Transformer Programs,"NeurIPS 2023 (oral). Our code is available at
  https://github.com/princeton-nlp/TransformerPrograms",,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent research in mechanistic interpretability has attempted to
reverse-engineer Transformer models by carefully inspecting network weights and
activations. However, these approaches require considerable manual effort and
still fall short of providing complete, faithful descriptions of the underlying
algorithms. In this work, we introduce a procedure for training Transformers
that are mechanistically interpretable by design. We build on RASP [Weiss et
al., 2021], a programming language that can be compiled into Transformer
weights. Instead of compiling human-written programs into Transformers, we
design a modified Transformer that can be trained using gradient-based
optimization and then automatically converted into a discrete, human-readable
program. We refer to these models as Transformer Programs. To validate our
approach, we learn Transformer Programs for a variety of problems, including an
in-context learning task, a suite of algorithmic problems (e.g. sorting,
recognizing Dyck languages), and NLP tasks including named entity recognition
and text classification. The Transformer Programs can automatically find
reasonable solutions, performing on par with standard Transformers of
comparable size; and, more importantly, they are easy to interpret. To
demonstrate these advantages, we convert Transformers into Python programs and
use off-the-shelf code analysis tools to debug model errors and identify the
""circuits"" used to solve different sub-problems. We hope that Transformer
Programs open a new path toward the goal of intrinsically interpretable machine
learning.
","[{'version': 'v1', 'created': 'Thu, 1 Jun 2023 20:27:01 GMT'}, {'version': 'v2', 'created': 'Tue, 31 Oct 2023 00:47:31 GMT'}]",2023-11-01,"[['Friedman', 'Dan', ''], ['Wettig', 'Alexander', ''], ['Chen', 'Danqi', '']]"
1905.01998,Oluwatobi Olabiyi,"Oluwatobi O. Olabiyi, Anish Khazane, Erik T. Mueller","A Persona-based Multi-turn Conversation Model in an Adversarial Learning
  Framework","2018 17th IEEE International Conference on Machine Learning and
  Applications (ICMLA). arXiv admin note: substantial text overlap with
  arXiv:1905.01992",,,,cs.CL cs.LG stat.ML,http://creativecommons.org/publicdomain/zero/1.0/,"  In this paper, we extend the persona-based sequence-to-sequence (Seq2Seq)
neural network conversation model to multi-turn dialogue by modifying the
state-of-the-art hredGAN architecture. To achieve this, we introduce an
additional input modality into the encoder and decoder of hredGAN to capture
other attributes such as speaker identity, location, sub-topics, and other
external attributes that might be available from the corpus of human-to-human
interactions. The resulting persona hredGAN ($phredGAN$) shows better
performance than both the existing persona-based Seq2Seq and hredGAN models
when those external attributes are available in a multi-turn dialogue corpus.
This superiority is demonstrated on TV drama series with character consistency
(such as Big Bang Theory and Friends) and customer service interaction datasets
such as Ubuntu dialogue corpus in terms of perplexity, BLEU, ROUGE, and
Distinct n-gram scores.
","[{'version': 'v1', 'created': 'Mon, 29 Apr 2019 15:09:34 GMT'}]",2019-05-07,"[['Olabiyi', 'Oluwatobi O.', ''], ['Khazane', 'Anish', ''], ['Mueller', 'Erik T.', '']]"
2204.00176,Tatsuya Komatsu,"Tatsuya Komatsu, Yusuke Fujita, Jaesong Lee, Lukas Lee, Shinji
  Watanabe, Yusuke Kida",Better Intermediates Improve CTC Inference,"5 pages, submitted INTERSPEECH2022",,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper proposes a method for improved CTC inference with searched
intermediates and multi-pass conditioning. The paper first formulates
self-conditioned CTC as a probabilistic model with an intermediate prediction
as a latent representation and provides a tractable conditioning framework. We
then propose two new conditioning methods based on the new formulation: (1)
Searched intermediate conditioning that refines intermediate predictions with
beam-search, (2) Multi-pass conditioning that uses predictions of previous
inference for conditioning the next inference. These new approaches enable
better conditioning than the original self-conditioned CTC during inference and
improve the final performance. Experiments with the LibriSpeech dataset show
relative 3%/12% performance improvement at the maximum in test clean/other sets
compared to the original self-conditioned CTC.
","[{'version': 'v1', 'created': 'Fri, 1 Apr 2022 02:51:23 GMT'}]",2022-04-04,"[['Komatsu', 'Tatsuya', ''], ['Fujita', 'Yusuke', ''], ['Lee', 'Jaesong', ''], ['Lee', 'Lukas', ''], ['Watanabe', 'Shinji', ''], ['Kida', 'Yusuke', '']]"
2205.10726,Ruofan Hu,"Ruofan Hu, Dongyu Zhang, Dandan Tao, Thomas Hartvigsen, Hao Feng, Elke
  Rundensteiner","TWEET-FID: An Annotated Dataset for Multiple Foodborne Illness Detection
  Tasks",LREC 2022,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Foodborne illness is a serious but preventable public health problem -- with
delays in detecting the associated outbreaks resulting in productivity loss,
expensive recalls, public safety hazards, and even loss of life. While social
media is a promising source for identifying unreported foodborne illnesses,
there is a dearth of labeled datasets for developing effective outbreak
detection models. To accelerate the development of machine learning-based
models for foodborne outbreak detection, we thus present TWEET-FID
(TWEET-Foodborne Illness Detection), the first publicly available annotated
dataset for multiple foodborne illness incident detection tasks. TWEET-FID
collected from Twitter is annotated with three facets: tweet class, entity
type, and slot type, with labels produced by experts as well as by crowdsource
workers. We introduce several domain tasks leveraging these three facets: text
relevance classification (TRC), entity mention detection (EMD), and slot
filling (SF). We describe the end-to-end methodology for dataset design,
creation, and labeling for supporting model development for these tasks. A
comprehensive set of results for these tasks leveraging state-of-the-art
single- and multi-task deep learning methods on the TWEET-FID dataset are
provided. This dataset opens opportunities for future research in foodborne
outbreak detection.
","[{'version': 'v1', 'created': 'Sun, 22 May 2022 03:47:18 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Sep 2022 03:18:41 GMT'}]",2022-09-15,"[['Hu', 'Ruofan', ''], ['Zhang', 'Dongyu', ''], ['Tao', 'Dandan', ''], ['Hartvigsen', 'Thomas', ''], ['Feng', 'Hao', ''], ['Rundensteiner', 'Elke', '']]"
1908.00785,Francois Coste,Fran\c{c}ois Coste (Dyliss),"Deep learning languages: a key fundamental shift from probabilities to
  weights?",,,,,q-bio.OT cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent successes in language modeling, notably with deep learning methods,
coincide with a shift from probabilistic to weighted representations. We raise
here the question of the importance of this evolution, in the light of the
practical limitations of a classical and simple probabilistic modeling approach
for the classification of protein sequences and in relation to the need for
principled methods to learn non-probabilistic models.
","[{'version': 'v1', 'created': 'Fri, 2 Aug 2019 10:09:51 GMT'}]",2019-08-05,"[['Coste', 'François', '', 'Dyliss']]"
1801.00215,Simon Stiebellehner,"Simon Stiebellehner, Jun Wang, Shuai Yuan","Learning Continuous User Representations through Hybrid Filtering with
  doc2vec",10 pages,,,,cs.IR cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Players in the online ad ecosystem are struggling to acquire the user data
required for precise targeting. Audience look-alike modeling has the potential
to alleviate this issue, but models' performance strongly depends on quantity
and quality of available data. In order to maximize the predictive performance
of our look-alike modeling algorithms, we propose two novel hybrid filtering
techniques that utilize the recent neural probabilistic language model
algorithm doc2vec. We apply these methods to data from a large mobile ad
exchange and additional app metadata acquired from the Apple App store and
Google Play store. First, we model mobile app users through their app usage
histories and app descriptions (user2vec). Second, we introduce context
awareness to that model by incorporating additional user and app-related
metadata in model training (context2vec). Our findings are threefold: (1) the
quality of recommendations provided by user2vec is notably higher than current
state-of-the-art techniques. (2) User representations generated through hybrid
filtering using doc2vec prove to be highly valuable features in supervised
machine learning models for look-alike modeling. This represents the first
application of hybrid filtering user models using neural probabilistic language
models, specifically doc2vec, in look-alike modeling. (3) Incorporating context
metadata in the doc2vec model training process to introduce context awareness
has positive effects on performance and is superior to directly including the
data as features in the downstream supervised models.
","[{'version': 'v1', 'created': 'Sun, 31 Dec 2017 00:51:56 GMT'}]",2018-01-03,"[['Stiebellehner', 'Simon', ''], ['Wang', 'Jun', ''], ['Yuan', 'Shuai', '']]"
2308.03151,Zheng Ma,"Zheng Ma, Mianzhi Pan, Wenhan Wu, Kanzhi Cheng, Jianbing Zhang,
  Shujian Huang and Jiajun Chen","Food-500 Cap: A Fine-Grained Food Caption Benchmark for Evaluating
  Vision-Language Models",Accepted at ACM Multimedia (ACMMM) 2023,,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Vision-language models (VLMs) have shown impressive performance in
substantial downstream multi-modal tasks. However, only comparing the
fine-tuned performance on downstream tasks leads to the poor interpretability
of VLMs, which is adverse to their future improvement. Several prior works have
identified this issue and used various probing methods under a zero-shot
setting to detect VLMs' limitations, but they all examine VLMs using general
datasets instead of specialized ones. In practical applications, VLMs are
usually applied to specific scenarios, such as e-commerce and news fields, so
the generalization of VLMs in specific domains should be given more attention.
In this paper, we comprehensively investigate the capabilities of popular VLMs
in a specific field, the food domain. To this end, we build a food caption
dataset, Food-500 Cap, which contains 24,700 food images with 494 categories.
Each image is accompanied by a detailed caption, including fine-grained
attributes of food, such as the ingredient, shape, and color. We also provide a
culinary culture taxonomy that classifies each food category based on its
geographic origin in order to better analyze the performance differences of VLM
in different regions. Experiments on our proposed datasets demonstrate that
popular VLMs underperform in the food domain compared with their performance in
the general domain. Furthermore, our research reveals severe bias in VLMs'
ability to handle food items from different geographic regions. We adopt
diverse probing methods and evaluate nine VLMs belonging to different
architectures to verify the aforementioned observations. We hope that our study
will bring researchers' attention to VLM's limitations when applying them to
the domain of food or culinary cultures, and spur further investigations to
address this issue.
","[{'version': 'v1', 'created': 'Sun, 6 Aug 2023 15:56:31 GMT'}]",2023-08-08,"[['Ma', 'Zheng', ''], ['Pan', 'Mianzhi', ''], ['Wu', 'Wenhan', ''], ['Cheng', 'Kanzhi', ''], ['Zhang', 'Jianbing', ''], ['Huang', 'Shujian', ''], ['Chen', 'Jiajun', '']]"
2305.14973,Jiazheng Li,"Jiazheng Li, Runcong Zhao, Yongxin Yang, Yulan He, Lin Gui",OverPrompt: Enhancing ChatGPT through Efficient In-Context Learning,NeurIPS 2023 R0-FoMo Workshop,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The remarkable performance of pre-trained large language models has
revolutionised various natural language processing applications. Due to huge
parametersizes and extensive running costs, companies or organisations tend to
transfer the models to the target task by zero-shot prompting techniques.
However, the prohibitive costs of tokens and time have hindered their adoption
in applications. We propose OverPrompt, leveraging the in-context learning
capability of LLMs to handle multiple task inputs, thereby reducing token and
time costs. This approach could potentially improve task performance during API
queries due to better conditional distribution mapping. Evaluated across
diverse classification datasets, our experiments show that OverPrompt can
achieve cost-efficient zero-shot classification without causing significant
detriment to task performance, and in some cases, even improving it. An
ablation study conducted on various LLMs, along with an investigation into the
robustness of our prompting strategy to different input ordering, offers
valuable insights into the broader applicability of our method across diverse
tasks. These findings also suggest a more seamless integration of our method
with LLMs through an API.
","[{'version': 'v1', 'created': 'Wed, 24 May 2023 10:08:04 GMT'}, {'version': 'v2', 'created': 'Thu, 14 Dec 2023 16:17:20 GMT'}]",2023-12-15,"[['Li', 'Jiazheng', ''], ['Zhao', 'Runcong', ''], ['Yang', 'Yongxin', ''], ['He', 'Yulan', ''], ['Gui', 'Lin', '']]"
2010.11125,Angela Fan,"Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky,
  Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav
  Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov,
  Edouard Grave, Michael Auli, Armand Joulin",Beyond English-Centric Multilingual Machine Translation,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing work in translation demonstrated the potential of massively
multilingual machine translation by training a single model able to translate
between any pair of languages. However, much of this work is English-Centric by
training only on data which was translated from or to English. While this is
supported by large sources of training data, it does not reflect translation
needs worldwide. In this work, we create a true Many-to-Many multilingual
translation model that can translate directly between any pair of 100
languages. We build and open source a training dataset that covers thousands of
language directions with supervised data, created through large-scale mining.
Then, we explore how to effectively increase model capacity through a
combination of dense scaling and language-specific sparse parameters to create
high quality models. Our focus on non-English-Centric models brings gains of
more than 10 BLEU when directly translating between non-English directions
while performing competitively to the best single systems of WMT. We
open-source our scripts so that others may reproduce the data, evaluation, and
final M2M-100 model.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 17:01:23 GMT'}]",2020-10-22,"[['Fan', 'Angela', ''], ['Bhosale', 'Shruti', ''], ['Schwenk', 'Holger', ''], ['Ma', 'Zhiyi', ''], ['El-Kishky', 'Ahmed', ''], ['Goyal', 'Siddharth', ''], ['Baines', 'Mandeep', ''], ['Celebi', 'Onur', ''], ['Wenzek', 'Guillaume', ''], ['Chaudhary', 'Vishrav', ''], ['Goyal', 'Naman', ''], ['Birch', 'Tom', ''], ['Liptchinsky', 'Vitaliy', ''], ['Edunov', 'Sergey', ''], ['Grave', 'Edouard', ''], ['Auli', 'Michael', ''], ['Joulin', 'Armand', '']]"
2309.14779,Hengyu Luo,"Hengyu Luo, Peng Liu, Stefan Esping","Exploring Small Language Models with Prompt-Learning Paradigm for
  Efficient Domain-Specific Text Classification",10 pages excluding appendix and reference,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Domain-specific text classification faces the challenge of scarce labeled
data due to the high cost of manual labeling. Prompt-learning, known for its
efficiency in few-shot scenarios, is proposed as an alternative to traditional
fine-tuning methods. And besides, although large language models (LLMs) have
gained prominence, small language models (SLMs, with under 1B parameters) offer
significant customizability, adaptability, and cost-effectiveness for
domain-specific tasks, given industry constraints. In this study, we
investigate the potential of SLMs combined with prompt-learning paradigm for
domain-specific text classification, specifically within customer-agent
interactions in retail. Our evaluations show that, in few-shot settings when
prompt-based model fine-tuning is possible, T5-base, a typical SLM with 220M
parameters, achieve approximately 75% accuracy with limited labeled data (up to
15% of full data), which shows great potentials of SLMs with prompt-learning.
Based on this, We further validate the effectiveness of active few-shot
sampling and the ensemble strategy in the prompt-learning pipeline that
contribute to a remarkable performance gain. Besides, in zero-shot settings
with a fixed model, we underscore a pivotal observation that, although the
GPT-3.5-turbo equipped with around 154B parameters garners an accuracy of
55.16%, the power of well designed prompts becomes evident when the
FLAN-T5-large, a model with a mere 0.5% of GPT-3.5-turbo's parameters, achieves
an accuracy exceeding 31% with the optimized prompt, a leap from its sub-18%
performance with an unoptimized one. Our findings underscore the promise of
prompt-learning in classification tasks with SLMs, emphasizing the benefits of
active few-shot sampling, and ensemble strategies in few-shot settings, and the
importance of prompt engineering in zero-shot settings.
","[{'version': 'v1', 'created': 'Tue, 26 Sep 2023 09:24:46 GMT'}]",2023-09-27,"[['Luo', 'Hengyu', ''], ['Liu', 'Peng', ''], ['Esping', 'Stefan', '']]"
2211.13813,Zhichao Yang,"Zhichao Yang, Sunjae Kwon, Zonghai Yao, Hong Yu",Multi-label Few-shot ICD Coding as Autoregressive Generation with Prompt,To be appear in AAAI2023,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Automatic International Classification of Diseases (ICD) coding aims to
assign multiple ICD codes to a medical note with an average of 3,000+ tokens.
This task is challenging due to the high-dimensional space of multi-label
assignment (155,000+ ICD code candidates) and the long-tail challenge - Many
ICD codes are infrequently assigned yet infrequent ICD codes are important
clinically. This study addresses the long-tail challenge by transforming this
multi-label classification task into an autoregressive generation task.
Specifically, we first introduce a novel pretraining objective to generate free
text diagnoses and procedure using the SOAP structure, the medical logic
physicians use for note documentation. Second, instead of directly predicting
the high dimensional space of ICD codes, our model generates the lower
dimension of text descriptions, which then infer ICD codes. Third, we designed
a novel prompt template for multi-label classification. We evaluate our
Generation with Prompt model with the benchmark of all code assignment
(MIMIC-III-full) and few shot ICD code assignment evaluation benchmark
(MIMIC-III-few). Experiments on MIMIC-III-few show that our model performs with
a marco F1 30.2, which substantially outperforms the previous MIMIC-III-full
SOTA model (marco F1 4.3) and the model specifically designed for few/zero shot
setting (marco F1 18.7). Finally, we design a novel ensemble learner, a cross
attention reranker with prompts, to integrate previous SOTA and our best
few-shot coding predictions. Experiments on MIMIC-III-full show that our
ensemble learner substantially improves both macro and micro F1, from 10.4 to
14.6 and from 58.2 to 59.1, respectively.
","[{'version': 'v1', 'created': 'Thu, 24 Nov 2022 22:10:50 GMT'}, {'version': 'v2', 'created': 'Tue, 29 Nov 2022 15:49:33 GMT'}]",2022-11-30,"[['Yang', 'Zhichao', ''], ['Kwon', 'Sunjae', ''], ['Yao', 'Zonghai', ''], ['Yu', 'Hong', '']]"
2310.11958,Yuval Pinter,"Yuval Pinter, Michael Elhadad",Emptying the Ocean with a Spoon: Should We Edit Models?,Findings of ACL: EMNLP 2023,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  We call into question the recently popularized method of direct model editing
as a means of correcting factual errors in LLM generations. We contrast model
editing with three similar but distinct approaches that pursue better defined
objectives: (1) retrieval-based architectures, which decouple factual memory
from inference and linguistic capabilities embodied in LLMs; (2) concept
erasure methods, which aim at preventing systemic bias in generated text; and
(3) attribution methods, which aim at grounding generations into identified
textual sources. We argue that direct model editing cannot be trusted as a
systematic remedy for the disadvantages inherent to LLMs, and while it has
proven potential in improving model explainability, it opens risks by
reinforcing the notion that models can be trusted for factuality. We call for
cautious promotion and application of model editing as part of the LLM
deployment process, and for responsibly limiting the use cases of LLMs to those
not relying on editing as a critical component.
","[{'version': 'v1', 'created': 'Wed, 18 Oct 2023 13:38:03 GMT'}]",2023-10-19,"[['Pinter', 'Yuval', ''], ['Elhadad', 'Michael', '']]"
2208.08280,Zhen Wu,"Yidong Wang, Hao Wu, Ao Liu, Wenxin Hou, Zhen Wu, Jindong Wang,
  Takahiro Shinozaki, Manabu Okumura, Yue Zhang",Exploiting Unlabeled Data for Target-Oriented Opinion Words Extraction,Accepted by COLING 2022,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Target-oriented Opinion Words Extraction (TOWE) is a fine-grained sentiment
analysis task that aims to extract the corresponding opinion words of a given
opinion target from the sentence. Recently, deep learning approaches have made
remarkable progress on this task. Nevertheless, the TOWE task still suffers
from the scarcity of training data due to the expensive data annotation
process. Limited labeled data increase the risk of distribution shift between
test data and training data. In this paper, we propose exploiting massive
unlabeled data to reduce the risk by increasing the exposure of the model to
varying distribution shifts. Specifically, we propose a novel Multi-Grained
Consistency Regularization (MGCR) method to make use of unlabeled data and
design two filters specifically for TOWE to filter noisy data at different
granularity. Extensive experimental results on four TOWE benchmark datasets
indicate the superiority of MGCR compared with current state-of-the-art
methods. The in-depth analysis also demonstrates the effectiveness of the
different-granularity filters. Our codes are available at
https://github.com/TOWESSL/TOWESSL.
","[{'version': 'v1', 'created': 'Wed, 17 Aug 2022 13:19:26 GMT'}]",2022-08-18,"[['Wang', 'Yidong', ''], ['Wu', 'Hao', ''], ['Liu', 'Ao', ''], ['Hou', 'Wenxin', ''], ['Wu', 'Zhen', ''], ['Wang', 'Jindong', ''], ['Shinozaki', 'Takahiro', ''], ['Okumura', 'Manabu', ''], ['Zhang', 'Yue', '']]"
2012.08013,Nicholas Egan,"Nicholas Egan, John Bohannon",Primer AI's Systems for Acronym Identification and Disambiguation,In the Scientific Document Understanding workshop at AAAI 2021,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The prevalence of ambiguous acronyms make scientific documents harder to
understand for humans and machines alike, presenting a need for models that can
automatically identify acronyms in text and disambiguate their meaning. We
introduce new methods for acronym identification and disambiguation: our
acronym identification model projects learned token embeddings onto tag
predictions, and our acronym disambiguation model finds training examples with
similar sentence embeddings as test examples. Both of our systems achieve
significant performance gains over previously suggested methods, and perform
competitively on the SDU@AAAI-21 shared task leaderboard. Our models were
trained in part on new distantly-supervised datasets for these tasks which we
call AuxAI and AuxAD. We also identified a duplication conflict issue in the
SciAD dataset, and formed a deduplicated version of SciAD that we call
SciAD-dedupe. We publicly released all three of these datasets, and hope that
they help the community make further strides in scientific document
understanding.
","[{'version': 'v1', 'created': 'Mon, 14 Dec 2020 23:59:05 GMT'}, {'version': 'v2', 'created': 'Wed, 6 Jan 2021 00:50:40 GMT'}]",2021-01-07,"[['Egan', 'Nicholas', ''], ['Bohannon', 'John', '']]"
2311.03348,Javier Rando,"Rusheb Shah, Quentin Feuillade--Montixi, Soroush Pour, Arush Tagade,
  Stephen Casper, Javier Rando","Scalable and Transferable Black-Box Jailbreaks for Language Models via
  Persona Modulation",,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Despite efforts to align large language models to produce harmless responses,
they are still vulnerable to jailbreak prompts that elicit unrestricted
behaviour. In this work, we investigate persona modulation as a black-box
jailbreaking method to steer a target model to take on personalities that are
willing to comply with harmful instructions. Rather than manually crafting
prompts for each persona, we automate the generation of jailbreaks using a
language model assistant. We demonstrate a range of harmful completions made
possible by persona modulation, including detailed instructions for
synthesising methamphetamine, building a bomb, and laundering money. These
automated attacks achieve a harmful completion rate of 42.5% in GPT-4, which is
185 times larger than before modulation (0.23%). These prompts also transfer to
Claude 2 and Vicuna with harmful completion rates of 61.0% and 35.9%,
respectively. Our work reveals yet another vulnerability in commercial large
language models and highlights the need for more comprehensive safeguards.
","[{'version': 'v1', 'created': 'Mon, 6 Nov 2023 18:55:18 GMT'}, {'version': 'v2', 'created': 'Fri, 24 Nov 2023 12:50:31 GMT'}]",2023-11-27,"[['Shah', 'Rusheb', ''], ['Feuillade--Montixi', 'Quentin', ''], ['Pour', 'Soroush', ''], ['Tagade', 'Arush', ''], ['Casper', 'Stephen', ''], ['Rando', 'Javier', '']]"
2302.09887,Tapas Nayak,Pratik Saini and Samiran Pal and Tapas Nayak and Indrajit Bhattacharya,90% F1 Score in Relational Triple Extraction: Is it Real ?,Accepted in GenBench workshop @ EMNLP 2023,,,,cs.CL,http://creativecommons.org/publicdomain/zero/1.0/,"  Extracting relational triples from text is a crucial task for constructing
knowledge bases. Recent advancements in joint entity and relation extraction
models have demonstrated remarkable F1 scores ($\ge 90\%$) in accurately
extracting relational triples from free text. However, these models have been
evaluated under restrictive experimental settings and unrealistic datasets.
They overlook sentences with zero triples (zero-cardinality), thereby
simplifying the task. In this paper, we present a benchmark study of
state-of-the-art joint entity and relation extraction models under a more
realistic setting. We include sentences that lack any triples in our
experiments, providing a comprehensive evaluation. Our findings reveal a
significant decline (approximately 10-15\% in one dataset and 6-14\% in another
dataset) in the models' F1 scores within this realistic experimental setup.
Furthermore, we propose a two-step modeling approach that utilizes a simple
BERT-based classifier. This approach leads to overall performance improvement
in these models within the realistic experimental setting.
","[{'version': 'v1', 'created': 'Mon, 20 Feb 2023 10:30:16 GMT'}, {'version': 'v2', 'created': 'Fri, 27 Oct 2023 05:14:46 GMT'}]",2023-10-30,"[['Saini', 'Pratik', ''], ['Pal', 'Samiran', ''], ['Nayak', 'Tapas', ''], ['Bhattacharya', 'Indrajit', '']]"
2211.06562,Heitor Guimar\~aes,"Heitor R. Guimar\~aes, Arthur Pimentel, Anderson R. Avila, Mehdi
  Rezagholizadeh, Tiago H. Falk","Improving the Robustness of DistilHuBERT to Unseen Noisy Conditions via
  Data Augmentation, Curriculum Learning, and Multi-Task Enhancement","ENLSP-II NeurIPS Workshop 2022, 6 pages",,,,cs.SD cs.CL eess.AS,http://creativecommons.org/licenses/by/4.0/,"  Self-supervised speech representation learning aims to extract meaningful
factors from the speech signal that can later be used across different
downstream tasks, such as speech and/or emotion recognition. Existing models,
such as HuBERT, however, can be fairly large thus may not be suitable for edge
speech applications. Moreover, realistic applications typically involve speech
corrupted by noise and room reverberation, hence models need to provide
representations that are robust to such environmental factors. In this study,
we build on the so-called DistilHuBERT model, which distils HuBERT to a
fraction of its original size, with three modifications, namely: (i) augment
the training data with noise and reverberation, while the student model needs
to distill the clean representations from the teacher model; (ii) introduce a
curriculum learning approach where increasing levels of noise are introduced as
the model trains, thus helping with convergence and with the creation of more
robust representations; and (iii) introduce a multi-task learning approach
where the model also reconstructs the clean waveform jointly with the
distillation task, thus also acting as an enhancement step to ensure additional
environment robustness to the representation. Experiments on three SUPERB tasks
show the advantages of the proposed method not only relative to the original
DistilHuBERT, but also to the original HuBERT, thus showing the advantages of
the proposed method for ``in the wild'' edge speech applications.
","[{'version': 'v1', 'created': 'Sat, 12 Nov 2022 03:50:22 GMT'}]",2022-11-15,"[['Guimarães', 'Heitor R.', ''], ['Pimentel', 'Arthur', ''], ['Avila', 'Anderson R.', ''], ['Rezagholizadeh', 'Mehdi', ''], ['Falk', 'Tiago H.', '']]"
1804.01452,David Harwath,"David Harwath, Adri\`a Recasens, D\'idac Sur\'is, Galen Chuang,
  Antonio Torralba, and James Glass","Jointly Discovering Visual Objects and Spoken Words from Raw Sensory
  Input",,,,,cs.CV cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we explore neural network models that learn to associate
segments of spoken audio captions with the semantically relevant portions of
natural images that they refer to. We demonstrate that these audio-visual
associative localizations emerge from network-internal representations learned
as a by-product of training to perform an image-audio retrieval task. Our
models operate directly on the image pixels and speech waveform, and do not
rely on any conventional supervision in the form of labels, segmentations, or
alignments between the modalities during training. We perform analysis using
the Places 205 and ADE20k datasets demonstrating that our models implicitly
learn semantically-coupled object and word detectors.
","[{'version': 'v1', 'created': 'Wed, 4 Apr 2018 15:03:08 GMT'}]",2018-04-05,"[['Harwath', 'David', ''], ['Recasens', 'Adrià', ''], ['Surís', 'Dídac', ''], ['Chuang', 'Galen', ''], ['Torralba', 'Antonio', ''], ['Glass', 'James', '']]"
1912.10435,Ankit Chadha Mr.,Ankit Chadha and Rewa Sood,BERTQA -- Attention on Steroids,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work, we extend the Bidirectional Encoder Representations from
Transformers (BERT) with an emphasis on directed coattention to obtain an
improved F1 performance on the SQUAD2.0 dataset. The Transformer architecture
on which BERT is based places hierarchical global attention on the
concatenation of the context and query. Our additions to the BERT architecture
augment this attention with a more focused context to query (C2Q) and query to
context (Q2C) attention via a set of modified Transformer encoder units. In
addition, we explore adding convolution-based feature extraction within the
coattention architecture to add localized information to self-attention. We
found that coattention significantly improves the no answer F1 by 4 points in
the base and 1 point in the large architecture. After adding skip connections
the no answer F1 improved further without causing an additional loss in has
answer F1. The addition of localized feature extraction added to attention
produced an overall dev F1 of 77.03 in the base architecture. We applied our
findings to the large BERT model which contains twice as many layers and
further used our own augmented version of the SQUAD 2.0 dataset created by back
translation, which we have named SQUAD 2.Q. Finally, we performed
hyperparameter tuning and ensembled our best models for a final F1/EM of
82.317/79.442 (Attention on Steroids, PCE Test Leaderboard).
","[{'version': 'v1', 'created': 'Sat, 14 Dec 2019 06:44:12 GMT'}]",2019-12-24,"[['Chadha', 'Ankit', ''], ['Sood', 'Rewa', '']]"
2206.03529,Timothee Mickus,"Timothee Mickus, Denis Paperno, Mathieu Constant",How to Dissect a Muppet: The Structure of Transformer Embedding Spaces,Accepted at TACL (pre-MIT Press publication version),,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Pretrained embeddings based on the Transformer architecture have taken the
NLP community by storm. We show that they can mathematically be reframed as a
sum of vector factors and showcase how to use this reframing to study the
impact of each component. We provide evidence that multi-head attentions and
feed-forwards are not equally useful in all downstream applications, as well as
a quantitative overview of the effects of finetuning on the overall embedding
space. This approach allows us to draw connections to a wide range of previous
studies, from vector space anisotropy to attention weights.
","[{'version': 'v1', 'created': 'Tue, 7 Jun 2022 18:24:46 GMT'}]",2022-06-09,"[['Mickus', 'Timothee', ''], ['Paperno', 'Denis', ''], ['Constant', 'Mathieu', '']]"
2402.17834,Marco Bellagente,"Marco Bellagente, Jonathan Tow, Dakota Mahan, Duy Phung, Maksym
  Zhuravinskyi, Reshinth Adithyan, James Baicoianu, Ben Brooks, Nathan Cooper,
  Ashish Datta, Meng Lee, Emad Mostaque, Michael Pieler, Nikhil Pinnaparju,
  Paulo Rocha, Harry Saini, Hannah Teufel, Niccolo Zanichelli, Carlos Riquelme",Stable LM 2 1.6B Technical Report,"23 pages, 6 figures",,,,cs.CL stat.ML,http://creativecommons.org/licenses/by/4.0/,"  We introduce StableLM 2 1.6B, the first in a new generation of our language
model series. In this technical report, we present in detail the data and
training procedure leading to the base and instruction-tuned versions of
StableLM 2 1.6B. The weights for both models are available via Hugging Face for
anyone to download and use. The report contains thorough evaluations of these
models, including zero- and few-shot benchmarks, multilingual benchmarks, and
the MT benchmark focusing on multi-turn dialogues. At the time of publishing
this report, StableLM 2 1.6B was the state-of-the-art open model under 2B
parameters by a significant margin. Given its appealing small size, we also
provide throughput measurements on a number of edge devices. In addition, we
open source several quantized checkpoints and provide their performance metrics
compared to the original model.
","[{'version': 'v1', 'created': 'Tue, 27 Feb 2024 19:00:07 GMT'}]",2024-02-29,"[['Bellagente', 'Marco', ''], ['Tow', 'Jonathan', ''], ['Mahan', 'Dakota', ''], ['Phung', 'Duy', ''], ['Zhuravinskyi', 'Maksym', ''], ['Adithyan', 'Reshinth', ''], ['Baicoianu', 'James', ''], ['Brooks', 'Ben', ''], ['Cooper', 'Nathan', ''], ['Datta', 'Ashish', ''], ['Lee', 'Meng', ''], ['Mostaque', 'Emad', ''], ['Pieler', 'Michael', ''], ['Pinnaparju', 'Nikhil', ''], ['Rocha', 'Paulo', ''], ['Saini', 'Harry', ''], ['Teufel', 'Hannah', ''], ['Zanichelli', 'Niccolo', ''], ['Riquelme', 'Carlos', '']]"
2211.08386,Dan Su,Dan Su,"Generative Long-form Question Answering: Relevance, Faithfulness and
  Succinctness",PhD Thesis,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  In this thesis, we investigated the relevance, faithfulness, and succinctness
aspects of Long Form Question Answering (LFQA). LFQA aims to generate an
in-depth, paragraph-length answer for a given question, to help bridge the gap
between real scenarios and the existing open-domain QA models which can only
extract short-span answers. LFQA is quite challenging and under-explored. Few
works have been done to build an effective LFQA system. It is even more
challenging to generate a good-quality long-form answer relevant to the query
and faithful to facts, since a considerable amount of redundant, complementary,
or contradictory information will be contained in the retrieved documents.
Moreover, no prior work has been investigated to generate succinct answers. We
are among the first to research the LFQA task. We pioneered the research
direction to improve the answer quality in terms of 1) query-relevance, 2)
answer faithfulness, and 3) answer succinctness.
","[{'version': 'v1', 'created': 'Tue, 15 Nov 2022 18:36:01 GMT'}]",2022-11-16,"[['Su', 'Dan', '']]"
2210.06576,Moussa Kamal Eddine,"Moussa Kamal Eddine, Guokan Shang, Michalis Vazirgiannis",DATScore: Evaluating Translation with Data Augmented Translations,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The rapid development of large pretrained language models has revolutionized
not only the field of Natural Language Generation (NLG) but also its
evaluation. Inspired by the recent work of BARTScore: a metric leveraging the
BART language model to evaluate the quality of generated text from various
aspects, we introduce DATScore. DATScore uses data augmentation techniques to
improve the evaluation of machine translation. Our main finding is that
introducing data augmented translations of the source and reference texts is
greatly helpful in evaluating the quality of the generated translation. We also
propose two novel score averaging and term weighting strategies to improve the
original score computing process of BARTScore. Experimental results on WMT show
that DATScore correlates better with human meta-evaluations than the other
recent state-of-the-art metrics, especially for low-resource languages.
Ablation studies demonstrate the value added by our new scoring strategies.
Moreover, we report in our extended experiments the performance of DATScore on
3 NLG tasks other than translation.
","[{'version': 'v1', 'created': 'Wed, 12 Oct 2022 20:31:42 GMT'}]",2022-10-14,"[['Eddine', 'Moussa Kamal', ''], ['Shang', 'Guokan', ''], ['Vazirgiannis', 'Michalis', '']]"
2205.11588,Tao Lei,"Tao Lei, Ran Tian, Jasmijn Bastings, Ankur P. Parikh",Simple Recurrence Improves Masked Language Models,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In this work, we explore whether modeling recurrence into the Transformer
architecture can both be beneficial and efficient, by building an extremely
simple recurrent module into the Transformer. We compare our model to baselines
following the training and evaluation recipe of BERT. Our results confirm that
recurrence can indeed improve Transformer models by a consistent margin,
without requiring low-level performance optimizations, and while keeping the
number of parameters constant. For example, our base model achieves an absolute
improvement of 2.1 points averaged across 10 tasks and also demonstrates
increased stability in fine-tuning over a range of learning rates.
","[{'version': 'v1', 'created': 'Mon, 23 May 2022 19:38:23 GMT'}]",2022-05-25,"[['Lei', 'Tao', ''], ['Tian', 'Ran', ''], ['Bastings', 'Jasmijn', ''], ['Parikh', 'Ankur P.', '']]"
1604.01178,Alessandro Moschitti,Aliaksei Severyn and Alessandro Moschitti,"Modeling Relational Information in Question-Answer Pairs with
  Convolutional Neural Networks",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we propose convolutional neural networks for learning an
optimal representation of question and answer sentences. Their main aspect is
the use of relational information given by the matches between words from the
two members of the pair. The matches are encoded as embeddings with additional
parameters (dimensions), which are tuned by the network. These allows for
better capturing interactions between questions and answers, resulting in a
significant boost in accuracy. We test our models on two widely used answer
sentence selection benchmarks. The results clearly show the effectiveness of
our relational information, which allows our relatively simple network to
approach the state of the art.
","[{'version': 'v1', 'created': 'Tue, 5 Apr 2016 08:50:27 GMT'}]",2016-04-06,"[['Severyn', 'Aliaksei', ''], ['Moschitti', 'Alessandro', '']]"
1709.00728,Wen Kokke,Wen Kokke,Formalising Type-Logical Grammars in Agda,"In 1st Workshop on Type Theory and Lexical Semantics at ESSLLI'15,
  Barcelona, Spain, August, 2015",,,,cs.LO cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  In recent years, the interest in using proof assistants to formalise and
reason about mathematics and programming languages has grown. Type-logical
grammars, being closely related to type theories and systems used in functional
programming, are a perfect candidate to next apply this curiosity to. The
advantages of using proof assistants is that they allow one to write formally
verified proofs about one's type-logical systems, and that any theory, once
implemented, can immediately be computed with. The downside is that in many
cases the formal proofs are written as an afterthought, are incomplete, or use
obtuse syntax. This makes it that the verified proofs are often much more
difficult to read than the pen-and-paper proofs, and almost never directly
published. In this paper, we will try to remedy that by example.
  Concretely, we use Agda to model the Lambek-Grishin calculus, a grammar logic
with a rich vocabulary of type-forming operations. We then present a verified
procedure for cut elimination in this system. Then we briefly outline a CPS
translation from proofs in the Lambek-Grishin calculus to programs in Agda. And
finally, we will put our system to use in the analysis of a simple example
sentence.
","[{'version': 'v1', 'created': 'Sun, 3 Sep 2017 14:54:29 GMT'}]",2017-09-06,"[['Kokke', 'Wen', '']]"
2112.05717,Marjan Ghazvininejad,"Marjan Ghazvininejad, Vladimir Karpukhin, Vera Gor, Asli Celikyilmaz",Discourse-Aware Soft Prompting for Text Generation,,,,,cs.CL cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current efficient fine-tuning methods (e.g., adapters, prefix-tuning, etc.)
have optimized conditional text generation via training a small set of extra
parameters of the neural language model, while freezing the rest for
efficiency. While showing strong performance on some generation tasks, they
don't generalize across all generation tasks. We show that soft-prompt based
conditional text generation can be improved with simple and efficient methods
that simulate modeling the discourse structure of human written text. We
investigate two design choices: First, we apply \textit{hierarchical blocking}
on the prefix parameters to simulate a higher-level discourse structure of
human written text. Second, we apply \textit{attention sparsity} on the prefix
parameters at different layers of the network and learn sparse transformations
on the softmax-function. We show that structured design of prefix parameters
yields more coherent, faithful and relevant generations than the baseline
prefix-tuning on all generation tasks.
","[{'version': 'v1', 'created': 'Fri, 10 Dec 2021 18:15:44 GMT'}, {'version': 'v2', 'created': 'Mon, 23 May 2022 17:27:22 GMT'}]",2022-05-24,"[['Ghazvininejad', 'Marjan', ''], ['Karpukhin', 'Vladimir', ''], ['Gor', 'Vera', ''], ['Celikyilmaz', 'Asli', '']]"
2301.11796,Ethan Wilcox,"Alex Warstadt, Leshem Choshen, Aaron Mueller, Adina Williams, Ethan
  Wilcox, Chengxu Zhuang","Call for Papers -- The BabyLM Challenge: Sample-efficient pretraining on
  a developmentally plausible corpus",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We present the call for papers for the BabyLM Challenge: Sample-efficient
pretraining on a developmentally plausible corpus. This shared task is intended
for participants with an interest in small scale language modeling, human
language acquisition, low-resource NLP, and cognitive modeling. In partnership
with CoNLL and CMCL, we provide a platform for approaches to pretraining with a
limited-size corpus sourced from data inspired by the input to children. The
task has three tracks, two of which restrict the training data to pre-released
datasets of 10M and 100M words and are dedicated to explorations of approaches
such as architectural variations, self-supervised objectives, or curriculum
learning. The final track only restricts the amount of text used, allowing
innovation in the choice of the data, its domain, and even its modality (i.e.,
data from sources other than text is welcome). We will release a shared
evaluation pipeline which scores models on a variety of benchmarks and tasks,
including targeted syntactic evaluations and natural language understanding.
","[{'version': 'v1', 'created': 'Fri, 27 Jan 2023 15:52:50 GMT'}]",2023-01-30,"[['Warstadt', 'Alex', ''], ['Choshen', 'Leshem', ''], ['Mueller', 'Aaron', ''], ['Williams', 'Adina', ''], ['Wilcox', 'Ethan', ''], ['Zhuang', 'Chengxu', '']]"
2309.12288,Owain Evans,"Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper
  Stickland, Tomasz Korbak, Owain Evans","The Reversal Curse: LLMs trained on ""A is B"" fail to learn ""B is A""","18 pages, 10 figures",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We expose a surprising failure of generalization in auto-regressive large
language models (LLMs). If a model is trained on a sentence of the form ""A is
B"", it will not automatically generalize to the reverse direction ""B is A"".
This is the Reversal Curse. For instance, if a model is trained on ""Olaf Scholz
was the ninth Chancellor of Germany"", it will not automatically be able to
answer the question, ""Who was the ninth Chancellor of Germany?"". Moreover, the
likelihood of the correct answer (""Olaf Scholz"") will not be higher than for a
random name. Thus, models exhibit a basic failure of logical deduction and do
not generalize a prevalent pattern in their training set (i.e. if ""A is B''
occurs, ""B is A"" is more likely to occur). We provide evidence for the Reversal
Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as ""Uriah
Hawthorne is the composer of 'Abyssal Melodies'"" and showing that they fail to
correctly answer ""Who composed 'Abyssal Melodies?'"". The Reversal Curse is
robust across model sizes and model families and is not alleviated by data
augmentation. We also evaluate ChatGPT (GPT-3.5 and GPT-4) on questions about
real-world celebrities, such as ""Who is Tom Cruise's mother? [A: Mary Lee
Pfeiffer]"" and the reverse ""Who is Mary Lee Pfeiffer's son?"". GPT-4 correctly
answers questions like the former 79% of the time, compared to 33% for the
latter. This shows a failure of logical deduction that we hypothesize is caused
by the Reversal Curse. Code is available at
https://github.com/lukasberglund/reversal_curse.
","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 17:52:19 GMT'}, {'version': 'v2', 'created': 'Fri, 22 Sep 2023 18:08:20 GMT'}]",2023-09-26,"[['Berglund', 'Lukas', ''], ['Tong', 'Meg', ''], ['Kaufmann', 'Max', ''], ['Balesni', 'Mikita', ''], ['Stickland', 'Asa Cooper', ''], ['Korbak', 'Tomasz', ''], ['Evans', 'Owain', '']]"
2212.10466,Howard Chen,"Howard Chen, Huihan Li, Danqi Chen, Karthik Narasimhan",Controllable Text Generation with Language Constraints,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We consider the task of text generation in language models with constraints
specified in natural language. To this end, we first create a challenging
benchmark Cognac that provides as input to the model a topic with example text,
along with a constraint on text to be avoided. Unlike prior work, our benchmark
contains knowledge-intensive constraints sourced from databases like Wordnet
and Wikidata, which allows for straightforward evaluation while striking a
balance between broad attribute-level and narrow lexical-level controls. We
find that even state-of-the-art language models like GPT-3 fail often on this
task, and propose a solution to leverage a language model's own internal
knowledge to guide generation. Our method, called CognacGen, first queries the
language model to generate guidance terms for a specified topic or constraint,
and uses the guidance to modify the model's token generation probabilities. We
propose three forms of guidance (binary verifier, top-k tokens, textual
example), and employ prefix-tuning approaches to distill the guidance to tackle
diverse natural language constraints. Through extensive empirical evaluations,
we demonstrate that CognacGen can successfully generalize to unseen
instructions and outperform competitive baselines in generating constraint
conforming text.
","[{'version': 'v1', 'created': 'Tue, 20 Dec 2022 17:39:21 GMT'}]",2022-12-21,"[['Chen', 'Howard', ''], ['Li', 'Huihan', ''], ['Chen', 'Danqi', ''], ['Narasimhan', 'Karthik', '']]"
2310.18075,Liangyu Chen,"Xiaoyu Tian, Liangyu Chen, Na Liu, Yaxuan Liu, Wei Zou, Kaijiang Chen,
  Ming Cui",DUMA: a Dual-Mind Conversational Agent with Fast and Slow Thinking,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Inspired by the dual-process theory of human cognition, we introduce DUMA, a
novel conversational agent framework that embodies a dual-mind mechanism
through the utilization of two generative Large Language Models (LLMs)
dedicated to fast and slow thinking respectively. The fast thinking model
serves as the primary interface for external interactions and initial response
generation, evaluating the necessity for engaging the slow thinking model based
on the complexity of the complete response. When invoked, the slow thinking
model takes over the conversation, engaging in meticulous planning, reasoning,
and tool utilization to provide a well-analyzed response. This dual-mind
configuration allows for a seamless transition between intuitive responses and
deliberate problem-solving processes based on the situation. We have
constructed a conversational agent to handle online inquiries in the real
estate industry. The experiment proves that our method balances effectiveness
and efficiency, and has a significant improvement compared to the baseline.
","[{'version': 'v1', 'created': 'Fri, 27 Oct 2023 11:43:46 GMT'}, {'version': 'v2', 'created': 'Mon, 30 Oct 2023 02:16:55 GMT'}, {'version': 'v3', 'created': 'Fri, 17 Nov 2023 06:55:45 GMT'}, {'version': 'v4', 'created': 'Fri, 24 Nov 2023 09:18:27 GMT'}]",2023-11-27,"[['Tian', 'Xiaoyu', ''], ['Chen', 'Liangyu', ''], ['Liu', 'Na', ''], ['Liu', 'Yaxuan', ''], ['Zou', 'Wei', ''], ['Chen', 'Kaijiang', ''], ['Cui', 'Ming', '']]"
2311.04467,Xusheng Zhao,"Xusheng Zhao, Hao Peng, Qiong Dai, Xu Bai, Huailiang Peng, Yanbing
  Liu, Qinglang Guo, Philip S. Yu","RDGCN: Reinforced Dependency Graph Convolutional Network for
  Aspect-based Sentiment Analysis",The 17th ACM International Conference on Web Search and Data Mining,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Aspect-based sentiment analysis (ABSA) is dedicated to forecasting the
sentiment polarity of aspect terms within sentences. Employing graph neural
networks to capture structural patterns from syntactic dependency parsing has
been confirmed as an effective approach for boosting ABSA. In most works, the
topology of dependency trees or dependency-based attention coefficients is
often loosely regarded as edges between aspects and opinions, which can result
in insufficient and ambiguous syntactic utilization. To address these problems,
we propose a new reinforced dependency graph convolutional network (RDGCN) that
improves the importance calculation of dependencies in both distance and type
views. Initially, we propose an importance calculation criterion for the
minimum distances over dependency trees. Under the criterion, we design a
distance-importance function that leverages reinforcement learning for weight
distribution search and dissimilarity control. Since dependency types often do
not have explicit syntax like tree distances, we use global attention and mask
mechanisms to design type-importance functions. Finally, we merge these weights
and implement feature aggregation and classification. Comprehensive experiments
on three popular datasets demonstrate the effectiveness of the criterion and
importance functions. RDGCN outperforms state-of-the-art GNN-based baselines in
all validations.
","[{'version': 'v1', 'created': 'Wed, 8 Nov 2023 05:37:49 GMT'}]",2023-11-09,"[['Zhao', 'Xusheng', ''], ['Peng', 'Hao', ''], ['Dai', 'Qiong', ''], ['Bai', 'Xu', ''], ['Peng', 'Huailiang', ''], ['Liu', 'Yanbing', ''], ['Guo', 'Qinglang', ''], ['Yu', 'Philip S.', '']]"
2211.00727,Amin Karamlou,"Amin Karamlou, Marcel Pfaffhauser and James Wootton",Quantum Natural Language Generation on Near-Term Devices,"To appear in proceedings of International Natural Language Generation
  Conference (INLG) 2022",,,,quant-ph cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The emergence of noisy medium-scale quantum devices has led to
proof-of-concept applications for quantum computing in various domains.
Examples include Natural Language Processing (NLP) where sentence
classification experiments have been carried out, as well as procedural
generation, where tasks such as geopolitical map creation, and image
manipulation have been performed. We explore applications at the intersection
of these two areas by designing a hybrid quantum-classical algorithm for
sentence generation.
  Our algorithm is based on the well-known simulated annealing technique for
combinatorial optimisation. An implementation is provided and used to
demonstrate successful sentence generation on both simulated and real quantum
hardware. A variant of our algorithm can also be used for music generation.
  This paper aims to be self-contained, introducing all the necessary
background on NLP and quantum computing along the way.
","[{'version': 'v1', 'created': 'Tue, 1 Nov 2022 20:12:35 GMT'}]",2022-11-03,"[['Karamlou', 'Amin', ''], ['Pfaffhauser', 'Marcel', ''], ['Wootton', 'James', '']]"
cmp-lg/9503019,David D. Palmer,David D. Palmer (University of California at Berkeley),SATZ - An Adaptive Sentence Segmentation System,"30 pages, uuencoded compressed PostScript file (about 170k)",,,UC Berkeley Technical Report UCB/CSD-94-846,cmp-lg cs.CL,,"  This paper provides a detailed description of the sentence segmentation
system first introduced in cmp-lg/9411022. It provides results of systematic
experiments involving sentence boundary determination, including context size,
lexicon size, and single-case texts. Also included are the results of
successfully adapting the system to German and French. The source code for the
system is available as a compressed tar file at
ftp://cs-tr.CS.Berkeley.EDU/pub/cstr/satz.tar.Z .
","[{'version': 'v1', 'created': 'Mon, 20 Mar 1995 20:11:05 GMT'}]",2016-08-31,"[['Palmer', 'David D.', '', 'University of California at Berkeley']]"
2012.14983,Sabrina Mielke,"Sabrina J. Mielke, Arthur Szlam, Emily Dinan, Y-Lan Boureau","Reducing conversational agents' overconfidence through linguistic
  calibration","Accepted in TACL, to be presented at NAACL 2022",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While improving neural dialogue agents' factual accuracy is the object of
much research, another important aspect of communication, less studied in the
setting of neural dialogue, is transparency about ignorance. In this work, we
analyze to what extent state-of-the-art chit-chat models are linguistically
calibrated in the sense that their verbalized expression of doubt (or
confidence) matches the likelihood that the model's responses are factually
incorrect (or correct). We find that these models are poorly calibrated, yet we
show that likelihood of correctness can accurately be predicted. By
incorporating such metacognitive features into the training of a controllable
generation model, we obtain a dialogue agent with greatly improved linguistic
calibration. While improving neural dialogue agents' factual accuracy is the
object of much research, another important aspect of communication, less
studied in the setting of neural dialogue, is transparency about ignorance. In
this work, we analyze to what extent state-of-the-art chit-chat models are
linguistically calibrated in the sense that their verbalized expression of
doubt (or confidence) matches the likelihood that the model's responses are
factually incorrect (or correct). We find that these models are poorly
calibrated, yet we show that likelihood of correctness can accurately be
predicted. By incorporating such metacognitive features into the training of a
controllable generation model, we obtain a dialogue agent with greatly improved
linguistic calibration.
","[{'version': 'v1', 'created': 'Wed, 30 Dec 2020 00:12:36 GMT'}, {'version': 'v2', 'created': 'Sun, 26 Jun 2022 22:11:23 GMT'}]",2022-06-28,"[['Mielke', 'Sabrina J.', ''], ['Szlam', 'Arthur', ''], ['Dinan', 'Emily', ''], ['Boureau', 'Y-Lan', '']]"
2104.09570,Shuaicheng Zhang,"Shuaicheng Zhang, Lifu Huang, Qiang Ning",Extracting Temporal Event Relation with Syntax-guided Graph Transformer,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  Extracting temporal relations (e.g., before, after, and simultaneous) among
events is crucial to natural language understanding. One of the key challenges
of this problem is that when the events of interest are far away in text, the
context in-between often becomes complicated, making it challenging to resolve
the temporal relationship between them. This paper thus proposes a new
Syntax-guided Graph Transformer network (SGT) to mitigate this issue, by (1)
explicitly exploiting the connection between two events based on their
dependency parsing trees, and (2) automatically locating temporal cues between
two events via a novel syntax-guided attention mechanism. Experiments on two
benchmark datasets, MATRES and TB-Dense, show that our approach significantly
outperforms previous state-of-the-art methods on both end-to-end temporal
relation extraction and temporal relation classification; This improvement also
proves to be robust on the contrast set of MATRES. The code is publicly
available at https://github.com/VT-NLP/Syntax-Guided-Graph-Transformer.
","[{'version': 'v1', 'created': 'Mon, 19 Apr 2021 19:00:45 GMT'}, {'version': 'v2', 'created': 'Mon, 24 Oct 2022 19:17:53 GMT'}]",2022-10-26,"[['Zhang', 'Shuaicheng', ''], ['Huang', 'Lifu', ''], ['Ning', 'Qiang', '']]"
2009.14459,Mireille Makary,Reda Khalaf and Mireille Makary,LEBANONUPRISING: a thorough study of Lebanese tweets,"9 pages, published at the CMLA 2020 conference",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent studies showed a huge interest in social networks sentiment analysis.
Twitter, which is a microblogging service, can be a great source of information
on how the users feel about a certain topic, or what their opinion is regarding
a social, economic and even political matter. On October 17, Lebanon witnessed
the start of a revolution; the LebanonUprising hashtag became viral on Twitter.
A dataset consisting of a 100,0000 tweets was collected between 18 and 21
October. In this paper, we conducted a sentiment analysis study for the tweets
in spoken Lebanese Arabic related to the LebanonUprising hashtag using
different machine learning algorithms. The dataset was manually annotated to
measure the precision and recall metrics and to compare between the different
algorithms. Furthermore, the work completed in this paper provides two more
contributions. The first is related to building a Lebanese to Modern Standard
Arabic mapping dictionary that was used for the preprocessing of the tweets and
the second is an attempt to move from sentiment analysis to emotion detection
using emojis, and the two emotions we tried to predict were the ""sarcastic"" and
""funny"" emotions. We built a training set from the tweets collected in October
2019 and then we used this set to predict sentiments and emotions of the tweets
we collected between May and August 2020. The analysis we conducted shows the
variation in sentiments, emotions and users between the two datasets. The
results we obtained seem satisfactory especially considering that there was no
previous or similar work done involving Lebanese Arabic tweets, to our
knowledge.
","[{'version': 'v1', 'created': 'Wed, 30 Sep 2020 05:50:08 GMT'}]",2020-10-01,"[['Khalaf', 'Reda', ''], ['Makary', 'Mireille', '']]"
2401.09041,Kittipitch Kuptavanich,"Kittipitch Kuptavanich, Ehud Reiter, Kees Van Deemter, Advaith
  Siddharthan",Textual Summarisation of Large Sets: Towards a General Approach,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We are developing techniques to generate summary descriptions of sets of
objects. In this paper, we present and evaluate a rule-based NLG technique for
summarising sets of bibliographical references in academic papers. This extends
our previous work on summarising sets of consumer products and shows how our
model generalises across these two very different domains.
","[{'version': 'v1', 'created': 'Wed, 17 Jan 2024 08:16:05 GMT'}]",2024-01-18,"[['Kuptavanich', 'Kittipitch', ''], ['Reiter', 'Ehud', ''], ['Van Deemter', 'Kees', ''], ['Siddharthan', 'Advaith', '']]"
2104.06271,Enes Avcu,"Enes Avcu, Olivia Newman, David Gow","A Tale of Two Lexica Testing Computational Hypotheses with Deep
  Convolutional Neural Networks","8 pages, 3 figures, Presented as a talk at the Psychonomic Society's
  61st Annual Meeting and poster at the SNL 2020 Annual Meeting",,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Gow's (2012) dual lexicon model suggests that the primary purpose of words is
to mediate the mappings between acoustic-phonetic input and other forms of
linguistic representation. Motivated by evidence from functional imaging,
aphasia, and behavioral results, the model argues for the existence of two
parallel wordform stores: the dorsal and ventral processing streams. In this
paper, we tested the hypothesis that the complex, but systematic mapping
between sound and articulation in the dorsal stream poses different
computational pressures on feature sets than the more arbitrary mapping between
sound and meaning. To test this hypothesis, we created two deep convolutional
neural networks (CNNs). While the dorsal network was trained to identify
individual spoken words, the ventral network was trained to map them onto
semantic classes. We then extracted patterns of network activation from the
penultimate level of each network and tested how well features generated by the
network supported generalization to linguistic categorization associated with
the dorsal versus ventral processing streams. Our preliminary results showed
both models successfully learned their tasks. Secondary generalization testing
showed the ventral CNN outperformed the dorsal CNN on a semantic task:
concreteness classification, while the dorsal CNN outperformed the ventral CNN
on articulation tasks: classification by onset phoneme class and syllable
length. These results are consistent with the hypothesis that the divergent
processing demands of the ventral and dorsal processing streams impose
computational pressures for the development of multiple lexica.
","[{'version': 'v1', 'created': 'Tue, 13 Apr 2021 15:03:14 GMT'}]",2021-04-14,"[['Avcu', 'Enes', ''], ['Newman', 'Olivia', ''], ['Gow', 'David', '']]"
2212.13465,Dingzirui Wang,"Dingzirui Wang, Longxu Dou, Wanxiang Che","A Survey on Table-and-Text HybridQA: Concepts, Methods, Challenges and
  Future Directions",7 pages,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Table-and-text hybrid question answering (HybridQA) is a widely used and
challenging NLP task commonly applied in the financial and scientific domain.
The early research focuses on migrating other QA task methods to HybridQA,
while with further research, more and more HybridQA-specific methods have been
present. With the rapid development of HybridQA, the systematic survey is still
under-explored to summarize the main techniques and advance further research.
So we present this work to summarize the current HybridQA benchmarks and
methods, then analyze the challenges and future directions of this task. The
contributions of this paper can be summarized in three folds: (1) first survey,
to our best knowledge, including benchmarks, methods and challenges for
HybridQA; (2) systematic investigation with the reasonable comparison of the
existing systems to articulate their advantages and shortcomings; (3) detailed
analysis of challenges in four important dimensions to shed light on future
directions.
","[{'version': 'v1', 'created': 'Tue, 27 Dec 2022 12:34:57 GMT'}, {'version': 'v2', 'created': 'Thu, 2 Feb 2023 02:44:58 GMT'}]",2023-02-03,"[['Wang', 'Dingzirui', ''], ['Dou', 'Longxu', ''], ['Che', 'Wanxiang', '']]"
2206.11184,Ghazi Felhi,"Ghazi Felhi, Joseph Le Roux, Djam\'e Seddah","Towards Unsupervised Content Disentanglement in Sentence Representations
  via Syntactic Roles","This is an extended version of the paper with the same name that was
  accepted to CTRLGEN Workshop@Neurips2021",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Linking neural representations to linguistic factors is crucial in order to
build and analyze NLP models interpretable by humans. Among these factors,
syntactic roles (e.g. subjects, direct objects,$\dots$) and their realizations
are essential markers since they can be understood as a decomposition of
predicative structures and thus the meaning of sentences. Starting from a deep
probabilistic generative model with attention, we measure the interaction
between latent variables and realizations of syntactic roles and show that it
is possible to obtain, without supervision, representations of sentences where
different syntactic roles correspond to clearly identified different latent
variables. The probabilistic model we propose is an Attention-Driven
Variational Autoencoder (ADVAE). Drawing inspiration from Transformer-based
machine translation models, ADVAEs enable the analysis of the interactions
between latent variables and input tokens through attention. We also develop an
evaluation protocol to measure disentanglement with regard to the realizations
of syntactic roles. This protocol is based on attention maxima for the encoder
and on latent variable perturbations for the decoder. Our experiments on raw
English text from the SNLI dataset show that $\textit{i)}$ disentanglement of
syntactic roles can be induced without supervision, $\textit{ii)}$ ADVAE
separates syntactic roles better than classical sequence VAEs and Transformer
VAEs, $\textit{iii)}$ realizations of syntactic roles can be separately
modified in sentences by mere intervention on the associated latent variables.
Our work constitutes a first step towards unsupervised controllable content
generation. The code for our work is publicly available.
","[{'version': 'v1', 'created': 'Wed, 22 Jun 2022 15:50:01 GMT'}]",2022-06-23,"[['Felhi', 'Ghazi', ''], ['Roux', 'Joseph Le', ''], ['Seddah', 'Djamé', '']]"
2309.12109,Zhou Mingjun,"Zhou Mingjun, Daiqing Zhuoma, Qun Nuo, Nyima Tashi","PEFTT: Parameter-Efficient Fine-Tuning for low-resource Tibetan
  pre-trained language models",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this era of large language models (LLMs), the traditional training of
models has become increasingly unimaginable for regular users and institutions.
The exploration of efficient fine-tuning for high-resource languages on these
models is an undeniable trend that is gradually gaining popularity. However,
there has been very little exploration for various low-resource languages, such
as Tibetan. Research in Tibetan NLP is inherently scarce and limited. While
there is currently no existing large language model for Tibetan due to its
low-resource nature, that day will undoubtedly arrive. Therefore, research on
efficient fine-tuning for low-resource language models like Tibetan is highly
necessary. Our research can serve as a reference to fill this crucial gap.
Efficient fine-tuning strategies for pre-trained language models (PLMs) in
Tibetan have seen minimal exploration. We conducted three types of efficient
fine-tuning experiments on the publicly available TNCC-title dataset:
""prompt-tuning,"" ""Adapter lightweight fine-tuning,"" and ""prompt-tuning +
Adapter fine-tuning."" The experimental results demonstrate significant
improvements using these methods, providing valuable insights for advancing
Tibetan language applications in the context of pre-trained models.
","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 14:29:23 GMT'}]",2023-09-22,"[['Mingjun', 'Zhou', ''], ['Zhuoma', 'Daiqing', ''], ['Nuo', 'Qun', ''], ['Tashi', 'Nyima', '']]"
2311.15055,Bob de Ruiter,Bob de Ruiter,Automatically Finding and Categorizing Replication Studies,,,,,cs.DL cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In many fields of experimental science, papers that failed to replicate
continue to be cited as a result of the poor discoverability of replication
studies. As a first step to creating a system that automatically finds
replication studies for a given paper, 334 replication studies and 344
replicated studies were collected. Replication studies could be identified in
the dataset based on text content at a higher rate than chance (AUROC = 0.886).
  Additionally, successful replication studies could be distinguished from
failed replication studies at a higher rate than chance (AUROC = 0.664).
","[{'version': 'v1', 'created': 'Sat, 25 Nov 2023 15:27:10 GMT'}]",2023-11-28,"[['de Ruiter', 'Bob', '']]"
1906.03672,Daniel Khashabi Mr.,"Daniel Khashabi, Tushar Khot, Ashish Sabharwal, Dan Roth",Question Answering as Global Reasoning over Semantic Abstractions,Appeared in AAAI'18,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a novel method for exploiting the semantic structure of text to
answer multiple-choice questions. The approach is especially suitable for
domains that require reasoning over a diverse set of linguistic constructs but
have limited training data. To address these challenges, we present the first
system, to the best of our knowledge, that reasons over a wide range of
semantic abstractions of the text, which are derived using off-the-shelf,
general-purpose, pre-trained natural language modules such as semantic role
labelers, coreference resolvers, and dependency parsers. Representing multiple
abstractions as a family of graphs, we translate question answering (QA) into a
search for an optimal subgraph that satisfies certain global and local
properties. This formulation generalizes several prior structured QA systems.
Our system, SEMANTICILP, demonstrates strong performance on two domains
simultaneously. In particular, on a collection of challenging science QA
datasets, it outperforms various state-of-the-art approaches, including neural
models, broad coverage information retrieval, and specialized techniques using
structured knowledge bases, by 2%-6%.
","[{'version': 'v1', 'created': 'Sun, 9 Jun 2019 16:56:31 GMT'}]",2019-06-11,"[['Khashabi', 'Daniel', ''], ['Khot', 'Tushar', ''], ['Sabharwal', 'Ashish', ''], ['Roth', 'Dan', '']]"
2209.15189,Ruiqi Zhong,"Charlie Snell, Dan Klein, Ruiqi Zhong",Learning by Distilling Context,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Language models significantly benefit from context tokens, such as prompts or
scratchpads. They perform better when prompted with informative instructions,
and they acquire new reasoning capabilities by generating a scratch-pad before
predicting the final answers. However, they do not \textit{internalize} these
performance gains, which disappear when the context tokens are gone. Our work
proposes to apply context distillation so that a language model can improve
itself by internalizing these gains. Concretely, given a synthetic unlabeled
input for the target task, we condition the model on ``[instructions] +
[task-input]'' to predict ``[scratch-pad] + [final answer]''; then we fine-tune
the same model to predict its own ``[final answer]'' conditioned on the
``[task-input]'', without seeing the ``[instructions]'' or using the
``[scratch-pad]''.
  We show that context distillation is a general method to train language
models, and it can effectively internalize 3 types of training signals. First,
it can internalize abstract task instructions and explanations, so we can
iteratively update the model parameters with new instructions and overwrite old
ones. Second, it can internalize step-by-step reasoning for complex tasks
(e.g., 8-digit addition), and such a newly acquired capability proves to be
useful for other downstream tasks. Finally, it can internalize concrete
training examples, and it outperforms directly learning with gradient descent
by 9\% on the SPIDER Text-to-SQL dataset; furthermore, combining context
distillation operations can internalize more training examples than the context
window size allows.
","[{'version': 'v1', 'created': 'Fri, 30 Sep 2022 02:30:15 GMT'}]",2022-10-03,"[['Snell', 'Charlie', ''], ['Klein', 'Dan', ''], ['Zhong', 'Ruiqi', '']]"
1707.07911,Maxim Khalilov,"Pavel Levin, Nishikant Dhanuka, Maxim Khalilov",Machine Translation at Booking.com: Journey and Lessons Learned,"6 pages, 8 figures, 2 tables. In proceedings of EAMT 2017. Prague,
  Czech Republic",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We describe our recently developed neural machine translation (NMT) system
and benchmark it against our own statistical machine translation (SMT) system
as well as two other general purpose online engines (statistical and neural).
We present automatic and human evaluation results of the translation output
provided by each system. We also analyze the effect of sentence length on the
quality of output for SMT and NMT systems.
","[{'version': 'v1', 'created': 'Tue, 25 Jul 2017 10:51:19 GMT'}]",2017-07-26,"[['Levin', 'Pavel', ''], ['Dhanuka', 'Nishikant', ''], ['Khalilov', 'Maxim', '']]"
2306.09064,Zihao Zhou,"Zihao Zhou, Maizhen Ning, Qiufeng Wang, Jie Yao, Wei Wang, Xiaowei
  Huang, Kaizhu Huang",Learning by Analogy: Diverse Questions Generation in Math Word Problem,ACL2023 Findings,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Solving math word problem (MWP) with AI techniques has recently made great
progress with the success of deep neural networks (DNN), but it is far from
being solved. We argue that the ability of learning by analogy is essential for
an MWP solver to better understand same problems which may typically be
formulated in diverse ways. However most existing works exploit the shortcut
learning to train MWP solvers simply based on samples with a single question.
In lack of diverse questions, these methods merely learn shallow heuristics. In
this paper, we make a first attempt to solve MWPs by generating diverse yet
consistent questions/equations. Given a typical MWP including the scenario
description, question, and equation (i.e., answer), we first generate multiple
consistent equations via a group of heuristic rules. We then feed them to a
question generator together with the scenario to obtain the corresponding
diverse questions, forming a new MWP with a variety of questions and equations.
Finally we engage a data filter to remove those unreasonable MWPs, keeping the
high-quality augmented ones. To evaluate the ability of learning by analogy for
an MWP solver, we generate a new MWP dataset (called DiverseMath23K) with
diverse questions by extending the current benchmark Math23K. Extensive
experimental results demonstrate that our proposed method can generate
high-quality diverse questions with corresponding equations, further leading to
performance improvement on Diverse-Math23K. The code and dataset is available
at: https://github.com/zhouzihao501/DiverseMWP
","[{'version': 'v1', 'created': 'Thu, 15 Jun 2023 11:47:07 GMT'}]",2023-06-16,"[['Zhou', 'Zihao', ''], ['Ning', 'Maizhen', ''], ['Wang', 'Qiufeng', ''], ['Yao', 'Jie', ''], ['Wang', 'Wei', ''], ['Huang', 'Xiaowei', ''], ['Huang', 'Kaizhu', '']]"
2401.00448,Nikhil Sardana,Nikhil Sardana and Jonathan Frankle,"Beyond Chinchilla-Optimal: Accounting for Inference in Language Model
  Scaling Laws","8 pages, 2 figures, To appear in the 3rd NeurIPS Workshop on
  Efficient Natural Language and Speech Processing (ENLSP), 2023",,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language model (LLM) scaling laws are empirical formulas that estimate
changes in model quality as a result of increasing parameter count and training
data. However, these formulas, including the popular DeepMind Chinchilla
scaling laws, neglect to include the cost of inference. We modify the
Chinchilla scaling laws to calculate the optimal LLM parameter count and
pre-training data size to train and deploy a model of a given quality and
inference demand. We conduct our analysis both in terms of a compute budget and
real-world costs and find that LLM researchers expecting reasonably large
inference demand (~1B requests) should train models smaller and longer than
Chinchilla-optimal.
","[{'version': 'v1', 'created': 'Sun, 31 Dec 2023 10:53:58 GMT'}]",2024-01-02,"[['Sardana', 'Nikhil', ''], ['Frankle', 'Jonathan', '']]"
2402.03407,Daniel S\'aez-Trigueros,"\'Alvaro Mart\'in-Cortinas, Daniel S\'aez-Trigueros, Iv\'an
  Vall\'es-P\'erez, Biel Tura-Vecino, Piotr Bili\'nski, Mateusz Lajszczak,
  Grzegorz Beringer, Roberto Barra-Chicote, Jaime Lorenzo-Trueba","Enhancing the Stability of LLM-based Speech Generation Systems through
  Self-Supervised Representations","10 pages, 1 figure, 3 tables",,,,eess.AS cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) are one of the most promising technologies for
the next era of speech generation systems, due to their scalability and
in-context learning capabilities. Nevertheless, they suffer from multiple
stability issues at inference time, such as hallucinations, content skipping or
speech repetitions. In this work, we introduce a new self-supervised Voice
Conversion (VC) architecture which can be used to learn to encode transitory
features, such as content, separately from stationary ones, such as speaker ID
or recording conditions, creating speaker-disentangled representations. Using
speaker-disentangled codes to train LLMs for text-to-speech (TTS) allows the
LLM to generate the content and the style of the speech only from the text,
similarly to humans, while the speaker identity is provided by the decoder of
the VC model. Results show that LLMs trained over speaker-disentangled
self-supervised representations provide an improvement of 4.7pp in speaker
similarity over SOTA entangled representations, and a word error rate (WER)
5.4pp lower. Furthermore, they achieve higher naturalness than human recordings
of the LibriTTS test-other dataset. Finally, we show that using explicit
reference embedding negatively impacts intelligibility (stability), with WER
increasing by 14pp compared to the model that only uses text to infer the
style.
","[{'version': 'v1', 'created': 'Mon, 5 Feb 2024 15:08:19 GMT'}]",2024-02-07,"[['Martín-Cortinas', 'Álvaro', ''], ['Sáez-Trigueros', 'Daniel', ''], ['Vallés-Pérez', 'Iván', ''], ['Tura-Vecino', 'Biel', ''], ['Biliński', 'Piotr', ''], ['Lajszczak', 'Mateusz', ''], ['Beringer', 'Grzegorz', ''], ['Barra-Chicote', 'Roberto', ''], ['Lorenzo-Trueba', 'Jaime', '']]"
2209.06058,Chao Zhang,"Chao Zhang, Bo Li, Tara Sainath, Trevor Strohman, Sepand Mavandadi,
  Shuo-yiin Chang, Parisa Haghani","Streaming End-to-End Multilingual Speech Recognition with Joint Language
  Identification",,,,,eess.AS cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language identification is critical for many downstream tasks in automatic
speech recognition (ASR), and is beneficial to integrate into multilingual
end-to-end ASR as an additional task. In this paper, we propose to modify the
structure of the cascaded-encoder-based recurrent neural network transducer
(RNN-T) model by integrating a per-frame language identifier (LID) predictor.
RNN-T with cascaded encoders can achieve streaming ASR with low latency using
first-pass decoding with no right-context, and achieve lower word error rates
(WERs) using second-pass decoding with longer right-context. By leveraging such
differences in the right-contexts and a streaming implementation of statistics
pooling, the proposed method can achieve accurate streaming LID prediction with
little extra test-time cost. Experimental results on a voice search dataset
with 9 language locales shows that the proposed method achieves an average of
96.2% LID prediction accuracy and the same second-pass WER as that obtained by
including oracle LID in the input.
","[{'version': 'v1', 'created': 'Tue, 13 Sep 2022 15:10:41 GMT'}]",2022-09-14,"[['Zhang', 'Chao', ''], ['Li', 'Bo', ''], ['Sainath', 'Tara', ''], ['Strohman', 'Trevor', ''], ['Mavandadi', 'Sepand', ''], ['Chang', 'Shuo-yiin', ''], ['Haghani', 'Parisa', '']]"
2305.12311,Ziyi Yang,"Ziyi Yang, Mahmoud Khademi, Yichong Xu, Reid Pryzant, Yuwei Fang,
  Chenguang Zhu, Dongdong Chen, Yao Qian, Mei Gao, Yi-Ling Chen, Robert Gmyr,
  Naoyuki Kanda, Noel Codella, Bin Xiao, Yu Shi, Lu Yuan, Takuya Yoshioka,
  Michael Zeng, Xuedong Huang","i-Code V2: An Autoregressive Generation Framework over Vision, Language,
  and Speech Data",,,,,cs.CL cs.AI cs.CV cs.LG eess.AS,http://creativecommons.org/licenses/by/4.0/,"  The convergence of text, visual, and audio data is a key step towards
human-like artificial intelligence, however the current Vision-Language-Speech
landscape is dominated by encoder-only models which lack generative abilities.
We propose closing this gap with i-Code V2, the first model capable of
generating natural language from any combination of Vision, Language, and
Speech data. i-Code V2 is an integrative system that leverages state-of-the-art
single-modality encoders, combining their outputs with a new modality-fusing
encoder in order to flexibly project combinations of modalities into a shared
representational space. Next, language tokens are generated from these
representations via an autoregressive decoder. The whole framework is
pretrained end-to-end on a large collection of dual- and single-modality
datasets using a novel text completion objective that can be generalized across
arbitrary combinations of modalities. i-Code V2 matches or outperforms
state-of-the-art single- and dual-modality baselines on 7 multimodal tasks,
demonstrating the power of generative multimodal pretraining across a diversity
of tasks and signals.
","[{'version': 'v1', 'created': 'Sun, 21 May 2023 01:25:44 GMT'}]",2023-05-23,"[['Yang', 'Ziyi', ''], ['Khademi', 'Mahmoud', ''], ['Xu', 'Yichong', ''], ['Pryzant', 'Reid', ''], ['Fang', 'Yuwei', ''], ['Zhu', 'Chenguang', ''], ['Chen', 'Dongdong', ''], ['Qian', 'Yao', ''], ['Gao', 'Mei', ''], ['Chen', 'Yi-Ling', ''], ['Gmyr', 'Robert', ''], ['Kanda', 'Naoyuki', ''], ['Codella', 'Noel', ''], ['Xiao', 'Bin', ''], ['Shi', 'Yu', ''], ['Yuan', 'Lu', ''], ['Yoshioka', 'Takuya', ''], ['Zeng', 'Michael', ''], ['Huang', 'Xuedong', '']]"
1909.13184,Anahita Davoudi,"Anahita Davoudi, Ari Z. Klein, Abeed Sarker, Graciela
  Gonzalez-Hernandez",Towards Automatic Bot Detection in Twitter for Health-related Tasks,,,,,cs.CL cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  With the increasing use of social media data for health-related research, the
credibility of the information from this source has been questioned as the
posts may originate from automated accounts or ""bots"". While automatic bot
detection approaches have been proposed, there are none that have been
evaluated on users posting health-related information. In this paper, we extend
an existing bot detection system and customize it for health-related research.
Using a dataset of Twitter users, we first show that the system, which was
designed for political bot detection, underperforms when applied to
health-related Twitter users. We then incorporate additional features and a
statistical machine learning classifier to significantly improve bot detection
performance. Our approach obtains F_1 scores of 0.7 for the ""bot"" class,
representing improvements of 0.339. Our approach is customizable and
generalizable for bot detection in other health-related social media cohorts.
","[{'version': 'v1', 'created': 'Sun, 29 Sep 2019 01:58:15 GMT'}]",2019-10-01,"[['Davoudi', 'Anahita', ''], ['Klein', 'Ari Z.', ''], ['Sarker', 'Abeed', ''], ['Gonzalez-Hernandez', 'Graciela', '']]"
2212.12137,Brian Thompson,"William Brannon, Yogesh Virkar, Brian Thompson","Dubbing in Practice: A Large Scale Study of Human Localization With
  Insights for Automatic Dubbing",Accepted at TACL. pre-MIT Press publication version,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigate how humans perform the task of dubbing video content from one
language into another, leveraging a novel corpus of 319.57 hours of video from
54 professionally produced titles. This is the first such large-scale study we
are aware of. The results challenge a number of assumptions commonly made in
both qualitative literature on human dubbing and machine-learning literature on
automatic dubbing, arguing for the importance of vocal naturalness and
translation quality over commonly emphasized isometric (character length) and
lip-sync constraints, and for a more qualified view of the importance of
isochronic (timing) constraints. We also find substantial influence of the
source-side audio on human dubs through channels other than the words of the
translation, pointing to the need for research on ways to preserve speech
characteristics, as well as semantic transfer such as emphasis/emotion, in
automatic dubbing systems.
","[{'version': 'v1', 'created': 'Fri, 23 Dec 2022 04:12:52 GMT'}]",2022-12-26,"[['Brannon', 'William', ''], ['Virkar', 'Yogesh', ''], ['Thompson', 'Brian', '']]"
1910.13105,Bo Chen,"Bo Chen, Jing Zhang, Xiaobin Tang, Hong Chen, Cuiping Li","JarKA: Modeling Attribute Interactions for Cross-lingual Knowledge
  Alignment",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Abstract. Cross-lingual knowledge alignment is the cornerstone in building a
comprehensive knowledge graph (KG), which can benefit various knowledge-driven
applications. As the structures of KGs are usually sparse, attributes of
entities may play an important role in aligning the entities. However, the
heterogeneity of the attributes across KGs prevents from accurately embedding
and comparing entities. To deal with the issue, we propose to model the
interactions between attributes, instead of globally embedding an entity with
all the attributes. We further propose a joint framework to merge the
alignments inferred from the attributes and the structures. Experimental
results show that the proposed model outperforms the state-of-art baselines by
up to 38.48% HitRatio@1. The results also demonstrate that our model can infer
the alignments between attributes, relationships and values, in addition to
entities.
","[{'version': 'v1', 'created': 'Tue, 29 Oct 2019 06:41:30 GMT'}, {'version': 'v2', 'created': 'Sat, 29 Feb 2020 08:15:00 GMT'}]",2020-03-03,"[['Chen', 'Bo', ''], ['Zhang', 'Jing', ''], ['Tang', 'Xiaobin', ''], ['Chen', 'Hong', ''], ['Li', 'Cuiping', '']]"
2402.07742,Yifei Yuan,"Yifei Yuan, Clemencia Siro, Mohammad Aliannejadi, Maarten de Rijke,
  Wai Lam","Asking Multimodal Clarifying Questions in Mixed-Initiative
  Conversational Search",Accepted to WWW24,,,,cs.CL cs.CV,http://creativecommons.org/publicdomain/zero/1.0/,"  In mixed-initiative conversational search systems, clarifying questions are
used to help users who struggle to express their intentions in a single query.
These questions aim to uncover user's information needs and resolve query
ambiguities. We hypothesize that in scenarios where multimodal information is
pertinent, the clarification process can be improved by using non-textual
information. Therefore, we propose to add images to clarifying questions and
formulate the novel task of asking multimodal clarifying questions in
open-domain, mixed-initiative conversational search systems. To facilitate
research into this task, we collect a dataset named Melon that contains over 4k
multimodal clarifying questions, enriched with over 14k images. We also propose
a multimodal query clarification model named Marto and adopt a prompt-based,
generative fine-tuning strategy to perform the training of different stages
with different prompts. Several analyses are conducted to understand the
importance of multimodal contents during the query clarification phase.
Experimental results indicate that the addition of images leads to significant
improvements of up to 90% in retrieval performance when selecting the relevant
images. Extensive analyses are also performed to show the superiority of Marto
compared with discriminative baselines in terms of effectiveness and
efficiency.
","[{'version': 'v1', 'created': 'Mon, 12 Feb 2024 16:04:01 GMT'}]",2024-02-13,"[['Yuan', 'Yifei', ''], ['Siro', 'Clemencia', ''], ['Aliannejadi', 'Mohammad', ''], ['de Rijke', 'Maarten', ''], ['Lam', 'Wai', '']]"
1307.8225,Rosy Madaan,"Deepti Kapri, Rosy Madaan, A. K Sharma, Ashutosh Dixit",A Novel Architecture for Relevant Blog Page Identifcation,"13 Pages. International Journal of Computer Engineering and
  Applications, June 2013",,,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Blogs are undoubtedly the richest source of information available in
cyberspace. Blogs can be of various natures i.e. personal blogs which contain
posts on mixed issues or blogs can be domain specific which contains posts on
particular topics, this is the reason, they offer wide variety of relevant
information which is often focused. A general search engine gives back a huge
collection of web pages which may or may not give correct answers, as web is
the repository of information of all kinds and a user has to go through various
documents before he gets what he was originally looking for, which is a very
time consuming process. So, the search can be made more focused and accurate if
it is limited to blogosphere instead of web pages. The reason being that the
blogs are more focused in terms of information. So, User will only get related
blogs in response to his query. These results will be then ranked according to
our proposed method and are finally presented in front of user in descending
order
","[{'version': 'v1', 'created': 'Wed, 31 Jul 2013 05:40:59 GMT'}]",2013-08-01,"[['Kapri', 'Deepti', ''], ['Madaan', 'Rosy', ''], ['Sharma', 'A. K', ''], ['Dixit', 'Ashutosh', '']]"
2005.04862,Ye Bai,"Ye Bai, Jiangyan Yi, Jianhua Tao, Zhengkun Tian, Zhengqi Wen, Shuai
  Zhang","Listen Attentively, and Spell Once: Whole Sentence Generation via a
  Non-Autoregressive Architecture for Low-Latency Speech Recognition",accepted by INTERSPEECH2020,,,,eess.AS cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Although attention based end-to-end models have achieved promising
performance in speech recognition, the multi-pass forward computation in
beam-search increases inference time cost, which limits their practical
applications. To address this issue, we propose a non-autoregressive end-to-end
speech recognition system called LASO (listen attentively, and spell once).
Because of the non-autoregressive property, LASO predicts a textual token in
the sequence without the dependence on other tokens. Without beam-search, the
one-pass propagation much reduces inference time cost of LASO. And because the
model is based on the attention based feedforward structure, the computation
can be implemented in parallel efficiently. We conduct experiments on publicly
available Chinese dataset AISHELL-1. LASO achieves a character error rate of
6.4%, which outperforms the state-of-the-art autoregressive transformer model
(6.7%). The average inference latency is 21 ms, which is 1/50 of the
autoregressive transformer model.
","[{'version': 'v1', 'created': 'Mon, 11 May 2020 04:45:02 GMT'}, {'version': 'v2', 'created': 'Sat, 30 May 2020 15:32:41 GMT'}, {'version': 'v3', 'created': 'Sun, 2 Aug 2020 09:52:53 GMT'}, {'version': 'v4', 'created': 'Thu, 6 Aug 2020 01:26:15 GMT'}]",2020-08-07,"[['Bai', 'Ye', ''], ['Yi', 'Jiangyan', ''], ['Tao', 'Jianhua', ''], ['Tian', 'Zhengkun', ''], ['Wen', 'Zhengqi', ''], ['Zhang', 'Shuai', '']]"
2306.05268,Paul Pu Liang,"Paul Pu Liang, Zihao Deng, Martin Ma, James Zou, Louis-Philippe
  Morency, Ruslan Salakhutdinov",Factorized Contrastive Learning: Going Beyond Multi-view Redundancy,"NeurIPS 2023. Code available at:
  https://github.com/pliang279/FactorCL",,,,cs.LG cs.AI cs.CL cs.CV cs.MM,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In a wide range of multimodal tasks, contrastive learning has become a
particularly appealing approach since it can successfully learn representations
from abundant unlabeled data with only pairing information (e.g., image-caption
or video-audio pairs). Underpinning these approaches is the assumption of
multi-view redundancy - that shared information between modalities is necessary
and sufficient for downstream tasks. However, in many real-world settings,
task-relevant information is also contained in modality-unique regions:
information that is only present in one modality but still relevant to the
task. How can we learn self-supervised multimodal representations to capture
both shared and unique information relevant to downstream tasks? This paper
proposes FactorCL, a new multimodal representation learning method to go beyond
multi-view redundancy. FactorCL is built from three new contributions: (1)
factorizing task-relevant information into shared and unique representations,
(2) capturing task-relevant information via maximizing MI lower bounds and
removing task-irrelevant information via minimizing MI upper bounds, and (3)
multimodal data augmentations to approximate task relevance without labels. On
large-scale real-world datasets, FactorCL captures both shared and unique
information and achieves state-of-the-art results on six benchmarks
","[{'version': 'v1', 'created': 'Thu, 8 Jun 2023 15:17:04 GMT'}, {'version': 'v2', 'created': 'Mon, 30 Oct 2023 05:31:05 GMT'}]",2023-10-31,"[['Liang', 'Paul Pu', ''], ['Deng', 'Zihao', ''], ['Ma', 'Martin', ''], ['Zou', 'James', ''], ['Morency', 'Louis-Philippe', ''], ['Salakhutdinov', 'Ruslan', '']]"
2305.11554,Shibo Hao,"Shibo Hao, Tianyang Liu, Zhen Wang, Zhiting Hu","ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via
  Tool Embeddings",NeurIPS 2023 (oral). Code: https://github.com/Ber666/ToolkenGPT,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Augmenting large language models (LLMs) with external tools has emerged as a
promising approach to solving complex problems. However, traditional methods,
which finetune LLMs with tool demonstration data, can be both costly and
restricted to a predefined set of tools. Recent in-context learning paradigm
alleviates these issues, but the limited context length only allows for a few
shots of demonstrations, leading to suboptimal understandings of the tools.
Moreover, when there are numerous tools to choose from, in-context learning
could completely fail to work. In this paper, we propose an alternative
approach, $\textbf{ToolkenGPT}$, which combines the benefits of both sides. Our
approach represents each $\underline{tool}$ as a to$\underline{ken}$
($\textit{toolken}$) and learns an embedding for it, enabling tool calls in the
same way as generating a regular word token. Once a toolken is triggered, the
LLM is prompted to complete arguments for the tool to execute. ToolkenGPT
offers the flexibility to plug in an arbitrary number of tools by expanding the
set of toolkens on the fly. In addition, it improves tool use by allowing
extensive demonstration data for learning the toolken embeddings. In diverse
domains, including numerical reasoning, knowledge-based question answering, and
embodied plan generation, our approach effectively augments LLMs with tools and
substantially outperforms various latest baselines. ToolkenGPT demonstrates the
promising ability to use relevant tools from a large tool set in complex
scenarios.
","[{'version': 'v1', 'created': 'Fri, 19 May 2023 09:54:21 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Jun 2023 07:58:56 GMT'}, {'version': 'v3', 'created': 'Mon, 30 Oct 2023 21:46:30 GMT'}, {'version': 'v4', 'created': 'Mon, 15 Jan 2024 23:52:21 GMT'}]",2024-01-17,"[['Hao', 'Shibo', ''], ['Liu', 'Tianyang', ''], ['Wang', 'Zhen', ''], ['Hu', 'Zhiting', '']]"
2312.11509,Michael Guerzhoy,"Pavlos Constas, Vikram Rawal, Matthew Honorio Oliveira, Andreas
  Constas, Aditya Khan, Kaison Cheung, Najma Sultani, Carrie Chen, Micol
  Altomare, Michael Akzam, Jiacheng Chen, Vhea He, Lauren Altomare, Heraa
  Murqi, Asad Khan, Nimit Amikumar Bhanshali, Youssef Rachad, Michael Guerzhoy","Toward a Reinforcement-Learning-Based System for Adjusting Medication to
  Minimize Speech Disfluency","In Proc. Machine Learning for Cognitive and Mental Health Workshop
  (ML4CMH) at AAAI 2024",,,,cs.CL cs.LG eess.AS,http://creativecommons.org/licenses/by/4.0/,"  We propose a reinforcement learning (RL)-based system that would
automatically prescribe a hypothetical patient medication that may help the
patient with their mental health-related speech disfluency, and adjust the
medication and the dosages in response to zero-cost frequent measurement of the
fluency of the patient. We demonstrate the components of the system: a module
that detects and evaluates speech disfluency on a large dataset we built, and
an RL algorithm that automatically finds good combinations of medications. To
support the two modules, we collect data on the effect of psychiatric
medications for speech disfluency from the literature, and build a plausible
patient simulation system. We demonstrate that the RL system is, under some
circumstances, able to converge to a good medication regime. We collect and
label a dataset of people with possible speech disfluency and demonstrate our
methods using that dataset. Our work is a proof of concept: we show that there
is promise in the idea of using automatic data collection to address speech
disfluency.
","[{'version': 'v1', 'created': 'Tue, 12 Dec 2023 04:58:11 GMT'}, {'version': 'v2', 'created': 'Mon, 8 Jan 2024 17:57:53 GMT'}, {'version': 'v3', 'created': 'Tue, 30 Jan 2024 04:15:00 GMT'}, {'version': 'v4', 'created': 'Tue, 6 Feb 2024 02:14:14 GMT'}]",2024-02-07,"[['Constas', 'Pavlos', ''], ['Rawal', 'Vikram', ''], ['Oliveira', 'Matthew Honorio', ''], ['Constas', 'Andreas', ''], ['Khan', 'Aditya', ''], ['Cheung', 'Kaison', ''], ['Sultani', 'Najma', ''], ['Chen', 'Carrie', ''], ['Altomare', 'Micol', ''], ['Akzam', 'Michael', ''], ['Chen', 'Jiacheng', ''], ['He', 'Vhea', ''], ['Altomare', 'Lauren', ''], ['Murqi', 'Heraa', ''], ['Khan', 'Asad', ''], ['Bhanshali', 'Nimit Amikumar', ''], ['Rachad', 'Youssef', ''], ['Guerzhoy', 'Michael', '']]"
2305.14325,Yilun Du,"Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, Igor
  Mordatch","Improving Factuality and Reasoning in Language Models through Multiagent
  Debate","Project Webpage and Code:
  https://composable-models.github.io/llm_debate/",,,,cs.CL cs.AI cs.CV cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have demonstrated remarkable capabilities in
language generation, understanding, and few-shot learning in recent years. An
extensive body of work has explored how their performance may be further
improved through the tools of prompting, ranging from verification,
self-consistency, or intermediate scratchpads. In this paper, we present a
complementary approach to improve language responses where multiple language
model instances propose and debate their individual responses and reasoning
processes over multiple rounds to arrive at a common final answer. Our findings
indicate that this approach significantly enhances mathematical and strategic
reasoning across a number of tasks. We also demonstrate that our approach
improves the factual validity of generated content, reducing fallacious answers
and hallucinations that contemporary models are prone to. Our approach may be
directly applied to existing black-box models and uses identical procedure and
prompts for all tasks we investigate. Overall, our findings suggest that such
""society of minds"" approach has the potential to significantly advance the
capabilities of LLMs and pave the way for further breakthroughs in language
generation and understanding.
","[{'version': 'v1', 'created': 'Tue, 23 May 2023 17:55:11 GMT'}]",2023-05-24,"[['Du', 'Yilun', ''], ['Li', 'Shuang', ''], ['Torralba', 'Antonio', ''], ['Tenenbaum', 'Joshua B.', ''], ['Mordatch', 'Igor', '']]"
2303.01248,Haocong Rao,"Haocong Rao, Cyril Leung, Chunyan Miao",Can ChatGPT Assess Human Personalities? A General Evaluation Framework,"Accepted to EMNLP 2023. Our codes are available at
  https://github.com/Kali-Hac/ChatGPT-MBTI",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) especially ChatGPT have produced impressive
results in various areas, but their potential human-like psychology is still
largely unexplored. Existing works study the virtual personalities of LLMs but
rarely explore the possibility of analyzing human personalities via LLMs. This
paper presents a generic evaluation framework for LLMs to assess human
personalities based on Myers Briggs Type Indicator (MBTI) tests. Specifically,
we first devise unbiased prompts by randomly permuting options in MBTI
questions and adopt the average testing result to encourage more impartial
answer generation. Then, we propose to replace the subject in question
statements to enable flexible queries and assessments on different subjects
from LLMs. Finally, we re-formulate the question instructions in a manner of
correctness evaluation to facilitate LLMs to generate clearer responses. The
proposed framework enables LLMs to flexibly assess personalities of different
groups of people. We further propose three evaluation metrics to measure the
consistency, robustness, and fairness of assessment results from
state-of-the-art LLMs including ChatGPT and GPT-4. Our experiments reveal
ChatGPT's ability to assess human personalities, and the average results
demonstrate that it can achieve more consistent and fairer assessments in spite
of lower robustness against prompt biases compared with InstructGPT.
","[{'version': 'v1', 'created': 'Wed, 1 Mar 2023 06:16:14 GMT'}, {'version': 'v2', 'created': 'Tue, 7 Mar 2023 05:35:39 GMT'}, {'version': 'v3', 'created': 'Fri, 13 Oct 2023 15:53:00 GMT'}]",2023-10-16,"[['Rao', 'Haocong', ''], ['Leung', 'Cyril', ''], ['Miao', 'Chunyan', '']]"
2403.12316,Chuang Liu,"Chuang Liu, Linhao Yu, Jiaxuan Li, Renren Jin, Yufei Huang, Ling Shi,
  Junhui Zhang, Xinmeng Ji, Tingting Cui, Tao Liu, Jinwang Song, Hongying Zan,
  Sun Li, Deyi Xiong","OpenEval: Benchmarking Chinese LLMs across Capability, Alignment and
  Safety",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The rapid development of Chinese large language models (LLMs) poses big
challenges for efficient LLM evaluation. While current initiatives have
introduced new benchmarks or evaluation platforms for assessing Chinese LLMs,
many of these focus primarily on capabilities, usually overlooking potential
alignment and safety issues. To address this gap, we introduce OpenEval, an
evaluation testbed that benchmarks Chinese LLMs across capability, alignment
and safety. For capability assessment, we include 12 benchmark datasets to
evaluate Chinese LLMs from 4 sub-dimensions: NLP tasks, disciplinary knowledge,
commonsense reasoning and mathematical reasoning. For alignment assessment,
OpenEval contains 7 datasets that examines the bias, offensiveness and
illegalness in the outputs yielded by Chinese LLMs. To evaluate safety,
especially anticipated risks (e.g., power-seeking, self-awareness) of advanced
LLMs, we include 6 datasets. In addition to these benchmarks, we have
implemented a phased public evaluation and benchmark update strategy to ensure
that OpenEval is in line with the development of Chinese LLMs or even able to
provide cutting-edge benchmark datasets to guide the development of Chinese
LLMs. In our first public evaluation, we have tested a range of Chinese LLMs,
spanning from 7B to 72B parameters, including both open-source and proprietary
models. Evaluation results indicate that while Chinese LLMs have shown
impressive performance in certain tasks, more attention should be directed
towards broader aspects such as commonsense reasoning, alignment, and safety.
","[{'version': 'v1', 'created': 'Mon, 18 Mar 2024 23:21:37 GMT'}]",2024-03-20,"[['Liu', 'Chuang', ''], ['Yu', 'Linhao', ''], ['Li', 'Jiaxuan', ''], ['Jin', 'Renren', ''], ['Huang', 'Yufei', ''], ['Shi', 'Ling', ''], ['Zhang', 'Junhui', ''], ['Ji', 'Xinmeng', ''], ['Cui', 'Tingting', ''], ['Liu', 'Tao', ''], ['Song', 'Jinwang', ''], ['Zan', 'Hongying', ''], ['Li', 'Sun', ''], ['Xiong', 'Deyi', '']]"
2205.05666,Catherine Wong,"Catherine Wong, William P. McCarthy, Gabriel Grand, Yoni Friedman,
  Joshua B. Tenenbaum, Jacob Andreas, Robert D. Hawkins, Judith E. Fan",Identifying concept libraries from language about object structure,Appears in the conference proceedings of CogSci 2022,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Our understanding of the visual world goes beyond naming objects,
encompassing our ability to parse objects into meaningful parts, attributes,
and relations. In this work, we leverage natural language descriptions for a
diverse set of 2K procedurally generated objects to identify the parts people
use and the principles leading these parts to be favored over others. We
formalize our problem as search over a space of program libraries that contain
different part concepts, using tools from machine translation to evaluate how
well programs expressed in each library align to human language. By combining
naturalistic language at scale with structured program representations, we
discover a fundamental information-theoretic tradeoff governing the part
concepts people name: people favor a lexicon that allows concise descriptions
of each object, while also minimizing the size of the lexicon itself.
","[{'version': 'v1', 'created': 'Wed, 11 May 2022 17:49:25 GMT'}]",2022-05-12,"[['Wong', 'Catherine', ''], ['McCarthy', 'William P.', ''], ['Grand', 'Gabriel', ''], ['Friedman', 'Yoni', ''], ['Tenenbaum', 'Joshua B.', ''], ['Andreas', 'Jacob', ''], ['Hawkins', 'Robert D.', ''], ['Fan', 'Judith E.', '']]"
2305.06218,Naveen Ram,"Naveen Ram, Dima Kuzmin, Ellie Ka In Chio, Moustafa Farid Alzantot,
  Santiago Ontanon, Ambarish Jash, and Judith Yue Li",Multi-Task End-to-End Training Improves Conversational Recommendation,"10 pages, 4 tables, 1 figure",,,,cs.CL cs.AI cs.IR,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we analyze the performance of a multitask end-to-end
transformer model on the task of conversational recommendations, which aim to
provide recommendations based on a user's explicit preferences expressed in
dialogue. While previous works in this area adopt complex multi-component
approaches where the dialogue management and entity recommendation tasks are
handled by separate components, we show that a unified transformer model, based
on the T5 text-to-text transformer model, can perform competitively in both
recommending relevant items and generating conversation dialogue. We fine-tune
our model on the ReDIAL conversational movie recommendation dataset, and create
additional training tasks derived from MovieLens (such as the prediction of
movie attributes and related movies based on an input movie), in a multitask
learning setting. Using a series of probe studies, we demonstrate that the
learned knowledge in the additional tasks is transferred to the conversational
setting, where each task leads to a 9%-52% increase in its related probe score.
","[{'version': 'v1', 'created': 'Mon, 8 May 2023 22:42:48 GMT'}]",2023-05-11,"[['Ram', 'Naveen', ''], ['Kuzmin', 'Dima', ''], ['Chio', 'Ellie Ka In', ''], ['Alzantot', 'Moustafa Farid', ''], ['Ontanon', 'Santiago', ''], ['Jash', 'Ambarish', ''], ['Li', 'Judith Yue', '']]"
1910.04196,Eunah Cho,"Eunah Cho, He Xie, John P. Lalor, Varun Kumar, William M. Campbell","Efficient Semi-Supervised Learning for Natural Language Understanding by
  Optimizing Diversity",IEEE Copyright. To appear at ASRU 2019,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Expanding new functionalities efficiently is an ongoing challenge for
single-turn task-oriented dialogue systems. In this work, we explore
functionality-specific semi-supervised learning via self-training. We consider
methods that augment training data automatically from unlabeled data sets in a
functionality-targeted manner. In addition, we examine multiple techniques for
efficient selection of augmented utterances to reduce training time and
increase diversity. First, we consider paraphrase detection methods that
attempt to find utterance variants of labeled training data with good coverage.
Second, we explore sub-modular optimization based on n-grams features for
utterance selection. Experiments show that functionality-specific self-training
is very effective for improving system performance. In addition, methods
optimizing diversity can reduce training data in many cases to 50% with little
impact on performance.
","[{'version': 'v1', 'created': 'Wed, 9 Oct 2019 18:34:17 GMT'}]",2019-10-11,"[['Cho', 'Eunah', ''], ['Xie', 'He', ''], ['Lalor', 'John P.', ''], ['Kumar', 'Varun', ''], ['Campbell', 'William M.', '']]"
2305.19972,Minglun Han PhD,"Ziyi Ni and Minglun Han and Feilong Chen and Linghui Meng and Jing Shi
  and Pin Lv and Bo Xu","VILAS: Exploring the Effects of Vision and Language Context in Automatic
  Speech Recognition",Accepted to ICASSP 2024,,,,eess.AS cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Enhancing automatic speech recognition (ASR) performance by leveraging
additional multimodal information has shown promising results in previous
studies. However, most of these works have primarily focused on utilizing
visual cues derived from human lip motions. In fact, context-dependent visual
and linguistic cues can also benefit in many scenarios. In this paper, we first
propose ViLaS (Vision and Language into Automatic Speech Recognition), a novel
multimodal ASR model based on the continuous integrate-and-fire (CIF)
mechanism, which can integrate visual and textual context simultaneously or
separately, to facilitate speech recognition. Next, we introduce an effective
training strategy that improves performance in modal-incomplete test scenarios.
Then, to explore the effects of integrating vision and language, we create
VSDial, a multimodal ASR dataset with multimodal context cues in both Chinese
and English versions. Finally, empirical results are reported on the public
Flickr8K and self-constructed VSDial datasets. We explore various cross-modal
fusion schemes, analyze fine-grained crossmodal alignment on VSDial, and
provide insights into the effects of integrating multimodal information on
speech recognition.
","[{'version': 'v1', 'created': 'Wed, 31 May 2023 16:01:20 GMT'}, {'version': 'v2', 'created': 'Mon, 18 Dec 2023 12:29:00 GMT'}]",2023-12-19,"[['Ni', 'Ziyi', ''], ['Han', 'Minglun', ''], ['Chen', 'Feilong', ''], ['Meng', 'Linghui', ''], ['Shi', 'Jing', ''], ['Lv', 'Pin', ''], ['Xu', 'Bo', '']]"
2301.09209,Razvan Pasca,"Razvan-George Pasca, Alexey Gavryushin, Muhammad Hamza, Yen-Ling Kuo,
  Kaichun Mo, Luc Van Gool, Otmar Hilliges, Xi Wang","Summarize the Past to Predict the Future: Natural Language Descriptions
  of Context Boost Multimodal Object Interaction Anticipation",,,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We study object interaction anticipation in egocentric videos. This task
requires an understanding of the spatio-temporal context formed by past actions
on objects, coined action context. We propose TransFusion, a multimodal
transformer-based architecture. It exploits the representational power of
language by summarizing the action context. TransFusion leverages pre-trained
image captioning and vision-language models to extract the action context from
past video frames. This action context together with the next video frame is
processed by the multimodal fusion module to forecast the next object
interaction. Our model enables more efficient end-to-end learning. The large
pre-trained language models add common sense and a generalisation capability.
Experiments on Ego4D and EPIC-KITCHENS-100 show the effectiveness of our
multimodal fusion model. They also highlight the benefits of using
language-based context summaries in a task where vision seems to suffice. Our
method outperforms state-of-the-art approaches by 40.4% in relative terms in
overall mAP on the Ego4D test set. We validate the effectiveness of TransFusion
via experiments on EPIC-KITCHENS-100. Video and code are available at
https://eth-ait.github.io/transfusion-proj/.
","[{'version': 'v1', 'created': 'Sun, 22 Jan 2023 21:30:12 GMT'}, {'version': 'v2', 'created': 'Wed, 22 Mar 2023 21:35:42 GMT'}, {'version': 'v3', 'created': 'Fri, 23 Jun 2023 10:43:14 GMT'}, {'version': 'v4', 'created': 'Sun, 10 Mar 2024 17:21:25 GMT'}]",2024-03-12,"[['Pasca', 'Razvan-George', ''], ['Gavryushin', 'Alexey', ''], ['Hamza', 'Muhammad', ''], ['Kuo', 'Yen-Ling', ''], ['Mo', 'Kaichun', ''], ['Van Gool', 'Luc', ''], ['Hilliges', 'Otmar', ''], ['Wang', 'Xi', '']]"
2306.08804,Aman Chadha Mr.,"Paras Sheth, Tharindu Kumarage, Raha Moraffah, Aman Chadha, and Huan
  Liu","PEACE: Cross-Platform Hate Speech Detection- A Causality-guided
  Framework",ECML PKDD 2023,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Hate speech detection refers to the task of detecting hateful content that
aims at denigrating an individual or a group based on their religion, gender,
sexual orientation, or other characteristics. Due to the different policies of
the platforms, different groups of people express hate in different ways.
Furthermore, due to the lack of labeled data in some platforms it becomes
challenging to build hate speech detection models. To this end, we revisit if
we can learn a generalizable hate speech detection model for the cross platform
setting, where we train the model on the data from one (source) platform and
generalize the model across multiple (target) platforms. Existing
generalization models rely on linguistic cues or auxiliary information, making
them biased towards certain tags or certain kinds of words (e.g., abusive
words) on the source platform and thus not applicable to the target platforms.
Inspired by social and psychological theories, we endeavor to explore if there
exist inherent causal cues that can be leveraged to learn generalizable
representations for detecting hate speech across these distribution shifts. To
this end, we propose a causality-guided framework, PEACE, that identifies and
leverages two intrinsic causal cues omnipresent in hateful content: the overall
sentiment and the aggression in the text. We conduct extensive experiments
across multiple platforms (representing the distribution shift) showing if
causal cues can help cross-platform generalization.
","[{'version': 'v1', 'created': 'Thu, 15 Jun 2023 01:18:02 GMT'}, {'version': 'v2', 'created': 'Sun, 8 Oct 2023 21:44:47 GMT'}]",2023-10-10,"[['Sheth', 'Paras', ''], ['Kumarage', 'Tharindu', ''], ['Moraffah', 'Raha', ''], ['Chadha', 'Aman', ''], ['Liu', 'Huan', '']]"
2311.11375,Xuxin Cheng,"Xuxin Cheng, Bowen Cao, Qichen Ye, Zhihong Zhu, Hongxiang Li, Yuexian
  Zou","ML-LMCL: Mutual Learning and Large-Margin Contrastive Learning for
  Improving ASR Robustness in Spoken Language Understanding",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Spoken language understanding (SLU) is a fundamental task in the
task-oriented dialogue systems. However, the inevitable errors from automatic
speech recognition (ASR) usually impair the understanding performance and lead
to error propagation. Although there are some attempts to address this problem
through contrastive learning, they (1) treat clean manual transcripts and ASR
transcripts equally without discrimination in fine-tuning; (2) neglect the fact
that the semantically similar pairs are still pushed away when applying
contrastive learning; (3) suffer from the problem of Kullback-Leibler (KL)
vanishing. In this paper, we propose Mutual Learning and Large-Margin
Contrastive Learning (ML-LMCL), a novel framework for improving ASR robustness
in SLU. Specifically, in fine-tuning, we apply mutual learning and train two
SLU models on the manual transcripts and the ASR transcripts, respectively,
aiming to iteratively share knowledge between these two models. We also
introduce a distance polarization regularizer to avoid pushing away the
intra-cluster pairs as much as possible. Moreover, we use a cyclical annealing
schedule to mitigate KL vanishing issue. Experiments on three datasets show
that ML-LMCL outperforms existing models and achieves new state-of-the-art
performance.
","[{'version': 'v1', 'created': 'Sun, 19 Nov 2023 16:53:35 GMT'}]",2023-11-21,"[['Cheng', 'Xuxin', ''], ['Cao', 'Bowen', ''], ['Ye', 'Qichen', ''], ['Zhu', 'Zhihong', ''], ['Li', 'Hongxiang', ''], ['Zou', 'Yuexian', '']]"
2210.11220,Shaolei Zhang,"Shaolei Zhang, Shoutao Guo, Yang Feng","Wait-info Policy: Balancing Source and Target at Information Level for
  Simultaneous Machine Translation","Accept to EMNLP 2022. 15 pages, 10 Figures, 6 Tables",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Simultaneous machine translation (SiMT) outputs the translation while
receiving the source inputs, and hence needs to balance the received source
information and translated target information to make a reasonable decision
between waiting for inputs or outputting translation. Previous methods always
balance source and target information at the token level, either directly
waiting for a fixed number of tokens or adjusting the waiting based on the
current token. In this paper, we propose a Wait-info Policy to balance source
and target at the information level. We first quantify the amount of
information contained in each token, named info. Then during simultaneous
translation, the decision of waiting or outputting is made based on the
comparison results between the total info of previous target outputs and
received source inputs. Experiments show that our method outperforms strong
baselines under and achieves better balance via the proposed info.
","[{'version': 'v1', 'created': 'Thu, 20 Oct 2022 12:53:25 GMT'}]",2022-10-21,"[['Zhang', 'Shaolei', ''], ['Guo', 'Shoutao', ''], ['Feng', 'Yang', '']]"
2402.03757,Tianyang Han,"Tianyang Han, Qing Lian, Rui Pan, Renjie Pi, Jipeng Zhang, Shizhe
  Diao, Yong Lin, Tong Zhang",The Instinctive Bias: Spurious Images lead to Hallucination in MLLMs,,,,,cs.CV cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) have recently experienced remarkable progress,
where the advent of multi-modal large language models (MLLMs) has endowed LLMs
with visual capabilities, leading to impressive performances in various
multi-modal tasks. However, those powerful MLLMs such as GPT-4V still fail
spectacularly when presented with certain image and text inputs. In this paper,
we identify a typical class of inputs that baffles MLLMs, which consist of
images that are highly relevant but inconsistent with answers, causing MLLMs to
suffer from hallucination. To quantify the effect, we propose CorrelationQA,
the first benchmark that assesses the hallucination level given spurious
images. This benchmark contains 7,308 text-image pairs across 13 categories.
Based on the proposed CorrelationQA, we conduct a thorough analysis on 9
mainstream MLLMs, illustrating that they universally suffer from this
instinctive bias to varying degrees. We hope that our curated benchmark and
evaluation results aid in better assessments of the MLLMs' robustness in the
presence of misleading images. The resource is available in
https://github.com/MasaiahHan/CorrelationQA.
","[{'version': 'v1', 'created': 'Tue, 6 Feb 2024 06:48:46 GMT'}]",2024-02-07,"[['Han', 'Tianyang', ''], ['Lian', 'Qing', ''], ['Pan', 'Rui', ''], ['Pi', 'Renjie', ''], ['Zhang', 'Jipeng', ''], ['Diao', 'Shizhe', ''], ['Lin', 'Yong', ''], ['Zhang', 'Tong', '']]"
2106.04935,Sara Meftah,"Sara Meftah, Nasredine Semmar, Youssef Tamaazousti, Hassane Essafi,
  Fatiha Sadat","Neural Supervised Domain Adaptation by Augmenting Pre-trained Models
  with Random Units",,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Neural Transfer Learning (TL) is becoming ubiquitous in Natural Language
Processing (NLP), thanks to its high performance on many tasks, especially in
low-resourced scenarios. Notably, TL is widely used for neural domain
adaptation to transfer valuable knowledge from high-resource to low-resource
domains. In the standard fine-tuning scheme of TL, a model is initially
pre-trained on a source domain and subsequently fine-tuned on a target domain
and, therefore, source and target domains are trained using the same
architecture. In this paper, we show through interpretation methods that such
scheme, despite its efficiency, is suffering from a main limitation. Indeed,
although capable of adapting to new domains, pre-trained neurons struggle with
learning certain patterns that are specific to the target domain. Moreover, we
shed light on the hidden negative transfer occurring despite the high
relatedness between source and target domains, which may mitigate the final
gain brought by transfer learning. To address these problems, we propose to
augment the pre-trained model with normalised, weighted and randomly
initialised units that foster a better adaptation while maintaining the
valuable source knowledge. We show that our approach exhibits significant
improvements to the standard fine-tuning scheme for neural domain adaptation
from the news domain to the social media domain on four NLP tasks:
part-of-speech tagging, chunking, named entity recognition and morphosyntactic
tagging.
","[{'version': 'v1', 'created': 'Wed, 9 Jun 2021 09:29:11 GMT'}]",2021-06-10,"[['Meftah', 'Sara', ''], ['Semmar', 'Nasredine', ''], ['Tamaazousti', 'Youssef', ''], ['Essafi', 'Hassane', ''], ['Sadat', 'Fatiha', '']]"
2211.08989,Dan Berrebbi,Dan Berrebbi and Brian Yan and Shinji Watanabe,Avoid Overthinking in Self-Supervised Models for Speech Recognition,,,,,cs.CL cs.SD eess.AS,http://creativecommons.org/licenses/by/4.0/,"  Self-supervised learning (SSL) models reshaped our approach to speech,
language and vision. However their huge size and the opaque relations between
their layers and tasks result in slow inference and network overthinking, where
predictions made from the last layer of large models is worse than those made
from intermediate layers. Early exit (EE) strategies can solve both issues by
dynamically reducing computations at inference time for certain samples.
Although popular for classification tasks in vision and language, EE has seen
less use for sequence-to-sequence speech recognition (ASR) tasks where outputs
from early layers are often degenerate. This challenge is further compounded
when speech SSL models are applied on out-of-distribution (OOD) data. This
paper first shows that SSL models do overthinking in ASR. We then motivate
further research in EE by computing an optimal bound for performance versus
speed trade-offs. To approach this bound we propose two new strategies for ASR:
(1) we adapt the recently proposed patience strategy to ASR; and (2) we design
a new EE strategy specific to ASR that performs better than all strategies
previously introduced.
","[{'version': 'v1', 'created': 'Tue, 1 Nov 2022 15:26:46 GMT'}]",2022-11-17,"[['Berrebbi', 'Dan', ''], ['Yan', 'Brian', ''], ['Watanabe', 'Shinji', '']]"
2312.16148,Timo Spinde,"Timo Spinde, Smi Hinterreiter, Fabian Haak, Terry Ruas, Helge Giese,
  Norman Meuschke, Bela Gipp","The Media Bias Taxonomy: A Systematic Literature Review on the Forms and
  Automated Detection of Media Bias",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The way the media presents events can significantly affect public perception,
which in turn can alter people's beliefs and views. Media bias describes a
one-sided or polarizing perspective on a topic. This article summarizes the
research on computational methods to detect media bias by systematically
reviewing 3140 research papers published between 2019 and 2022. To structure
our review and support a mutual understanding of bias across research domains,
we introduce the Media Bias Taxonomy, which provides a coherent overview of the
current state of research on media bias from different perspectives. We show
that media bias detection is a highly active research field, in which
transformer-based classification approaches have led to significant
improvements in recent years. These improvements include higher classification
accuracy and the ability to detect more fine-granular types of bias. However,
we have identified a lack of interdisciplinarity in existing projects, and a
need for more awareness of the various types of media bias to support
methodologically thorough performance evaluations of media bias detection
systems. Concluding from our analysis, we see the integration of recent machine
learning advancements with reliable and diverse bias assessment strategies from
other research areas as the most promising area for future research
contributions in the field.
","[{'version': 'v1', 'created': 'Tue, 26 Dec 2023 18:13:52 GMT'}, {'version': 'v2', 'created': 'Wed, 27 Dec 2023 09:07:57 GMT'}, {'version': 'v3', 'created': 'Wed, 10 Jan 2024 20:38:55 GMT'}]",2024-01-12,"[['Spinde', 'Timo', ''], ['Hinterreiter', 'Smi', ''], ['Haak', 'Fabian', ''], ['Ruas', 'Terry', ''], ['Giese', 'Helge', ''], ['Meuschke', 'Norman', ''], ['Gipp', 'Bela', '']]"
2112.12672,Francesco Moramarco,"Francesco Moramarco, Damir Juric, Aleksandar Savkov, Jack Flann, Maria
  Lehl, Kristian Boda, Tessa Grafen, Vitalii Zhelezniak, Sunir Gohil, Alex
  Papadopoulos Korfiatis, Nils Hammerla","Towards more patient friendly clinical notes through language models and
  ontologies",,,,35308976,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Clinical notes are an efficient way to record patient information but are
notoriously hard to decipher for non-experts. Automatically simplifying medical
text can empower patients with valuable information about their health, while
saving clinicians time. We present a novel approach to automated simplification
of medical text based on word frequencies and language modelling, grounded on
medical ontologies enriched with layman terms. We release a new dataset of
pairs of publicly available medical sentences and a version of them simplified
by clinicians. Also, we define a novel text simplification metric and
evaluation framework, which we use to conduct a large-scale human evaluation of
our method against the state of the art. Our method based on a language model
trained on medical forum data generates simpler sentences while preserving both
grammar and the original meaning, surpassing the current state of the art.
","[{'version': 'v1', 'created': 'Thu, 23 Dec 2021 16:11:19 GMT'}]",2022-04-04,"[['Moramarco', 'Francesco', ''], ['Juric', 'Damir', ''], ['Savkov', 'Aleksandar', ''], ['Flann', 'Jack', ''], ['Lehl', 'Maria', ''], ['Boda', 'Kristian', ''], ['Grafen', 'Tessa', ''], ['Zhelezniak', 'Vitalii', ''], ['Gohil', 'Sunir', ''], ['Korfiatis', 'Alex Papadopoulos', ''], ['Hammerla', 'Nils', '']]"
2305.05940,Eshaan Tanwar,"Eshaan Tanwar, Subhabrata Dutta, Manish Borthakur, Tanmoy Chakraborty","Multilingual LLMs are Better Cross-lingual In-context Learners with
  Alignment","Accepted in ACL 2023. Code available at
  https://github.com/EshaanT/X-InSTA",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In-context learning (ICL) unfolds as large language models become capable of
inferring test labels conditioned on a few labeled samples without any gradient
update. ICL-enabled large language models provide a promising step forward
toward bypassing recurrent annotation costs in a low-resource setting. Yet,
only a handful of past studies have explored ICL in a cross-lingual setting, in
which the need for transferring label-knowledge from a high-resource language
to a low-resource one is immensely crucial. To bridge the gap, we provide the
first in-depth analysis of ICL for cross-lingual text classification. We find
that the prevalent mode of selecting random input-label pairs to construct the
prompt-context is severely limited in the case of cross-lingual ICL, primarily
due to the lack of alignment in the input as well as the output spaces. To
mitigate this, we propose a novel prompt construction strategy -- Cross-lingual
In-context Source-Target Alignment (X-InSTA). With an injected coherence in the
semantics of the input examples and a task-based alignment across the source
and target languages, X-InSTA is able to outperform random prompt selection by
a large margin across three different tasks using 44 different cross-lingual
pairs.
","[{'version': 'v1', 'created': 'Wed, 10 May 2023 07:24:36 GMT'}, {'version': 'v2', 'created': 'Fri, 26 May 2023 11:13:55 GMT'}, {'version': 'v3', 'created': 'Sat, 24 Jun 2023 07:43:35 GMT'}]",2023-06-27,"[['Tanwar', 'Eshaan', ''], ['Dutta', 'Subhabrata', ''], ['Borthakur', 'Manish', ''], ['Chakraborty', 'Tanmoy', '']]"
2310.05914,Neel Jain,"Neel Jain, Ping-yeh Chiang, Yuxin Wen, John Kirchenbauer, Hong-Min
  Chu, Gowthami Somepalli, Brian R. Bartoldson, Bhavya Kailkhura, Avi
  Schwarzschild, Aniruddha Saha, Micah Goldblum, Jonas Geiping, Tom Goldstein",NEFTune: Noisy Embeddings Improve Instruction Finetuning,"25 pages, Code is available on Github:
  https://github.com/neelsjain/NEFTune",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We show that language model finetuning can be improved, sometimes
dramatically, with a simple augmentation. NEFTune adds noise to the embedding
vectors during training. Standard finetuning of LLaMA-2-7B using Alpaca
achieves 29.79% on AlpacaEval, which rises to 64.69% using noisy embeddings.
NEFTune also improves over strong baselines on modern instruction datasets.
Models trained with Evol-Instruct see a 10% improvement, with ShareGPT an 8%
improvement, and with OpenPlatypus an 8% improvement. Even powerful models
further refined with RLHF such as LLaMA-2-Chat benefit from additional training
with NEFTune.
","[{'version': 'v1', 'created': 'Mon, 9 Oct 2023 17:58:34 GMT'}, {'version': 'v2', 'created': 'Tue, 10 Oct 2023 17:31:00 GMT'}]",2023-10-11,"[['Jain', 'Neel', ''], ['Chiang', 'Ping-yeh', ''], ['Wen', 'Yuxin', ''], ['Kirchenbauer', 'John', ''], ['Chu', 'Hong-Min', ''], ['Somepalli', 'Gowthami', ''], ['Bartoldson', 'Brian R.', ''], ['Kailkhura', 'Bhavya', ''], ['Schwarzschild', 'Avi', ''], ['Saha', 'Aniruddha', ''], ['Goldblum', 'Micah', ''], ['Geiping', 'Jonas', ''], ['Goldstein', 'Tom', '']]"
2305.14239,Yixin Liu,"Yixin Liu, Kejian Shi, Katherine S He, Longtian Ye, Alexander R.
  Fabbri, Pengfei Liu, Dragomir Radev, Arman Cohan",On Learning to Summarize with Large Language Models as References,GitHub Repo: https://github.com/yixinL7/SumLLM,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent studies have found that summaries generated by large language models
(LLMs) are favored by human annotators over the original reference summaries in
commonly used summarization datasets. Therefore, we investigate a new learning
setting of text summarization models that considers the LLMs as the reference
or the gold-standard oracle on these datasets. To examine the standard
practices that are aligned with this new learning setting, we investigate two
LLM-based summary quality evaluation methods for model training and adopt a
contrastive learning training method to leverage the LLM-guided learning
signals. Our experiments on the CNN/DailyMail and XSum datasets demonstrate
that smaller summarization models can achieve similar performance as LLMs under
LLM-based evaluation. However, we found that the smaller models can not yet
reach LLM-level performance under human evaluation despite promising
improvements brought by our proposed training methods. Meanwhile, we perform a
meta-analysis on this new learning setting that reveals a discrepancy between
human and LLM-based evaluation, highlighting the benefits and risks of this
LLM-as-reference setting we investigated.
","[{'version': 'v1', 'created': 'Tue, 23 May 2023 16:56:04 GMT'}, {'version': 'v2', 'created': 'Thu, 16 Nov 2023 05:55:43 GMT'}]",2023-11-17,"[['Liu', 'Yixin', ''], ['Shi', 'Kejian', ''], ['He', 'Katherine S', ''], ['Ye', 'Longtian', ''], ['Fabbri', 'Alexander R.', ''], ['Liu', 'Pengfei', ''], ['Radev', 'Dragomir', ''], ['Cohan', 'Arman', '']]"
1803.06500,Joseph Corneli,"Joseph Corneli, Ursula Martin, Dave Murray-Rust, Gabriela Rino Nesin,
  and Alison Pease",Argumentation theory for mathematical argument,44 pages; to appear in Argumentation,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  To adequately model mathematical arguments the analyst must be able to
represent the mathematical objects under discussion and the relationships
between them, as well as inferences drawn about these objects and relationships
as the discourse unfolds. We introduce a framework with these properties, which
has been used to analyse mathematical dialogues and expository texts. The
framework can recover salient elements of discourse at, and within, the
sentence level, as well as the way mathematical content connects to form larger
argumentative structures. We show how the framework might be used to support
computational reasoning, and argue that it provides a more natural way to
examine the process of proving theorems than do Lamport's structured proofs.
","[{'version': 'v1', 'created': 'Sat, 17 Mar 2018 13:20:37 GMT'}, {'version': 'v2', 'created': 'Sun, 15 Jul 2018 14:16:51 GMT'}]",2018-07-17,"[['Corneli', 'Joseph', ''], ['Martin', 'Ursula', ''], ['Murray-Rust', 'Dave', ''], ['Nesin', 'Gabriela Rino', ''], ['Pease', 'Alison', '']]"
1612.00584,Yuanzhi Ke,"Yuanzhi Ke, Masafumi Hagiwara","Alleviating Overfitting for Polysemous Words for Word Representation
  Estimation Using Lexicons",Accepted by IEEE IJCNN 2017. Copyright transferred to IEEE,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Though there are some works on improving distributed word representations
using lexicons, the improper overfitting of the words that have multiple
meanings is a remaining issue deteriorating the learning when lexicons are
used, which needs to be solved. An alternative method is to allocate a vector
per sense instead of a vector per word. However, the word representations
estimated in the former way are not as easy to use as the latter one. Our
previous work uses a probabilistic method to alleviate the overfitting, but it
is not robust with a small corpus. In this paper, we propose a new neural
network to estimate distributed word representations using a lexicon and a
corpus. We add a lexicon layer in the continuous bag-of-words model and a
threshold node after the output of the lexicon layer. The threshold rejects the
unreliable outputs of the lexicon layer that are less likely to be the same
with their inputs. In this way, it alleviates the overfitting of the polysemous
words. The proposed neural network can be trained using negative sampling,
which maximizing the log probabilities of target words given the context words,
by distinguishing the target words from random noises. We compare the proposed
neural network with the continuous bag-of-words model, the other works
improving it, and the previous works estimating distributed word
representations using both a lexicon and a corpus. The experimental results
show that the proposed neural network is more efficient and balanced for both
semantic tasks and syntactic tasks than the previous works, and robust to the
size of the corpus.
","[{'version': 'v1', 'created': 'Fri, 2 Dec 2016 07:45:40 GMT'}, {'version': 'v2', 'created': 'Thu, 9 Mar 2017 12:36:26 GMT'}]",2017-03-10,"[['Ke', 'Yuanzhi', ''], ['Hagiwara', 'Masafumi', '']]"
2101.08426,Yutao Zhu,"Yutao Zhu, Jian-Yun Nie, Kun Zhou, Pan Du, Zhicheng Dou",Content Selection Network for Document-grounded Retrieval-based Chatbots,ECIR 2021 Camera Ready,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Grounding human-machine conversation in a document is an effective way to
improve the performance of retrieval-based chatbots. However, only a part of
the document content may be relevant to help select the appropriate response at
a round. It is thus crucial to select the part of document content relevant to
the current conversation context. In this paper, we propose a document content
selection network (CSN) to perform explicit selection of relevant document
contents, and filter out the irrelevant parts. We show in experiments on two
public document-grounded conversation datasets that CSN can effectively help
select the relevant document contents to the conversation context, and it
produces better results than the state-of-the-art approaches. Our code and
datasets are available at https://github.com/DaoD/CSN.
","[{'version': 'v1', 'created': 'Thu, 21 Jan 2021 03:47:06 GMT'}]",2021-01-22,"[['Zhu', 'Yutao', ''], ['Nie', 'Jian-Yun', ''], ['Zhou', 'Kun', ''], ['Du', 'Pan', ''], ['Dou', 'Zhicheng', '']]"
2301.04788,Shaonan Wang,"Shaonan Wang, Nai Ding, Nan Lin, Jiajun Zhang, Chengqing Zong","Language Cognition and Language Computation -- Human and Machine
  Language Understanding","A survey of language comprehension in cognitive sciences and language
  understanding in computer sciences and their relations",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Language understanding is a key scientific issue in the fields of cognitive
and computer science. However, the two disciplines differ substantially in the
specific research questions. Cognitive science focuses on analyzing the
specific mechanism of the brain and investigating the brain's response to
language; few studies have examined the brain's language system as a whole. By
contrast, computer scientists focus on the efficiency of practical applications
when choosing research questions but may ignore the most essential laws of
language. Given these differences, can a combination of the disciplines offer
new insights for building intelligent language models and studying language
cognitive mechanisms? In the following text, we first review the research
questions, history, and methods of language understanding in cognitive and
computer science, focusing on the current progress and challenges. We then
compare and contrast the research of language understanding in cognitive and
computer sciences. Finally, we review existing work that combines insights from
language cognition and language computation and offer prospects for future
development trends.
","[{'version': 'v1', 'created': 'Thu, 12 Jan 2023 02:37:00 GMT'}]",2023-01-13,"[['Wang', 'Shaonan', ''], ['Ding', 'Nai', ''], ['Lin', 'Nan', ''], ['Zhang', 'Jiajun', ''], ['Zong', 'Chengqing', '']]"
2210.02659,Agostina Calabrese,"Agostina Calabrese, Bj\""orn Ross, Mirella Lapata",Explainable Abuse Detection as Intent Classification and Slot Filling,"14 pages, 2 figures, to be published in TACL (pre-MIT Press
  publication version)",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  To proactively offer social media users a safe online experience, there is a
need for systems that can detect harmful posts and promptly alert platform
moderators. In order to guarantee the enforcement of a consistent policy,
moderators are provided with detailed guidelines. In contrast, most
state-of-the-art models learn what abuse is from labelled examples and as a
result base their predictions on spurious cues, such as the presence of group
identifiers, which can be unreliable. In this work we introduce the concept of
policy-aware abuse detection, abandoning the unrealistic expectation that
systems can reliably learn which phenomena constitute abuse from inspecting the
data alone. We propose a machine-friendly representation of the policy that
moderators wish to enforce, by breaking it down into a collection of intents
and slots. We collect and annotate a dataset of 3,535 English posts with such
slots, and show how architectures for intent classification and slot filling
can be used for abuse detection, while providing a rationale for model
decisions.
","[{'version': 'v1', 'created': 'Thu, 6 Oct 2022 03:33:30 GMT'}]",2022-10-07,"[['Calabrese', 'Agostina', ''], ['Ross', 'Björn', ''], ['Lapata', 'Mirella', '']]"
2004.13886,Bradley Hauer,"Bradley Hauer, Grzegorz Kondrak",Synonymy = Translational Equivalence,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Synonymy and translational equivalence are the relations of sameness of
meaning within and across languages. As the principal relations in wordnets and
multi-wordnets, they are vital to computational lexical semantics, yet the
field suffers from the absence of a common formal framework to define their
properties and relationship. This paper proposes a unifying treatment of these
two relations, which is validated by experiments on existing resources. In our
view, synonymy and translational equivalence are simply different types of
semantic identity. The theory establishes a solid foundation for critically
re-evaluating prior work in cross-lingual semantics, and facilitating the
creation, verification, and amelioration of lexical resources.
","[{'version': 'v1', 'created': 'Tue, 28 Apr 2020 23:15:02 GMT'}, {'version': 'v2', 'created': 'Fri, 11 Dec 2020 22:58:05 GMT'}]",2020-12-15,"[['Hauer', 'Bradley', ''], ['Kondrak', 'Grzegorz', '']]"
2401.17827,Ivan P Yamshchikov,"Christeena Varghese, Sergey Koshelev, Ivan P. Yamshchikov",Neural Machine Translation for Malayalam Paraphrase Generation,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This study explores four methods of generating paraphrases in Malayalam,
utilizing resources available for English paraphrasing and pre-trained Neural
Machine Translation (NMT) models. We evaluate the resulting paraphrases using
both automated metrics, such as BLEU, METEOR, and cosine similarity, as well as
human annotation. Our findings suggest that automated evaluation measures may
not be fully appropriate for Malayalam, as they do not consistently align with
human judgment. This discrepancy underscores the need for more nuanced
paraphrase evaluation approaches especially for highly agglutinative languages.
","[{'version': 'v1', 'created': 'Wed, 31 Jan 2024 13:40:00 GMT'}]",2024-02-01,"[['Varghese', 'Christeena', ''], ['Koshelev', 'Sergey', ''], ['Yamshchikov', 'Ivan P.', '']]"
2302.00907,Tong Zhang,"Tong Zhang, Yong Liu, Boyang Li, Zhiwei Zeng, Pengwei Wang, Yuan You,
  Chunyan Miao, Lizhen Cui","History-Aware Hierarchical Transformer for Multi-session Open-domain
  Dialogue System",EMNLP 2022(Findings),,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  With the evolution of pre-trained language models, current open-domain
dialogue systems have achieved great progress in conducting one-session
conversations. In contrast, Multi-Session Conversation (MSC), which consists of
multiple sessions over a long term with the same user, is under-investigated.
In this paper, we propose History-Aware Hierarchical Transformer (HAHT) for
multi-session open-domain dialogue. HAHT maintains a long-term memory of
history conversations and utilizes history information to understand current
conversation context and generate well-informed and context-relevant responses.
Specifically, HAHT first encodes history conversation sessions hierarchically
into a history memory. Then, HAHT leverages historical information to
facilitate the understanding of the current conversation context by encoding
the history memory together with the current context with attention-based
mechanisms. Finally, to explicitly utilize historical information, HAHT uses a
history-aware response generator that switches between a generic vocabulary and
a history-aware vocabulary. Experimental results on a large-scale MSC dataset
suggest that the proposed HAHT model consistently outperforms baseline models.
Human evaluation results support that HAHT generates more human-like,
context-relevant and history-relevant responses than baseline models.
","[{'version': 'v1', 'created': 'Thu, 2 Feb 2023 06:54:33 GMT'}]",2023-02-03,"[['Zhang', 'Tong', ''], ['Liu', 'Yong', ''], ['Li', 'Boyang', ''], ['Zeng', 'Zhiwei', ''], ['Wang', 'Pengwei', ''], ['You', 'Yuan', ''], ['Miao', 'Chunyan', ''], ['Cui', 'Lizhen', '']]"
1909.08681,Zheng Zhang,"Zheng Zhang, Ruiqing Yin, Jun Zhu, Pierre Zweigenbaum","Cross-Lingual Contextual Word Embeddings Mapping With Multi-Sense Words
  In Mind",12 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent work in cross-lingual contextual word embedding learning cannot handle
multi-sense words well. In this work, we explore the characteristics of
contextual word embeddings and show the link between contextual word embeddings
and word senses. We propose two improving solutions by considering contextual
multi-sense word embeddings as noise (removal) and by generating cluster level
average anchor embeddings for contextual multi-sense word embeddings
(replacement). Experiments show that our solutions can improve the supervised
contextual word embeddings alignment for multi-sense words in a microscopic
perspective without hurting the macroscopic performance on the bilingual
lexicon induction task. For unsupervised alignment, our methods significantly
improve the performance on the bilingual lexicon induction task for more than
10 points.
","[{'version': 'v1', 'created': 'Wed, 18 Sep 2019 20:10:32 GMT'}]",2019-09-20,"[['Zhang', 'Zheng', ''], ['Yin', 'Ruiqing', ''], ['Zhu', 'Jun', ''], ['Zweigenbaum', 'Pierre', '']]"
2210.06431,Yan Sym,"Yan V. Sym, Jo\~ao Gabriel M. Campos, Fabio G. Cozman",BLAB Reporter: Automated journalism covering the Blue Amazon,"Accepted at the 15th International Natural Language Generation
  Conference (INLG 2022)",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This demo paper introduces the BLAB Reporter, a robot-journalist covering the
Brazilian Blue Amazon. The Reporter is based on a pipeline architecture for
Natural Language Generation; it offers daily reports, news summaries and
curious facts in Brazilian Portuguese. By collecting, storing and analysing
structured data from publicly available sources, the robot-journalist uses
domain knowledge to generate and publish texts in Twitter. Code and corpus are
publicly available
","[{'version': 'v1', 'created': 'Sat, 8 Oct 2022 21:51:50 GMT'}]",2022-10-13,"[['Sym', 'Yan V.', ''], ['Campos', 'João Gabriel M.', ''], ['Cozman', 'Fabio G.', '']]"
2212.10711,Alex Tamkin,"Alex Tamkin, Kunal Handa, Avash Shrestha, Noah Goodman",Task Ambiguity in Humans and Language Models,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language models have recently achieved strong performance across a wide range
of NLP benchmarks. However, unlike benchmarks, real world tasks are often
poorly specified, and agents must deduce the user's intended behavior from a
combination of context, instructions, and examples. We investigate how both
humans and models behave in the face of such task ambiguity by proposing
AmbiBench, a new benchmark of six ambiguously-specified classification tasks.
We evaluate humans and models on AmbiBench by seeing how well they identify the
intended task using 1) instructions with varying degrees of ambiguity, and 2)
different numbers of labeled examples. We find that the combination of model
scaling (to 175B parameters) and training with human feedback data enables
models to approach or exceed the accuracy of human participants across tasks,
but that either one alone is not sufficient. In addition, we show how to
dramatically improve the accuracy of language models trained without
large-scale human feedback training by finetuning on a small number of
ambiguous in-context examples, providing a promising direction for teaching
models to generalize well in the face of ambiguity.
","[{'version': 'v1', 'created': 'Tue, 20 Dec 2022 18:35:33 GMT'}]",2022-12-22,"[['Tamkin', 'Alex', ''], ['Handa', 'Kunal', ''], ['Shrestha', 'Avash', ''], ['Goodman', 'Noah', '']]"
2403.12666,Dojun Park,"Dojun Park, Sebastian Pad\'o","Multi-Dimensional Machine Translation Evaluation: Model Evaluation and
  Resource for Korean","9 pages, accepted at LREC-COLING 2024",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Almost all frameworks for the manual or automatic evaluation of machine
translation characterize the quality of an MT output with a single number. An
exception is the Multidimensional Quality Metrics (MQM) framework which offers
a fine-grained ontology of quality dimensions for scoring (such as style,
fluency, accuracy, and terminology). Previous studies have demonstrated the
feasibility of MQM annotation but there are, to our knowledge, no computational
models that predict MQM scores for novel texts, due to a lack of resources. In
this paper, we address these shortcomings by (a) providing a 1200-sentence MQM
evaluation benchmark for the language pair English-Korean and (b) reframing MT
evaluation as the multi-task problem of simultaneously predicting several MQM
scores using SOTA language models, both in a reference-based MT evaluation
setup and a reference-free quality estimation (QE) setup. We find that
reference-free setup outperforms its counterpart in the style dimension while
reference-based models retain an edge regarding accuracy. Overall, RemBERT
emerges as the most promising model. Through our evaluation, we offer an
insight into the translation quality in a more fine-grained, interpretable
manner.
","[{'version': 'v1', 'created': 'Tue, 19 Mar 2024 12:02:38 GMT'}]",2024-03-20,"[['Park', 'Dojun', ''], ['Padó', 'Sebastian', '']]"
2212.06121,Guilherme Moraes Rosa,"Guilherme Rosa and Luiz Bonifacio and Vitor Jeronymo and Hugo Abonizio
  and Marzieh Fadaee and Roberto Lotufo and Rodrigo Nogueira",In Defense of Cross-Encoders for Zero-Shot Retrieval,arXiv admin note: substantial text overlap with arXiv:2206.02873,,,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Bi-encoders and cross-encoders are widely used in many state-of-the-art
retrieval pipelines. In this work we study the generalization ability of these
two types of architectures on a wide range of parameter count on both in-domain
and out-of-domain scenarios. We find that the number of parameters and early
query-document interactions of cross-encoders play a significant role in the
generalization ability of retrieval models. Our experiments show that
increasing model size results in marginal gains on in-domain test sets, but
much larger gains in new domains never seen during fine-tuning. Furthermore, we
show that cross-encoders largely outperform bi-encoders of similar size in
several tasks. In the BEIR benchmark, our largest cross-encoder surpasses a
state-of-the-art bi-encoder by more than 4 average points. Finally, we show
that using bi-encoders as first-stage retrievers provides no gains in
comparison to a simpler retriever such as BM25 on out-of-domain tasks. The code
is available at
https://github.com/guilhermemr04/scaling-zero-shot-retrieval.git
","[{'version': 'v1', 'created': 'Mon, 12 Dec 2022 18:50:03 GMT'}]",2022-12-13,"[['Rosa', 'Guilherme', ''], ['Bonifacio', 'Luiz', ''], ['Jeronymo', 'Vitor', ''], ['Abonizio', 'Hugo', ''], ['Fadaee', 'Marzieh', ''], ['Lotufo', 'Roberto', ''], ['Nogueira', 'Rodrigo', '']]"
1410.7382,Sunil Kumar Kopparapu Dr,Kiran Kumar Bhuvanagiri and Sunil Kumar Kopparapu,Modified Mel Filter Bank to Compute MFCC of Subsampled Speech,arXiv admin note: substantial text overlap with arXiv:1410.6903,,,,cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Mel Frequency Cepstral Coefficients (MFCCs) are the most popularly used
speech features in most speech and speaker recognition applications. In this
work, we propose a modified Mel filter bank to extract MFCCs from subsampled
speech. We also propose a stronger metric which effectively captures the
correlation between MFCCs of original speech and MFCC of resampled speech. It
is found that the proposed method of filter bank construction performs
distinguishably well and gives recognition performance on resampled speech
close to recognition accuracies on original speech.
","[{'version': 'v1', 'created': 'Sat, 25 Oct 2014 10:00:14 GMT'}]",2014-10-29,"[['Bhuvanagiri', 'Kiran Kumar', ''], ['Kopparapu', 'Sunil Kumar', '']]"
2208.05051,Jing Qian,"Jing Qian, Hong Wang, Zekun Li, Shiyang Li, Xifeng Yan",Limitations of Language Models in Arithmetic and Symbolic Induction,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Recent work has shown that large pretrained Language Models (LMs) can not
only perform remarkably well on a range of Natural Language Processing (NLP)
tasks but also start improving on reasoning tasks such as arithmetic induction,
symbolic manipulation, and commonsense reasoning with increasing size of
models. However, it is still unclear what the underlying capabilities of these
LMs are. Surprisingly, we find that these models have limitations on certain
basic symbolic manipulation tasks such as copy, reverse, and addition. When the
total number of symbols or repeating symbols increases, the model performance
drops quickly. We investigate the potential causes behind this phenomenon and
examine a set of possible methods, including explicit positional markers,
fine-grained computation steps, and LMs with callable programs. Experimental
results show that none of these techniques can solve the simplest addition
induction problem completely. In the end, we introduce LMs with tutor, which
demonstrates every single step of teaching. LMs with tutor is able to deliver
100% accuracy in situations of OOD and repeating symbols, shedding new insights
on the boundary of large LMs in induction.
","[{'version': 'v1', 'created': 'Tue, 9 Aug 2022 21:47:01 GMT'}]",2022-08-11,"[['Qian', 'Jing', ''], ['Wang', 'Hong', ''], ['Li', 'Zekun', ''], ['Li', 'Shiyang', ''], ['Yan', 'Xifeng', '']]"
cs/9910011,Anand V. Raman,Anand Venkataraman,A statistical model for word discovery in child directed speech,"48 pgs, 10 figs",,,,cs.CL cs.LG,,"  A statistical model for segmentation and word discovery in child directed
speech is presented. An incremental unsupervised learning algorithm to infer
word boundaries based on this model is described and results of empirical tests
showing that the algorithm is competitive with other models that have been used
for similar tasks are also presented.
","[{'version': 'v1', 'created': 'Wed, 13 Oct 1999 03:25:33 GMT'}]",2007-05-23,"[['Venkataraman', 'Anand', '']]"
2402.04268,Markus Buehler,"A. Ghafarollahi, M.J. Buehler","ProtAgents: Protein discovery via large language model multi-agent
  collaborations combining physics and machine learning",,,,,cond-mat.soft cs.AI cs.CL q-bio.BM,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Designing de novo proteins beyond those found in nature holds significant
promise for advancements in both scientific and engineering applications.
Current methodologies for protein design often rely on AI-based models, such as
surrogate models that address end-to-end problems by linking protein structure
to material properties or vice versa. However, these models frequently focus on
specific material objectives or structural properties, limiting their
flexibility when incorporating out-of-domain knowledge into the design process
or comprehensive data analysis is required. In this study, we introduce
ProtAgents, a platform for de novo protein design based on Large Language
Models (LLMs), where multiple AI agents with distinct capabilities
collaboratively address complex tasks within a dynamic environment. The
versatility in agent development allows for expertise in diverse domains,
including knowledge retrieval, protein structure analysis, physics-based
simulations, and results analysis. The dynamic collaboration between agents,
empowered by LLMs, provides a versatile approach to tackling protein design and
analysis problems, as demonstrated through diverse examples in this study. The
problems of interest encompass designing new proteins, analyzing protein
structures and obtaining new first-principles data -- natural vibrational
frequencies -- via physics simulations. The concerted effort of the system
allows for powerful automated and synergistic design of de novo proteins with
targeted mechanical properties. The flexibility in designing the agents, on one
hand, and their capacity in autonomous collaboration through the dynamic
LLM-based multi-agent environment on the other hand, unleashes great potentials
of LLMs in addressing multi-objective materials problems and opens up new
avenues for autonomous materials discovery and design.
","[{'version': 'v1', 'created': 'Sat, 27 Jan 2024 20:19:49 GMT'}]",2024-02-08,"[['Ghafarollahi', 'A.', ''], ['Buehler', 'M. J.', '']]"
2305.14263,Milind Agarwal,"Milind Agarwal, Md Mahfuz Ibn Alam, Antonios Anastasopoulos","LIMIT: Language Identification, Misidentification, and Translation using
  Hierarchical Models in 350+ Languages","To appear at EMNLP 2023. 24 pages, 2 figures, 12 tables",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  Knowing the language of an input text/audio is a necessary first step for
using almost every NLP tool such as taggers, parsers, or translation systems.
Language identification is a well-studied problem, sometimes even considered
solved; in reality, due to lack of data and computational challenges, current
systems cannot accurately identify most of the world's 7000 languages. To
tackle this bottleneck, we first compile a corpus, MCS-350, of 50K multilingual
and parallel children's stories in 350+ languages. MCS-350 can serve as a
benchmark for language identification of short texts and for 1400+ new
translation directions in low-resource Indian and African languages. Second, we
propose a novel misprediction-resolution hierarchical model, LIMIt, for
language identification that reduces error by 55% (from 0.71 to 0.32) on our
compiled children's stories dataset and by 40% (from 0.23 to 0.14) on the
FLORES-200 benchmark. Our method can expand language identification coverage
into low-resource languages by relying solely on systemic misprediction
patterns, bypassing the need to retrain large models from scratch.
","[{'version': 'v1', 'created': 'Tue, 23 May 2023 17:15:43 GMT'}, {'version': 'v2', 'created': 'Mon, 6 Nov 2023 16:29:21 GMT'}]",2023-11-07,"[['Agarwal', 'Milind', ''], ['Alam', 'Md Mahfuz Ibn', ''], ['Anastasopoulos', 'Antonios', '']]"
2204.05522,Baihan Lin,"Baihan Lin, Guillermo Cecchi, Djallel Bouneffouf",Deep Annotation of Therapeutic Working Alliance in Psychotherapy,,,,,q-bio.NC cs.AI cs.CL cs.HC cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The therapeutic working alliance is an important predictor of the outcome of
the psychotherapy treatment. In practice, the working alliance is estimated
from a set of scoring questionnaires in an inventory that both the patient and
the therapists fill out. In this work, we propose an analytical framework of
directly inferring the therapeutic working alliance from the natural language
within the psychotherapy sessions in a turn-level resolution with deep
embeddings such as the Doc2Vec and SentenceBERT models. The transcript of each
psychotherapy session can be transcribed and generated in real-time from the
session speech recordings, and these embedded dialogues are compared with the
distributed representations of the statements in the working alliance
inventory. We demonstrate, in a real-world dataset with over 950 sessions of
psychotherapy treatments in anxiety, depression, schizophrenia and suicidal
patients, the effectiveness of this method in mapping out trajectories of
patient-therapist alignment and the interpretability that can offer insights in
clinical psychiatry. We believe such a framework can be provide timely feedback
to the therapist regarding the quality of the conversation in interview
sessions.
","[{'version': 'v1', 'created': 'Tue, 12 Apr 2022 04:42:51 GMT'}]",2022-04-14,"[['Lin', 'Baihan', ''], ['Cecchi', 'Guillermo', ''], ['Bouneffouf', 'Djallel', '']]"
1901.08407,Diego Krivochen,Diego Gabriel Krivochen and Beth Phillips,A model for a Lindenmayer reconstruction algorithm,Manuscript. Comments welcomed,,,,cs.FL cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Given an input string s and a specific Lindenmayer system (the so-called
Fibonacci grammar), we define an automaton which is capable of (i) determining
whether s belongs to the set of strings that the Fibonacci grammar can generate
(in other words, if s corresponds to a generation of the grammar) and, if so,
(ii) reconstructing the previous generation.
","[{'version': 'v1', 'created': 'Thu, 24 Jan 2019 13:53:17 GMT'}]",2019-01-25,"[['Krivochen', 'Diego Gabriel', ''], ['Phillips', 'Beth', '']]"
2309.08902,Gene Louis Kim,"Mahammed Kamruzzaman, Md. Minul Islam Shovon, Gene Louis Kim","Investigating Subtler Biases in LLMs: Ageism, Beauty, Institutional, and
  Nationality Bias in Generative Models",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  LLMs are increasingly powerful and widely used to assist users in a variety
of tasks. This use risks the introduction of LLM biases to consequential
decisions such as job hiring, human performance evaluation, and criminal
sentencing. Bias in NLP systems along the lines of gender and ethnicity has
been widely studied, especially for specific stereotypes (e.g., Asians are good
at math). In this paper, we investigate bias along less-studied but still
consequential, dimensions, such as age and beauty, measuring subtler correlated
decisions that LLMs make between social groups and unrelated positive and
negative attributes. We ask whether LLMs hold wide-reaching biases of positive
or negative sentiment for specific social groups similar to the ``what is
beautiful is good'' bias found in people in experimental psychology. We
introduce a template-generated dataset of sentence completion tasks that asks
the model to select the most appropriate attribute to complete an evaluative
statement about a person described as a member of a specific social group. We
also reverse the completion task to select the social group based on an
attribute. We report the correlations that we find for 4 cutting-edge LLMs.
This dataset can be used as a benchmark to evaluate progress in more
generalized biases and the templating technique can be used to expand the
benchmark with minimal additional human annotation.
","[{'version': 'v1', 'created': 'Sat, 16 Sep 2023 07:07:04 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Feb 2024 21:52:50 GMT'}]",2024-02-20,"[['Kamruzzaman', 'Mahammed', ''], ['Shovon', 'Md. Minul Islam', ''], ['Kim', 'Gene Louis', '']]"
1609.03777,Kyuyeon Hwang,"Kyuyeon Hwang, Wonyong Sung","Character-Level Language Modeling with Hierarchical Recurrent Neural
  Networks","Submitted to NIPS 2016 on May 20, 2016 (v1), accepted to ICASSP 2017
  (v2)",,,,cs.LG cs.CL cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recurrent neural network (RNN) based character-level language models (CLMs)
are extremely useful for modeling out-of-vocabulary words by nature. However,
their performance is generally much worse than the word-level language models
(WLMs), since CLMs need to consider longer history of tokens to properly
predict the next one. We address this problem by proposing hierarchical RNN
architectures, which consist of multiple modules with different timescales.
Despite the multi-timescale structures, the input and output layers operate
with the character-level clock, which allows the existing RNN CLM training
approaches to be directly applicable without any modifications. Our CLM models
show better perplexity than Kneser-Ney (KN) 5-gram WLMs on the One Billion Word
Benchmark with only 2% of parameters. Also, we present real-time
character-level end-to-end speech recognition examples on the Wall Street
Journal (WSJ) corpus, where replacing traditional mono-clock RNN CLMs with the
proposed models results in better recognition accuracies even though the number
of parameters are reduced to 30%.
","[{'version': 'v1', 'created': 'Tue, 13 Sep 2016 11:41:48 GMT'}, {'version': 'v2', 'created': 'Thu, 2 Feb 2017 13:49:41 GMT'}]",2017-02-03,"[['Hwang', 'Kyuyeon', ''], ['Sung', 'Wonyong', '']]"
2303.17799,Feng-Ju Chang,"Feng-Ju Chang, Thejaswi Muniyappa, Kanthashree Mysore Sathyendra, Kai
  Wei, Grant P. Strimel, Ross McGowan",Dialog act guided contextual adapter for personalized speech recognition,Accepted at ICASSP 2023,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Personalization in multi-turn dialogs has been a long standing challenge for
end-to-end automatic speech recognition (E2E ASR) models. Recent work on
contextual adapters has tackled rare word recognition using user catalogs. This
adaptation, however, does not incorporate an important cue, the dialog act,
which is available in a multi-turn dialog scenario. In this work, we propose a
dialog act guided contextual adapter network. Specifically, it leverages dialog
acts to select the most relevant user catalogs and creates queries based on
both -- the audio as well as the semantic relationship between the carrier
phrase and user catalogs to better guide the contextual biasing. On industrial
voice assistant datasets, our model outperforms both the baselines - dialog act
encoder-only model, and the contextual adaptation, leading to the most
improvement over the no-context model: 58% average relative word error rate
reduction (WERR) in the multi-turn dialog scenario, in comparison to the
prior-art contextual adapter, which has achieved 39% WERR over the no-context
model.
","[{'version': 'v1', 'created': 'Fri, 31 Mar 2023 05:13:44 GMT'}]",2023-04-03,"[['Chang', 'Feng-Ju', ''], ['Muniyappa', 'Thejaswi', ''], ['Sathyendra', 'Kanthashree Mysore', ''], ['Wei', 'Kai', ''], ['Strimel', 'Grant P.', ''], ['McGowan', 'Ross', '']]"
2103.10763,Jiayan Pei,"Jiayan Pei, Yimin Wu, Zishan Qin, Yao Cong, Jingtao Guan","Attention-based model for predicting question relatedness on Stack
  Overflow","11 pages, 4 figures, IEEE/ACM MSR 2021",,,,cs.CL cs.AI cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Stack Overflow is one of the most popular Programming Community-based
Question Answering (PCQA) websites that has attracted more and more users in
recent years. When users raise or inquire questions in Stack Overflow,
providing related questions can help them solve problems. Although there are
many approaches based on deep learning that can automatically predict the
relatedness between questions, those approaches are limited since interaction
information between two questions may be lost. In this paper, we adopt the deep
learning technique, propose an Attention-based Sentence pair Interaction Model
(ASIM) to predict the relatedness between questions on Stack Overflow
automatically. We adopt the attention mechanism to capture the semantic
interaction information between the questions. Besides, we have pre-trained and
released word embeddings specific to the software engineering domain for this
task, which may also help other related tasks. The experiment results
demonstrate that ASIM has made significant improvement over the baseline
approaches in Precision, Recall, and Micro-F1 evaluation metrics, achieving
state-of-the-art performance in this task. Our model also performs well in the
duplicate question detection task of AskUbuntu, which is a similar but
different task, proving its generalization and robustness.
","[{'version': 'v1', 'created': 'Fri, 19 Mar 2021 12:18:03 GMT'}, {'version': 'v2', 'created': 'Mon, 22 Mar 2021 09:12:02 GMT'}, {'version': 'v3', 'created': 'Thu, 25 Mar 2021 13:06:57 GMT'}, {'version': 'v4', 'created': 'Sat, 27 Mar 2021 06:44:49 GMT'}, {'version': 'v5', 'created': 'Thu, 1 Apr 2021 11:57:51 GMT'}, {'version': 'v6', 'created': 'Mon, 5 Apr 2021 10:37:13 GMT'}]",2021-04-06,"[['Pei', 'Jiayan', ''], ['Wu', 'Yimin', ''], ['Qin', 'Zishan', ''], ['Cong', 'Yao', ''], ['Guan', 'Jingtao', '']]"
2111.00732,Yongrui Chen,"Yongrui Chen, Huiying Li, Guilin Qi, Tianxing Wu, and Tenggou Wang","Outlining and Filling: Hierarchical Query Graph Generation for Answering
  Complex Questions over Knowledge Graphs","Accepted by IEEE Transactions on Knowledge and Data Engineering, 2022",,,,cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Query graph construction aims to construct the correct executable SPARQL on
the KG to answer natural language questions. Although recent methods have
achieved good results using neural network-based query graph ranking, they
suffer from three new challenges when handling more complex questions: 1)
complicated SPARQL syntax, 2) huge search space, and 3) locally ambiguous query
graphs. In this paper, we provide a new solution. As a preparation, we extend
the query graph by treating each SPARQL clause as a subgraph consisting of
vertices and edges and define a unified graph grammar called AQG to describe
the structure of query graphs. Based on these concepts, we propose a novel
end-to-end model that performs hierarchical autoregressive decoding to generate
query graphs. The high-level decoding generates an AQG as a constraint to prune
the search space and reduce the locally ambiguous query graph. The bottom-level
decoding accomplishes the query graph construction by selecting appropriate
instances from the preprepared candidates to fill the slots in the AQG. The
experimental results show that our method greatly improves the SOTA performance
on complex KGQA benchmarks. Equipped with pre-trained models, the performance
of our method is further improved, achieving SOTA for all three datasets used.
","[{'version': 'v1', 'created': 'Mon, 1 Nov 2021 07:08:46 GMT'}, {'version': 'v2', 'created': 'Sun, 11 Sep 2022 13:20:43 GMT'}]",2022-09-13,"[['Chen', 'Yongrui', ''], ['Li', 'Huiying', ''], ['Qi', 'Guilin', ''], ['Wu', 'Tianxing', ''], ['Wang', 'Tenggou', '']]"
2212.10784,Jiashu Xu,"Jiashu Xu, Mingyu Derek Ma, Muhao Chen","Can NLI Provide Proper Indirect Supervision for Low-resource Biomedical
  Relation Extraction?","16 pages; ACL 2023; code in
  https://github.com/luka-group/NLI_as_Indirect_Supervision",,,,cs.CL cs.AI q-bio.QM,http://creativecommons.org/licenses/by/4.0/,"  Two key obstacles in biomedical relation extraction (RE) are the scarcity of
annotations and the prevalence of instances without explicitly pre-defined
labels due to low annotation coverage. Existing approaches, which treat
biomedical RE as a multi-class classification task, often result in poor
generalization in low-resource settings and do not have the ability to make
selective prediction on unknown cases but give a guess from seen relations,
hindering the applicability of those approaches. We present NBR, which converts
biomedical RE as natural language inference formulation through indirect
supervision. By converting relations to natural language hypotheses, NBR is
capable of exploiting semantic cues to alleviate annotation scarcity. By
incorporating a ranking-based loss that implicitly calibrates abstinent
instances, NBR learns a clearer decision boundary and is instructed to abstain
on uncertain instances. Extensive experiments on three widely-used biomedical
RE benchmarks, namely ChemProt, DDI and GAD, verify the effectiveness of NBR in
both full-set and low-resource regimes. Our analysis demonstrates that indirect
supervision benefits biomedical RE even when a domain gap exists, and combining
NLI knowledge with biomedical knowledge leads to the best performance gains.
","[{'version': 'v1', 'created': 'Wed, 21 Dec 2022 05:49:08 GMT'}, {'version': 'v2', 'created': 'Tue, 23 May 2023 05:22:07 GMT'}, {'version': 'v3', 'created': 'Thu, 19 Oct 2023 05:46:10 GMT'}]",2023-10-20,"[['Xu', 'Jiashu', ''], ['Ma', 'Mingyu Derek', ''], ['Chen', 'Muhao', '']]"
2210.07032,Hao Zhou,"Hao Zhou, Man Lan, Yuanbin Wu, Yuefeng Chen and Meirong Ma","Prompt-based Connective Prediction Method for Fine-grained Implicit
  Discourse Relation Recognition",Findings of EMNLP 2022 Accepted,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Due to the absence of connectives, implicit discourse relation recognition
(IDRR) is still a challenging and crucial task in discourse analysis. Most of
the current work adopted multi-task learning to aid IDRR through explicit
discourse relation recognition (EDRR) or utilized dependencies between
discourse relation labels to constrain model predictions. But these methods
still performed poorly on fine-grained IDRR and even utterly misidentified on
most of the few-shot discourse relation classes. To address these problems, we
propose a novel Prompt-based Connective Prediction (PCP) method for IDRR. Our
method instructs large-scale pre-trained models to use knowledge relevant to
discourse relation and utilizes the strong correlation between connectives and
discourse relation to help the model recognize implicit discourse relations.
Experimental results show that our method surpasses the current
state-of-the-art model and achieves significant improvements on those
fine-grained few-shot discourse relation. Moreover, our approach is able to be
transferred to EDRR and obtain acceptable results. Our code is released in
https://github.com/zh-i9/PCP-for-IDRR.
","[{'version': 'v1', 'created': 'Thu, 13 Oct 2022 13:47:13 GMT'}, {'version': 'v2', 'created': 'Sun, 16 Oct 2022 05:33:52 GMT'}]",2022-10-18,"[['Zhou', 'Hao', ''], ['Lan', 'Man', ''], ['Wu', 'Yuanbin', ''], ['Chen', 'Yuefeng', ''], ['Ma', 'Meirong', '']]"
1805.01035,Roee Aharoni,Roee Aharoni and Yoav Goldberg,Split and Rephrase: Better Evaluation and a Stronger Baseline,Accepted as a short paper in ACL 2018,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Splitting and rephrasing a complex sentence into several shorter sentences
that convey the same meaning is a challenging problem in NLP. We show that
while vanilla seq2seq models can reach high scores on the proposed benchmark
(Narayan et al., 2017), they suffer from memorization of the training set which
contains more than 89% of the unique simple sentences from the validation and
test sets. To aid this, we present a new train-development-test data split and
neural models augmented with a copy-mechanism, outperforming the best reported
baseline by 8.68 BLEU and fostering further progress on the task.
","[{'version': 'v1', 'created': 'Wed, 2 May 2018 21:36:38 GMT'}]",2018-05-04,"[['Aharoni', 'Roee', ''], ['Goldberg', 'Yoav', '']]"
2210.14140,Yixuan Su,Yixuan Su and Nigel Collier,Contrastive Search Is What You Need For Neural Text Generation,TMLR'23,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Generating text with autoregressive language models (LMs) is of great
importance to many natural language processing (NLP) applications. Previous
solutions for this task often produce text that contains degenerative
expressions or lacks semantic consistency. Recently, Su et al. introduced a new
decoding method, contrastive search, based on the isotropic representation
space of the language model and obtained new state of the art on various
benchmarks. Additionally, Su et al. argued that the representations of
autoregressive LMs (e.g. GPT-2) are intrinsically anisotropic which is also
shared by previous studies. Therefore, to ensure the language model follows an
isotropic distribution, Su et al. proposed a contrastive learning scheme,
SimCTG, which calibrates the language model's representations through
additional training.
  In this study, we first answer the question: ""Are autoregressive LMs really
anisotropic?"". To this end, we extensively evaluate the isotropy of LMs across
16 major languages. Surprisingly, we find that the anisotropic problem only
exists in the two specific English GPT-2-small/medium models. On the other
hand, all other evaluated LMs are naturally isotropic which is in contrast to
the conclusion drawn by previous studies. Based on our findings, we further
assess the contrastive search decoding method using off-the-shelf LMs on four
generation tasks across 16 languages. Our experimental results demonstrate that
contrastive search significantly outperforms previous decoding methods without
any additional training. More notably, on 12 out of the 16 evaluated languages,
contrastive search performs comparably with human-level performances as judged
by human evaluations. Our code and other related resources are publicly
available at https://github.com/yxuansu/Contrastive_Search_Is_What_You_Need.
","[{'version': 'v1', 'created': 'Tue, 25 Oct 2022 16:40:48 GMT'}, {'version': 'v2', 'created': 'Fri, 28 Oct 2022 18:48:56 GMT'}, {'version': 'v3', 'created': 'Tue, 14 Feb 2023 14:22:42 GMT'}]",2023-02-15,"[['Su', 'Yixuan', ''], ['Collier', 'Nigel', '']]"
2306.08122,Mujahid Quidwai,"Mujahid Ali Quidwai, Chunhui Li, Parijat Dube","Beyond Black Box AI-Generated Plagiarism Detection: From Sentence to
  Document Level","10 Pages, 4 Figures, 9 Tables, to be published in 18th Workshop on
  Innovative Use of NLP for Building Educational Applications",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  The increasing reliance on large language models (LLMs) in academic writing
has led to a rise in plagiarism. Existing AI-generated text classifiers have
limited accuracy and often produce false positives. We propose a novel approach
using natural language processing (NLP) techniques, offering quantifiable
metrics at both sentence and document levels for easier interpretation by human
evaluators. Our method employs a multi-faceted approach, generating multiple
paraphrased versions of a given question and inputting them into the LLM to
generate answers. By using a contrastive loss function based on cosine
similarity, we match generated sentences with those from the student's
response. Our approach achieves up to 94% accuracy in classifying human and AI
text, providing a robust and adaptable solution for plagiarism detection in
academic settings. This method improves with LLM advancements, reducing the
need for new model training or reconfiguration, and offers a more transparent
way of evaluating and detecting AI-generated text.
","[{'version': 'v1', 'created': 'Tue, 13 Jun 2023 20:34:55 GMT'}]",2023-06-16,"[['Quidwai', 'Mujahid Ali', ''], ['Li', 'Chunhui', ''], ['Dube', 'Parijat', '']]"
1806.00754,Hwiyeol Jo,Hwiyeol Jo and Jeong Ryu,Psychological State in Text: A Limitation of Sentiment Analysis,"In Proceedings of IJCAI-ECAI Workshop on AI and Computational
  Psychology: Theories, Algorithms and Applications (CompPsy)",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Starting with the idea that sentiment analysis models should be able to
predict not only positive or negative but also other psychological states of a
person, we implement a sentiment analysis model to investigate the relationship
between the model and emotional state. We first examine psychological
measurements of 64 participants and ask them to write a book report about a
story. After that, we train our sentiment analysis model using crawled movie
review data. We finally evaluate participants' writings, using the pretrained
model as a concept of transfer learning. The result shows that sentiment
analysis model performs good at predicting a score, but the score does not have
any correlation with human's self-checked sentiment.
","[{'version': 'v1', 'created': 'Sun, 3 Jun 2018 08:52:23 GMT'}]",2018-06-05,"[['Jo', 'Hwiyeol', ''], ['Ryu', 'Jeong', '']]"
2311.12537,Tong Zhou,"Tong Zhou, Yubo Chen, Pengfei Cao, Kang Liu, Jun Zhao, Shengping Liu","Oasis: Data Curation and Assessment System for Pretraining of Large
  Language Models",,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Data is one of the most critical elements in building a large language model.
However, existing systems either fail to customize a corpus curation pipeline
or neglect to leverage comprehensive corpus assessment for iterative
optimization of the curation. To this end, we present a pretraining corpus
curation and assessment platform called Oasis -- a one-stop system for data
quality improvement and quantification with user-friendly interactive
interfaces. Specifically, the interactive modular rule filter module can devise
customized rules according to explicit feedback. The debiased neural filter
module builds the quality classification dataset in a negative-centric manner
to remove the undesired bias. The adaptive document deduplication module could
execute large-scale deduplication with limited memory resources. These three
parts constitute the customized data curation module. And in the holistic data
assessment module, a corpus can be assessed in local and global views, with
three evaluation means including human, GPT-4, and heuristic metrics. We
exhibit a complete process to use Oasis for the curation and assessment of
pretraining data. In addition, an 800GB bilingual corpus curated by Oasis is
publicly released.
","[{'version': 'v1', 'created': 'Tue, 21 Nov 2023 11:32:23 GMT'}]",2023-11-22,"[['Zhou', 'Tong', ''], ['Chen', 'Yubo', ''], ['Cao', 'Pengfei', ''], ['Liu', 'Kang', ''], ['Zhao', 'Jun', ''], ['Liu', 'Shengping', '']]"
1506.08349,Lantian Li Mr.,Lantian Li and Yiye Lin and Zhiyong Zhang and Dong Wang,"Improved Deep Speaker Feature Learning for Text-Dependent Speaker
  Recognition",arXiv admin note: substantial text overlap with arXiv:1505.06427,,,,cs.CL cs.LG cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A deep learning approach has been proposed recently to derive speaker
identifies (d-vector) by a deep neural network (DNN). This approach has been
applied to text-dependent speaker recognition tasks and shows reasonable
performance gains when combined with the conventional i-vector approach.
Although promising, the existing d-vector implementation still can not compete
with the i-vector baseline. This paper presents two improvements for the deep
learning approach: a phonedependent DNN structure to normalize phone variation,
and a new scoring approach based on dynamic time warping (DTW). Experiments on
a text-dependent speaker recognition task demonstrated that the proposed
methods can provide considerable performance improvement over the existing
d-vector implementation.
","[{'version': 'v1', 'created': 'Sun, 28 Jun 2015 03:32:02 GMT'}]",2015-06-30,"[['Li', 'Lantian', ''], ['Lin', 'Yiye', ''], ['Zhang', 'Zhiyong', ''], ['Wang', 'Dong', '']]"
2211.14360,Viktor Scherbakov,Viktor Scherbakov and Vladimir Mayorov,Finetuning BERT on Partially Annotated NER Corpora,"6 pages, to be published in Proceedings of ISP RAS Open Conference
  2022",,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Most Named Entity Recognition (NER) models operate under the assumption that
training datasets are fully labelled. While it is valid for established
datasets like CoNLL 2003 and OntoNotes, sometimes it is not feasible to obtain
the complete dataset annotation. These situations may occur, for instance,
after selective annotation of entities for cost reduction. This work presents
an approach to finetuning BERT on such partially labelled datasets using
self-supervision and label preprocessing. Our approach outperforms the previous
LSTM-based label preprocessing baseline, significantly improving the
performance on poorly labelled datasets. We demonstrate that following our
approach while finetuning RoBERTa on CoNLL 2003 dataset with only 10% of total
entities labelled is enough to reach the performance of the baseline trained on
the same dataset with 50% of the entities labelled.
","[{'version': 'v1', 'created': 'Fri, 25 Nov 2022 19:54:30 GMT'}]",2022-11-29,"[['Scherbakov', 'Viktor', ''], ['Mayorov', 'Vladimir', '']]"
2211.01638,Zhicheng Wang,"Zhicheng Wang, Tianyu Shi, Cong Liu",Joint Chinese Word Segmentation and Span-based Constituency Parsing,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In constituency parsing, span-based decoding is an important direction.
However, for Chinese sentences, because of their linguistic characteristics, it
is necessary to utilize other models to perform word segmentation first, which
introduces a series of uncertainties and generally leads to errors in the
computation of the constituency tree afterward. This work proposes a method for
joint Chinese word segmentation and Span-based Constituency Parsing by adding
extra labels to individual Chinese characters on the parse trees. Through
experiments, the proposed algorithm outperforms the recent models for joint
segmentation and constituency parsing on CTB 5.1.
","[{'version': 'v1', 'created': 'Thu, 3 Nov 2022 08:19:00 GMT'}, {'version': 'v2', 'created': 'Wed, 30 Nov 2022 11:24:05 GMT'}]",2022-12-01,"[['Wang', 'Zhicheng', ''], ['Shi', 'Tianyu', ''], ['Liu', 'Cong', '']]"
1511.02274,Zichao Yang,"Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Smola",Stacked Attention Networks for Image Question Answering,test-dev/standard results added,,,,cs.LG cs.CL cs.CV cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents stacked attention networks (SANs) that learn to answer
natural language questions from images. SANs use semantic representation of a
question as query to search for the regions in an image that are related to the
answer. We argue that image question answering (QA) often requires multiple
steps of reasoning. Thus, we develop a multiple-layer SAN in which we query an
image multiple times to infer the answer progressively. Experiments conducted
on four image QA data sets demonstrate that the proposed SANs significantly
outperform previous state-of-the-art approaches. The visualization of the
attention layers illustrates the progress that the SAN locates the relevant
visual clues that lead to the answer of the question layer-by-layer.
","[{'version': 'v1', 'created': 'Sat, 7 Nov 2015 00:43:32 GMT'}, {'version': 'v2', 'created': 'Tue, 26 Jan 2016 20:37:49 GMT'}]",2016-01-27,"[['Yang', 'Zichao', ''], ['He', 'Xiaodong', ''], ['Gao', 'Jianfeng', ''], ['Deng', 'Li', ''], ['Smola', 'Alex', '']]"
2205.11930,Kawin Ethayarajh,"Kawin Ethayarajh, Dan Jurafsky",The Authenticity Gap in Human Evaluation,EMNLP 2022,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Human ratings are the gold standard in NLG evaluation. The standard protocol
is to collect ratings of generated text, average across annotators, and rank
NLG systems by their average scores. However, little consideration has been
given as to whether this approach faithfully captures human preferences.
Analyzing this standard protocol through the lens of utility theory in
economics, we identify the implicit assumptions it makes about annotators.
These assumptions are often violated in practice, in which case annotator
ratings cease to reflect their preferences. The most egregious violations come
from using Likert scales, which provably reverse the direction of the true
preference in certain cases. We suggest improvements to the standard protocol
to make it more theoretically sound, but even in its improved form, it cannot
be used to evaluate open-ended tasks like story generation. For the latter, we
propose a new human evaluation protocol called $\textit{system-level
probabilistic assessment}$ (SPA). When human evaluation of stories is done with
SPA, we can recover the ordering of GPT-3 models by size, with statistically
significant results. However, when human evaluation is done with the standard
protocol, less than half of the expected preferences can be recovered (e.g.,
there is no significant difference between $\texttt{curie}$ and
$\texttt{davinci}$, despite using a highly powered test).
","[{'version': 'v1', 'created': 'Tue, 24 May 2022 09:51:27 GMT'}, {'version': 'v2', 'created': 'Thu, 3 Nov 2022 03:04:39 GMT'}]",2022-11-04,"[['Ethayarajh', 'Kawin', ''], ['Jurafsky', 'Dan', '']]"
2111.14709,Zhengxiang Wang,Zhengxiang Wang,"Linguistic Knowledge in Data Augmentation for Natural Language
  Processing: An Example on Chinese Question Matching",10 pages; 7 tables; 3 figures,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  To investigate the role of linguistic knowledge in data augmentation (DA) for
Natural Language Processing (NLP), we designed two adapted DA programs and
applied them to LCQMC (a Large-scale Chinese Question Matching Corpus) for a
binary Chinese question matching classification task. The two DA programs
produce augmented texts by five simple text editing operations (or DA
techniques), largely irrespective of language generation rules, but one is
enhanced with a pre-trained n-gram language model to fuse it with prior
linguistic knowledge. We then trained four neural network models (BOW, CNN,
LSTM, and GRU) and a pre-trained model (ERNIE-Gram) on the LCQMCs train sets of
varying size as well as the related augmented train sets produced by the two DA
programs. The results show that there are no significant performance
differences between the models trained on the two types of augmented train
sets, both when the five DA techniques are applied together or separately.
Moreover, due to the inability of the five DA techniques to make strictly
paraphrastic augmented texts, the results indicate the need of sufficient
amounts of training examples for the classification models trained on them to
mediate the negative impact of false matching augmented text pairs and improve
performance, a limitation of random text editing perturbations used as a DA
approach. Similar results were also obtained for English.
","[{'version': 'v1', 'created': 'Mon, 29 Nov 2021 17:07:49 GMT'}, {'version': 'v2', 'created': 'Wed, 15 Dec 2021 21:02:52 GMT'}, {'version': 'v3', 'created': 'Mon, 5 Sep 2022 22:38:53 GMT'}]",2022-09-07,"[['Wang', 'Zhengxiang', '']]"
1807.09623,Alon Talmor,Alon Talmor and Jonathan Berant,Repartitioning of the ComplexWebQuestions Dataset,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, Talmor and Berant (2018) introduced ComplexWebQuestions - a dataset
focused on answering complex questions by decomposing them into a sequence of
simpler questions and extracting the answer from retrieved web snippets. In
their work the authors used a pre-trained reading comprehension (RC) model
(Salant and Berant, 2018) to extract the answer from the web snippets. In this
short note we show that training a RC model directly on the training data of
ComplexWebQuestions reveals a leakage from the training set to the test set
that allows to obtain unreasonably high performance. As a solution, we
construct a new partitioning of ComplexWebQuestions that does not suffer from
this leakage and publicly release it. We also perform an empirical evaluation
on these two datasets and show that training a RC model on the training data
substantially improves state-of-the-art performance.
","[{'version': 'v1', 'created': 'Wed, 25 Jul 2018 14:15:40 GMT'}]",2018-07-26,"[['Talmor', 'Alon', ''], ['Berant', 'Jonathan', '']]"
1703.10661,Md Shopon,"Mithun Biswas, Rafiqul Islam, Gautam Kumar Shom, Md Shopon, Nabeel
  Mohammed, Sifat Momen, Md Anowarul Abedin","BanglaLekha-Isolated: A Comprehensive Bangla Handwritten Character
  Dataset","Bangla Handwriting Dataset, OCR",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Bangla handwriting recognition is becoming a very important issue nowadays.
It is potentially a very important task specially for Bangla speaking
population of Bangladesh and West Bengal. By keeping that in our mind we are
introducing a comprehensive Bangla handwritten character dataset named
BanglaLekha-Isolated. This dataset contains Bangla handwritten numerals, basic
characters and compound characters. This dataset was collected from multiple
geographical location within Bangladesh and includes sample collected from a
variety of aged groups. This dataset can also be used for other classification
problems i.e: gender, age, district. This is the largest dataset on Bangla
handwritten characters yet.
","[{'version': 'v1', 'created': 'Wed, 22 Feb 2017 07:57:14 GMT'}]",2017-04-03,"[['Biswas', 'Mithun', ''], ['Islam', 'Rafiqul', ''], ['Shom', 'Gautam Kumar', ''], ['Shopon', 'Md', ''], ['Mohammed', 'Nabeel', ''], ['Momen', 'Sifat', ''], ['Abedin', 'Md Anowarul', '']]"
1901.00707,Huaiping Ming,"Huaiping Ming, Lei He, Haohan Guo, Frank K. Soong","Feature reinforcement with word embedding and parsing information in
  neural TTS",,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we propose a feature reinforcement method under the
sequence-to-sequence neural text-to-speech (TTS) synthesis framework. The
proposed method utilizes the multiple input encoder to take three levels of
text information, i.e., phoneme sequence, pre-trained word embedding, and
grammatical structure of sentences from parser as the input feature for the
neural TTS system. The added word and sentence level information can be viewed
as the feature based pre-training strategy, which clearly enhances the model
generalization ability. The proposed method not only improves the system
robustness significantly but also improves the synthesized speech to near
recording quality in our experiments for out-of-domain text.
","[{'version': 'v1', 'created': 'Thu, 3 Jan 2019 13:15:19 GMT'}, {'version': 'v2', 'created': 'Wed, 6 Mar 2019 15:24:38 GMT'}]",2019-03-07,"[['Ming', 'Huaiping', ''], ['He', 'Lei', ''], ['Guo', 'Haohan', ''], ['Soong', 'Frank K.', '']]"
2101.09004,Suman Dowlagar,"Suman Dowlagar, Radhika Mamidi","CMSAOne@Dravidian-CodeMix-FIRE2020: A Meta Embedding and Transformer
  model for Code-Mixed Sentiment Analysis on Social Media Text","FIRE 2020: Forum for Information Retrieval Evaluation, December
  16-20, 2020, Hyderabad, India",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Code-mixing(CM) is a frequently observed phenomenon that uses multiple
languages in an utterance or sentence. CM is mostly practiced on various social
media platforms and in informal conversations. Sentiment analysis (SA) is a
fundamental step in NLP and is well studied in the monolingual text.
Code-mixing adds a challenge to sentiment analysis due to its non-standard
representations. This paper proposes a meta embedding with a transformer method
for sentiment analysis on the Dravidian code-mixed dataset. In our method, we
used meta embeddings to capture rich text representations. We used the proposed
method for the Task: ""Sentiment Analysis for Dravidian Languages in Code-Mixed
Text"", and it achieved an F1 score of $0.58$ and $0.66$ for the given Dravidian
code mixed data sets. The code is provided in the Github
https://github.com/suman101112/fire-2020-Dravidian-CodeMix.
","[{'version': 'v1', 'created': 'Fri, 22 Jan 2021 08:48:27 GMT'}]",2021-01-25,"[['Dowlagar', 'Suman', ''], ['Mamidi', 'Radhika', '']]"
2209.14627,Yuqiao Wen,"Yuqiao Wen, Yongchang Hao, Yanshuai Cao, Lili Mou",An Equal-Size Hard EM Algorithm for Diverse Dialogue Generation,Accepted by ICLR 2023,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Open-domain dialogue systems aim to interact with humans through natural
language texts in an open-ended fashion. Despite the recent success of super
large dialogue systems such as ChatGPT, using medium-to-small-sized dialogue
systems remains the common practice as they are more lightweight and
accessible; however, generating diverse dialogue responses is challenging,
especially with smaller models. In this work, we propose an Equal-size Hard
Expectation--Maximization (EqHard-EM) algorithm to train a multi-decoder model
for diverse dialogue generation. Our algorithm assigns a sample to a decoder in
a hard manner and additionally imposes an equal-assignment constraint to ensure
that all decoders are well-trained. We provide detailed theoretical analysis to
justify our approach. Further, experiments on two large-scale open-domain
dialogue datasets verify that our EqHard-EM algorithm generates high-quality
diverse responses.
","[{'version': 'v1', 'created': 'Thu, 29 Sep 2022 08:41:32 GMT'}, {'version': 'v2', 'created': 'Fri, 24 Mar 2023 20:10:15 GMT'}]",2023-03-28,"[['Wen', 'Yuqiao', ''], ['Hao', 'Yongchang', ''], ['Cao', 'Yanshuai', ''], ['Mou', 'Lili', '']]"
2302.08215,Dongyoung Go,"Dongyoung Go, Tomasz Korbak, Germ\'an Kruszewski, Jos Rozen, Nahyeon
  Ryu, Marc Dymetman","Aligning Language Models with Preferences through f-divergence
  Minimization",,,,,cs.CL cs.LG stat.ML,http://creativecommons.org/licenses/by/4.0/,"  Aligning language models with preferences can be posed as approximating a
target distribution representing some desired behavior. Existing approaches
differ both in the functional form of the target distribution and the algorithm
used to approximate it. For instance, Reinforcement Learning from Human
Feedback (RLHF) corresponds to minimizing a reverse KL from an implicit target
distribution arising from a KL penalty in the objective. On the other hand,
Generative Distributional Control (GDC) has an explicit target distribution and
minimizes a forward KL from it using the Distributional Policy Gradient (DPG)
algorithm. In this paper, we propose a new approach, f-DPG, which allows the
use of any f-divergence to approximate any target distribution that can be
evaluated. f-DPG unifies both frameworks (RLHF, GDC) and the approximation
methods (DPG, RL with KL penalties). We show the practical benefits of various
choices of divergence objectives and demonstrate that there is no universally
optimal objective but that different divergences present different alignment
and diversity trade-offs. We show that Jensen-Shannon divergence strikes a good
balance between these objectives, and frequently outperforms forward KL
divergence by a wide margin, leading to significant improvements over prior
work. These distinguishing characteristics between divergences persist as the
model size increases, highlighting the importance of selecting appropriate
divergence objectives.
","[{'version': 'v1', 'created': 'Thu, 16 Feb 2023 10:59:39 GMT'}, {'version': 'v2', 'created': 'Tue, 6 Jun 2023 13:09:21 GMT'}]",2023-06-07,"[['Go', 'Dongyoung', ''], ['Korbak', 'Tomasz', ''], ['Kruszewski', 'Germán', ''], ['Rozen', 'Jos', ''], ['Ryu', 'Nahyeon', ''], ['Dymetman', 'Marc', '']]"
2112.02997,Yiqiao Yin,"Shaw-Hwa Lo, Yiqiao Yin","Language Semantics Interpretation with an Interaction-based Recurrent
  Neural Networks",,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Text classification is a fundamental language task in Natural Language
Processing. A variety of sequential models is capable making good predictions
yet there is lack of connection between language semantics and prediction
results. This paper proposes a novel influence score (I-score), a greedy search
algorithm called Backward Dropping Algorithm (BDA), and a novel feature
engineering technique called the ""dagger technique"". First, the paper proposes
a novel influence score (I-score) to detect and search for the important
language semantics in text document that are useful for making good prediction
in text classification tasks. Next, a greedy search algorithm called the
Backward Dropping Algorithm is proposed to handle long-term dependencies in the
dataset. Moreover, the paper proposes a novel engineering technique called the
""dagger technique"" that fully preserve the relationship between explanatory
variable and response variable. The proposed techniques can be further
generalized into any feed-forward Artificial Neural Networks (ANNs) and
Convolutional Neural Networks (CNNs), and any neural network. A real-world
application on the Internet Movie Database (IMDB) is used and the proposed
methods are applied to improve prediction performance with an 81% error
reduction comparing with other popular peers if I-score and ""dagger technique""
are not implemented.
","[{'version': 'v1', 'created': 'Tue, 2 Nov 2021 00:39:21 GMT'}]",2021-12-07,"[['Lo', 'Shaw-Hwa', ''], ['Yin', 'Yiqiao', '']]"
2203.10294,Manex Agirrezabal,"Janek Amann, Manex Agirrezabal","From meaning to perception -- exploring the space between word and odor
  perception embeddings","First International Workshop on Multisensory Data & Knowledge (LDK
  2021)",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In this paper we propose the use of the Word2vec algorithm in order to obtain
odor perception embeddings (or smell embeddings), only using publicly available
perfume descriptions. Besides showing meaningful similarity relationships among
each other, these embeddings also demonstrate to possess some shared
information with their respective word embeddings. The meaningfulness of these
embeddings suggests that aesthetics might provide enough constraints for using
algorithms motivated by distributional semantics on non-randomly combined data.
Furthermore, they provide possibilities for new ways of classifying odors and
analyzing perfumes. We have also employed the embeddings in an attempt to
understand the aesthetic nature of perfumes, based on the difference between
real and randomly generated perfumes. In an additional tentative experiment we
explore the possibility of a mapping between the word embedding space and the
odor perception embedding space by fitting a regressor on the shared vocabulary
and then predict the odor perception embeddings of words without an a priori
associated smell, such as night or sky.
","[{'version': 'v1', 'created': 'Sat, 19 Mar 2022 10:44:20 GMT'}]",2022-03-22,"[['Amann', 'Janek', ''], ['Agirrezabal', 'Manex', '']]"
1905.08063,Mark Keane,"Molly S Quinn, Kathleen Campbell, Mark T Keane","The Unexpected Unexpected and the Expected Unexpected: How People's
  Conception of the Unexpected is Not That Unexpected",7 pages,,,,cs.CL cs.AI cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The answers people give when asked to 'think of the unexpected' for everyday
event scenarios appear to be more expected than unexpected. There are expected
unexpected outcomes that closely adhere to the given information in a scenario,
based on familiar disruptions and common plan-failures. There are also
unexpected unexpected outcomes that are more inventive, that depart from given
information, adding new concepts/actions. However, people seem to tend to
conceive of the unexpected as the former more than the latter. Study 1 tests
these proposals by analysing the object-concepts people mention in their
reports of the unexpected and the agreement between their answers. Study 2
shows that object-choices are weakly influenced by recency, the order of
sentences in the scenario. The implications of these results for ideas in
philosophy, psychology and computing is discussed
","[{'version': 'v1', 'created': 'Fri, 17 May 2019 10:14:07 GMT'}]",2019-09-17,"[['Quinn', 'Molly S', ''], ['Campbell', 'Kathleen', ''], ['Keane', 'Mark T', '']]"
2107.10651,Erniel Barrios,Dominic B. Dayta and Erniel B. Barrios,Semiparametric Latent Topic Modeling on Consumer-Generated Corpora,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Legacy procedures for topic modelling have generally suffered problems of
overfitting and a weakness towards reconstructing sparse topic structures. With
motivation from a consumer-generated corpora, this paper proposes
semiparametric topic model, a two-step approach utilizing nonnegative matrix
factorization and semiparametric regression in topic modeling. The model
enables the reconstruction of sparse topic structures in the corpus and
provides a generative model for predicting topics in new documents entering the
corpus. Assuming the presence of auxiliary information related to the topics,
this approach exhibits better performance in discovering underlying topic
structures in cases where the corpora are small and limited in vocabulary. In
an actual consumer feedback corpus, the model also demonstrably provides
interpretable and useful topic definitions comparable with those produced by
other methods.
","[{'version': 'v1', 'created': 'Tue, 13 Jul 2021 00:22:02 GMT'}]",2021-07-23,"[['Dayta', 'Dominic B.', ''], ['Barrios', 'Erniel B.', '']]"
2310.09501,Jivnesh Sandhan,"Jivnesh Sandhan, Yaswanth Narsupalli, Sreevatsa Muppirala, Sriram
  Krishnan, Pavankumar Satuluri, Amba Kulkarni and Pawan Goyal","DepNeCTI: Dependency-based Nested Compound Type Identification for
  Sanskrit","9 Pages, Camera-ready version accepted at EMNLP23 (Findings)",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Multi-component compounding is a prevalent phenomenon in Sanskrit, and
understanding the implicit structure of a compound's components is crucial for
deciphering its meaning. Earlier approaches in Sanskrit have focused on binary
compounds and neglected the multi-component compound setting. This work
introduces the novel task of nested compound type identification (NeCTI), which
aims to identify nested spans of a multi-component compound and decode the
implicit semantic relations between them. To the best of our knowledge, this is
the first attempt in the field of lexical semantics to propose this task.
  We present 2 newly annotated datasets including an out-of-domain dataset for
this task. We also benchmark these datasets by exploring the efficacy of the
standard problem formulations such as nested named entity recognition,
constituency parsing and seq2seq, etc. We present a novel framework named
DepNeCTI: Dependency-based Nested Compound Type Identifier that surpasses the
performance of the best baseline with an average absolute improvement of 13.1
points F1-score in terms of Labeled Span Score (LSS) and a 5-fold enhancement
in inference efficiency. In line with the previous findings in the binary
Sanskrit compound identification task, context provides benefits for the NeCTI
task. The codebase and datasets are publicly available at:
https://github.com/yaswanth-iitkgp/DepNeCTI
","[{'version': 'v1', 'created': 'Sat, 14 Oct 2023 06:11:53 GMT'}]",2023-10-17,"[['Sandhan', 'Jivnesh', ''], ['Narsupalli', 'Yaswanth', ''], ['Muppirala', 'Sreevatsa', ''], ['Krishnan', 'Sriram', ''], ['Satuluri', 'Pavankumar', ''], ['Kulkarni', 'Amba', ''], ['Goyal', 'Pawan', '']]"
1511.06361,Ivan Vendrov,"Ivan Vendrov, Ryan Kiros, Sanja Fidler, Raquel Urtasun",Order-Embeddings of Images and Language,ICLR camera-ready version,,,,cs.LG cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Hypernymy, textual entailment, and image captioning can be seen as special
cases of a single visual-semantic hierarchy over words, sentences, and images.
In this paper we advocate for explicitly modeling the partial order structure
of this hierarchy. Towards this goal, we introduce a general method for
learning ordered representations, and show how it can be applied to a variety
of tasks involving images and language. We show that the resulting
representations improve performance over current approaches for hypernym
prediction and image-caption retrieval.
","[{'version': 'v1', 'created': 'Thu, 19 Nov 2015 20:56:14 GMT'}, {'version': 'v2', 'created': 'Tue, 8 Dec 2015 21:19:30 GMT'}, {'version': 'v3', 'created': 'Thu, 10 Dec 2015 04:32:53 GMT'}, {'version': 'v4', 'created': 'Thu, 7 Jan 2016 04:58:08 GMT'}, {'version': 'v5', 'created': 'Sun, 17 Jan 2016 03:08:20 GMT'}, {'version': 'v6', 'created': 'Tue, 1 Mar 2016 08:23:50 GMT'}]",2016-03-02,"[['Vendrov', 'Ivan', ''], ['Kiros', 'Ryan', ''], ['Fidler', 'Sanja', ''], ['Urtasun', 'Raquel', '']]"
2204.02790,Ishani Mondal,"Ishani Mondal, Kabir Ahuja, Mohit Jain, Jacki O Neil, Kalika Bali,
  Monojit Choudhury","Global Readiness of Language Technology for Healthcare: What would it
  Take to Combat the Next Pandemic?",Under Revision,,,,cs.CY cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The COVID-19 pandemic has brought out both the best and worst of language
technology (LT). On one hand, conversational agents for information
dissemination and basic diagnosis have seen widespread use, and arguably, had
an important role in combating the pandemic. On the other hand, it has also
become clear that such technologies are readily available for a handful of
languages, and the vast majority of the global south is completely bereft of
these benefits. What is the state of LT, especially conversational agents, for
healthcare across the world's languages? And, what would it take to ensure
global readiness of LT before the next pandemic? In this paper, we try to
answer these questions through survey of existing literature and resources, as
well as through a rapid chatbot building exercise for 15 Asian and African
languages with varying amount of resource-availability. The study confirms the
pitiful state of LT even for languages with large speaker bases, such as
Sinhala and Hausa, and identifies the gaps that could help us prioritize
research and investment strategies in LT for healthcare.
","[{'version': 'v1', 'created': 'Wed, 6 Apr 2022 13:03:28 GMT'}]",2022-04-07,"[['Mondal', 'Ishani', ''], ['Ahuja', 'Kabir', ''], ['Jain', 'Mohit', ''], ['Neil', 'Jacki O', ''], ['Bali', 'Kalika', ''], ['Choudhury', 'Monojit', '']]"
2209.15003,Andrew Drozdov,"Andrew Drozdov, Nathanael Sch\""arli, Ekin Aky\""urek, Nathan Scales,
  Xinying Song, Xinyun Chen, Olivier Bousquet, Denny Zhou",Compositional Semantic Parsing with Large Language Models,Fixed metadata. No other changes,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Humans can reason compositionally when presented with new tasks. Previous
research shows that appropriate prompting techniques enable large language
models (LLMs) to solve artificial compositional generalization tasks such as
SCAN. In this work, we identify additional challenges in more realistic
semantic parsing tasks with larger vocabulary and refine these prompting
techniques to address them. Our best method is based on least-to-most
prompting: it decomposes the problem using prompting-based syntactic parsing,
then uses this decomposition to select appropriate exemplars and to
sequentially generate the semantic parse. This method allows us to set a new
state of the art for CFQ while requiring only 1% of the training data used by
traditional approaches. Due to the general nature of our approach, we expect
similar efforts will lead to new results in other tasks and domains, especially
for knowledge-intensive applications.
","[{'version': 'v1', 'created': 'Thu, 29 Sep 2022 17:58:28 GMT'}, {'version': 'v2', 'created': 'Fri, 30 Sep 2022 01:15:10 GMT'}]",2022-10-03,"[['Drozdov', 'Andrew', ''], ['Schärli', 'Nathanael', ''], ['Akyürek', 'Ekin', ''], ['Scales', 'Nathan', ''], ['Song', 'Xinying', ''], ['Chen', 'Xinyun', ''], ['Bousquet', 'Olivier', ''], ['Zhou', 'Denny', '']]"
2108.03670,Yichao Zhou,"Yichao Zhou, Jyun-yu Jiang, Xiusi Chen, Wei Wang","#StayHome or #Marathon? Social Media Enhanced Pandemic Surveillance on
  Spatial-temporal Dynamic Graphs","7 figures, 6 tables",,,,cs.SI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  COVID-19 has caused lasting damage to almost every domain in public health,
society, and economy. To monitor the pandemic trend, existing studies rely on
the aggregation of traditional statistical models and epidemic spread theory.
In other words, historical statistics of COVID-19, as well as the population
mobility data, become the essential knowledge for monitoring the pandemic
trend. However, these solutions can barely provide precise prediction and
satisfactory explanations on the long-term disease surveillance while the
ubiquitous social media resources can be the key enabler for solving this
problem. For example, serious discussions may occur on social media before and
after some breaking events take place. These events, such as marathon and
parade, may impact the spread of the virus. To take advantage of the social
media data, we propose a novel framework, Social Media enhAnced pandemic
suRveillance Technique (SMART), which is composed of two modules: (i)
information extraction module to construct heterogeneous knowledge graphs based
on the extracted events and relationships among them; (ii) time series
prediction module to provide both short-term and long-term forecasts of the
confirmed cases and fatality at the state-level in the United States and to
discover risk factors for COVID-19 interventions. Extensive experiments show
that our method largely outperforms the state-of-the-art baselines by 7.3% and
7.4% in confirmed case/fatality prediction, respectively.
","[{'version': 'v1', 'created': 'Sun, 8 Aug 2021 15:46:05 GMT'}]",2021-08-10,"[['Zhou', 'Yichao', ''], ['Jiang', 'Jyun-yu', ''], ['Chen', 'Xiusi', ''], ['Wang', 'Wei', '']]"
2211.02178,Anuj Diwan,"Anuj Diwan, Puyuan Peng, Raymond J. Mooney",Zero-shot Video Moment Retrieval With Off-the-Shelf Models,"Accepted to the NeurIPS 2022 Workshop on Transfer Learning for NLP
  (TL4NLP). 12 pages, 5 figures",,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  For the majority of the machine learning community, the expensive nature of
collecting high-quality human-annotated data and the inability to efficiently
finetune very large state-of-the-art pretrained models on limited compute are
major bottlenecks for building models for new tasks. We propose a zero-shot
simple approach for one such task, Video Moment Retrieval (VMR), that does not
perform any additional finetuning and simply repurposes off-the-shelf models
trained on other tasks. Our three-step approach consists of moment proposal,
moment-query matching and postprocessing, all using only off-the-shelf models.
On the QVHighlights benchmark for VMR, we vastly improve performance of
previous zero-shot approaches by at least 2.5x on all metrics and reduce the
gap between zero-shot and state-of-the-art supervised by over 74%. Further, we
also show that our zero-shot approach beats non-pretrained supervised models on
the Recall metrics and comes very close on mAP metrics; and that it also
performs better than the best pretrained supervised model on shorter moments.
Finally, we ablate and analyze our results and propose interesting future
directions.
","[{'version': 'v1', 'created': 'Thu, 3 Nov 2022 23:11:04 GMT'}]",2022-11-07,"[['Diwan', 'Anuj', ''], ['Peng', 'Puyuan', ''], ['Mooney', 'Raymond J.', '']]"
2310.11363,Stefan Arnold,"Stefan Arnold, Nils Kemmerzell, and Annika Schreiner",Disentangling the Linguistic Competence of Privacy-Preserving BERT,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Differential Privacy (DP) has been tailored to address the unique challenges
of text-to-text privatization. However, text-to-text privatization is known for
degrading the performance of language models when trained on perturbed text.
Employing a series of interpretation techniques on the internal representations
extracted from BERT trained on perturbed pre-text, we intend to disentangle at
the linguistic level the distortion induced by differential privacy.
Experimental results from a representational similarity analysis indicate that
the overall similarity of internal representations is substantially reduced.
Using probing tasks to unpack this dissimilarity, we find evidence that
text-to-text privatization affects the linguistic competence across several
formalisms, encoding localized properties of words while falling short at
encoding the contextual relationships between spans of words.
","[{'version': 'v1', 'created': 'Tue, 17 Oct 2023 16:00:26 GMT'}]",2023-10-18,"[['Arnold', 'Stefan', ''], ['Kemmerzell', 'Nils', ''], ['Schreiner', 'Annika', '']]"
2312.01701,Lei Wang,"Lei Wang, Jiabang He, Shenshen Li, Ning Liu, Ee-Peng Lim","Mitigating Fine-Grained Hallucination by Fine-Tuning Large
  Vision-Language Models with Caption Rewrites",MMM 2024,,,,cs.CV cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have shown remarkable performance in natural
language processing (NLP) tasks. To comprehend and execute diverse human
instructions over image data, instruction-tuned large vision-language models
(LVLMs) have been introduced. However, LVLMs may suffer from different types of
object hallucinations. Nevertheless, LVLMs are evaluated for coarse-grained
object hallucinations only (i.e., generated objects non-existent in the input
image). The fine-grained object attributes and behaviors non-existent in the
image may still be generated but not measured by the current evaluation
methods. In this paper, we thus focus on reducing fine-grained hallucinations
of LVLMs. We propose \textit{ReCaption}, a framework that consists of two
components: rewriting captions using ChatGPT and fine-tuning the
instruction-tuned LVLMs on the rewritten captions. We also propose a
fine-grained probing-based evaluation method named \textit{Fine-Grained Object
Hallucination Evaluation} (\textit{FGHE}). Our experiment results demonstrate
that ReCaption effectively reduces fine-grained object hallucination for
different LVLM options and improves their text generation quality. The code can
be found at https://github.com/Anonymousanoy/FOHE.
","[{'version': 'v1', 'created': 'Mon, 4 Dec 2023 07:43:02 GMT'}]",2023-12-05,"[['Wang', 'Lei', ''], ['He', 'Jiabang', ''], ['Li', 'Shenshen', ''], ['Liu', 'Ning', ''], ['Lim', 'Ee-Peng', '']]"
2111.10157,Prabhat Pandey,"Prabhat Pandey, Sergio Duarte Torres, Ali Orkan Bayer, Ankur Gandhe,
  Volker Leutnant",Lattention: Lattice-attention in ASR rescoring,Submitted to ICASSP 2022,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Lattices form a compact representation of multiple hypotheses generated from
an automatic speech recognition system and have been shown to improve
performance of downstream tasks like spoken language understanding and speech
translation, compared to using one-best hypothesis. In this work, we look into
the effectiveness of lattice cues for rescoring n-best lists in second-pass. We
encode lattices with a recurrent network and train an attention encoder-decoder
model for n-best rescoring. The rescoring model with attention to lattices
achieves 4-5% relative word error rate reduction over first-pass and 6-8% with
attention to both lattices and acoustic features. We show that rescoring models
with attention to lattices outperform models with attention to n-best
hypotheses. We also study different ways to incorporate lattice weights in the
lattice encoder and demonstrate their importance for n-best rescoring.
","[{'version': 'v1', 'created': 'Fri, 19 Nov 2021 11:13:37 GMT'}]",2021-11-22,"[['Pandey', 'Prabhat', ''], ['Torres', 'Sergio Duarte', ''], ['Bayer', 'Ali Orkan', ''], ['Gandhe', 'Ankur', ''], ['Leutnant', 'Volker', '']]"
2108.03861,Shangbin Feng,"Shangbin Feng, Zilong Chen, Wenqian Zhang, Qingyao Li, Qinghua Zheng,
  Xiaojun Chang, Minnan Luo","KGAP: Knowledge Graph Augmented Political Perspective Detection in News
  Media",,,,,cs.CL cs.AI cs.CY,http://creativecommons.org/licenses/by-sa/4.0/,"  Identifying political perspectives in news media has become an important task
due to the rapid growth of political commentary and the increasingly polarized
political ideologies. Previous approaches focus on textual content and leave
out the rich social and political context that is essential in the perspective
detection process. To address this limitation, we propose KGAP, a political
perspective detection method that incorporates external domain knowledge.
Specifically, we construct a political knowledge graph to serve as
domain-specific external knowledge. We then construct heterogeneous information
networks to represent news documents, which jointly model news text and
external knowledge. Finally, we adopt relational graph neural networks and
conduct political perspective detection as graph-level classification.
Extensive experiments demonstrate that our method consistently achieves the
best performance on two real-world perspective detection benchmarks. Ablation
studies further bear out the necessity of external knowledge and the
effectiveness of our graph-based approach.
","[{'version': 'v1', 'created': 'Mon, 9 Aug 2021 08:05:56 GMT'}, {'version': 'v2', 'created': 'Tue, 7 Sep 2021 08:15:07 GMT'}, {'version': 'v3', 'created': 'Mon, 3 Jan 2022 13:11:35 GMT'}, {'version': 'v4', 'created': 'Tue, 17 May 2022 07:48:24 GMT'}]",2022-05-18,"[['Feng', 'Shangbin', ''], ['Chen', 'Zilong', ''], ['Zhang', 'Wenqian', ''], ['Li', 'Qingyao', ''], ['Zheng', 'Qinghua', ''], ['Chang', 'Xiaojun', ''], ['Luo', 'Minnan', '']]"
2011.01035,Akshar Nair,"Nikhil Fernandes, Alexandra Gkolia, Nicolas Pizzo, James Davenport,
  Akshar Nair","Unification of HDP and LDA Models for Optimal Topic Clustering of
  Subject Specific Question Banks","8 pages, 5 figures, Submitted to EAAI21",,,,cs.IR cs.CL cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  There has been an increasingly popular trend in Universities for curriculum
transformation to make teaching more interactive and suitable for online
courses. An increase in the popularity of online courses would result in an
increase in the number of course-related queries for academics. This, coupled
with the fact that if lectures were delivered in a video on demand format,
there would be no fixed time where the majority of students could ask
questions. When questions are asked in a lecture there is a negligible chance
of having similar questions repeatedly, but asynchronously this is more likely.
In order to reduce the time spent on answering each individual question,
clustering them is an ideal choice. There are different unsupervised models fit
for text clustering, of which the Latent Dirichlet Allocation model is the most
commonly used. We use the Hierarchical Dirichlet Process to determine an
optimal topic number input for our LDA model runs. Due to the probabilistic
nature of these topic models, the outputs of them vary for different runs. The
general trend we found is that not all the topics were being used for
clustering on the first run of the LDA model, which results in a less effective
clustering. To tackle probabilistic output, we recursively use the LDA model on
the effective topics being used until we obtain an efficiency ratio of 1.
Through our experimental results we also establish a reasoning on how Zeno's
paradox is avoided.
","[{'version': 'v1', 'created': 'Sun, 4 Oct 2020 18:21:20 GMT'}]",2020-11-03,"[['Fernandes', 'Nikhil', ''], ['Gkolia', 'Alexandra', ''], ['Pizzo', 'Nicolas', ''], ['Davenport', 'James', ''], ['Nair', 'Akshar', '']]"
2110.08270,Dhruv Agarwal,"Dhruv Agarwal, Tanay Agrawal, Laura M. Ferrari, Fran\c{c}ois Bremond","From Multimodal to Unimodal Attention in Transformers using Knowledge
  Distillation","Preprint. Final paper accepted at the 17th IEEE International
  Conference on Advanced Video and Signal-based Surveillance, AVSS 2021,
  Virtual, November 16-19, 2021. 10 pages",,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Multimodal Deep Learning has garnered much interest, and transformers have
triggered novel approaches, thanks to the cross-attention mechanism. Here we
propose an approach to deal with two key existing challenges: the high
computational resource demanded and the issue of missing modalities. We
introduce for the first time the concept of knowledge distillation in
transformers to use only one modality at inference time. We report a full study
analyzing multiple student-teacher configurations, levels at which distillation
is applied, and different methodologies. With the best configuration, we
improved the state-of-the-art accuracy by 3%, we reduced the number of
parameters by 2.5 times and the inference time by 22%. Such
performance-computation tradeoff can be exploited in many applications and we
aim at opening a new research area where the deployment of complex models with
limited resources is demanded.
","[{'version': 'v1', 'created': 'Fri, 15 Oct 2021 12:30:21 GMT'}, {'version': 'v2', 'created': 'Tue, 19 Oct 2021 04:55:27 GMT'}]",2021-10-20,"[['Agarwal', 'Dhruv', ''], ['Agrawal', 'Tanay', ''], ['Ferrari', 'Laura M.', ''], ['Bremond', 'François', '']]"
1908.08507,Ningyu Zhang,"Ningyu Zhang, Shumin Deng, Zhanlin Sun, Jiaoyan Chen, Wei Zhang,
  Huajun Chen","Transfer Learning for Relation Extraction via Relation-Gated Adversarial
  Learning",,,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Relation extraction aims to extract relational facts from sentences. Previous
models mainly rely on manually labeled datasets, seed instances or
human-crafted patterns, and distant supervision. However, the human annotation
is expensive, while human-crafted patterns suffer from semantic drift and
distant supervision samples are usually noisy. Domain adaptation methods enable
leveraging labeled data from a different but related domain. However, different
domains usually have various textual relation descriptions and different label
space (the source label space is usually a superset of the target label space).
To solve these problems, we propose a novel model of relation-gated adversarial
learning for relation extraction, which extends the adversarial based domain
adaptation. Experimental results have shown that the proposed approach
outperforms previous domain adaptation methods regarding partial domain
adaptation and can improve the accuracy of distance supervised relation
extraction through fine-tuning.
","[{'version': 'v1', 'created': 'Thu, 22 Aug 2019 17:27:54 GMT'}]",2019-08-23,"[['Zhang', 'Ningyu', ''], ['Deng', 'Shumin', ''], ['Sun', 'Zhanlin', ''], ['Chen', 'Jiaoyan', ''], ['Zhang', 'Wei', ''], ['Chen', 'Huajun', '']]"
1804.03209,Pete Warden,Pete Warden,Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition,,,,,cs.CL cs.HC,http://creativecommons.org/licenses/by/4.0/,"  Describes an audio dataset of spoken words designed to help train and
evaluate keyword spotting systems. Discusses why this task is an interesting
challenge, and why it requires a specialized dataset that is different from
conventional datasets used for automatic speech recognition of full sentences.
Suggests a methodology for reproducible and comparable accuracy metrics for
this task. Describes how the data was collected and verified, what it contains,
previous versions and properties. Concludes by reporting baseline results of
models trained on this dataset.
","[{'version': 'v1', 'created': 'Mon, 9 Apr 2018 19:58:17 GMT'}]",2018-04-11,"[['Warden', 'Pete', '']]"
1906.00800,Artem Artemov,"A.Artemov, I.Bolokhov, D.Kem, I.Khasenevich","Neural Network-based Object Classification by Known and Unknown Features
  (Based on Text Queries)","7 pages, 3 figures, 2 tables",,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The article presents a method that improves the quality of classification of
objects described by a combination of known and unknown features. The method is
based on modernized Informational Neurobayesian Approach with consideration of
unknown features. The proposed method was developed and trained on 1500 text
queries of Promobot users in Russian to classify them into 20 categories
(classes). As a result, the use of the method allowed to completely solve the
problem of misclassification for queries with combining known and unknown
features of the model. The theoretical substantiation of the method is
presented by the formulated and proved theorem On the Model with Limited
Knowledge. It states, that in conditions of limited data, an equal number of
equally unknown features of an object cannot have different significance for
the classification problem.
","[{'version': 'v1', 'created': 'Mon, 3 Jun 2019 13:38:20 GMT'}]",2019-06-04,"[['Artemov', 'A.', ''], ['Bolokhov', 'I.', ''], ['Kem', 'D.', ''], ['Khasenevich', 'I.', '']]"
2108.05652,Liang Pang,"Lin Bo, Liang Pang, Gang Wang, Jun Xu, XiuQiang He, Ji-Rong Wen","Modeling Relevance Ranking under the Pre-training and Fine-tuning
  Paradigm",,,,,cs.IR cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Recently, pre-trained language models such as BERT have been applied to
document ranking for information retrieval, which first pre-train a general
language model on an unlabeled large corpus and then conduct ranking-specific
fine-tuning on expert-labeled relevance datasets. Ideally, an IR system would
model relevance from a user-system dualism: the user's view and the system's
view. User's view judges the relevance based on the activities of ""real users""
while the system's view focuses on the relevance signals from the system side,
e.g., from the experts or algorithms, etc. Inspired by the user-system
relevance views and the success of pre-trained language models, in this paper
we propose a novel ranking framework called Pre-Rank that takes both user's
view and system's view into consideration, under the pre-training and
fine-tuning paradigm. Specifically, to model the user's view of relevance,
Pre-Rank pre-trains the initial query-document representations based on
large-scale user activities data such as the click log. To model the system's
view of relevance, Pre-Rank further fine-tunes the model on expert-labeled
relevance data. More importantly, the pre-trained representations, are
fine-tuned together with handcrafted learning-to-rank features under a wide and
deep network architecture. In this way, Pre-Rank can model the relevance by
incorporating the relevant knowledge and signals from both real search users
and the IR experts. To verify the effectiveness of Pre-Rank, we showed two
implementations by using BERT and SetRank as the underlying ranking model,
respectively. Experimental results base on three publicly available benchmarks
showed that in both of the implementations, Pre-Rank can respectively
outperform the underlying ranking models and achieved state-of-the-art
performances.
","[{'version': 'v1', 'created': 'Thu, 12 Aug 2021 10:37:12 GMT'}]",2021-08-13,"[['Bo', 'Lin', ''], ['Pang', 'Liang', ''], ['Wang', 'Gang', ''], ['Xu', 'Jun', ''], ['He', 'XiuQiang', ''], ['Wen', 'Ji-Rong', '']]"
2210.13168,Stefano Bann\`o,Stefano Bann\`o and Marco Matassoni,Proficiency assessment of L2 spoken English using wav2vec 2.0,Accepted at SLT 2022,,,,cs.CL cs.SD eess.AS,http://creativecommons.org/licenses/by/4.0/,"  The increasing demand for learning English as a second language has led to a
growing interest in methods for automatically assessing spoken language
proficiency. Most approaches use hand-crafted features, but their efficacy
relies on their particular underlying assumptions and they risk discarding
potentially salient information about proficiency. Other approaches rely on
transcriptions produced by ASR systems which may not provide a faithful
rendition of a learner's utterance in specific scenarios (e.g., non-native
children's spontaneous speech). Furthermore, transcriptions do not yield any
information about relevant aspects such as intonation, rhythm or prosody. In
this paper, we investigate the use of wav2vec 2.0 for assessing overall and
individual aspects of proficiency on two small datasets, one of which is
publicly available. We find that this approach significantly outperforms the
BERT-based baseline system trained on ASR and manual transcriptions used for
comparison.
","[{'version': 'v1', 'created': 'Mon, 24 Oct 2022 12:36:49 GMT'}]",2022-10-25,"[['Bannò', 'Stefano', ''], ['Matassoni', 'Marco', '']]"
2305.17746,Wenjie Zhuo,"Wenjie Zhuo, Yifan Sun, Xiaohan Wang, Linchao Zhu, Yi Yang",Whitening-based Contrastive Learning of Sentence Embeddings,ACL 2023 Main Conference(Oral),,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents a whitening-based contrastive learning method for
sentence embedding learning (WhitenedCSE), which combines contrastive learning
with a novel shuffled group whitening. Generally, contrastive learning pulls
distortions of a single sample (i.e., positive samples) close and push negative
samples far away, correspondingly facilitating the alignment and uniformity in
the feature space. A popular alternative to the ""pushing'' operation is
whitening the feature space, which scatters all the samples for uniformity.
Since the whitening and the contrastive learning have large redundancy w.r.t.
the uniformity, they are usually used separately and do not easily work
together. For the first time, this paper integrates whitening into the
contrastive learning scheme and facilitates two benefits. 1) Better uniformity.
We find that these two approaches are not totally redundant but actually have
some complementarity due to different uniformity mechanism. 2) Better
alignment. We randomly divide the feature into multiple groups along the
channel axis and perform whitening independently within each group. By
shuffling the group division, we derive multiple distortions of a single sample
and thus increase the positive sample diversity. Consequently, using multiple
positive samples with enhanced diversity further improves contrastive learning
due to better alignment. Extensive experiments on seven semantic textual
similarity tasks show our method achieves consistent improvement over the
contrastive learning baseline and sets new states of the art, e.g., 78.78\%
(+2.53\% based on BERT\ba) Spearman correlation on STS tasks.
","[{'version': 'v1', 'created': 'Sun, 28 May 2023 14:58:10 GMT'}, {'version': 'v2', 'created': 'Thu, 8 Jun 2023 05:33:55 GMT'}]",2023-06-09,"[['Zhuo', 'Wenjie', ''], ['Sun', 'Yifan', ''], ['Wang', 'Xiaohan', ''], ['Zhu', 'Linchao', ''], ['Yang', 'Yi', '']]"
2310.09166,Seth Benson,Seth P. Benson and Iain J. Cruickshank,"Developing a Natural Language Understanding Model to Characterize Cable
  News Bias",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Media bias has been extensively studied by both social and computational
sciences. However, current work still has a large reliance on human input and
subjective assessment to label biases. This is especially true for cable news
research. To address these issues, we develop an unsupervised machine learning
method to characterize the bias of cable news programs without any human input.
This method relies on the analysis of what topics are mentioned through Named
Entity Recognition and how those topics are discussed through Stance Analysis
in order to cluster programs with similar biases together. Applying our method
to 2020 cable news transcripts, we find that program clusters are consistent
over time and roughly correspond to the cable news network of the program. This
method reveals the potential for future tools to objectively assess media bias
and characterize unfamiliar media environments.
","[{'version': 'v1', 'created': 'Fri, 13 Oct 2023 15:01:17 GMT'}, {'version': 'v2', 'created': 'Tue, 17 Oct 2023 22:37:58 GMT'}]",2023-10-19,"[['Benson', 'Seth P.', ''], ['Cruickshank', 'Iain J.', '']]"
2202.04173,Wei Ping,"Boxin Wang, Wei Ping, Chaowei Xiao, Peng Xu, Mostofa Patwary, Mohammad
  Shoeybi, Bo Li, Anima Anandkumar, Bryan Catanzaro","Exploring the Limits of Domain-Adaptive Training for Detoxifying
  Large-Scale Language Models",NeurIPS 2022,,,,cs.CL cs.AI cs.CY cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Pre-trained language models (LMs) are shown to easily generate toxic
language. In this work, we systematically explore domain-adaptive training to
reduce the toxicity of language models. We conduct this study on three
dimensions: training corpus, model size, and parameter efficiency. For the
training corpus, we propose to leverage the generative power of LMs and
generate nontoxic datasets for domain-adaptive training, which mitigates the
exposure bias and is shown to be more data-efficient than using a curated
pre-training corpus. We demonstrate that the self-generation method
consistently outperforms the existing baselines across various model sizes on
both automatic and human evaluations, even when it uses a 1/3 smaller training
corpus. We then comprehensively study detoxifying LMs with parameter sizes
ranging from 126M up to 530B (3x larger than GPT-3), a scale that has never
been studied before. We find that i) large LMs have similar toxicity levels as
smaller ones given the same pre-training corpus, and ii) large LMs require more
endeavor to detoxify. We also explore parameter-efficient training methods for
detoxification. We demonstrate that adding and training adapter-only layers in
LMs not only saves a lot of parameters but also achieves a better trade-off
between toxicity and perplexity than whole model adaptation for the large-scale
models.
","[{'version': 'v1', 'created': 'Tue, 8 Feb 2022 22:10:40 GMT'}, {'version': 'v2', 'created': 'Fri, 7 Oct 2022 06:32:54 GMT'}, {'version': 'v3', 'created': 'Fri, 21 Oct 2022 23:01:28 GMT'}]",2022-10-25,"[['Wang', 'Boxin', ''], ['Ping', 'Wei', ''], ['Xiao', 'Chaowei', ''], ['Xu', 'Peng', ''], ['Patwary', 'Mostofa', ''], ['Shoeybi', 'Mohammad', ''], ['Li', 'Bo', ''], ['Anandkumar', 'Anima', ''], ['Catanzaro', 'Bryan', '']]"
2310.16417,Kang Kim,Kang Kim and Hankyu Cho,Enhanced Simultaneous Machine Translation with Word-level Policies,EMNLP 2023 Findings,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Recent years have seen remarkable advances in the field of Simultaneous
Machine Translation (SiMT) due to the introduction of innovative policies that
dictate whether to READ or WRITE at each step of the translation process.
However, a common assumption in many existing studies is that operations are
carried out at the subword level, even though the standard unit for input and
output in most practical scenarios is typically at the word level. This paper
demonstrates that policies devised and validated at the subword level are
surpassed by those operating at the word level, which process multiple subwords
to form a complete word in a single step. Additionally, we suggest a method to
boost SiMT models using language models (LMs), wherein the proposed word-level
policy plays a vital role in addressing the subword disparity between LMs and
SiMT models. Code is available at https://github.com/xl8-ai/WordSiMT.
","[{'version': 'v1', 'created': 'Wed, 25 Oct 2023 07:10:42 GMT'}]",2023-10-26,"[['Kim', 'Kang', ''], ['Cho', 'Hankyu', '']]"
1812.00271,Mirco Ravanelli,"Mirco Ravanelli, Yoshua Bengio",Learning Speaker Representations with Mutual Information,Submitted to Interspeech 2019,,,,eess.AS cs.CL cs.LG cs.NE cs.SD,http://creativecommons.org/licenses/by/4.0/,"  Learning good representations is of crucial importance in deep learning.
Mutual Information (MI) or similar measures of statistical dependence are
promising tools for learning these representations in an unsupervised way. Even
though the mutual information between two random variables is hard to measure
directly in high dimensional spaces, some recent studies have shown that an
implicit optimization of MI can be achieved with an encoder-discriminator
architecture similar to that of Generative Adversarial Networks (GANs). In this
work, we learn representations that capture speaker identities by maximizing
the mutual information between the encoded representations of chunks of speech
randomly sampled from the same sentence. The proposed encoder relies on the
SincNet architecture and transforms raw speech waveform into a compact feature
vector. The discriminator is fed by either positive samples (of the joint
distribution of encoded chunks) or negative samples (from the product of the
marginals) and is trained to separate them. We report experiments showing that
this approach effectively learns useful speaker representations, leading to
promising results on speaker identification and verification tasks. Our
experiments consider both unsupervised and semi-supervised settings and compare
the performance achieved with different objective functions.
","[{'version': 'v1', 'created': 'Sat, 1 Dec 2018 21:48:28 GMT'}, {'version': 'v2', 'created': 'Fri, 5 Apr 2019 22:49:01 GMT'}]",2019-04-09,"[['Ravanelli', 'Mirco', ''], ['Bengio', 'Yoshua', '']]"
2308.12022,Hongyin Zhu,Hongyin Zhu,"Reranking Passages with Coarse-to-Fine Neural Retriever Enhanced by
  List-Context Information",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Passage reranking is a critical task in various applications, particularly
when dealing with large volumes of documents. Existing neural architectures
have limitations in retrieving the most relevant passage for a given question
because the semantics of the segmented passages are often incomplete, and they
typically match the question to each passage individually, rarely considering
contextual information from other passages that could provide comparative and
reference information. This paper presents a list-context attention mechanism
to augment the passage representation by incorporating the list-context
information from other candidates. The proposed coarse-to-fine (C2F) neural
retriever addresses the out-of-memory limitation of the passage attention
mechanism by dividing the list-context modeling process into two sub-processes
with a cache policy learning algorithm, enabling the efficient encoding of
context information from a large number of candidate answers. This method can
be generally used to encode context information from any number of candidate
answers in one pass. Different from most multi-stage information retrieval
architectures, this model integrates the coarse and fine rankers into the joint
optimization process, allowing for feedback between the two layers to update
the model simultaneously. Experiments demonstrate the effectiveness of the
proposed approach.
","[{'version': 'v1', 'created': 'Wed, 23 Aug 2023 09:29:29 GMT'}, {'version': 'v2', 'created': 'Thu, 21 Mar 2024 09:11:22 GMT'}]",2024-03-22,"[['Zhu', 'Hongyin', '']]"
2402.09320,Feifan Song,"Feifan Song, Yuxuan Fan, Xin Zhang, Peiyi Wang, Houfeng Wang","ICDPO: Effectively Borrowing Alignment Capability of Others via
  In-context Direct Preference Optimization",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) rely on Human Preference Alignment (HPA) to
ensure the generation of safe content. Due to the heavy cost associated with
fine-tuning, fine-tuning-free methods have emerged, typically modifying LLM
decoding with external auxiliary methods. However, these methods do not
essentially enhance the LLM itself. In this paper, we rethink the derivation
procedures of DPO, based on which we conversely build an instant scorer using
the states of the LLM before and after In-context Learning (ICL). Accordingly,
we propose a novel approach called In-Context Direct Preference Optimization
(ICDPO). It enables LLMs to borrow the HPA capabilities from superior LLMs with
ICL, generating well-aligned responses as estimated by the aforementioned
instant scorer, thereby enhancing the final performance. ICDPO can be further
enhanced with a two-stage retriever and an upgraded scorer, both offering
benefits. Extensive experiments show its effectiveness, particularly in
outperforming two fine-tuning-free baselines, and it exhibits competitiveness
with SFT + LoRA. We also conduct detailed analyses to offer comprehensive
insights into ICDPO.
","[{'version': 'v1', 'created': 'Wed, 14 Feb 2024 17:14:34 GMT'}]",2024-02-15,"[['Song', 'Feifan', ''], ['Fan', 'Yuxuan', ''], ['Zhang', 'Xin', ''], ['Wang', 'Peiyi', ''], ['Wang', 'Houfeng', '']]"
2205.09391,M. \c{S}afak Bilici,"M. \c{S}afak Bilici, Mehmet Fatih Amasyali","Transformers as Neural Augmentors: Class Conditional Sentence Generation
  via Variational Bayes",,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Data augmentation methods for Natural Language Processing tasks are explored
in recent years, however they are limited and it is hard to capture the
diversity on sentence level. Besides, it is not always possible to perform data
augmentation on supervised tasks. To address those problems, we propose a
neural data augmentation method, which is a combination of Conditional
Variational Autoencoder and encoder-decoder Transformer model. While encoding
and decoding the input sentence, our model captures the syntactic and semantic
representation of the input language with its class condition. Following the
developments in the past years on pre-trained language models, we train and
evaluate our models on several benchmarks to strengthen the downstream tasks.
We compare our method with 3 different augmentation techniques. The presented
results show that, our model increases the performance of current models
compared to other data augmentation techniques with a small amount of
computation power.
","[{'version': 'v1', 'created': 'Thu, 19 May 2022 08:42:33 GMT'}]",2022-05-20,"[['Bilici', 'M. Şafak', ''], ['Amasyali', 'Mehmet Fatih', '']]"
1605.05134,Soroush Vosoughi Dr,"Soroush Vosoughi, Deb Roy","A Semi-automatic Method for Efficient Detection of Stories on Social
  Media","ICWSM'16, May 17-20, Cologne, Germany. In Proceedings of the 10th
  International AAAI Conference on Weblogs and Social Media (ICWSM 2016).
  Cologne, Germany",,,,cs.SI cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Twitter has become one of the main sources of news for many people. As
real-world events and emergencies unfold, Twitter is abuzz with hundreds of
thousands of stories about the events. Some of these stories are harmless,
while others could potentially be life-saving or sources of malicious rumors.
Thus, it is critically important to be able to efficiently track stories that
spread on Twitter during these events. In this paper, we present a novel
semi-automatic tool that enables users to efficiently identify and track
stories about real-world events on Twitter. We ran a user study with 25
participants, demonstrating that compared to more conventional methods, our
tool can increase the speed and the accuracy with which users can track stories
about real-world events.
","[{'version': 'v1', 'created': 'Tue, 17 May 2016 12:33:24 GMT'}]",2016-06-21,"[['Vosoughi', 'Soroush', ''], ['Roy', 'Deb', '']]"
2304.05371,Conor Atkins,"Conor Atkins, Benjamin Zi Hao Zhao, Hassan Jameel Asghar, Ian Wood,
  Mohamed Ali Kaafar","Those Aren't Your Memories, They're Somebody Else's: Seeding
  Misinformation in Chat Bot Memories","To be published in 21st International Conference on Applied
  Cryptography and Network Security, ACNS 2023",,,,cs.CL cs.AI cs.CR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  One of the new developments in chit-chat bots is a long-term memory mechanism
that remembers information from past conversations for increasing engagement
and consistency of responses. The bot is designed to extract knowledge of
personal nature from their conversation partner, e.g., stating preference for a
particular color. In this paper, we show that this memory mechanism can result
in unintended behavior. In particular, we found that one can combine a personal
statement with an informative statement that would lead the bot to remember the
informative statement alongside personal knowledge in its long term memory.
This means that the bot can be tricked into remembering misinformation which it
would regurgitate as statements of fact when recalling information relevant to
the topic of conversation. We demonstrate this vulnerability on the BlenderBot
2 framework implemented on the ParlAI platform and provide examples on the more
recent and significantly larger BlenderBot 3 model. We generate 150 examples of
misinformation, of which 114 (76%) were remembered by BlenderBot 2 when
combined with a personal statement. We further assessed the risk of this
misinformation being recalled after intervening innocuous conversation and in
response to multiple questions relevant to the injected memory. Our evaluation
was performed on both the memory-only and the combination of memory and
internet search modes of BlenderBot 2. From the combinations of these
variables, we generated 12,890 conversations and analyzed recalled
misinformation in the responses. We found that when the chat bot is questioned
on the misinformation topic, it was 328% more likely to respond with the
misinformation as fact when the misinformation was in the long-term memory.
","[{'version': 'v1', 'created': 'Thu, 6 Apr 2023 05:09:39 GMT'}]",2023-04-12,"[['Atkins', 'Conor', ''], ['Zhao', 'Benjamin Zi Hao', ''], ['Asghar', 'Hassan Jameel', ''], ['Wood', 'Ian', ''], ['Kaafar', 'Mohamed Ali', '']]"
1807.08669,Raghav Menon,"Raghav Menon, Astik Biswas, Armin Saeb, John Quinn and Thomas Niesler",Automatic Speech Recognition for Humanitarian Applications in Somali,"5 pages, 3 figures, 5 tables accepted at SLTU 2018",,,,cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present our first efforts in building an automatic speech recognition
system for Somali, an under-resourced language, using 1.57 hrs of annotated
speech for acoustic model training. The system is part of an ongoing effort by
the United Nations (UN) to implement keyword spotting systems supporting
humanitarian relief programmes in parts of Africa where languages are severely
under-resourced. We evaluate several types of acoustic model, including recent
neural architectures. Language model data augmentation using a combination of
recurrent neural networks (RNN) and long short-term memory neural networks
(LSTMs) as well as the perturbation of acoustic data are also considered. We
find that both types of data augmentation are beneficial to performance, with
our best system using a combination of convolutional neural networks (CNNs),
time-delay neural networks (TDNNs) and bi-directional long short term memory
(BLSTMs) to achieve a word error rate of 53.75%.
","[{'version': 'v1', 'created': 'Mon, 23 Jul 2018 15:17:04 GMT'}]",2018-07-24,"[['Menon', 'Raghav', ''], ['Biswas', 'Astik', ''], ['Saeb', 'Armin', ''], ['Quinn', 'John', ''], ['Niesler', 'Thomas', '']]"
1806.04550,Florian Schmidt,Florian Schmidt and Thomas Hofmann,Deep State Space Models for Unconditional Word Generation,NIPS camera-ready version,,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Autoregressive feedback is considered a necessity for successful
unconditional text generation using stochastic sequence models. However, such
feedback is known to introduce systematic biases into the training process and
it obscures a principle of generation: committing to global information and
forgetting local nuances. We show that a non-autoregressive deep state space
model with a clear separation of global and local uncertainty can be built from
only two ingredients: An independent noise source and a deterministic
transition function. Recent advances on flow-based variational inference can be
used to train an evidence lower-bound without resorting to annealing, auxiliary
losses or similar measures. The result is a highly interpretable generative
model on par with comparable auto-regressive models on the task of word
generation.
","[{'version': 'v1', 'created': 'Tue, 12 Jun 2018 14:19:48 GMT'}, {'version': 'v2', 'created': 'Sun, 28 Oct 2018 19:07:26 GMT'}]",2018-10-30,"[['Schmidt', 'Florian', ''], ['Hofmann', 'Thomas', '']]"
2210.17108,Zhenwei An,"Zhenwei An, Quzhe Huang, Cong Jiang, Yansong Feng, Dongyan Zhao",Do Charge Prediction Models Learn Legal Theory?,findings of emnlp2022,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The charge prediction task aims to predict the charge for a case given its
fact description. Recent models have already achieved impressive accuracy in
this task, however, little is understood about the mechanisms they use to
perform the judgment.For practical applications, a charge prediction model
should conform to the certain legal theory in civil law countries, as under the
framework of civil law, all cases are judged according to certain local legal
theories. In China, for example, nearly all criminal judges make decisions
based on the Four Elements Theory (FET).In this paper, we argue that
trustworthy charge prediction models should take legal theories into
consideration, and standing on prior studies in model interpretation, we
propose three principles for trustworthy models should follow in this task,
which are sensitive, selective, and presumption of innocence.We further design
a new framework to evaluate whether existing charge prediction models learn
legal theories. Our findings indicate that, while existing charge prediction
models meet the selective principle on a benchmark dataset, most of them are
still not sensitive enough and do not satisfy the presumption of innocence. Our
code and dataset are released at https://github.com/ZhenweiAn/EXP_LJP.
","[{'version': 'v1', 'created': 'Mon, 31 Oct 2022 07:32:12 GMT'}]",2022-11-01,"[['An', 'Zhenwei', ''], ['Huang', 'Quzhe', ''], ['Jiang', 'Cong', ''], ['Feng', 'Yansong', ''], ['Zhao', 'Dongyan', '']]"
2211.13819,Xiang Dai,Xiang Dai and Sarvnaz Karimi,"Detecting Entities in the Astrophysics Literature: A Comparison of
  Word-based and Span-based Entity Recognition Methods","AACL-IJCNLP Workshop on Information Extraction from Scientific
  Publications (WIESP 2022)",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Information Extraction from scientific literature can be challenging due to
the highly specialised nature of such text. We describe our entity recognition
methods developed as part of the DEAL (Detecting Entities in the Astrophysics
Literature) shared task. The aim of the task is to build a system that can
identify Named Entities in a dataset composed by scholarly articles from
astrophysics literature. We planned our participation such that it enables us
to conduct an empirical comparison between word-based tagging and span-based
classification methods. When evaluated on two hidden test sets provided by the
organizer, our best-performing submission achieved $F_1$ scores of 0.8307
(validation phase) and 0.7990 (testing phase).
","[{'version': 'v1', 'created': 'Thu, 24 Nov 2022 23:07:48 GMT'}]",2022-11-28,"[['Dai', 'Xiang', ''], ['Karimi', 'Sarvnaz', '']]"
2207.05133,Maaz Amjad,"Maaz Amjad, Sabur Butt, Hamza Imam Amjad, Alisa Zhila, Grigori
  Sidorov, Alexander Gelbukh",Overview of the Shared Task on Fake News Detection in Urdu at FIRE 2021,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Automatic detection of fake news is a highly important task in the
contemporary world. This study reports the 2nd shared task called
UrduFake@FIRE2021 on identifying fake news detection in Urdu. The goal of the
shared task is to motivate the community to come up with efficient methods for
solving this vital problem, particularly for the Urdu language. The task is
posed as a binary classification problem to label a given news article as a
real or a fake news article. The organizers provide a dataset comprising news
in five domains: (i) Health, (ii) Sports, (iii) Showbiz, (iv) Technology, and
(v) Business, split into training and testing sets. The training set contains
1300 annotated news articles -- 750 real news, 550 fake news, while the testing
set contains 300 news articles -- 200 real, 100 fake news. 34 teams from 7
different countries (China, Egypt, Israel, India, Mexico, Pakistan, and UAE)
registered to participate in the UrduFake@FIRE2021 shared task. Out of those,
18 teams submitted their experimental results, and 11 of those submitted their
technical reports, which is substantially higher compared to the UrduFake
shared task in 2020 when only 6 teams submitted their technical reports. The
technical reports submitted by the participants demonstrated different data
representation techniques ranging from count-based BoW features to word vector
embeddings as well as the use of numerous machine learning algorithms ranging
from traditional SVM to various neural network architectures including
Transformers such as BERT and RoBERTa. In this year's competition, the best
performing system obtained an F1-macro score of 0.679, which is lower than the
past year's best result of 0.907 F1-macro. Admittedly, while training sets from
the past and the current years overlap to a large extent, the testing set
provided this year is completely different.
","[{'version': 'v1', 'created': 'Mon, 11 Jul 2022 18:58:36 GMT'}]",2022-07-13,"[['Amjad', 'Maaz', ''], ['Butt', 'Sabur', ''], ['Amjad', 'Hamza Imam', ''], ['Zhila', 'Alisa', ''], ['Sidorov', 'Grigori', ''], ['Gelbukh', 'Alexander', '']]"
1701.03227,Angela Fan,"Angela Fan, Finale Doshi-Velez, Luke Miratrix","Prior matters: simple and general methods for evaluating and improving
  topic quality in topic modeling",,,,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Latent Dirichlet Allocation (LDA) models trained without stopword removal
often produce topics with high posterior probabilities on uninformative words,
obscuring the underlying corpus content. Even when canonical stopwords are
manually removed, uninformative words common in that corpus will still dominate
the most probable words in a topic. In this work, we first show how the
standard topic quality measures of coherence and pointwise mutual information
act counter-intuitively in the presence of common but irrelevant words, making
it difficult to even quantitatively identify situations in which topics may be
dominated by stopwords. We propose an additional topic quality metric that
targets the stopword problem, and show that it, unlike the standard measures,
correctly correlates with human judgements of quality. We also propose a
simple-to-implement strategy for generating topics that are evaluated to be of
much higher quality by both human assessment and our new metric. This approach,
a collection of informative priors easily introduced into most LDA-style
inference methods, automatically promotes terms with domain relevance and
demotes domain-specific stop words. We demonstrate this approach's
effectiveness in three very different domains: Department of Labor accident
reports, online health forum posts, and NIPS abstracts. Overall we find that
current practices thought to solve this problem do not do so adequately, and
that our proposal offers a substantial improvement for those interested in
interpreting their topics as objects in their own right.
","[{'version': 'v1', 'created': 'Thu, 12 Jan 2017 04:26:00 GMT'}, {'version': 'v2', 'created': 'Sun, 11 Jun 2017 23:17:12 GMT'}, {'version': 'v3', 'created': 'Sat, 14 Oct 2017 18:25:03 GMT'}]",2017-10-17,"[['Fan', 'Angela', ''], ['Doshi-Velez', 'Finale', ''], ['Miratrix', 'Luke', '']]"
2203.15276,Kei Furukawa,"Kei Furukawa, Takeshi Kishiyama, and Satoshi Nakamura","Applying Syntax$\unicode{x2013}$Prosody Mapping Hypothesis and Prosodic
  Well-Formedness Constraints to Neural Sequence-to-Sequence Speech Synthesis",Submitted to INTERSPEECH 2022,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end text-to-speech synthesis (TTS), which generates speech sounds
directly from strings of texts or phonemes, has improved the quality of speech
synthesis over the conventional TTS. However, most previous studies have been
evaluated based on subjective naturalness and have not objectively examined
whether they can reproduce pitch patterns of phonological phenomena such as
downstep, rhythmic boost, and initial lowering that reflect syntactic
structures in Japanese. These phenomena can be linguistically explained by
phonological constraints and the syntax$\unicode{x2013}$prosody mapping
hypothesis (SPMH), which assumes projections from syntactic structures to
phonological hierarchy. Although some experiments in psycholinguistics have
verified the validity of the SPMH, it is crucial to investigate whether it can
be implemented in TTS. To synthesize linguistic phenomena involving syntactic
or phonological constraints, we propose a model using phonological symbols
based on the SPMH and prosodic well-formedness constraints. Experimental
results showed that the proposed method synthesized similar pitch patterns to
those reported in linguistics experiments for the phenomena of initial lowering
and rhythmic boost. The proposed model efficiently synthesizes phonological
phenomena in the test data that were not explicitly included in the training
data.
","[{'version': 'v1', 'created': 'Tue, 29 Mar 2022 06:45:28 GMT'}]",2022-03-30,"[['Furukawa', 'Kei', ''], ['Kishiyama', 'Takeshi', ''], ['Nakamura', 'Satoshi', '']]"
2307.02018,Jionghao Lin,"Dollaya Hirunyasiri, Danielle R. Thomas, Jionghao Lin, Kenneth R.
  Koedinger, Vincent Aleven","Comparative Analysis of GPT-4 and Human Graders in Evaluating Praise
  Given to Students in Synthetic Dialogues","12 pages Workshop paper, The 24th International Conference on
  Artificial Intelligence in Education, AIED 2023 Educational Dialogue Act
  Classification, Large Language Models, Tutor Training",,,,cs.CL cs.AI cs.HC,http://creativecommons.org/licenses/by/4.0/,"  Research suggests that providing specific and timely feedback to human tutors
enhances their performance. However, it presents challenges due to the
time-consuming nature of assessing tutor performance by human evaluators. Large
language models, such as the AI-chatbot ChatGPT, hold potential for offering
constructive feedback to tutors in practical settings. Nevertheless, the
accuracy of AI-generated feedback remains uncertain, with scant research
investigating the ability of models like ChatGPT to deliver effective feedback.
In this work-in-progress, we evaluate 30 dialogues generated by GPT-4 in a
tutor-student setting. We use two different prompting approaches, the zero-shot
chain of thought and the few-shot chain of thought, to identify specific
components of effective praise based on five criteria. These approaches are
then compared to the results of human graders for accuracy. Our goal is to
assess the extent to which GPT-4 can accurately identify each praise criterion.
We found that both zero-shot and few-shot chain of thought approaches yield
comparable results. GPT-4 performs moderately well in identifying instances
when the tutor offers specific and immediate praise. However, GPT-4
underperforms in identifying the tutor's ability to deliver sincere praise,
particularly in the zero-shot prompting scenario where examples of sincere
tutor praise statements were not provided. Future work will focus on enhancing
prompt engineering, developing a more general tutoring rubric, and evaluating
our method using real-life tutoring dialogues.
","[{'version': 'v1', 'created': 'Wed, 5 Jul 2023 04:14:01 GMT'}]",2023-07-06,"[['Hirunyasiri', 'Dollaya', ''], ['Thomas', 'Danielle R.', ''], ['Lin', 'Jionghao', ''], ['Koedinger', 'Kenneth R.', ''], ['Aleven', 'Vincent', '']]"
2104.04298,Peter Vieting,"Peter Vieting, Christoph L\""uscher, Wilfried Michel, Ralf Schl\""uter,
  Hermann Ney",On Architectures and Training for Raw Waveform Feature Extraction in ASR,Accepted for ASRU 2021,,,,eess.AS cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  With the success of neural network based modeling in automatic speech
recognition (ASR), many studies investigated acoustic modeling and learning of
feature extractors directly based on the raw waveform. Recently, one line of
research has focused on unsupervised pre-training of feature extractors on
audio-only data to improve downstream ASR performance. In this work, we
investigate the usefulness of one of these front-end frameworks, namely
wav2vec, in a setting without additional untranscribed data for hybrid ASR
systems. We compare this framework both to the manually defined standard
Gammatone feature set, as well as to features extracted as part of the acoustic
model of an ASR system trained supervised. We study the benefits of using the
pre-trained feature extractor and explore how to additionally exploit an
existing acoustic model trained with different features. Finally, we
systematically examine combinations of the described features in order to
further advance the performance.
","[{'version': 'v1', 'created': 'Fri, 9 Apr 2021 11:04:58 GMT'}, {'version': 'v2', 'created': 'Wed, 9 Jun 2021 21:42:32 GMT'}, {'version': 'v3', 'created': 'Tue, 5 Oct 2021 14:25:45 GMT'}]",2021-10-06,"[['Vieting', 'Peter', ''], ['Lüscher', 'Christoph', ''], ['Michel', 'Wilfried', ''], ['Schlüter', 'Ralf', ''], ['Ney', 'Hermann', '']]"
2106.07349,Anmol Nayak,"Anmol Nayak, Hari Prasad Timmapathini","Using Integrated Gradients and Constituency Parse Trees to explain
  Linguistic Acceptability learnt by BERT","Accepted at International Conference on Natural Language Processing
  (ICON) 2021. 6 pages, 3 figures",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Linguistic Acceptability is the task of determining whether a sentence is
grammatical or ungrammatical. It has applications in several use cases like
Question-Answering, Natural Language Generation, Neural Machine Translation,
where grammatical correctness is crucial. In this paper we aim to understand
the decision-making process of BERT (Devlin et al., 2019) in distinguishing
between Linguistically Acceptable sentences (LA) and Linguistically
Unacceptable sentences (LUA). We leverage Layer Integrated Gradients
Attribution Scores (LIG) to explain the Linguistic Acceptability criteria that
are learnt by BERT on the Corpus of Linguistic Acceptability (CoLA) (Warstadt
et al., 2018) benchmark dataset. Our experiments on 5 categories of sentences
lead to the following interesting findings: 1) LIG for LA are significantly
smaller in comparison to LUA, 2) There are specific subtrees of the
Constituency Parse Tree (CPT) for LA and LUA which contribute larger LIG, 3)
Across the different categories of sentences we observed around 88% to 100% of
the Correctly classified sentences had positive LIG, indicating a strong
positive relationship to the prediction confidence of the model, and 4) Around
43% of the Misclassified sentences had negative LIG, which we believe can
become correctly classified sentences if the LIG are parameterized in the loss
function of the model.
","[{'version': 'v1', 'created': 'Tue, 1 Jun 2021 15:17:45 GMT'}, {'version': 'v2', 'created': 'Tue, 8 Mar 2022 11:52:08 GMT'}]",2022-03-09,"[['Nayak', 'Anmol', ''], ['Timmapathini', 'Hari Prasad', '']]"
2307.10234,Hamid Karimi,Kiana Kheiri and Hamid Karimi,"SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its
  Departure from Current Machine Learning",,,,,cs.CL cs.AI cs.LG cs.SI,http://creativecommons.org/licenses/by/4.0/,"  This study presents a thorough examination of various Generative Pretrained
Transformer (GPT) methodologies in sentiment analysis, specifically in the
context of Task 4 on the SemEval 2017 dataset. Three primary strategies are
employed: 1) prompt engineering using the advanced GPT-3.5 Turbo, 2)
fine-tuning GPT models, and 3) an inventive approach to embedding
classification. The research yields detailed comparative insights among these
strategies and individual GPT models, revealing their unique strengths and
potential limitations. Additionally, the study compares these GPT-based
methodologies with other current, high-performing models previously used with
the same dataset. The results illustrate the significant superiority of the GPT
approaches in terms of predictive performance, more than 22\% in F1-score
compared to the state-of-the-art. Further, the paper sheds light on common
challenges in sentiment analysis tasks, such as understanding context and
detecting sarcasm. It underscores the enhanced capabilities of the GPT models
to effectively handle these complexities. Taken together, these findings
highlight the promising potential of GPT models in sentiment analysis, setting
the stage for future research in this field. The code can be found at
https://github.com/DSAatUSU/SentimentGPT
","[{'version': 'v1', 'created': 'Sun, 16 Jul 2023 05:33:35 GMT'}, {'version': 'v2', 'created': 'Sun, 23 Jul 2023 13:48:15 GMT'}]",2023-07-25,"[['Kheiri', 'Kiana', ''], ['Karimi', 'Hamid', '']]"
2111.03108,Anthony Bau,Anthony Bau and Jacob Andreas,"How Do Neural Sequence Models Generalize? Local and Global Context Cues
  for Out-of-Distribution Prediction",,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  After a neural sequence model encounters an unexpected token, can its
behavior be predicted? We show that RNN and transformer language models exhibit
structured, consistent generalization in out-of-distribution contexts. We begin
by introducing two idealized models of generalization in next-word prediction:
a local context model in which generalization is consistent with the last word
observed, and a global context model in which generalization is consistent with
the global structure of the input. In experiments in English, Finnish,
Mandarin, and random regular languages, we demonstrate that neural language
models interpolate between these two forms of generalization: their predictions
are well-approximated by a log-linear combination of local and global
predictive distributions. We then show that, in some languages, noise mediates
the two forms of generalization: noise applied to input tokens encourages
global generalization, while noise in history representations encourages local
generalization. Finally, we offer a preliminary theoretical explanation of
these results by proving that the observed interpolation behavior is expected
in log-linear models with a particular feature correlation structure. These
results help explain the effectiveness of two popular regularization schemes
and show that aspects of sequence model generalization can be understood and
controlled.
","[{'version': 'v1', 'created': 'Thu, 4 Nov 2021 19:08:14 GMT'}]",2021-11-08,"[['Bau', 'Anthony', ''], ['Andreas', 'Jacob', '']]"
1912.04971,Nitish Gupta,"Nitish Gupta, Kevin Lin, Dan Roth, Sameer Singh, Matt Gardner",Neural Module Networks for Reasoning over Text,"Published in ICLR 2020 (International Conference on Learning
  Representations, 2020)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Answering compositional questions that require multiple steps of reasoning
against text is challenging, especially when they involve discrete, symbolic
operations. Neural module networks (NMNs) learn to parse such questions as
executable programs composed of learnable modules, performing well on synthetic
visual QA domains. However, we find that it is challenging to learn these
models for non-synthetic questions on open-domain text, where a model needs to
deal with the diversity of natural language and perform a broader range of
reasoning. We extend NMNs by: (a) introducing modules that reason over a
paragraph of text, performing symbolic reasoning (such as arithmetic, sorting,
counting) over numbers and dates in a probabilistic and differentiable manner;
and (b) proposing an unsupervised auxiliary loss to help extract arguments
associated with the events in text. Additionally, we show that a limited amount
of heuristically-obtained question program and intermediate module output
supervision provides sufficient inductive bias for accurate learning. Our
proposed model significantly outperforms state-of-the-art models on a subset of
the DROP dataset that poses a variety of reasoning challenges that are covered
by our modules.
","[{'version': 'v1', 'created': 'Tue, 10 Dec 2019 20:36:07 GMT'}, {'version': 'v2', 'created': 'Sat, 15 Feb 2020 19:26:05 GMT'}]",2020-02-18,"[['Gupta', 'Nitish', ''], ['Lin', 'Kevin', ''], ['Roth', 'Dan', ''], ['Singh', 'Sameer', ''], ['Gardner', 'Matt', '']]"
2208.01341,Gizem Sogancioglu,"Gizem Sogancioglu, Fabian Mijsters, Amar van Uden, Jelle Peperzak","Gender bias in (non)-contextual clinical word embeddings for
  stereotypical medical categories",,,,,cs.CL cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Clinical word embeddings are extensively used in various Bio-NLP problems as
a state-of-the-art feature vector representation. Although they are quite
successful at the semantic representation of words, due to the dataset - which
potentially carries statistical and societal bias - on which they are trained,
they might exhibit gender stereotypes. This study analyses gender bias of
clinical embeddings on three medical categories: mental disorders, sexually
transmitted diseases, and personality traits. To this extent, we analyze two
different pre-trained embeddings namely (contextualized) clinical-BERT and
(non-contextualized) BioWordVec. We show that both embeddings are biased
towards sensitive gender groups but BioWordVec exhibits a higher bias than
clinical-BERT for all three categories. Moreover, our analyses show that
clinical embeddings carry a high degree of bias for some medical terms and
diseases which is conflicting with medical literature. Having such an
ill-founded relationship might cause harm in downstream applications that use
clinical embeddings.
","[{'version': 'v1', 'created': 'Tue, 2 Aug 2022 10:02:21 GMT'}, {'version': 'v2', 'created': 'Mon, 8 Aug 2022 14:18:42 GMT'}]",2022-08-09,"[['Sogancioglu', 'Gizem', ''], ['Mijsters', 'Fabian', ''], ['van Uden', 'Amar', ''], ['Peperzak', 'Jelle', '']]"
1904.05862,Steffen Schneider,"Steffen Schneider, Alexei Baevski, Ronan Collobert, Michael Auli",wav2vec: Unsupervised Pre-training for Speech Recognition,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We explore unsupervised pre-training for speech recognition by learning
representations of raw audio. wav2vec is trained on large amounts of unlabeled
audio data and the resulting representations are then used to improve acoustic
model training. We pre-train a simple multi-layer convolutional neural network
optimized via a noise contrastive binary classification task. Our experiments
on WSJ reduce WER of a strong character-based log-mel filterbank baseline by up
to 36% when only a few hours of transcribed data is available. Our approach
achieves 2.43% WER on the nov92 test set. This outperforms Deep Speech 2, the
best reported character-based system in the literature while using two orders
of magnitude less labeled training data.
","[{'version': 'v1', 'created': 'Thu, 11 Apr 2019 17:29:30 GMT'}, {'version': 'v2', 'created': 'Fri, 24 May 2019 06:09:03 GMT'}, {'version': 'v3', 'created': 'Tue, 2 Jul 2019 06:16:44 GMT'}, {'version': 'v4', 'created': 'Wed, 11 Sep 2019 08:19:49 GMT'}]",2019-09-12,"[['Schneider', 'Steffen', ''], ['Baevski', 'Alexei', ''], ['Collobert', 'Ronan', ''], ['Auli', 'Michael', '']]"
2111.06625,Ovishake Sen,"Ovishake Sen, Al-Mahmud and Pias Roy","A Convolutional Neural Network Based Approach to Recognize Bangla Spoken
  Digits from Speech Signal","4 pages, 5 figures, 2021 International Conference on Electronics,
  Communications and Information Technology (ICECIT), 14 to 16 September 2021,
  Khulna, Bangladesh",,,,cs.SD cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Speech recognition is a technique that converts human speech signals into
text or words or in any form that can be easily understood by computers or
other machines. There have been a few studies on Bangla digit recognition
systems, the majority of which used small datasets with few variations in
genders, ages, dialects, and other variables. Audio recordings of Bangladeshi
people of various genders, ages, and dialects were used to create a large
speech dataset of spoken '0-9' Bangla digits in this study. Here, 400 noisy and
noise-free samples per digit have been recorded for creating the dataset. Mel
Frequency Cepstrum Coefficients (MFCCs) have been utilized for extracting
meaningful features from the raw speech data. Then, to detect Bangla numeral
digits, Convolutional Neural Networks (CNNs) were utilized. The suggested
technique recognizes '0-9' Bangla spoken digits with 97.1% accuracy throughout
the whole dataset. The efficiency of the model was also assessed using 10-fold
crossvalidation, which yielded a 96.7% accuracy.
","[{'version': 'v1', 'created': 'Fri, 12 Nov 2021 09:38:15 GMT'}]",2021-11-15,"[['Sen', 'Ovishake', ''], ['Al-Mahmud', '', ''], ['Roy', 'Pias', '']]"
2311.11979,Rohan Das,"Dananjay Srinivas, Rohan Das, Saeid Tizpaz-Niari, Ashutosh Trivedi,
  Maria Leonor Pacheco","On the Potential and Limitations of Few-Shot In-Context Learning to
  Generate Metamorphic Specifications for Tax Preparation Software","Accepted to the Proceedings of the Natural Legal Language Processing
  Workshop, EMNLP 2023",,,,cs.SE cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Due to the ever-increasing complexity of income tax laws in the United
States, the number of US taxpayers filing their taxes using tax preparation
software (henceforth, tax software) continues to increase. According to the
U.S. Internal Revenue Service (IRS), in FY22, nearly 50% of taxpayers filed
their individual income taxes using tax software. Given the legal consequences
of incorrectly filing taxes for the taxpayer, ensuring the correctness of tax
software is of paramount importance. Metamorphic testing has emerged as a
leading solution to test and debug legal-critical tax software due to the
absence of correctness requirements and trustworthy datasets. The key idea
behind metamorphic testing is to express the properties of a system in terms of
the relationship between one input and its slightly metamorphosed twinned
input. Extracting metamorphic properties from IRS tax publications is a tedious
and time-consuming process. As a response, this paper formulates the task of
generating metamorphic specifications as a translation task between properties
extracted from tax documents - expressed in natural language - to a contrastive
first-order logic form. We perform a systematic analysis on the potential and
limitations of in-context learning with Large Language Models(LLMs) for this
task, and outline a research agenda towards automating the generation of
metamorphic specifications for tax preparation software.
","[{'version': 'v1', 'created': 'Mon, 20 Nov 2023 18:12:28 GMT'}]",2023-11-21,"[['Srinivas', 'Dananjay', ''], ['Das', 'Rohan', ''], ['Tizpaz-Niari', 'Saeid', ''], ['Trivedi', 'Ashutosh', ''], ['Pacheco', 'Maria Leonor', '']]"
2402.10294,Bryan Wang,"Bryan Wang, Yuliang Li, Zhaoyang Lv, Haijun Xia, Yan Xu, Raj Sodhi","LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video
  Editing","Paper accepted to the ACM Conference on Intelligent User Interfaces
  (ACM IUI) 2024",,,,cs.HC cs.AI cs.CL cs.MM,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Video creation has become increasingly popular, yet the expertise and effort
required for editing often pose barriers to beginners. In this paper, we
explore the integration of large language models (LLMs) into the video editing
workflow to reduce these barriers. Our design vision is embodied in LAVE, a
novel system that provides LLM-powered agent assistance and language-augmented
editing features. LAVE automatically generates language descriptions for the
user's footage, serving as the foundation for enabling the LLM to process
videos and assist in editing tasks. When the user provides editing objectives,
the agent plans and executes relevant actions to fulfill them. Moreover, LAVE
allows users to edit videos through either the agent or direct UI manipulation,
providing flexibility and enabling manual refinement of agent actions. Our user
study, which included eight participants ranging from novices to proficient
editors, demonstrated LAVE's effectiveness. The results also shed light on user
perceptions of the proposed LLM-assisted editing paradigm and its impact on
users' creativity and sense of co-creation. Based on these findings, we propose
design implications to inform the future development of agent-assisted content
editing.
","[{'version': 'v1', 'created': 'Thu, 15 Feb 2024 19:53:11 GMT'}]",2024-02-29,"[['Wang', 'Bryan', ''], ['Li', 'Yuliang', ''], ['Lv', 'Zhaoyang', ''], ['Xia', 'Haijun', ''], ['Xu', 'Yan', ''], ['Sodhi', 'Raj', '']]"
2011.03322,Shen Gao,"Shen Gao, Xiuying Chen, Li Liu, Dongyan Zhao and Rui Yan","Learning to Respond with Your Favorite Stickers: A Framework of Unifying
  Multi-Modality and User Preference in Multi-Turn Dialog","Accepted by TOIS. arXiv admin note: substantial text overlap with
  arXiv:2003.04679",,,,cs.CL cs.CV cs.MM,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Stickers with vivid and engaging expressions are becoming increasingly
popular in online messaging apps, and some works are dedicated to automatically
select sticker response by matching the stickers image with previous
utterances. However, existing methods usually focus on measuring the matching
degree between the dialog context and sticker image, which ignores the user
preference of using stickers. Hence, in this paper, we propose to recommend an
appropriate sticker to user based on multi-turn dialog context and sticker
using history of user. Two main challenges are confronted in this task. One is
to model the sticker preference of user based on the previous sticker selection
history. Another challenge is to jointly fuse the user preference and the
matching between dialog context and candidate sticker into final prediction
making. To tackle these challenges, we propose a \emph{Preference Enhanced
Sticker Response Selector} (PESRS) model. Specifically, PESRS first employs a
convolutional based sticker image encoder and a self-attention based multi-turn
dialog encoder to obtain the representation of stickers and utterances. Next,
deep interaction network is proposed to conduct deep matching between the
sticker and each utterance. Then, we model the user preference by using the
recently selected stickers as input, and use a key-value memory network to
store the preference representation. PESRS then learns the short-term and
long-term dependency between all interaction results by a fusion network, and
dynamically fuse the user preference representation into the final sticker
selection prediction. Extensive experiments conducted on a large-scale
real-world dialog dataset show that our model achieves the state-of-the-art
performance for all commonly-used metrics. Experiments also verify the
effectiveness of each component of PESRS.
","[{'version': 'v1', 'created': 'Thu, 5 Nov 2020 03:31:17 GMT'}]",2020-11-09,"[['Gao', 'Shen', ''], ['Chen', 'Xiuying', ''], ['Liu', 'Li', ''], ['Zhao', 'Dongyan', ''], ['Yan', 'Rui', '']]"
2309.07677,Jinho D. Choi,"Chen Gong, Peilin Wu, Jinho D. Choi","Aligning Speakers: Evaluating and Visualizing Text-based Diarization
  Using Efficient Multiple Sequence Alignment (Extended Version)","Accepted to the 35th IEEE International Conference on Tools with
  Artificial Intelligence (ICTAI) 2023",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This paper presents a novel evaluation approach to text-based speaker
diarization (SD), tackling the limitations of traditional metrics that do not
account for any contextual information in text. Two new metrics are proposed,
Text-based Diarization Error Rate and Diarization F1, which perform utterance-
and word-level evaluations by aligning tokens in reference and hypothesis
transcripts. Our metrics encompass more types of errors compared to existing
ones, allowing us to make a more comprehensive analysis in SD. To align tokens,
a multiple sequence alignment algorithm is introduced that supports multiple
sequences in the reference while handling high-dimensional alignment to the
hypothesis using dynamic programming. Our work is packaged into two tools,
align4d providing an API for our alignment algorithm and TranscribeView for
visualizing and evaluating SD errors, which can greatly aid in the creation of
high-quality data, fostering the advancement of dialogue systems.
","[{'version': 'v1', 'created': 'Thu, 14 Sep 2023 12:43:26 GMT'}]",2023-09-15,"[['Gong', 'Chen', ''], ['Wu', 'Peilin', ''], ['Choi', 'Jinho D.', '']]"
2103.07766,Endri Kacupaj,"Joan Plepi, Endri Kacupaj, Kuldeep Singh, Harsh Thakkar, Jens Lehmann","Context Transformer with Stacked Pointer Networks for Conversational
  Question Answering over Knowledge Graphs","18th Extended Semantic Web Conference 2021 (ESWC'2021) - Research
  Track",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Neural semantic parsing approaches have been widely used for Question
Answering (QA) systems over knowledge graphs. Such methods provide the
flexibility to handle QA datasets with complex queries and a large number of
entities. In this work, we propose a novel framework named CARTON, which
performs multi-task semantic parsing for handling the problem of conversational
question answering over a large-scale knowledge graph. Our framework consists
of a stack of pointer networks as an extension of a context transformer model
for parsing the input question and the dialog history. The framework generates
a sequence of actions that can be executed on the knowledge graph. We evaluate
CARTON on a standard dataset for complex sequential question answering on which
CARTON outperforms all baselines. Specifically, we observe performance
improvements in F1-score on eight out of ten question types compared to the
previous state of the art. For logical reasoning questions, an improvement of
11 absolute points is reached.
","[{'version': 'v1', 'created': 'Sat, 13 Mar 2021 18:16:43 GMT'}, {'version': 'v2', 'created': 'Thu, 24 Jun 2021 11:30:50 GMT'}]",2021-06-25,"[['Plepi', 'Joan', ''], ['Kacupaj', 'Endri', ''], ['Singh', 'Kuldeep', ''], ['Thakkar', 'Harsh', ''], ['Lehmann', 'Jens', '']]"
2308.09597,Cheng Li,"Cheng Li, Ziang Leng, Chenxi Yan, Junyi Shen, Hao Wang, Weishi MI,
  Yaying Fei, Xiaoyang Feng, Song Yan, HaoSheng Wang, Linkang Zhan, Yaokai Jia,
  Pingyu Wu, Haozhen Sun",ChatHaruhi: Reviving Anime Character in Reality via Large Language Model,v1 - First version of techique report,,,,cs.CL cs.HC,http://creativecommons.org/licenses/by-sa/4.0/,"  Role-playing chatbots built on large language models have drawn interest, but
better techniques are needed to enable mimicking specific fictional characters.
We propose an algorithm that controls language models via an improved prompt
and memories of the character extracted from scripts. We construct ChatHaruhi,
a dataset covering 32 Chinese / English TV / anime characters with over 54k
simulated dialogues. Both automatic and human evaluations show our approach
improves role-playing ability over baselines. Code and data are available at
https://github.com/LC1332/Chat-Haruhi-Suzumiya .
","[{'version': 'v1', 'created': 'Fri, 18 Aug 2023 14:50:25 GMT'}]",2023-08-21,"[['Li', 'Cheng', ''], ['Leng', 'Ziang', ''], ['Yan', 'Chenxi', ''], ['Shen', 'Junyi', ''], ['Wang', 'Hao', ''], ['MI', 'Weishi', ''], ['Fei', 'Yaying', ''], ['Feng', 'Xiaoyang', ''], ['Yan', 'Song', ''], ['Wang', 'HaoSheng', ''], ['Zhan', 'Linkang', ''], ['Jia', 'Yaokai', ''], ['Wu', 'Pingyu', ''], ['Sun', 'Haozhen', '']]"
2303.02513,Md Rabiul Awal,"Md Rabiul Awal, Roy Ka-Wei Lee, Eshaan Tanwar, Tanmay Garg, Tanmoy
  Chakraborty",Model-Agnostic Meta-Learning for Multilingual Hate Speech Detection,,,,,cs.CL cs.SI,http://creativecommons.org/licenses/by/4.0/,"  Hate speech in social media is a growing phenomenon, and detecting such toxic
content has recently gained significant traction in the research community.
Existing studies have explored fine-tuning language models (LMs) to perform
hate speech detection, and these solutions have yielded significant
performance. However, most of these studies are limited to detecting hate
speech only in English, neglecting the bulk of hateful content that is
generated in other languages, particularly in low-resource languages.
Developing a classifier that captures hate speech and nuances in a low-resource
language with limited data is extremely challenging. To fill the research gap,
we propose HateMAML, a model-agnostic meta-learning-based framework that
effectively performs hate speech detection in low-resource languages. HateMAML
utilizes a self-supervision strategy to overcome the limitation of data
scarcity and produces better LM initialization for fast adaptation to an unseen
target language (i.e., cross-lingual transfer) or other hate speech datasets
(i.e., domain generalization). Extensive experiments are conducted on five
datasets across eight different low-resource languages. The results show that
HateMAML outperforms the state-of-the-art baselines by more than 3% in the
cross-domain multilingual transfer setting. We also conduct ablation studies to
analyze the characteristics of HateMAML.
","[{'version': 'v1', 'created': 'Sat, 4 Mar 2023 22:28:29 GMT'}]",2023-03-07,"[['Awal', 'Md Rabiul', ''], ['Lee', 'Roy Ka-Wei', ''], ['Tanwar', 'Eshaan', ''], ['Garg', 'Tanmay', ''], ['Chakraborty', 'Tanmoy', '']]"
2401.12981,Nicholas Yan,"Nicholas Yan, Gil Alterovitz",A General-purpose AI Avatar in Healthcare,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Recent advancements in machine learning and natural language processing have
led to the rapid development of artificial intelligence (AI) as a valuable tool
in the healthcare industry. Using large language models (LLMs) as
conversational agents or chatbots has the potential to assist doctors in
diagnosing patients, detecting early symptoms of diseases, and providing health
advice to patients. This paper focuses on the role of chatbots in healthcare
and explores the use of avatars to make AI interactions more appealing to
patients. A framework of a general-purpose AI avatar application is
demonstrated by using a three-category prompt dictionary and prompt improvement
mechanism. A two-phase approach is suggested to fine-tune a general-purpose AI
language model and create different AI avatars to discuss medical issues with
users. Prompt engineering enhances the chatbot's conversational abilities and
personality traits, fostering a more human-like interaction with patients.
Ultimately, the injection of personality into the chatbot could potentially
increase patient engagement. Future directions for research include
investigating ways to improve chatbots' understanding of context and ensuring
the accuracy of their outputs through fine-tuning with specialized medical data
sets.
","[{'version': 'v1', 'created': 'Wed, 10 Jan 2024 03:44:15 GMT'}]",2024-01-25,"[['Yan', 'Nicholas', ''], ['Alterovitz', 'Gil', '']]"
2402.05140,Junhong Shen,"Junhong Shen, Neil Tenenholtz, James Brian Hall, David Alvarez-Melis,
  Nicolo Fusi",Tag-LLM: Repurposing General-Purpose LLMs for Specialized Domains,,,,,cs.LG cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) have demonstrated remarkable proficiency in
understanding and generating natural language. However, their capabilities wane
in highly specialized domains underrepresented in the pretraining corpus, such
as physical and biomedical sciences. This work explores how to repurpose
general LLMs into effective task solvers for specialized domains. We introduce
a novel, model-agnostic framework for learning custom input tags, which are
parameterized as continuous vectors appended to the LLM's embedding layer, to
condition the LLM. We design two types of input tags: domain tags are used to
delimit specialized representations (e.g., chemical formulas) and provide
domain-relevant context; function tags are used to represent specific functions
(e.g., predicting molecular properties) and compress function-solving
instructions. We develop a three-stage protocol to learn these tags using
auxiliary data and domain knowledge. By explicitly disentangling task domains
from task functions, our method enables zero-shot generalization to unseen
problems through diverse combinations of the input tags. It also boosts LLM's
performance in various specialized domains, such as predicting protein or
chemical properties and modeling drug-target interactions, outperforming expert
models tailored to these tasks.
","[{'version': 'v1', 'created': 'Tue, 6 Feb 2024 20:11:54 GMT'}]",2024-02-09,"[['Shen', 'Junhong', ''], ['Tenenholtz', 'Neil', ''], ['Hall', 'James Brian', ''], ['Alvarez-Melis', 'David', ''], ['Fusi', 'Nicolo', '']]"
1904.02633,Tzu-Ming Harry Hsu,"Guanxiong Liu, Tzu-Ming Harry Hsu, Matthew McDermott, Willie Boag,
  Wei-Hung Weng, Peter Szolovits, Marzyeh Ghassemi",Clinically Accurate Chest X-Ray Report Generation,,,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The automatic generation of radiology reports given medical radiographs has
significant potential to operationally and improve clinical patient care. A
number of prior works have focused on this problem, employing advanced methods
from computer vision and natural language generation to produce readable
reports. However, these works often fail to account for the particular nuances
of the radiology domain, and, in particular, the critical importance of
clinical accuracy in the resulting generated reports. In this work, we present
a domain-aware automatic chest X-ray radiology report generation system which
first predicts what topics will be discussed in the report, then conditionally
generates sentences corresponding to these topics. The resulting system is
fine-tuned using reinforcement learning, considering both readability and
clinical accuracy, as assessed by the proposed Clinically Coherent Reward. We
verify this system on two datasets, Open-I and MIMIC-CXR, and demonstrate that
our model offers marked improvements on both language generation metrics and
CheXpert assessed accuracy over a variety of competitive baselines.
","[{'version': 'v1', 'created': 'Thu, 4 Apr 2019 16:04:30 GMT'}, {'version': 'v2', 'created': 'Mon, 29 Jul 2019 04:15:47 GMT'}]",2019-07-30,"[['Liu', 'Guanxiong', ''], ['Hsu', 'Tzu-Ming Harry', ''], ['McDermott', 'Matthew', ''], ['Boag', 'Willie', ''], ['Weng', 'Wei-Hung', ''], ['Szolovits', 'Peter', ''], ['Ghassemi', 'Marzyeh', '']]"
2402.08496,Chinonso Cynthia Osuji,"Chinonso Cynthia Osuji, Thiago Castro Ferreira, Brian Davis",A Systematic Review of Data-to-Text NLG,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  This systematic review undertakes a comprehensive analysis of current
research on data-to-text generation, identifying gaps, challenges, and future
directions within the field. Relevant literature in this field on datasets,
evaluation metrics, application areas, multilingualism, language models, and
hallucination mitigation methods is reviewed. Various methods for producing
high-quality text are explored, addressing the challenge of hallucinations in
data-to-text generation. These methods include re-ranking, traditional and
neural pipeline architecture, planning architectures, data cleaning, controlled
generation, and modification of models and training techniques. Their
effectiveness and limitations are assessed, highlighting the need for
universally applicable strategies to mitigate hallucinations. The review also
examines the usage, popularity, and impact of datasets, alongside evaluation
metrics, with an emphasis on both automatic and human assessment. Additionally,
the evolution of data-to-text models, particularly the widespread adoption of
transformer models, is discussed. Despite advancements in text quality, the
review emphasizes the importance of research in low-resourced languages and the
engineering of datasets in these languages to promote inclusivity. Finally,
several application domains of data-to-text are highlighted, emphasizing their
relevance in such domains. Overall, this review serves as a guiding framework
for fostering innovation and advancing data-to-text generation.
","[{'version': 'v1', 'created': 'Tue, 13 Feb 2024 14:51:45 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Feb 2024 07:26:21 GMT'}, {'version': 'v3', 'created': 'Tue, 27 Feb 2024 00:05:28 GMT'}]",2024-02-28,"[['Osuji', 'Chinonso Cynthia', ''], ['Ferreira', 'Thiago Castro', ''], ['Davis', 'Brian', '']]"
1503.06151,Maxim Litvak,Maxim Litvak,On measuring linguistic intelligence,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This work addresses the problem of measuring how many languages a person
""effectively"" speaks given that some of the languages are close to each other.
In other words, to assign a meaningful number to her language portfolio.
Intuition says that someone who speaks fluently Spanish and Portuguese is
linguistically less proficient compared to someone who speaks fluently Spanish
and Chinese since it takes more effort for a native Spanish speaker to learn
Chinese than Portuguese. As the number of languages grows and their proficiency
levels vary, it gets even more complicated to assign a score to a language
portfolio. In this article we propose such a measure (""linguistic quotient"" -
LQ) that can account for these effects.
  We define the properties that such a measure should have. They are based on
the idea of coherent risk measures from the mathematical finance. Having laid
down the foundation, we propose one such a measure together with the algorithm
that works on languages classification tree as input.
  The algorithm together with the input is available online at lingvometer.com
","[{'version': 'v1', 'created': 'Fri, 20 Mar 2015 16:41:05 GMT'}]",2015-03-23,"[['Litvak', 'Maxim', '']]"
2011.03286,Haryo Akbarianto Wibowo,"Haryo Akbarianto Wibowo, Tatag Aziz Prawiro, Muhammad Ihsan, Alham
  Fikri Aji, Radityo Eko Prasojo, Rahmad Mahendra, Suci Fitriany","Semi-Supervised Low-Resource Style Transfer of Indonesian Informal to
  Formal Language with Iterative Forward-Translation","6 pages, Camera ready to be presented at IALP 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In its daily use, the Indonesian language is riddled with informality, that
is, deviations from the standard in terms of vocabulary, spelling, and word
order. On the other hand, current available Indonesian NLP models are typically
developed with the standard Indonesian in mind. In this work, we address a
style-transfer from informal to formal Indonesian as a low-resource machine
translation problem. We build a new dataset of parallel sentences of informal
Indonesian and its formal counterpart. We benchmark several strategies to
perform style transfer from informal to formal Indonesian. We also explore
augmenting the training set with artificial forward-translated data. Since we
are dealing with an extremely low-resource setting, we find that a phrase-based
machine translation approach outperforms the Transformer-based approach.
Alternatively, a pre-trained GPT-2 fined-tuned to this task performed equally
well but costs more computational resource. Our findings show a promising step
towards leveraging machine translation models for style transfer. Our code and
data are available in https://github.com/haryoa/stif-indonesia
","[{'version': 'v1', 'created': 'Fri, 6 Nov 2020 11:19:47 GMT'}, {'version': 'v2', 'created': 'Tue, 22 Dec 2020 17:32:47 GMT'}]",2020-12-23,"[['Wibowo', 'Haryo Akbarianto', ''], ['Prawiro', 'Tatag Aziz', ''], ['Ihsan', 'Muhammad', ''], ['Aji', 'Alham Fikri', ''], ['Prasojo', 'Radityo Eko', ''], ['Mahendra', 'Rahmad', ''], ['Fitriany', 'Suci', '']]"
2110.15684,Yuanchao Li,"Yuanchao Li, Peter Bell, Catherine Lai",Fusing ASR Outputs in Joint Training for Speech Emotion Recognition,Accepted for ICASSP 2022,,,,eess.AS cs.CL cs.MM cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Alongside acoustic information, linguistic features based on speech
transcripts have been proven useful in Speech Emotion Recognition (SER).
However, due to the scarcity of emotion labelled data and the difficulty of
recognizing emotional speech, it is hard to obtain reliable linguistic features
and models in this research area. In this paper, we propose to fuse Automatic
Speech Recognition (ASR) outputs into the pipeline for joint training SER. The
relationship between ASR and SER is understudied, and it is unclear what and
how ASR features benefit SER. By examining various ASR outputs and fusion
methods, our experiments show that in joint ASR-SER training, incorporating
both ASR hidden and text output using a hierarchical co-attention fusion
approach improves the SER performance the most. On the IEMOCAP corpus, our
approach achieves 63.4% weighted accuracy, which is close to the baseline
results achieved by combining ground-truth transcripts. In addition, we also
present novel word error rate analysis on IEMOCAP and layer-difference analysis
of the Wav2vec 2.0 model to better understand the relationship between ASR and
SER.
","[{'version': 'v1', 'created': 'Fri, 29 Oct 2021 11:21:17 GMT'}, {'version': 'v2', 'created': 'Thu, 17 Mar 2022 20:36:43 GMT'}]",2022-11-11,"[['Li', 'Yuanchao', ''], ['Bell', 'Peter', ''], ['Lai', 'Catherine', '']]"
2210.05359,Ruibo Liu,"Ruibo Liu, Jason Wei, Shixiang Shane Gu, Te-Yen Wu, Soroush Vosoughi,
  Claire Cui, Denny Zhou, Andrew M. Dai",Mind's Eye: Grounded Language Model Reasoning through Simulation,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Successful and effective communication between humans and AI relies on a
shared experience of the world. By training solely on written text, current
language models (LMs) miss the grounded experience of humans in the real-world
-- their failure to relate language to the physical world causes knowledge to
be misrepresented and obvious mistakes in their reasoning. We present Mind's
Eye, a paradigm to ground language model reasoning in the physical world. Given
a physical reasoning question, we use a computational physics engine
(DeepMind's MuJoCo) to simulate the possible outcomes, and then use the
simulation results as part of the input, which enables language models to
perform reasoning. Experiments on 39 tasks in a physics alignment benchmark
demonstrate that Mind's Eye can improve reasoning ability by a large margin
(27.9% zero-shot, and 46.0% few-shot absolute accuracy improvement on average).
Smaller language models armed with Mind's Eye can obtain similar performance to
models that are 100x larger. Finally, we confirm the robustness of Mind's Eye
through ablation studies.
","[{'version': 'v1', 'created': 'Tue, 11 Oct 2022 11:39:23 GMT'}]",2022-10-12,"[['Liu', 'Ruibo', ''], ['Wei', 'Jason', ''], ['Gu', 'Shixiang Shane', ''], ['Wu', 'Te-Yen', ''], ['Vosoughi', 'Soroush', ''], ['Cui', 'Claire', ''], ['Zhou', 'Denny', ''], ['Dai', 'Andrew M.', '']]"
2206.03318,Siddharth Dalmia,"Siddharth Dalmia, Dmytro Okhonko, Mike Lewis, Sergey Edunov, Shinji
  Watanabe, Florian Metze, Luke Zettlemoyer, and Abdelrahman Mohamed",LegoNN: Building Modular Encoder-Decoder Models,"IEEE/ACM Transactions on Audio, Speech, and Language Processing
  (TASLP)",,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  State-of-the-art encoder-decoder models (e.g. for machine translation (MT) or
automatic speech recognition (ASR)) are constructed and trained end-to-end as
an atomic unit. No component of the model can be (re-)used without the others,
making it impossible to share parts, e.g. a high resourced decoder, across
tasks. We describe LegoNN, a procedure for building encoder-decoder
architectures in a way so that its parts can be applied to other tasks without
the need for any fine-tuning. To achieve this reusability, the interface
between encoder and decoder modules is grounded to a sequence of marginal
distributions over a pre-defined discrete vocabulary. We present two approaches
for ingesting these marginals; one is differentiable, allowing the flow of
gradients across the entire network, and the other is gradient-isolating. To
enable the portability of decoder modules between MT tasks for different source
languages and across other tasks like ASR, we introduce a modality agnostic
encoder which consists of a length control mechanism to dynamically adapt
encoders' output lengths in order to match the expected input length range of
pre-trained decoders. We present several experiments to demonstrate the
effectiveness of LegoNN models: a trained language generation LegoNN decoder
module from German-English (De-En) MT task can be reused without any
fine-tuning for the Europarl English ASR and the Romanian-English (Ro-En) MT
tasks, matching or beating the performance of baseline. After fine-tuning,
LegoNN models improve the Ro-En MT task by 1.5 BLEU points and achieve 12.5%
relative WER reduction on the Europarl ASR task. To show how the approach
generalizes, we compose a LegoNN ASR model from three modules -- each has been
learned within different end-to-end trained models on three different datasets
-- achieving an overall WER reduction of 19.5%.
","[{'version': 'v1', 'created': 'Tue, 7 Jun 2022 14:08:07 GMT'}, {'version': 'v2', 'created': 'Tue, 11 Jul 2023 17:43:57 GMT'}]",2023-07-12,"[['Dalmia', 'Siddharth', ''], ['Okhonko', 'Dmytro', ''], ['Lewis', 'Mike', ''], ['Edunov', 'Sergey', ''], ['Watanabe', 'Shinji', ''], ['Metze', 'Florian', ''], ['Zettlemoyer', 'Luke', ''], ['Mohamed', 'Abdelrahman', '']]"
1411.6718,Mohamed Aly,"Mahmoud Nabil, Mohamed Aly, Amir Atiya",LABR: A Large Scale Arabic Sentiment Analysis Benchmark,10 pages,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce LABR, the largest sentiment analysis dataset to-date for the
Arabic language. It consists of over 63,000 book reviews, each rated on a scale
of 1 to 5 stars. We investigate the properties of the dataset, and present its
statistics. We explore using the dataset for two tasks: (1) sentiment polarity
classification; and (2) ratings classification. Moreover, we provide standard
splits of the dataset into training, validation and testing, for both polarity
and ratings classification, in both balanced and unbalanced settings. We extend
our previous work by performing a comprehensive analysis on the dataset. In
particular, we perform an extended survey of the different classifiers
typically used for the sentiment polarity classification problem. We also
construct a sentiment lexicon from the dataset that contains both single and
compound sentiment words and we explore its effectiveness. We make the dataset
and experimental details publicly available.
","[{'version': 'v1', 'created': 'Tue, 25 Nov 2014 03:48:56 GMT'}, {'version': 'v2', 'created': 'Sun, 3 May 2015 08:35:59 GMT'}]",2015-05-05,"[['Nabil', 'Mahmoud', ''], ['Aly', 'Mohamed', ''], ['Atiya', 'Amir', '']]"
2401.04319,Junjie Wang,"Junjie Wang, Dan Yang, Binbin Hu, Yue Shen, Ziqi Liu, Wen Zhang,
  Jinjie Gu, Zhiqiang Zhang","Know Your Needs Better: Towards Structured Understanding of Marketer
  Demands with Analogical Reasoning Augmented LLMs",Under review,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we explore a new way for user targeting, where non-expert
marketers could select their target users solely given demands in natural
language form. The key to this issue is how to transform natural languages into
practical structured logical languages, i.e., the structured understanding of
marketer demands. Considering the impressive natural language processing
ability of large language models (LLMs), we try to leverage LLMs to solve this
issue. Past research indicates that the reasoning ability of LLMs can be
effectively enhanced through chain-of-thought (CoT) prompting. But existing
methods still have some limitations: (1) Previous methods either use simple
""Let's think step by step"" spells or provide fixed examples in demonstrations
without considering compatibility between prompts and questions, making LLMs
ineffective in some complex reasoning tasks such as structured language
transformation. (2) Previous methods are often implemented in closed-source
models or excessively large models, which is not suitable in industrial
practical scenarios. Based on these, we propose ARALLM (i.e., Analogical
Reasoning Augmented Large Language Models) consisting of two modules:
Analogical Reasoning based Prompting and Reasoning-Augmented Multi-Task Model
Distillation.
","[{'version': 'v1', 'created': 'Tue, 9 Jan 2024 02:25:23 GMT'}, {'version': 'v2', 'created': 'Wed, 7 Feb 2024 15:01:21 GMT'}]",2024-02-08,"[['Wang', 'Junjie', ''], ['Yang', 'Dan', ''], ['Hu', 'Binbin', ''], ['Shen', 'Yue', ''], ['Liu', 'Ziqi', ''], ['Zhang', 'Wen', ''], ['Gu', 'Jinjie', ''], ['Zhang', 'Zhiqiang', '']]"
2203.02385,Dou Hu,"Dou Hu, Xiaolong Hou, Lingwei Wei, Lianxin Jiang, Yang Mo","MM-DFN: Multimodal Dynamic Fusion Network for Emotion Recognition in
  Conversations",Accepted by ICASSP 2022,,,,cs.CL cs.AI cs.MM,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Emotion Recognition in Conversations (ERC) has considerable prospects for
developing empathetic machines. For multimodal ERC, it is vital to understand
context and fuse modality information in conversations. Recent graph-based
fusion methods generally aggregate multimodal information by exploring unimodal
and cross-modal interactions in a graph. However, they accumulate redundant
information at each layer, limiting the context understanding between
modalities. In this paper, we propose a novel Multimodal Dynamic Fusion Network
(MM-DFN) to recognize emotions by fully understanding multimodal conversational
context. Specifically, we design a new graph-based dynamic fusion module to
fuse multimodal contextual features in a conversation. The module reduces
redundancy and enhances complementarity between modalities by capturing the
dynamics of contextual information in different semantic spaces. Extensive
experiments on two public benchmark datasets demonstrate the effectiveness and
superiority of MM-DFN.
","[{'version': 'v1', 'created': 'Fri, 4 Mar 2022 15:42:53 GMT'}]",2022-03-07,"[['Hu', 'Dou', ''], ['Hou', 'Xiaolong', ''], ['Wei', 'Lingwei', ''], ['Jiang', 'Lianxin', ''], ['Mo', 'Yang', '']]"
2203.12865,Shaily Bhatt,"Karthikeyan K, Shaily Bhatt, Pankaj Singh, Somak Aditya, Sandipan
  Dandapat, Sunayana Sitaram, Monojit Choudhury",Multilingual CheckList: Generation and Evaluation,Accepted to Findings of AACL-IJCNLP 2022,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multilingual evaluation benchmarks usually contain limited high-resource
languages and do not test models for specific linguistic capabilities.
CheckList is a template-based evaluation approach that tests models for
specific capabilities. The CheckList template creation process requires native
speakers, posing a challenge in scaling to hundreds of languages. In this work,
we explore multiple approaches to generate Multilingual CheckLists. We device
an algorithm - Template Extraction Algorithm (TEA) for automatically extracting
target language CheckList templates from machine translated instances of a
source language templates. We compare the TEA CheckLists with CheckLists
created with different levels of human intervention. We further introduce
metrics along the dimensions of cost, diversity, utility, and correctness to
compare the CheckLists. We thoroughly analyze different approaches to creating
CheckLists in Hindi. Furthermore, we experiment with 9 more different
languages. We find that TEA followed by human verification is ideal for scaling
Checklist-based evaluation to multiple languages while TEA gives a good
estimates of model performance.
","[{'version': 'v1', 'created': 'Thu, 24 Mar 2022 06:05:28 GMT'}, {'version': 'v2', 'created': 'Wed, 30 Mar 2022 11:29:17 GMT'}, {'version': 'v3', 'created': 'Wed, 12 Oct 2022 03:43:20 GMT'}]",2022-10-13,"[['K', 'Karthikeyan', ''], ['Bhatt', 'Shaily', ''], ['Singh', 'Pankaj', ''], ['Aditya', 'Somak', ''], ['Dandapat', 'Sandipan', ''], ['Sitaram', 'Sunayana', ''], ['Choudhury', 'Monojit', '']]"
2011.15124,Emanuele Bugliarello,"Emanuele Bugliarello, Ryan Cotterell, Naoaki Okazaki, Desmond Elliott","Multimodal Pretraining Unmasked: A Meta-Analysis and a Unified Framework
  of Vision-and-Language BERTs",To appear in TACL 2021,,,,cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large-scale pretraining and task-specific fine-tuning is now the standard
methodology for many tasks in computer vision and natural language processing.
Recently, a multitude of methods have been proposed for pretraining vision and
language BERTs to tackle challenges at the intersection of these two key areas
of AI. These models can be categorised into either single-stream or dual-stream
encoders. We study the differences between these two categories, and show how
they can be unified under a single theoretical framework. We then conduct
controlled experiments to discern the empirical differences between five V&L
BERTs. Our experiments show that training data and hyperparameters are
responsible for most of the differences between the reported results, but they
also reveal that the embedding layer plays a crucial role in these massive
models.
","[{'version': 'v1', 'created': 'Mon, 30 Nov 2020 18:55:24 GMT'}, {'version': 'v2', 'created': 'Sun, 30 May 2021 23:37:58 GMT'}]",2021-06-01,"[['Bugliarello', 'Emanuele', ''], ['Cotterell', 'Ryan', ''], ['Okazaki', 'Naoaki', ''], ['Elliott', 'Desmond', '']]"
1504.07678,Hongzhao Huang,Hongzhao Huang and Larry Heck and Heng Ji,"Leveraging Deep Neural Networks and Knowledge Graphs for Entity
  Disambiguation",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Entity Disambiguation aims to link mentions of ambiguous entities to a
knowledge base (e.g., Wikipedia). Modeling topical coherence is crucial for
this task based on the assumption that information from the same semantic
context tends to belong to the same topic. This paper presents a novel deep
semantic relatedness model (DSRM) based on deep neural networks (DNN) and
semantic knowledge graphs (KGs) to measure entity semantic relatedness for
topical coherence modeling. The DSRM is directly trained on large-scale KGs and
it maps heterogeneous types of knowledge of an entity from KGs to numerical
feature vectors in a latent space such that the distance between two
semantically-related entities is minimized. Compared with the state-of-the-art
relatedness approach proposed by (Milne and Witten, 2008a), the DSRM obtains
19.4% and 24.5% reductions in entity disambiguation errors on two publicly
available datasets respectively.
","[{'version': 'v1', 'created': 'Tue, 28 Apr 2015 22:47:25 GMT'}]",2015-04-30,"[['Huang', 'Hongzhao', ''], ['Heck', 'Larry', ''], ['Ji', 'Heng', '']]"
2008.05750,Wenyong Huang,"Wenyong Huang, Wenchao Hu, Yu Ting Yeung, Xiao Chen","Conv-Transformer Transducer: Low Latency, Low Frame Rate, Streamable
  End-to-End Speech Recognition",Accepted by INTERSPEECH 2020,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transformer has achieved competitive performance against state-of-the-art
end-to-end models in automatic speech recognition (ASR), and requires
significantly less training time than RNN-based models. The original
Transformer, with encoder-decoder architecture, is only suitable for offline
ASR. It relies on an attention mechanism to learn alignments, and encodes input
audio bidirectionally. The high computation cost of Transformer decoding also
limits its use in production streaming systems. To make Transformer suitable
for streaming ASR, we explore Transducer framework as a streamable way to learn
alignments. For audio encoding, we apply unidirectional Transformer with
interleaved convolution layers. The interleaved convolution layers are used for
modeling future context which is important to performance. To reduce
computation cost, we gradually downsample acoustic input, also with the
interleaved convolution layers. Moreover, we limit the length of history
context in self-attention to maintain constant computation cost for each
decoding step. We show that this architecture, named Conv-Transformer
Transducer, achieves competitive performance on LibriSpeech dataset (3.6\% WER
on test-clean) without external language models. The performance is comparable
to previously published streamable Transformer Transducer and strong hybrid
streaming ASR systems, and is achieved with smaller look-ahead window (140~ms),
fewer parameters and lower frame rate.
","[{'version': 'v1', 'created': 'Thu, 13 Aug 2020 08:20:02 GMT'}]",2020-08-14,"[['Huang', 'Wenyong', ''], ['Hu', 'Wenchao', ''], ['Yeung', 'Yu Ting', ''], ['Chen', 'Xiao', '']]"
1705.04416,Joshua Peterson,"Dawn Chen, Joshua C. Peterson, Thomas L. Griffiths",Evaluating vector-space models of analogy,"6 pages, 4 figures, In the Proceedings of the 39th Annual Conference
  of the Cognitive Science Society",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Vector-space representations provide geometric tools for reasoning about the
similarity of a set of objects and their relationships. Recent machine learning
methods for deriving vector-space embeddings of words (e.g., word2vec) have
achieved considerable success in natural language processing. These vector
spaces have also been shown to exhibit a surprising capacity to capture verbal
analogies, with similar results for natural images, giving new life to a
classic model of analogies as parallelograms that was first proposed by
cognitive scientists. We evaluate the parallelogram model of analogy as applied
to modern word embeddings, providing a detailed analysis of the extent to which
this approach captures human relational similarity judgments in a large
benchmark dataset. We find that that some semantic relationships are better
captured than others. We then provide evidence for deeper limitations of the
parallelogram model based on the intrinsic geometric constraints of vector
spaces, paralleling classic results for first-order similarity.
","[{'version': 'v1', 'created': 'Fri, 12 May 2017 01:26:23 GMT'}, {'version': 'v2', 'created': 'Thu, 8 Jun 2017 20:52:12 GMT'}]",2017-06-12,"[['Chen', 'Dawn', ''], ['Peterson', 'Joshua C.', ''], ['Griffiths', 'Thomas L.', '']]"
2012.04584,Gautier Izacard,Gautier Izacard and Edouard Grave,Distilling Knowledge from Reader to Retriever for Question Answering,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The task of information retrieval is an important component of many natural
language processing systems, such as open domain question answering. While
traditional methods were based on hand-crafted features, continuous
representations based on neural networks recently obtained competitive results.
A challenge of using such methods is to obtain supervised data to train the
retriever model, corresponding to pairs of query and support documents. In this
paper, we propose a technique to learn retriever models for downstream tasks,
inspired by knowledge distillation, and which does not require annotated pairs
of query and documents. Our approach leverages attention scores of a reader
model, used to solve the task based on retrieved documents, to obtain synthetic
labels for the retriever. We evaluate our method on question answering,
obtaining state-of-the-art results.
","[{'version': 'v1', 'created': 'Tue, 8 Dec 2020 17:36:34 GMT'}, {'version': 'v2', 'created': 'Thu, 4 Aug 2022 17:36:08 GMT'}]",2022-08-05,"[['Izacard', 'Gautier', ''], ['Grave', 'Edouard', '']]"
2211.09458,Yifu Qiu,"Yifu Qiu, Shay B. Cohen","Abstractive Summarization Guided by Latent Hierarchical Document
  Structure","EMNLP 2022, 15 pages",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sequential abstractive neural summarizers often do not use the underlying
structure in the input article or dependencies between the input sentences.
This structure is essential to integrate and consolidate information from
different parts of the text. To address this shortcoming, we propose a
hierarchy-aware graph neural network (HierGNN) which captures such dependencies
through three main steps: 1) learning a hierarchical document structure through
a latent structure tree learned by a sparse matrix-tree computation; 2)
propagating sentence information over this structure using a novel
message-passing node propagation mechanism to identify salient information; 3)
using graph-level attention to concentrate the decoder on salient information.
Experiments confirm HierGNN improves strong sequence models such as BART, with
a 0.55 and 0.75 margin in average ROUGE-1/2/L for CNN/DM and XSum. Further
human evaluation demonstrates that summaries produced by our model are more
relevant and less redundant than the baselines, into which HierGNN is
incorporated. We also find HierGNN synthesizes summaries by fusing multiple
source sentences more, rather than compressing a single source sentence, and
that it processes long inputs more effectively.
","[{'version': 'v1', 'created': 'Thu, 17 Nov 2022 11:02:30 GMT'}]",2022-11-18,"[['Qiu', 'Yifu', ''], ['Cohen', 'Shay B.', '']]"
2402.10644,Nikita Balagansky,"Yaroslav Aksenov, Nikita Balagansky, Sofia Maria Lo Cicero Vaina,
  Boris Shaposhnikov, Alexey Gorbatovski, Daniil Gavrilov","Linear Transformers with Learnable Kernel Functions are Better
  In-Context Models",,,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Advancing the frontier of subquadratic architectures for Language Models
(LMs) is crucial in the rapidly evolving field of natural language processing.
Current innovations, including State Space Models, were initially celebrated
for surpassing Transformer performance on language modeling tasks. However,
these models have revealed deficiencies in essential In-Context Learning
capabilities - a domain where the Transformer traditionally shines. The Based
model emerged as a hybrid solution, blending a Linear Transformer with a kernel
inspired by the Taylor expansion of exponential functions, augmented by
convolutional networks. Mirroring the Transformer's in-context adeptness, it
became a strong contender in the field. In our work, we present a singular,
elegant alteration to the Based kernel that amplifies its In-Context Learning
abilities evaluated with the Multi-Query Associative Recall task and overall
language modeling process, as demonstrated on the Pile dataset.
","[{'version': 'v1', 'created': 'Fri, 16 Feb 2024 12:44:15 GMT'}]",2024-02-19,"[['Aksenov', 'Yaroslav', ''], ['Balagansky', 'Nikita', ''], ['Vaina', 'Sofia Maria Lo Cicero', ''], ['Shaposhnikov', 'Boris', ''], ['Gorbatovski', 'Alexey', ''], ['Gavrilov', 'Daniil', '']]"
2312.16682,Jason Weston,"Jing Xu, Andrew Lee, Sainbayar Sukhbaatar, Jason Weston","Some things are more CRINGE than others: Preference Optimization with
  the Pairwise Cringe Loss",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Practitioners commonly align large language models using pairwise
preferences, i.e., given labels of the type response A is preferred to response
B for a given input. Perhaps less commonly, methods have also been developed
for binary feedback, i.e. training models given labels of type response A is
good or bad. We show how an existing performant binary feedback method, the
Cringe Loss (Adolphs et al., 2022), can be generalized to the pairwise
preference setting using a simple soft margin extension. Pairwise Cringe Loss
is straightforward to implement and efficient to train, and we find it
outperforms state-of-the-art preference optimization algorithms such as PPO and
DPO on the AlpacaFarm benchmark.
","[{'version': 'v1', 'created': 'Wed, 27 Dec 2023 18:53:09 GMT'}]",2023-12-29,"[['Xu', 'Jing', ''], ['Lee', 'Andrew', ''], ['Sukhbaatar', 'Sainbayar', ''], ['Weston', 'Jason', '']]"
1909.12208,C\u{a}t\u{a}lin Zoril\u{a},"Catalin Zorila, Christoph Boeddeker, Rama Doddipatla and Reinhold
  Haeb-Umbach","An Investigation into the Effectiveness of Enhancement in ASR Training
  and Test for CHiME-5 Dinner Party Transcription",Accepted for ASRU 2019,,,,cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the strong modeling power of neural network acoustic models, speech
enhancement has been shown to deliver additional word error rate improvements
if multi-channel data is available. However, there has been a longstanding
debate whether enhancement should also be carried out on the ASR training data.
In an extensive experimental evaluation on the acoustically very challenging
CHiME-5 dinner party data we show that: (i) cleaning up the training data can
lead to substantial error rate reductions, and (ii) enhancement in training is
advisable as long as enhancement in test is at least as strong as in training.
This approach stands in contrast and delivers larger gains than the common
strategy reported in the literature to augment the training database with
additional artificially degraded speech. Together with an acoustic model
topology consisting of initial CNN layers followed by factorized TDNN layers we
achieve with 41.6% and 43.2% WER on the DEV and EVAL test sets, respectively, a
new single-system state-of-the-art result on the CHiME-5 data. This is a 8%
relative improvement compared to the best word error rate published so far for
a speech recognizer without system combination.
","[{'version': 'v1', 'created': 'Thu, 26 Sep 2019 15:59:37 GMT'}]",2019-09-27,"[['Zorila', 'Catalin', ''], ['Boeddeker', 'Christoph', ''], ['Doddipatla', 'Rama', ''], ['Haeb-Umbach', 'Reinhold', '']]"
2306.17020,Haoxuan Xu,"Haoxuan Xu, Zeyu He, Mengfan Shen, Songning Lai, Ziqiang Han and Yifan
  Peng",Classifying Crime Types using Judgment Documents from Social Media,"The paper has no errors; it just needs to be supplemented to become a
  new article",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The task of determining crime types based on criminal behavior facts has
become a very important and meaningful task in social science. But the problem
facing the field now is that the data samples themselves are unevenly
distributed, due to the nature of the crime itself. At the same time, data sets
in the judicial field are less publicly available, and it is not practical to
produce large data sets for direct training. This article proposes a new
training model to solve this problem through NLP processing methods. We first
propose a Crime Fact Data Preprocessing Module (CFDPM), which can balance the
defects of uneven data set distribution by generating new samples. Then we use
a large open source dataset (CAIL-big) as our pretraining dataset and a small
dataset collected by ourselves for Fine-tuning, giving it good generalization
ability to unfamiliar small datasets. At the same time, we use the improved
Bert model with dynamic masking to improve the model. Experiments show that the
proposed method achieves state-of-the-art results on the present dataset. At
the same time, the effectiveness of module CFDPM is proved by experiments. This
article provides a valuable methodology contribution for classifying social
science texts such as criminal behaviors. Extensive experiments on public
benchmarks show that the proposed method achieves new state-of-the-art results.
","[{'version': 'v1', 'created': 'Thu, 29 Jun 2023 15:12:24 GMT'}, {'version': 'v2', 'created': 'Sat, 21 Oct 2023 14:44:41 GMT'}]",2023-10-24,"[['Xu', 'Haoxuan', ''], ['He', 'Zeyu', ''], ['Shen', 'Mengfan', ''], ['Lai', 'Songning', ''], ['Han', 'Ziqiang', ''], ['Peng', 'Yifan', '']]"
2402.12326,Qisen Yang,"Qisen Yang, Zekun Wang, Honghui Chen, Shenzhi Wang, Yifan Pu, Xin Gao,
  Wenhao Huang, Shiji Song, Gao Huang",LLM Agents for Psychology: A Study on Gamified Assessments,,,,,cs.CL cs.CY cs.HC cs.LG cs.MA,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Psychological measurement is essential for mental health, self-understanding,
and personal development. Traditional methods, such as self-report scales and
psychologist interviews, often face challenges with engagement and
accessibility. While game-based and LLM-based tools have been explored to
improve user interest and automate assessment, they struggle to balance
engagement with generalizability. In this work, we propose PsychoGAT
(Psychological Game AgenTs) to achieve a generic gamification of psychological
assessment. The main insight is that powerful LLMs can function both as adept
psychologists and innovative game designers. By incorporating LLM agents into
designated roles and carefully managing their interactions, PsychoGAT can
transform any standardized scales into personalized and engaging interactive
fiction games. To validate the proposed method, we conduct psychometric
evaluations to assess its effectiveness and employ human evaluators to examine
the generated content across various psychological constructs, including
depression, cognitive distortions, and personality traits. Results demonstrate
that PsychoGAT serves as an effective assessment tool, achieving statistically
significant excellence in psychometric metrics such as reliability, convergent
validity, and discriminant validity. Moreover, human evaluations confirm
PsychoGAT's enhancements in content coherence, interactivity, interest,
immersion, and satisfaction.
","[{'version': 'v1', 'created': 'Mon, 19 Feb 2024 18:00:30 GMT'}]",2024-02-20,"[['Yang', 'Qisen', ''], ['Wang', 'Zekun', ''], ['Chen', 'Honghui', ''], ['Wang', 'Shenzhi', ''], ['Pu', 'Yifan', ''], ['Gao', 'Xin', ''], ['Huang', 'Wenhao', ''], ['Song', 'Shiji', ''], ['Huang', 'Gao', '']]"
2301.00836,Vishweshwar Dixit,Vishweshwar V. Dixit,Kannudi -- A Reference Editor for Kannada,"7 pages, 2 figures, 4 tables",,,,cs.HC cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Kannudi is a reference editor for Kannada based on OPOK! and OHOK!
principles, and domain knowledge. It introduces a method of input for Kannada,
called OHOK!, that is, Ottu Haku Ottu Kodu! (apply pressure and give ottu).
This is especially suited for pressure sensitive input devices, though the
current online implementation uses the regular mechanical keyboard. OHOK! has
three possible modes, namely, sva-ottu (self-conjunct), kandante (as you see),
and andante (as you say). It may be noted that kandante mode does not follow
the phonetic order. However, this mode may work well for those who are inclined
to visualize as they type rather than vocalizing the sounds.
  Kannudi also demonstrates how domain knowledge can be effectively used to
potentially increase speed, accuracy, and user friendliness. For example,
selection of a default vowel, automatic shunyification, and arkification. Also
implemented are four types Deletes that are necessary for phono-syllabic
languages like Kannada.
","[{'version': 'v1', 'created': 'Sat, 24 Dec 2022 01:40:56 GMT'}]",2023-01-04,"[['Dixit', 'Vishweshwar V.', '']]"
2312.02590,Tanmay Chavan,Tanmay Chavan and Ved Patwardhan,Text Intimacy Analysis using Ensembles of Multilingual Transformers,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Intimacy estimation of a given text has recently gained importance due to the
increase in direct interaction of NLP systems with humans. Intimacy is an
important aspect of natural language and has a substantial impact on our
everyday communication. Thus the level of intimacy can provide us with deeper
insights and richer semantics of conversations. In this paper, we present our
work on the SemEval shared task 9 on predicting the level of intimacy for the
given text. The dataset consists of tweets in ten languages, out of which only
six are available in the training dataset. We conduct several experiments and
show that an ensemble of multilingual models along with a language-specific
monolingual model has the best performance. We also evaluate other data
augmentation methods such as translation and present the results. Lastly, we
study the results thoroughly and present some noteworthy insights into this
problem.
","[{'version': 'v1', 'created': 'Tue, 5 Dec 2023 09:04:22 GMT'}]",2023-12-06,"[['Chavan', 'Tanmay', ''], ['Patwardhan', 'Ved', '']]"
2306.06598,Andrei-Marius Avram,"Iulian-Marius T\u{a}iatu, Andrei-Marius Avram, Dumitru-Clementin
  Cercel and Florin Pop",RoBERTweet: A BERT Language Model for Romanian Tweets,Accepted at NLDB2023,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Developing natural language processing (NLP) systems for social media
analysis remains an important topic in artificial intelligence research. This
article introduces RoBERTweet, the first Transformer architecture trained on
Romanian tweets. Our RoBERTweet comes in two versions, following the base and
large architectures of BERT. The corpus used for pre-training the models
represents a novelty for the Romanian NLP community and consists of all tweets
collected from 2008 to 2022. Experiments show that RoBERTweet models outperform
the previous general-domain Romanian and multilingual language models on three
NLP tasks with tweet inputs: emotion detection, sexist language identification,
and named entity recognition. We make our models and the newly created corpus
of Romanian tweets freely available.
","[{'version': 'v1', 'created': 'Sun, 11 Jun 2023 06:11:56 GMT'}]",2023-06-13,"[['Tăiatu', 'Iulian-Marius', ''], ['Avram', 'Andrei-Marius', ''], ['Cercel', 'Dumitru-Clementin', ''], ['Pop', 'Florin', '']]"
2309.12646,Chen-Wei Yu,"Chen-Wei Yu, Yun-Shiuan Chuang, Alexandros N. Lotsos, and Claudia M.
  Haase","Decoding Emotional Experiences in Dyadic Conversations of Married
  Couples: Leveraging Semantic Similarity through Sentence Embedding",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent advancements in Natural Language Processing (NLP) have highlighted the
potential of sentence embeddings in measuring semantic similarity (hereafter
similarity). Yet, whether this approach can be used to analyze real-world
dyadic interactions and predict people's emotional experiences in response to
these interactions remains largely uncharted. To bridge this gap, the present
study analyzes verbal conversations of 50 married couples who engage in
naturalistic 10-minute conflict and 10-minute positive conversations.
Transformer-based model General Text Embeddings-Large is employed to obtain the
embeddings of the utterances from each speaker. The overall similarity of the
conversations is then quantified by the average cosine similarity between the
embeddings of adjacent utterances. Results show that lower similarity is
associated with greater positive emotional experiences in the positive (but not
conflict) conversation. Follow-up analyses show that (a) findings remain stable
when controlling for marital satisfaction and the number of utterance pairs and
(b) the similarity measure is valid in capturing critical features of a dyadic
conversation. The present study underscores the potency of sentence embeddings
in understanding links between interpersonal dynamics and individual emotional
experiences, paving the way for innovative applications of NLP tools in
affective and relationship science.
","[{'version': 'v1', 'created': 'Fri, 22 Sep 2023 06:37:45 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Feb 2024 19:43:20 GMT'}]",2024-02-27,"[['Yu', 'Chen-Wei', ''], ['Chuang', 'Yun-Shiuan', ''], ['Lotsos', 'Alexandros N.', ''], ['Haase', 'Claudia M.', '']]"
2010.10439,Wenhu Chen,"Wenhu Chen, Ming-Wei Chang, Eva Schlinger, William Wang, William W.
  Cohen",Open Question Answering over Tables and Text,Accepted to ICLR 2021. Main paper has 9 pages,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In open question answering (QA), the answer to a question is produced by
retrieving and then analyzing documents that might contain answers to the
question. Most open QA systems have considered only retrieving information from
unstructured text. Here we consider for the first time open QA over both
tabular and textual data and present a new large-scale dataset Open
Table-and-Text Question Answering (OTT-QA) to evaluate performance on this
task. Most questions in OTT-QA require multi-hop inference across tabular data
and unstructured text, and the evidence required to answer a question can be
distributed in different ways over these two types of input, making evidence
retrieval challenging -- our baseline model using an iterative retriever and
BERT-based reader achieves an exact match score less than 10%. We then propose
two novel techniques to address the challenge of retrieving and aggregating
evidence for OTT-QA. The first technique is to use ""early fusion"" to group
multiple highly relevant tabular and textual units into a fused block, which
provides more context for the retriever to search for. The second technique is
to use a cross-block reader to model the cross-dependency between multiple
retrieved evidence with global-local sparse attention. Combining these two
techniques improves the score significantly, to above 27%.
","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 16:48:14 GMT'}, {'version': 'v2', 'created': 'Wed, 10 Feb 2021 08:21:18 GMT'}]",2021-02-11,"[['Chen', 'Wenhu', ''], ['Chang', 'Ming-Wei', ''], ['Schlinger', 'Eva', ''], ['Wang', 'William', ''], ['Cohen', 'William W.', '']]"
2401.06837,Parag Jain,"Parag Jain, Andreea Marzoca, Francesco Piccinno",Structsum Generation for Faster Text Comprehension,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  We consider the task of generating structured representations of text using
large language models (LLMs). We focus on tables and mind maps as
representative modalities. Tables are more organized way of representing data,
while mind maps provide a visually dynamic and flexible approach, particularly
suitable for sparse content. Despite the effectiveness of LLMs on different
tasks, we show that current models struggle with generating structured outputs.
In response, we present effective prompting strategies for both of these tasks.
We introduce a taxonomy of problems around factuality, global and local
structure, common to both modalities and propose a set of critiques to tackle
these issues resulting in an absolute improvement in accuracy of +37pp (79%)
for mind maps and +15pp (78%) for tables. To evaluate semantic coverage of
generated structured representations we propose Auto-QA, and we verify the
adequacy of Auto-QA using SQuAD dataset. We further evaluate the usefulness of
structured representations via a text comprehension user study. The results
show a significant reduction in comprehension time compared to text when using
table (42.9%) and mind map (31.9%), without loss in accuracy.
","[{'version': 'v1', 'created': 'Fri, 12 Jan 2024 17:43:51 GMT'}]",2024-01-17,"[['Jain', 'Parag', ''], ['Marzoca', 'Andreea', ''], ['Piccinno', 'Francesco', '']]"
1307.6235,Anindya Kumar Biswas,Anindya Kumar Biswas,Graphical law beneath each written natural language,"107 pages, 35 figures, all tables given. all Bethe-Peierls curves for
  $\gamma$ not equal to four replaced",,,,physics.gen-ph cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We study twenty four written natural languages. We draw in the log scale,
number of words starting with a letter vs rank of the letter, both normalised.
We find that all the graphs are of the similar type. The graphs are
tantalisingly closer to the curves of reduced magnetisation vs reduced
temperature for magnetic materials. We make a weak conjecture that a curve of
magnetisation underlies a written natural language.
","[{'version': 'v1', 'created': 'Thu, 18 Jul 2013 11:03:14 GMT'}, {'version': 'v2', 'created': 'Fri, 26 Jul 2013 17:39:34 GMT'}, {'version': 'v3', 'created': 'Tue, 13 Aug 2013 04:16:23 GMT'}, {'version': 'v4', 'created': 'Tue, 8 Oct 2013 11:33:38 GMT'}, {'version': 'v5', 'created': 'Tue, 21 Jan 2020 06:54:26 GMT'}]",2020-01-22,"[['Biswas', 'Anindya Kumar', '']]"
2209.08207,Sabit Hassan,"Katherine Atwell, Sabit Hassan, Malihe Alikhani","APPDIA: A Discourse-aware Transformer-based Style Transfer Model for
  Offensive Social Media Conversations","To be published in Proceedings of COLING 2022, the 29th International
  Conference on Computational Linguistics",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Using style-transfer models to reduce offensiveness of social media comments
can help foster a more inclusive environment. However, there are no sizable
datasets that contain offensive texts and their inoffensive counterparts, and
fine-tuning pretrained models with limited labeled data can lead to the loss of
original meaning in the style-transferred text. To address this issue, we
provide two major contributions. First, we release the first
publicly-available, parallel corpus of offensive Reddit comments and their
style-transferred counterparts annotated by expert sociolinguists. Then, we
introduce the first discourse-aware style-transfer models that can effectively
reduce offensiveness in Reddit text while preserving the meaning of the
original text. These models are the first to examine inferential links between
the comment and the text it is replying to when transferring the style of
offensive Reddit text. We propose two different methods of integrating
discourse relations with pretrained transformer models and evaluate them on our
dataset of offensive comments from Reddit and their inoffensive counterparts.
Improvements over the baseline with respect to both automatic metrics and human
evaluation indicate that our discourse-aware models are better at preserving
meaning in style-transferred text when compared to the state-of-the-art
discourse-agnostic models.
","[{'version': 'v1', 'created': 'Sat, 17 Sep 2022 00:50:24 GMT'}]",2022-09-20,"[['Atwell', 'Katherine', ''], ['Hassan', 'Sabit', ''], ['Alikhani', 'Malihe', '']]"
2210.12321,Adam Wiemerslage,Adam Wiemerslage and Shiran Dudy and Katharina Kann,"A Comprehensive Comparison of Neural Networks as Cognitive Models of
  Inflection",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Neural networks have long been at the center of a debate around the cognitive
mechanism by which humans process inflectional morphology. This debate has
gravitated into NLP by way of the question: Are neural networks a feasible
account for human behavior in morphological inflection? We address that
question by measuring the correlation between human judgments and neural
network probabilities for unknown word inflections. We test a larger range of
architectures than previously studied on two important tasks for the cognitive
processing debate: English past tense, and German number inflection. We find
evidence that the Transformer may be a better account of human behavior than
LSTMs on these datasets, and that LSTM features known to increase inflection
accuracy do not always result in more human-like behavior.
","[{'version': 'v1', 'created': 'Sat, 22 Oct 2022 00:59:40 GMT'}]",2022-10-25,"[['Wiemerslage', 'Adam', ''], ['Dudy', 'Shiran', ''], ['Kann', 'Katharina', '']]"
2402.16914,Xirui Li,"Xirui Li, Ruochen Wang, Minhao Cheng, Tianyi Zhou, Cho-Jui Hsieh","DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM
  Jailbreakers",,,,,cs.CR cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The safety alignment of Large Language Models (LLMs) is vulnerable to both
manual and automated jailbreak attacks, which adversarially trigger LLMs to
output harmful content. However, current methods for jailbreaking LLMs, which
nest entire harmful prompts, are not effective at concealing malicious intent
and can be easily identified and rejected by well-aligned LLMs. This paper
discovers that decomposing a malicious prompt into separated sub-prompts can
effectively obscure its underlying malicious intent by presenting it in a
fragmented, less detectable form, thereby addressing these limitations. We
introduce an automatic prompt \textbf{D}ecomposition and
\textbf{R}econstruction framework for jailbreak \textbf{Attack} (DrAttack).
DrAttack includes three key components: (a) `Decomposition' of the original
prompt into sub-prompts, (b) `Reconstruction' of these sub-prompts implicitly
by in-context learning with semantically similar but harmless reassembling
demo, and (c) a `Synonym Search' of sub-prompts, aiming to find sub-prompts'
synonyms that maintain the original intent while jailbreaking LLMs. An
extensive empirical study across multiple open-source and closed-source LLMs
demonstrates that, with a significantly reduced number of queries, DrAttack
obtains a substantial gain of success rate over prior SOTA prompt-only
attackers. Notably, the success rate of 78.0\% on GPT-4 with merely 15 queries
surpassed previous art by 33.1\%. The project is available at
https://github.com/xirui-li/DrAttack.
","[{'version': 'v1', 'created': 'Sun, 25 Feb 2024 17:43:29 GMT'}, {'version': 'v2', 'created': 'Fri, 1 Mar 2024 07:26:50 GMT'}]",2024-03-04,"[['Li', 'Xirui', ''], ['Wang', 'Ruochen', ''], ['Cheng', 'Minhao', ''], ['Zhou', 'Tianyi', ''], ['Hsieh', 'Cho-Jui', '']]"
2107.07940,Wenliang Chen,"Pengju Zhang, Yonghui Jia, Muhua Zhu, Wenliang Chen, Min Zhang",Exploiting Rich Syntax for Better Knowledge Base Question Answering,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent studies on Knowledge Base Question Answering (KBQA) have shown great
progress on this task via better question understanding. Previous works for
encoding questions mainly focus on the word sequences, but seldom consider the
information from syntactic trees.In this paper, we propose an approach to learn
syntax-based representations for KBQA. First, we encode path-based syntax by
considering the shortest dependency paths between keywords. Then, we propose
two encoding strategies to mode the information of whole syntactic trees to
obtain tree-based syntax. Finally, we combine both path-based and tree-based
syntax representations for KBQA. We conduct extensive experiments on a widely
used benchmark dataset and the experimental results show that our syntax-aware
systems can make full use of syntax information in different settings and
achieve state-of-the-art performance of KBQA.
","[{'version': 'v1', 'created': 'Fri, 16 Jul 2021 14:59:05 GMT'}]",2021-07-19,"[['Zhang', 'Pengju', ''], ['Jia', 'Yonghui', ''], ['Zhu', 'Muhua', ''], ['Chen', 'Wenliang', ''], ['Zhang', 'Min', '']]"
1911.03743,Homagni Saha,"Homagni Saha, Vijay Venkataraman, Alberto Speranzon, Soumik Sarkar",A perspective on multi-agent communication for information fusion,"NeuRIPS 2019, Workshop on Visually Grounded Interaction and Language,
  Vancouver, CA",,,,cs.MA cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Collaborative decision making in multi-agent systems typically requires a
predefined communication protocol among agents. Usually, agent-level
observations are locally processed and information is exchanged using the
predefined protocol, enabling the team to perform more efficiently than each
agent operating in isolation. In this work, we consider the situation where
agents, with complementary sensing modalities must co-operate to achieve a
common goal/task by learning an efficient communication protocol. We frame the
problem within an actor-critic scheme, where the agents learn optimal policies
in a centralized fashion, while taking action in a distributed manner. We
provide an interpretation of the emergent communication between the agents. We
observe that the information exchanged is not just an encoding of the raw
sensor data but is, rather, a specific set of directive actions that depend on
the overall task. Simulation results demonstrate the interpretability of the
learnt communication in a variety of tasks.
","[{'version': 'v1', 'created': 'Sat, 9 Nov 2019 17:56:47 GMT'}]",2019-11-12,"[['Saha', 'Homagni', ''], ['Venkataraman', 'Vijay', ''], ['Speranzon', 'Alberto', ''], ['Sarkar', 'Soumik', '']]"
2309.14519,Umer Farooq,"Umer Farooq, Saira Anwar","ChatGPT Performance on Standardized Testing Exam -- A Proposed Strategy
  for Learners",,,,,cs.CY cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This study explores the problem solving capabilities of ChatGPT and its
prospective applications in standardized test preparation, focusing on the GRE
quantitative exam. Prior research has shown great potential for the utilization
of ChatGPT for academic purposes in revolutionizing the approach to studying
across various disciplines. We investigate how ChatGPT performs across various
question types in the GRE quantitative domain, and how modifying question
prompts impacts its accuracy. More specifically this study addressed two
research questions: 1. How does ChatGPT perform in answering GRE-based
quantitative questions across various content areas? 2. How does the accuracy
of ChatGPT vary with modifying the question prompts? The dataset consisting of
100 randomly selected GRE quantitative questions was collected from the ETS
official guide to GRE test preparation. We used quantitative evaluation to
answer our first research question, and t-test to examine the statistical
association between prompt modification and ChatGPT's accuracy. Results show a
statistical improvement in the ChatGPT's accuracy after applying instruction
priming and contextual prompts to the original questions. ChatGPT showed 84%
accuracy with the modified prompts compared to 69% with the original data. The
study discusses the areas where ChatGPT struggled with certain questions and
how modifications can be helpful for preparing for standardized tests like GRE
and provides future directions for prompt modifications.
","[{'version': 'v1', 'created': 'Mon, 25 Sep 2023 20:25:29 GMT'}]",2023-09-27,"[['Farooq', 'Umer', ''], ['Anwar', 'Saira', '']]"
2112.09467,P{\i}nar Baki,P{\i}nar Baki,A Multimodal Approach for Automatic Mania Assessment in Bipolar Disorder,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Bipolar disorder is a mental health disorder that causes mood swings that
range from depression to mania. Diagnosis of bipolar disorder is usually done
based on patient interviews, and reports obtained from the caregivers of the
patients. Subsequently, the diagnosis depends on the experience of the expert,
and it is possible to have confusions of the disorder with other mental
disorders. Automated processes in the diagnosis of bipolar disorder can help
providing quantitative indicators, and allow easier observations of the
patients for longer periods. Furthermore, the need for remote treatment and
diagnosis became especially important during the COVID-19 pandemic. In this
thesis, we create a multimodal decision system based on recordings of the
patient in acoustic, linguistic, and visual modalities. The system is trained
on the Bipolar Disorder corpus. Comprehensive analysis of unimodal and
multimodal systems, as well as various fusion techniques are performed. Besides
processing entire patient sessions using unimodal features, a task-level
investigation of the clips is studied. Using acoustic, linguistic, and visual
features in a multimodal fusion system, we achieved a 64.8% unweighted average
recall score, which improves the state-of-the-art performance achieved on this
dataset.
","[{'version': 'v1', 'created': 'Fri, 17 Dec 2021 12:09:01 GMT'}]",2021-12-20,"[['Baki', 'Pınar', '']]"
2304.07396,Daniel Kapitan,"Danny M. den Hamer, Perry Schoor, Tobias B. Polak and Daniel Kapitan","Improving Patient Pre-screening for Clinical Trials: Assisting
  Physicians with Large Language Models","11 pages, 4 tables, 2 figures",,,,cs.LG cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Physicians considering clinical trials for their patients are met with the
laborious process of checking many text based eligibility criteria. Large
Language Models (LLMs) have shown to perform well for clinical information
extraction and clinical reasoning, including medical tests, but not yet in
real-world scenarios. This paper investigates the use of InstructGPT to assist
physicians in determining eligibility for clinical trials based on a patient's
summarised medical profile. Using a prompting strategy combining one-shot,
selection-inference and chain-of-thought techniques, we investigate the
performance of LLMs on 10 synthetically created patient profiles. Performance
is evaluated at four levels: ability to identify screenable eligibility
criteria from a trial given a medical profile; ability to classify for each
individual criterion whether the patient qualifies; the overall classification
whether a patient is eligible for a clinical trial and the percentage of
criteria to be screened by physician. We evaluated against 146 clinical trials
and a total of 4,135 eligibility criteria. The LLM was able to correctly
identify the screenability of 72% (2,994/4,135) of the criteria. Additionally,
72% (341/471) of the screenable criteria were evaluated correctly. The
resulting trial level classification as eligible or ineligible resulted in a
recall of 0.5. By leveraging LLMs with a physician-in-the-loop, a recall of 1.0
and precision of 0.71 on clinical trial level can be achieved while reducing
the amount of criteria to be checked by an estimated 90%. LLMs can be used to
assist physicians with pre-screening of patients for clinical trials. By
forcing instruction-tuned LLMs to produce chain-of-thought responses, the
reasoning can be made transparent to and the decision process becomes amenable
by physicians, thereby making such a system feasible for use in real-world
scenarios.
","[{'version': 'v1', 'created': 'Fri, 14 Apr 2023 21:19:46 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Jun 2023 12:59:16 GMT'}]",2023-06-30,"[['Hamer', 'Danny M. den', ''], ['Schoor', 'Perry', ''], ['Polak', 'Tobias B.', ''], ['Kapitan', 'Daniel', '']]"
2010.10820,Chan Young Park,"Chan Young Park, Xinru Yan, Anjalie Field, Yulia Tsvetkov","Multilingual Contextual Affective Analysis of LGBT People Portrayals in
  Wikipedia",ICWSM 2021,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Specific lexical choices in narrative text reflect both the writer's
attitudes towards people in the narrative and influence the audience's
reactions. Prior work has examined descriptions of people in English using
contextual affective analysis, a natural language processing (NLP) technique
that seeks to analyze how people are portrayed along dimensions of power,
agency, and sentiment. Our work presents an extension of this methodology to
multilingual settings, which is enabled by a new corpus that we collect and a
new multilingual model. We additionally show how word connotations differ
across languages and cultures, highlighting the difficulty of generalizing
existing English datasets and methods. We then demonstrate the usefulness of
our method by analyzing Wikipedia biography pages of members of the LGBT
community across three languages: English, Russian, and Spanish. Our results
show systematic differences in how the LGBT community is portrayed across
languages, surfacing cultural differences in narratives and signs of social
biases. Practically, this model can be used to identify Wikipedia articles for
further manual analysis -- articles that might contain content gaps or an
imbalanced representation of particular social groups.
","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 08:27:36 GMT'}, {'version': 'v2', 'created': 'Thu, 8 Apr 2021 08:20:12 GMT'}]",2021-04-09,"[['Park', 'Chan Young', ''], ['Yan', 'Xinru', ''], ['Field', 'Anjalie', ''], ['Tsvetkov', 'Yulia', '']]"
2203.03584,Hadi Mansourifar,"Dana Alsagheer, Hadi Mansourifar, Weidong Shi",Counter Hate Speech in Social Media: A Survey,"arXiv admin note: text overlap with arXiv:1909.04251,
  arXiv:2009.08392, arXiv:2006.01974, arXiv:2004.04216, arXiv:1812.02712 by
  other authors",,,,cs.CL,http://creativecommons.org/publicdomain/zero/1.0/,"  With the high prevalence of offensive language against minorities in social
media, counter-hate speeches (CHS) generation is considered an automatic way of
tackling this challenge. The CHS is supposed to appear as a third voice to
educate people and keep the social [red lines bold] without limiting the
principles of freedom of speech. In this paper, we review the most important
research in the past and present with a main focus on methodologies, collected
datasets and statistical analysis CHS's impact on social media. The CHS
generation is based on the optimistic assumption that any attempt to intervene
the hate speech in social media can play a positive role in this context.
Beyond that, previous works ignored the investigation of the sequence of
comments before and after the CHS. However, the positive impact is not
guaranteed, as shown in some previous works. To the best of our knowledge, no
attempt has been made to survey the related work to compare the past research
in terms of CHS's impact on social media. We take the first step in this
direction by providing a comprehensive review on related works and categorizing
them based on different factors including impact, methodology, data source,
etc.
","[{'version': 'v1', 'created': 'Mon, 21 Feb 2022 06:16:46 GMT'}]",2022-03-08,"[['Alsagheer', 'Dana', ''], ['Mansourifar', 'Hadi', ''], ['Shi', 'Weidong', '']]"
2402.13449,Zexue He,"Zexue He, Leonid Karlinsky, Donghyun Kim, Julian McAuley, Dmitry
  Krotov, Rogerio Feris","CAMELoT: Towards Large Language Models with Training-Free Consolidated
  Associative Memory",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) struggle to handle long input sequences due to
high memory and runtime costs. Memory-augmented models have emerged as a
promising solution to this problem, but current methods are hindered by limited
memory capacity and require costly re-training to integrate with a new LLM. In
this work, we introduce an associative memory module which can be coupled to
any pre-trained (frozen) attention-based LLM without re-training, enabling it
to handle arbitrarily long input sequences. Unlike previous methods, our
associative memory module consolidates representations of individual tokens
into a non-parametric distribution model, dynamically managed by properly
balancing the novelty and recency of the incoming data. By retrieving
information from this consolidated associative memory, the base LLM can achieve
significant (up to 29.7% on Arxiv) perplexity reduction in long-context
modeling compared to other baselines evaluated on standard benchmarks. This
architecture, which we call CAMELoT (Consolidated Associative Memory Enhanced
Long Transformer), demonstrates superior performance even with a tiny context
window of 128 tokens, and also enables improved in-context learning with a much
larger set of demonstrations.
","[{'version': 'v1', 'created': 'Wed, 21 Feb 2024 01:00:17 GMT'}]",2024-02-22,"[['He', 'Zexue', ''], ['Karlinsky', 'Leonid', ''], ['Kim', 'Donghyun', ''], ['McAuley', 'Julian', ''], ['Krotov', 'Dmitry', ''], ['Feris', 'Rogerio', '']]"
2312.04965,Ziqiao Ma,"Sihan Xu, Yidong Huang, Jiayi Pan, Ziqiao Ma, Joyce Chai",Inversion-Free Image Editing with Natural Language,Project Page: https://sled-group.github.io/InfEdit/,,,,cs.CV cs.AI cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Despite recent advances in inversion-based editing, text-guided image
manipulation remains challenging for diffusion models. The primary bottlenecks
include 1) the time-consuming nature of the inversion process; 2) the struggle
to balance consistency with accuracy; 3) the lack of compatibility with
efficient consistency sampling methods used in consistency models. To address
the above issues, we start by asking ourselves if the inversion process can be
eliminated for editing. We show that when the initial sample is known, a
special variance schedule reduces the denoising step to the same form as the
multi-step consistency sampling. We name this Denoising Diffusion Consistent
Model (DDCM), and note that it implies a virtual inversion strategy without
explicit inversion in sampling. We further unify the attention control
mechanisms in a tuning-free framework for text-guided editing. Combining them,
we present inversion-free editing (InfEdit), which allows for consistent and
faithful editing for both rigid and non-rigid semantic changes, catering to
intricate modifications without compromising on the image's integrity and
explicit inversion. Through extensive experiments, InfEdit shows strong
performance in various editing tasks and also maintains a seamless workflow
(less than 3 seconds on one single A40), demonstrating the potential for
real-time applications. Project Page: https://sled-group.github.io/InfEdit/
","[{'version': 'v1', 'created': 'Thu, 7 Dec 2023 18:58:27 GMT'}]",2023-12-11,"[['Xu', 'Sihan', ''], ['Huang', 'Yidong', ''], ['Pan', 'Jiayi', ''], ['Ma', 'Ziqiao', ''], ['Chai', 'Joyce', '']]"
1909.09428,Chris Dyer,"Chris Dyer, G\'abor Melis, Phil Blunsom",A Critical Analysis of Biased Parsers in Unsupervised Parsing,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A series of recent papers has used a parsing algorithm due to Shen et al.
(2018) to recover phrase-structure trees based on proxies for ""syntactic
depth."" These proxy depths are obtained from the representations learned by
recurrent language models augmented with mechanisms that encourage the
(unsupervised) discovery of hierarchical structure latent in natural language
sentences. Using the same parser, we show that proxies derived from a
conventional LSTM language model produce trees comparably well to the
specialized architectures used in previous work. However, we also provide a
detailed analysis of the parsing algorithm, showing (1) that it is
incomplete---that is, it can recover only a fraction of possible trees---and
(2) that it has a marked bias for right-branching structures which results in
inflated performance in right-branching languages like English. Our analysis
shows that evaluating with biased parsing algorithms can inflate the apparent
structural competence of language models.
","[{'version': 'v1', 'created': 'Fri, 20 Sep 2019 11:09:52 GMT'}]",2019-09-23,"[['Dyer', 'Chris', ''], ['Melis', 'Gábor', ''], ['Blunsom', 'Phil', '']]"
1909.06058,Mengdi Zhu,"Mengdi Zhu, Zheye Deng, Wenhan Xiong, Mo Yu, Ming Zhang, William Yang
  Wang",Neural Correction Model for Open-Domain Named Entity Recognition,,,,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Named Entity Recognition (NER) plays an important role in a wide range of
natural language processing tasks, such as relation extraction, question
answering, etc. However, previous studies on NER are limited to particular
genres, using small manually-annotated or large but low-quality datasets.
Meanwhile, previous datasets for open-domain NER, built using distant
supervision, suffer from low precision, recall and ratio of annotated tokens
(RAT). In this work, to address the low precision and recall problems, we first
utilize DBpedia as the source of distant supervision to annotate abstracts from
Wikipedia and design a neural correction model trained with a human-annotated
NER dataset, DocRED, to correct the false entity labels. In this way, we build
a large and high-quality dataset called AnchorNER and then train various models
with it. To address the low RAT problem of previous datasets, we introduce a
multi-task learning method to exploit the context information. We evaluate our
methods on five NER datasets and our experimental results show that models
trained with AnchorNER and our multi-task learning method obtain
state-of-the-art performances in the open-domain setting.
","[{'version': 'v1', 'created': 'Fri, 13 Sep 2019 06:44:30 GMT'}, {'version': 'v2', 'created': 'Sun, 1 Nov 2020 10:14:01 GMT'}]",2020-11-03,"[['Zhu', 'Mengdi', ''], ['Deng', 'Zheye', ''], ['Xiong', 'Wenhan', ''], ['Yu', 'Mo', ''], ['Zhang', 'Ming', ''], ['Wang', 'William Yang', '']]"
2303.17161,Yu Wang,"Sid Wang, Akshat Shrivastava, Sasha Livshits",TreePiece: Faster Semantic Parsing via Tree Tokenization,4 pages main body + 4 pages appendices,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Autoregressive (AR) encoder-decoder neural networks have proved successful in
many NLP problems, including Semantic Parsing -- a task that translates natural
language to machine-readable parse trees. However, the sequential prediction
process of AR models can be slow. To accelerate AR for semantic parsing, we
introduce a new technique called TreePiece that tokenizes a parse tree into
subtrees and generates one subtree per decoding step. On TopV2 benchmark,
TreePiece shows 4.6 times faster decoding speed than standard AR, and
comparable speed but significantly higher accuracy compared to
Non-Autoregressive (NAR).
","[{'version': 'v1', 'created': 'Thu, 30 Mar 2023 05:44:44 GMT'}]",2023-03-31,"[['Wang', 'Sid', ''], ['Shrivastava', 'Akshat', ''], ['Livshits', 'Sasha', '']]"
2402.11243,Deniz Gorur,"Deniz Gorur, Antonio Rago, Francesca Toni",Can Large Language Models perform Relation-based Argument Mining?,"10 pages, 9 figures, submitted to ACL 2024",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  Argument mining (AM) is the process of automatically extracting arguments,
their components and/or relations amongst arguments and components from text.
As the number of platforms supporting online debate increases, the need for AM
becomes ever more urgent, especially in support of downstream tasks.
Relation-based AM (RbAM) is a form of AM focusing on identifying agreement
(support) and disagreement (attack) relations amongst arguments. RbAM is a
challenging classification task, with existing methods failing to perform
satisfactorily. In this paper, we show that general-purpose Large Language
Models (LLMs), appropriately primed and prompted, can significantly outperform
the best performing (RoBERTa-based) baseline. Specifically, we experiment with
two open-source LLMs (Llama-2 and Mistral) with ten datasets.
","[{'version': 'v1', 'created': 'Sat, 17 Feb 2024 10:37:51 GMT'}]",2024-02-20,"[['Gorur', 'Deniz', ''], ['Rago', 'Antonio', ''], ['Toni', 'Francesca', '']]"
2208.08750,Nuo Chen,"Nuo Chen, Chenyu You","Exploring and Exploiting Multi-Granularity Representations for Machine
  Reading Comprehension","13 pages. arXiv admin note: text overlap with arXiv:2012.10877; text
  overlap with arXiv:1804.09541 by other authors",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, the attention-enhanced multi-layer encoder, such as Transformer,
has been extensively studied in Machine Reading Comprehension (MRC). To predict
the answer, it is common practice to employ a predictor to draw information
only from the final encoder layer which generates the coarse-grained
representations of the source sequences, i.e., passage and question. The
analysis shows that the representation of source sequence becomes more
coarse-grained from finegrained as the encoding layer increases. It is
generally believed that with the growing number of layers in deep neural
networks, the encoding process will gather relevant information for each
location increasingly, resulting in more coarse-grained representations, which
adds the likelihood of similarity to other locations (referring to
homogeneity). Such phenomenon will mislead the model to make wrong judgement
and degrade the performance. In this paper, we argue that it would be better if
the predictor could exploit representations of different granularity from the
encoder, providing different views of the source sequences, such that the
expressive power of the model could be fully utilized. To this end, we propose
a novel approach called Adaptive Bidirectional Attention-Capsule Network
(ABA-Net), which adaptively exploits the source representations of different
levels to the predictor. Furthermore, due to the better representations are at
the core for boosting MRC performance, the capsule network and self-attention
module are carefully designed as the building blocks of our encoders, which
provides the capability to explore the local and global representations,
respectively. Experimental results on three benchmark datasets, i.e., SQuAD
1.0, SQuAD 2.0 and COQA, demonstrate the effectiveness of our approach. In
particular, we set the new state-of-the-art performance on the SQuAD 1.0
dataset
","[{'version': 'v1', 'created': 'Thu, 18 Aug 2022 10:14:32 GMT'}]",2022-08-19,"[['Chen', 'Nuo', ''], ['You', 'Chenyu', '']]"
2204.04043,Daniele Jahier Pagliari,"Yukai Chen, Roberta Chiaro, Enrico Macii, Massimo Poncino, Daniele
  Jahier Pagliari","C-NMT: A Collaborative Inference Framework for Neural Machine
  Translation","Accepted as a conference paper at the 2022 IEEE International
  Symposium on Circuits and Systems (ISCAS)",,,,cs.LG cs.AI cs.CL cs.SY eess.SY,http://creativecommons.org/licenses/by/4.0/,"  Collaborative Inference (CI) optimizes the latency and energy consumption of
deep learning inference through the inter-operation of edge and cloud devices.
Albeit beneficial for other tasks, CI has never been applied to the sequence-
to-sequence mapping problem at the heart of Neural Machine Translation (NMT).
In this work, we address the specific issues of collaborative NMT, such as
estimating the latency required to generate the (unknown) output sequence, and
show how existing CI methods can be adapted to these applications. Our
experiments show that CI can reduce the latency of NMT by up to 44% compared to
a non-collaborative approach.
","[{'version': 'v1', 'created': 'Fri, 8 Apr 2022 13:04:10 GMT'}]",2022-04-11,"[['Chen', 'Yukai', ''], ['Chiaro', 'Roberta', ''], ['Macii', 'Enrico', ''], ['Poncino', 'Massimo', ''], ['Pagliari', 'Daniele Jahier', '']]"
2110.00416,Chandresh Maurya,"Sundesh Gupta, Aditya Shah, Miten Shah, Laribok Syiemlieh, Chandresh
  Maurya",FiLMing Multimodal Sarcasm Detection with Attention,13 pages,,,,cs.MM cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sarcasm detection identifies natural language expressions whose intended
meaning is different from what is implied by its surface meaning. It finds
applications in many NLP tasks such as opinion mining, sentiment analysis, etc.
Today, social media has given rise to an abundant amount of multimodal data
where users express their opinions through text and images. Our paper aims to
leverage multimodal data to improve the performance of the existing systems for
sarcasm detection. So far, various approaches have been proposed that uses text
and image modality and a fusion of both. We propose a novel architecture that
uses the RoBERTa model with a co-attention layer on top to incorporate context
incongruity between input text and image attributes. Further, we integrate
feature-wise affine transformation by conditioning the input image through
FiLMed ResNet blocks with the textual features using the GRU network to capture
the multimodal information. The output from both the models and the CLS token
from RoBERTa is concatenated and used for the final prediction. Our results
demonstrate that our proposed model outperforms the existing state-of-the-art
method by 6.14% F1 score on the public Twitter multimodal sarcasm detection
dataset.
","[{'version': 'v1', 'created': 'Mon, 9 Aug 2021 06:33:29 GMT'}]",2021-10-04,"[['Gupta', 'Sundesh', ''], ['Shah', 'Aditya', ''], ['Shah', 'Miten', ''], ['Syiemlieh', 'Laribok', ''], ['Maurya', 'Chandresh', '']]"
2402.03501,William Alberto Cruz Casta\~neda PhD,"Felipe Rodrigues Perche-Mahlow and Andr\'e Felipe-Zanella and William
  Alberto Cruz-Casta\~neda and Marcellus Amadeus",An Inpainting-Infused Pipeline for Attire and Background Replacement,,,,,cs.CV cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In recent years, groundbreaking advancements in Generative Artificial
Intelligence (GenAI) have triggered a transformative paradigm shift,
significantly influencing various domains. In this work, we specifically
explore an integrated approach, leveraging advanced techniques in GenAI and
computer vision emphasizing image manipulation. The methodology unfolds through
several stages, including depth estimation, the creation of inpaint masks based
on depth information, the generation and replacement of backgrounds utilizing
Stable Diffusion in conjunction with Latent Consistency Models (LCMs), and the
subsequent replacement of clothes and application of aesthetic changes through
an inpainting pipeline. Experiments conducted in this study underscore the
methodology's efficacy, highlighting its potential to produce visually
captivating content. The convergence of these advanced techniques allows users
to input photographs of individuals and manipulate them to modify clothing and
background based on specific prompts without manually input inpainting masks,
effectively placing the subjects within the vast landscape of creative
imagination.
","[{'version': 'v1', 'created': 'Mon, 5 Feb 2024 20:34:32 GMT'}]",2024-02-07,"[['Perche-Mahlow', 'Felipe Rodrigues', ''], ['Felipe-Zanella', 'André', ''], ['Cruz-Castañeda', 'William Alberto', ''], ['Amadeus', 'Marcellus', '']]"
2009.07382,Junjie Yang,"Junjie Yang, Zhuosheng Zhang, Hai Zhao",Multi-span Style Extraction for Generative Reading Comprehension,AAAI-21 SDU Workshop,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generative machine reading comprehension (MRC) requires a model to generate
well-formed answers. For this type of MRC, answer generation method is crucial
to the model performance. However, generative models, which are supposed to be
the right model for the task, in generally perform poorly. At the same time,
single-span extraction models have been proven effective for extractive MRC,
where the answer is constrained to a single span in the passage. Nevertheless,
they generally suffer from generating incomplete answers or introducing
redundant words when applied to the generative MRC. Thus, we extend the
single-span extraction method to multi-span, proposing a new framework which
enables generative MRC to be smoothly solved as multi-span extraction. Thorough
experiments demonstrate that this novel approach can alleviate the dilemma
between generative models and single-span models and produce answers with
better-formed syntax and semantics.
","[{'version': 'v1', 'created': 'Tue, 15 Sep 2020 23:06:48 GMT'}, {'version': 'v2', 'created': 'Mon, 28 Dec 2020 13:56:13 GMT'}]",2020-12-29,"[['Yang', 'Junjie', ''], ['Zhang', 'Zhuosheng', ''], ['Zhao', 'Hai', '']]"
2211.04668,Chonghua Liao,"Chonghua Liao, Yanan Zheng, Zhilin Yang",Zero-Label Prompt Selection,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Natural language prompts have been shown to facilitate cross-task
generalization for large language models. However, with no or limited labeled
examples, the cross-task performance is highly sensitive to the choice of
prompts, while selecting a high-performing prompt is challenging given the
scarcity of labels. To address the issue, we propose a Zero-Label Prompt
Selection (ZPS) method that selects prompts without any labeled data or
gradient update. Specifically, given the candidate human-written prompts for a
task, ZPS labels a set of unlabeled data with a prompt ensemble and uses the
pseudo-labels for prompt selection. Experiments show that ZPS improves over
prior methods by a sizeable margin in zero-label performance. We also extend
ZPS to a few-shot setting and show its advantages over strong baselines such as
prompt tuning and model tuning.
","[{'version': 'v1', 'created': 'Wed, 9 Nov 2022 04:13:31 GMT'}]",2022-11-10,"[['Liao', 'Chonghua', ''], ['Zheng', 'Yanan', ''], ['Yang', 'Zhilin', '']]"
2303.00722,Javad Pourmostafa Roshan Sharami,"J. Pourmostafa Roshan Sharami, D. Shterionov, P. Spronck","A Systematic Analysis of Vocabulary and BPE Settings for Optimal
  Fine-tuning of NMT: A Case Study of In-domain Translation",,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The effectiveness of Neural Machine Translation (NMT) models largely depends
on the vocabulary used at training; small vocabularies can lead to
out-of-vocabulary problems -- large ones, to memory issues. Subword (SW)
tokenization has been successfully employed to mitigate these issues. The
choice of vocabulary and SW tokenization has a significant impact on both
training and fine-tuning an NMT model. Fine-tuning is a common practice in
optimizing an MT model with respect to new data. However, new data potentially
introduces new words (or tokens), which, if not taken into consideration, may
lead to suboptimal performance. In addition, the distribution of tokens in the
new data can differ from the distribution of the original data. As such, the
original SW tokenization model could be less suitable for the new data. Through
a systematic empirical evaluation, in this work we compare different strategies
for SW tokenization and vocabulary generation with the ultimate goal to uncover
an optimal setting for fine-tuning a domain-specific model. Furthermore, we
developed several (in-domain) models, the best of which achieves 6 BLEU points
improvement over the baseline.
","[{'version': 'v1', 'created': 'Wed, 1 Mar 2023 18:26:47 GMT'}]",2023-03-02,"[['Sharami', 'J. Pourmostafa Roshan', ''], ['Shterionov', 'D.', ''], ['Spronck', 'P.', '']]"
2211.03468,Qihao Zhu,Qihao Zhu and Jianxi Luo,Generative Transformers for Design Concept Generation,Accepted by J. Comput. Inf. Sci. Eng,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Generating novel and useful concepts is essential during the early design
stage to explore a large variety of design opportunities, which usually
requires advanced design thinking ability and a wide range of knowledge from
designers. Growing works on computer-aided tools have explored the retrieval of
knowledge and heuristics from design data. However, they only provide stimuli
to inspire designers from limited aspects. This study explores the recent
advance of the natural language generation (NLG) technique in the artificial
intelligence (AI) field to automate the early-stage design concept generation.
Specifically, a novel approach utilizing the generative pre-trained transformer
(GPT) is proposed to leverage the knowledge and reasoning from textual data and
transform them into new concepts in understandable language. Three concept
generation tasks are defined to leverage different knowledge and reasoning:
domain knowledge synthesis, problem-driven synthesis, and analogy-driven
synthesis. The experiments with both human and data-driven evaluation show good
performance in generating novel and useful concepts.
","[{'version': 'v1', 'created': 'Mon, 7 Nov 2022 11:29:10 GMT'}]",2022-11-08,"[['Zhu', 'Qihao', ''], ['Luo', 'Jianxi', '']]"
2102.11009,Justin Lane,"Justin E. Lane, Kevin McCaffree, F. LeRon Shults","The Moral Foundations of Left-Wing Authoritarianism: On the Character,
  Cohesion, and Clout of Tribal Equalitarian Discourse",,,,,cs.SI cs.CL cs.CY,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Left-wing authoritarianism remains far less understood than right-wing
authoritarianism. We contribute to the literature on the former, which
typically relies on surveys, using a new social media analytics approach. We
use a list of 60 terms to provide an exploratory sketch of the outlines of a
political ideology (tribal equalitarianism) with origins in 19th and 20th
century social philosophy. We then use analyses of the English Corpus of Google
Books (over 8 million books) and scraped unique tweets from Twitter (n =
202,852) to conduct a series of investigations to discern the extent to which
this ideology is cohesive amongst the public, reveals signatures of
authoritarianism and has been growing in popularity. Though exploratory, our
results provide some evidence of left-wing authoritarianism in two forms (1) a
uniquely conservative moral signature amongst ostensible liberals using
measures from Moral Foundations Theory and (2) a substantial prevalence of
anger, relative to anxiety or sadness. In general, results indicate that this
worldview is growing in popularity, is increasingly cohesive, and shows
signatures of authoritarianism.
","[{'version': 'v1', 'created': 'Mon, 22 Feb 2021 14:06:25 GMT'}]",2021-02-23,"[['Lane', 'Justin E.', ''], ['McCaffree', 'Kevin', ''], ['Shults', 'F. LeRon', '']]"
2303.13386,Stephanie L. Hyland,"Fangyu Liu, Qianchu Liu, Shruthi Bannur, Fernando P\'erez-Garc\'ia,
  Naoto Usuyama, Sheng Zhang, Tristan Naumann, Aditya Nori, Hoifung Poon,
  Javier Alvarez-Valle, Ozan Oktay, Stephanie L. Hyland",Compositional Zero-Shot Domain Transfer with Text-to-Text Models,"Accepted at TACL, pre-MIT Press publication version. 16 pages, 4
  figures",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Label scarcity is a bottleneck for improving task performance in specialised
domains. We propose a novel compositional transfer learning framework (DoT5 -
domain compositional zero-shot T5) for zero-shot domain transfer. Without
access to in-domain labels, DoT5 jointly learns domain knowledge (from MLM of
unlabelled in-domain free text) and task knowledge (from task training on more
readily available general-domain data) in a multi-task manner. To improve the
transferability of task training, we design a strategy named NLGU: we
simultaneously train NLG for in-domain label-to-data generation which enables
data augmentation for self-finetuning and NLU for label prediction. We evaluate
DoT5 on the biomedical domain and the resource-lean subdomain of radiology,
focusing on NLI, text summarisation and embedding learning. DoT5 demonstrates
the effectiveness of compositional transfer learning through multi-task
learning. In particular, DoT5 outperforms the current SOTA in zero-shot
transfer by over 7 absolute points in accuracy on RadNLI. We validate DoT5 with
ablations and a case study demonstrating its ability to solve challenging NLI
examples requiring in-domain expertise.
","[{'version': 'v1', 'created': 'Thu, 23 Mar 2023 15:58:41 GMT'}]",2023-03-24,"[['Liu', 'Fangyu', ''], ['Liu', 'Qianchu', ''], ['Bannur', 'Shruthi', ''], ['Pérez-García', 'Fernando', ''], ['Usuyama', 'Naoto', ''], ['Zhang', 'Sheng', ''], ['Naumann', 'Tristan', ''], ['Nori', 'Aditya', ''], ['Poon', 'Hoifung', ''], ['Alvarez-Valle', 'Javier', ''], ['Oktay', 'Ozan', ''], ['Hyland', 'Stephanie L.', '']]"
2306.04950,Jun Zhao,"Jun Zhao, Xin Zhao, Wenyu Zhan, Qi Zhang, Tao Gui, Zhongyu Wei, Yunwen
  Chen, Xiang Gao, Xuanjing Huang",Open Set Relation Extraction via Unknown-Aware Training,Accepted by ACL2023,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The existing supervised relation extraction methods have achieved impressive
performance in a closed-set setting, where the relations during both training
and testing remain the same. In a more realistic open-set setting, unknown
relations may appear in the test set. Due to the lack of supervision signals
from unknown relations, a well-performing closed-set relation extractor can
still confidently misclassify them into known relations. In this paper, we
propose an unknown-aware training method, regularizing the model by dynamically
synthesizing negative instances. To facilitate a compact decision boundary,
``difficult'' negative instances are necessary. Inspired by text adversarial
attacks, we adaptively apply small but critical perturbations to original
training instances and thus synthesizing negative instances that are more
likely to be mistaken by the model as known relations. Experimental results
show that this method achieves SOTA unknown relation detection without
compromising the classification of known relations.
","[{'version': 'v1', 'created': 'Thu, 8 Jun 2023 05:45:25 GMT'}]",2023-06-09,"[['Zhao', 'Jun', ''], ['Zhao', 'Xin', ''], ['Zhan', 'Wenyu', ''], ['Zhang', 'Qi', ''], ['Gui', 'Tao', ''], ['Wei', 'Zhongyu', ''], ['Chen', 'Yunwen', ''], ['Gao', 'Xiang', ''], ['Huang', 'Xuanjing', '']]"
2309.08590,Raphael Reinauer,"Raphael Reinauer and Patrick Simianer and Kaden Uhlig and Johannes E.
  M. Mosig and Joern Wuebker",Neural Machine Translation Models Can Learn to be Few-shot Learners,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The emergent ability of Large Language Models to use a small number of
examples to learn to perform in novel domains and tasks, also called in-context
learning (ICL). In this work, we show that a much smaller model can be trained
to perform ICL by fine-tuning towards a specialized training objective,
exemplified on the task of domain adaptation for neural machine translation.
With this capacity for ICL, the model can take advantage of relevant few-shot
examples to adapt its output towards the domain. We compare the quality of this
domain adaptation to traditional supervised techniques and ICL with a
40B-parameter Large Language Model. Our approach allows efficient batch
inference on a mix of domains and outperforms state-of-the-art baselines in
terms of both translation quality and immediate adaptation rate, i.e. the
ability to reproduce a specific term after being shown a single example.
","[{'version': 'v1', 'created': 'Fri, 15 Sep 2023 17:44:21 GMT'}]",2023-09-18,"[['Reinauer', 'Raphael', ''], ['Simianer', 'Patrick', ''], ['Uhlig', 'Kaden', ''], ['Mosig', 'Johannes E. M.', ''], ['Wuebker', 'Joern', '']]"
2004.03742,Boxin Wang,"Boxin Wang, Boyuan Pan, Xin Li, Bo Li",Towards Evaluating the Robustness of Chinese BERT Classifiers,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent advances in large-scale language representation models such as BERT
have improved the state-of-the-art performances in many NLP tasks. Meanwhile,
character-level Chinese NLP models, including BERT for Chinese, have also
demonstrated that they can outperform the existing models. In this paper, we
show that, however, such BERT-based models are vulnerable under character-level
adversarial attacks. We propose a novel Chinese char-level attack method
against BERT-based classifiers. Essentially, we generate ""small"" perturbation
on the character level in the embedding space and guide the character
substitution procedure. Extensive experiments show that the classification
accuracy on a Chinese news dataset drops from 91.8% to 0% by manipulating less
than 2 characters on average based on the proposed attack. Human evaluations
also confirm that our generated Chinese adversarial examples barely affect
human performance on these NLP tasks.
","[{'version': 'v1', 'created': 'Tue, 7 Apr 2020 23:02:37 GMT'}]",2020-04-09,"[['Wang', 'Boxin', ''], ['Pan', 'Boyuan', ''], ['Li', 'Xin', ''], ['Li', 'Bo', '']]"
2310.17526,Qusai Khraisha,"Qusai Khraisha, Sophie Put, Johanna Kappenberg, Azza Warraitch,
  Kristin Hadfield","Can large language models replace humans in the systematic review
  process? Evaluating GPT-4's efficacy in screening and extracting data from
  peer-reviewed and grey literature in multiple languages","9 pages, 2 figures, 1 table",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Systematic reviews are vital for guiding practice, research, and policy, yet
they are often slow and labour-intensive. Large language models (LLMs) could
offer a way to speed up and automate systematic reviews, but their performance
in such tasks has not been comprehensively evaluated against humans, and no
study has tested GPT-4, the biggest LLM so far. This pre-registered study
evaluates GPT-4's capability in title/abstract screening, full-text review, and
data extraction across various literature types and languages using a
'human-out-of-the-loop' approach. Although GPT-4 had accuracy on par with human
performance in most tasks, results were skewed by chance agreement and dataset
imbalance. After adjusting for these, there was a moderate level of performance
for data extraction, and - barring studies that used highly reliable prompts -
screening performance levelled at none to moderate for different stages and
languages. When screening full-text literature using highly reliable prompts,
GPT-4's performance was 'almost perfect.' Penalising GPT-4 for missing key
studies using highly reliable prompts improved its performance even more. Our
findings indicate that, currently, substantial caution should be used if LLMs
are being used to conduct systematic reviews, but suggest that, for certain
systematic review tasks delivered under reliable prompts, LLMs can rival human
performance.
","[{'version': 'v1', 'created': 'Thu, 26 Oct 2023 16:18:30 GMT'}, {'version': 'v2', 'created': 'Fri, 27 Oct 2023 12:14:27 GMT'}]",2023-10-30,"[['Khraisha', 'Qusai', ''], ['Put', 'Sophie', ''], ['Kappenberg', 'Johanna', ''], ['Warraitch', 'Azza', ''], ['Hadfield', 'Kristin', '']]"
1712.01476,J\'ulio Hoffimann,"J\'ulio Hoffimann, Youli Mao, Avinash Wesley and Aimee Taylor","Sequence Mining and Pattern Analysis in Drilling Reports with Deep
  Natural Language Processing","7 pages, 14 figures, technical report",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Drilling activities in the oil and gas industry have been reported over
decades for thousands of wells on a daily basis, yet the analysis of this text
at large-scale for information retrieval, sequence mining, and pattern analysis
is very challenging. Drilling reports contain interpretations written by
drillers from noting measurements in downhole sensors and surface equipment,
and can be used for operation optimization and accident mitigation. In this
initial work, a methodology is proposed for automatic classification of
sentences written in drilling reports into three relevant labels (EVENT,
SYMPTOM and ACTION) for hundreds of wells in an actual field. Some of the main
challenges in the text corpus were overcome, which include the high frequency
of technical symbols, mistyping/abbreviation of technical terms, and the
presence of incomplete sentences in the drilling reports. We obtain
state-of-the-art classification accuracy within this technical language and
illustrate advanced queries enabled by the tool.
","[{'version': 'v1', 'created': 'Tue, 5 Dec 2017 04:49:58 GMT'}]",2017-12-06,"[['Hoffimann', 'Júlio', ''], ['Mao', 'Youli', ''], ['Wesley', 'Avinash', ''], ['Taylor', 'Aimee', '']]"
1905.04914,Wei Hu,Lingbing Guo and Zequn Sun and Wei Hu,"Learning to Exploit Long-term Relational Dependencies in Knowledge
  Graphs","Accepted by the 36th International Conference on Machine Learning
  (ICML 2019)",,,,cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We study the problem of knowledge graph (KG) embedding. A widely-established
assumption to this problem is that similar entities are likely to have similar
relational roles. However, existing related methods derive KG embeddings mainly
based on triple-level learning, which lack the capability of capturing
long-term relational dependencies of entities. Moreover, triple-level learning
is insufficient for the propagation of semantic information among entities,
especially for the case of cross-KG embedding. In this paper, we propose
recurrent skipping networks (RSNs), which employ a skipping mechanism to bridge
the gaps between entities. RSNs integrate recurrent neural networks (RNNs) with
residual learning to efficiently capture the long-term relational dependencies
within and between KGs. We design an end-to-end framework to support RSNs on
different tasks. Our experimental results showed that RSNs outperformed
state-of-the-art embedding-based methods for entity alignment and achieved
competitive performance for KG completion.
","[{'version': 'v1', 'created': 'Mon, 13 May 2019 08:53:31 GMT'}]",2019-05-14,"[['Guo', 'Lingbing', ''], ['Sun', 'Zequn', ''], ['Hu', 'Wei', '']]"
2211.08237,Zihan Wang,"Zihan Wang, Qi Meng, HaiFeng Lan, XinRui Zhang, KeHao Guo, Akshat
  Gupta","Multilingual Speech Emotion Recognition With Multi-Gating Mechanism and
  Neural Architecture Search",,,,,cs.SD cs.CL eess.AS,http://creativecommons.org/licenses/by/4.0/,"  Speech emotion recognition (SER) classifies audio into emotion categories
such as Happy, Angry, Fear, Disgust and Neutral. While Speech Emotion
Recognition (SER) is a common application for popular languages, it continues
to be a problem for low-resourced languages, i.e., languages with no pretrained
speech-to-text recognition models. This paper firstly proposes a
language-specific model that extract emotional information from multiple
pre-trained speech models, and then designs a multi-domain model that
simultaneously performs SER for various languages. Our multidomain model
employs a multi-gating mechanism to generate unique weighted feature
combination for each language, and also searches for specific neural network
structure for each language through a neural architecture search module. In
addition, we introduce a contrastive auxiliary loss to build more separable
representations for audio data. Our experiments show that our model raises the
state-of-the-art accuracy by 3% for German and 14.3% for French.
","[{'version': 'v1', 'created': 'Mon, 31 Oct 2022 19:55:33 GMT'}, {'version': 'v2', 'created': 'Wed, 16 Nov 2022 01:47:34 GMT'}]",2022-11-17,"[['Wang', 'Zihan', ''], ['Meng', 'Qi', ''], ['Lan', 'HaiFeng', ''], ['Zhang', 'XinRui', ''], ['Guo', 'KeHao', ''], ['Gupta', 'Akshat', '']]"
2306.02871,Sondre Wold,Sondre Wold and Lilja {\O}vrelid and Erik Velldal,Text-To-KG Alignment: Comparing Current Methods on Classification Tasks,Camera ready version for MATCHING workshop at ACL 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In contrast to large text corpora, knowledge graphs (KG) provide dense and
structured representations of factual information. This makes them attractive
for systems that supplement or ground the knowledge found in pre-trained
language models with an external knowledge source. This has especially been the
case for classification tasks, where recent work has focused on creating
pipeline models that retrieve information from KGs like ConceptNet as
additional context. Many of these models consist of multiple components, and
although they differ in the number and nature of these parts, they all have in
common that for some given text query, they attempt to identify and retrieve a
relevant subgraph from the KG. Due to the noise and idiosyncrasies often found
in KGs, it is not known how current methods compare to a scenario where the
aligned subgraph is completely relevant to the query. In this work, we try to
bridge this knowledge gap by reviewing current approaches to text-to-KG
alignment and evaluating them on two datasets where manually created graphs are
available, providing insights into the effectiveness of current methods.
","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 13:45:45 GMT'}]",2023-06-06,"[['Wold', 'Sondre', ''], ['Øvrelid', 'Lilja', ''], ['Velldal', 'Erik', '']]"
2205.05535,Niall Taylor,"Niall Taylor, Yi Zhang, Dan Joyce, Alejo Nevado-Holgado, Andrey
  Kormilitzin",Clinical Prompt Learning with Frozen Language Models,"18 pages, 6 figures, 6 tables",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Prompt learning is a new paradigm in the Natural Language Processing (NLP)
field which has shown impressive performance on a number of natural language
tasks with common benchmarking text datasets in full, few-shot, and zero-shot
train-evaluation setups. Recently, it has even been observed that large but
frozen pre-trained language models (PLMs) with prompt learning outperform
smaller but fine-tuned models. However, as with many recent NLP trends, the
performance of even the largest PLMs such as GPT-3 do not perform well on
specialized domains (e.g. medical text), and the common practice to achieve
State of the Art (SoTA) results still consists of pre-training and fine-tuning
the PLMs on downstream tasks. The reliance on fine-tuning large PLMs is
problematic in clinical settings where data is often held in non-GPU
environments, and more resource efficient methods of training specialized
domain models is crucial. We investigated the viability of prompt learning on
clinically meaningful decision tasks and directly compared with more
traditional fine-tuning methods. Results are partially in line with the prompt
learning literature, with prompt learning able to match or improve on
traditional fine-tuning with substantially fewer trainable parameters and
requiring less training data. We argue that prompt learning therefore provides
lower computational resource costs applicable to clinical settings, that can
serve as an alternative to fine-tuning ever increasing in size PLMs.
Complementary code to reproduce experiments presented in this work can be found
at: https://github.com/NtaylorOX/Public_Clinical_Prompt.
","[{'version': 'v1', 'created': 'Wed, 11 May 2022 14:25:13 GMT'}]",2022-05-12,"[['Taylor', 'Niall', ''], ['Zhang', 'Yi', ''], ['Joyce', 'Dan', ''], ['Nevado-Holgado', 'Alejo', ''], ['Kormilitzin', 'Andrey', '']]"
2305.05098,Yassir Fathullah,"Yassir Fathullah, Puria Radmard, Adian Liusie, Mark J. F. Gales",Who Needs Decoders? Efficient Estimation of Sequence-level Attributes,,,,,cs.LG cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  State-of-the-art sequence-to-sequence models often require autoregressive
decoding, which can be highly expensive. However, for some downstream tasks
such as out-of-distribution (OOD) detection and resource allocation, the actual
decoding output is not needed just a scalar attribute of this sequence. In
these scenarios, where for example knowing the quality of a system's output to
predict poor performance prevails over knowing the output itself, is it
possible to bypass the autoregressive decoding? We propose Non-Autoregressive
Proxy (NAP) models that can efficiently predict general scalar-valued
sequence-level attributes. Importantly, NAPs predict these metrics directly
from the encodings, avoiding the expensive autoregressive decoding stage. We
consider two sequence-to-sequence task: Machine Translation (MT); and Automatic
Speech Recognition (ASR). In OOD for MT, NAPs outperform a deep ensemble while
being significantly faster. NAPs are also shown to be able to predict
performance metrics such as BERTScore (MT) or word error rate (ASR). For
downstream tasks, such as data filtering and resource optimization, NAPs
generate performance predictions that outperform predictive uncertainty while
being highly inference efficient.
","[{'version': 'v1', 'created': 'Tue, 9 May 2023 00:01:32 GMT'}]",2023-05-10,"[['Fathullah', 'Yassir', ''], ['Radmard', 'Puria', ''], ['Liusie', 'Adian', ''], ['Gales', 'Mark J. F.', '']]"
cmp-lg/9605031,Rens Bod,Rens Bod (University of Amsterdam),"Efficient Algorithms for Parsing the DOP Model? A Reply to Joshua
  Goodman","5 pages, Postscript file",,,,cmp-lg cs.CL,,"  This note is a reply to Joshua Goodman's paper ""Efficient Algorithms for
Parsing the DOP Model"" (Goodman, 1996; cmp-lg/9604008). In his paper, Goodman
makes a number of claims about (my work on) the Data-Oriented Parsing model
(Bod, 1992-1996). This note shows that some of these claims must be mistaken.
","[{'version': 'v1', 'created': 'Fri, 24 May 1996 12:01:01 GMT'}]",2016-08-31,"[['Bod', 'Rens', '', 'University of Amsterdam']]"
2102.12109,Aso Mahmudi,"Aso Mahmudi, Hadi Veisi",Automatic Meter Classification of Kurdish Poems,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Most of the classic texts in Kurdish literature are poems. Knowing the meter
of the poems is helpful for correct reading, a better understanding of the
meaning, and avoidance of ambiguity. This paper presents a rule-based method
for automatic classification of the poem meter for the Central Kurdish
language. The metrical system of Kurdish poetry is divided into three classes
of quantitative, syllabic, and free verses. As the vowel length is not phonemic
in the language, there are uncertainties in syllable weight and meter
identification. The proposed method generates all the possible situations and
then, by considering all lines of the input poem and the common meter patterns
of Kurdish poetry, identifies the most probable meter type and pattern of the
input poem. Evaluation of the method on a dataset from VejinBooks Kurdish
corpus resulted in 97.3% of precision in meter type and 96.2% of precision in
pattern identification.
","[{'version': 'v1', 'created': 'Wed, 24 Feb 2021 07:57:38 GMT'}]",2021-02-25,"[['Mahmudi', 'Aso', ''], ['Veisi', 'Hadi', '']]"
2212.01349,Sewon Min,"Sewon Min, Weijia Shi, Mike Lewis, Xilun Chen, Wen-tau Yih, Hannaneh
  Hajishirzi, Luke Zettlemoyer",Nonparametric Masked Language Modeling,"20 pages; 9 figures. Published at ACL 2023 Findings. Code available
  at https://github.com/facebookresearch/NPM",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Existing language models (LMs) predict tokens with a softmax over a finite
vocabulary, which can make it difficult to predict rare tokens or phrases. We
introduce NPM, the first nonparametric masked language model that replaces this
softmax with a nonparametric distribution over every phrase in a reference
corpus. NPM fills in the [MASK] solely from retrieving a token from a text
corpus. We show that NPM can be efficiently trained with a contrastive
objective and an in-batch approximation to full corpus retrieval. Zero-shot
evaluation on 16 tasks including classification, fact probing and question
answering demonstrates that NPM outperforms significantly larger parametric
models, either with or without a retrieve-and-generate approach. It is
particularly better at dealing with rare patterns (word senses or facts) and
predicting rare or nearly unseen words (e.g., non-Latin script). We release the
model and code at github.com/facebookresearch/NPM.
","[{'version': 'v1', 'created': 'Fri, 2 Dec 2022 18:10:42 GMT'}, {'version': 'v2', 'created': 'Thu, 25 May 2023 23:18:35 GMT'}]",2023-05-29,"[['Min', 'Sewon', ''], ['Shi', 'Weijia', ''], ['Lewis', 'Mike', ''], ['Chen', 'Xilun', ''], ['Yih', 'Wen-tau', ''], ['Hajishirzi', 'Hannaneh', ''], ['Zettlemoyer', 'Luke', '']]"
2206.01832,Xiaoyi Chen,"Xiaoyi Chen, Yinpeng Dong, Zeyu Sun, Shengfang Zhai, Qingni Shen,
  Zhonghai Wu",Kallima: A Clean-label Framework for Textual Backdoor Attacks,,,,,cs.CR cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Although Deep Neural Network (DNN) has led to unprecedented progress in
various natural language processing (NLP) tasks, research shows that deep
models are extremely vulnerable to backdoor attacks. The existing backdoor
attacks mainly inject a small number of poisoned samples into the training
dataset with the labels changed to the target one. Such mislabeled samples
would raise suspicion upon human inspection, potentially revealing the attack.
To improve the stealthiness of textual backdoor attacks, we propose the first
clean-label framework Kallima for synthesizing mimesis-style backdoor samples
to develop insidious textual backdoor attacks. We modify inputs belonging to
the target class with adversarial perturbations, making the model rely more on
the backdoor trigger. Our framework is compatible with most existing backdoor
triggers. The experimental results on three benchmark datasets demonstrate the
effectiveness of the proposed method.
","[{'version': 'v1', 'created': 'Fri, 3 Jun 2022 21:44:43 GMT'}]",2022-06-07,"[['Chen', 'Xiaoyi', ''], ['Dong', 'Yinpeng', ''], ['Sun', 'Zeyu', ''], ['Zhai', 'Shengfang', ''], ['Shen', 'Qingni', ''], ['Wu', 'Zhonghai', '']]"
2302.02060,Yu Meng,"Yu Meng, Jitin Krishnan, Sinong Wang, Qifan Wang, Yuning Mao, Han
  Fang, Marjan Ghazvininejad, Jiawei Han, Luke Zettlemoyer",Representation Deficiency in Masked Language Modeling,ICLR 2024,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Masked Language Modeling (MLM) has been one of the most prominent approaches
for pretraining bidirectional text encoders due to its simplicity and
effectiveness. One notable concern about MLM is that the special
$\texttt{[MASK]}$ symbol causes a discrepancy between pretraining data and
downstream data as it is present only in pretraining but not in fine-tuning. In
this work, we offer a new perspective on the consequence of such a discrepancy:
We demonstrate empirically and theoretically that MLM pretraining allocates
some model dimensions exclusively for representing $\texttt{[MASK]}$ tokens,
resulting in a representation deficiency for real tokens and limiting the
pretrained model's expressiveness when it is adapted to downstream data without
$\texttt{[MASK]}$ tokens. Motivated by the identified issue, we propose MAE-LM,
which pretrains the Masked Autoencoder architecture with MLM where
$\texttt{[MASK]}$ tokens are excluded from the encoder. Empirically, we show
that MAE-LM improves the utilization of model dimensions for real token
representations, and MAE-LM consistently outperforms MLM-pretrained models
across different pretraining settings and model sizes when fine-tuned on the
GLUE and SQuAD benchmarks.
","[{'version': 'v1', 'created': 'Sat, 4 Feb 2023 01:54:17 GMT'}, {'version': 'v2', 'created': 'Sat, 16 Mar 2024 04:28:35 GMT'}]",2024-03-19,"[['Meng', 'Yu', ''], ['Krishnan', 'Jitin', ''], ['Wang', 'Sinong', ''], ['Wang', 'Qifan', ''], ['Mao', 'Yuning', ''], ['Fang', 'Han', ''], ['Ghazvininejad', 'Marjan', ''], ['Han', 'Jiawei', ''], ['Zettlemoyer', 'Luke', '']]"
2110.06486,Digbalay Bose,"Digbalay Bose, Krishna Somandepalli, Souvik Kundu, Rimita Lahiri,
  Jonathan Gratch and Shrikanth Narayanan",Understanding of Emotion Perception from Art,"5 pages, 5 figures. Accepted at ICCV2021: 4th Workshop on Closing the
  loop between Vision and Language",,,,cs.CV cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Computational modeling of the emotions evoked by art in humans is a
challenging problem because of the subjective and nuanced nature of art and
affective signals. In this paper, we consider the above-mentioned problem of
understanding emotions evoked in viewers by artwork using both text and visual
modalities. Specifically, we analyze images and the accompanying text captions
from the viewers expressing emotions as a multimodal classification task. Our
results show that single-stream multimodal transformer-based models like MMBT
and VisualBERT perform better compared to both image-only models and
dual-stream multimodal models having separate pathways for text and image
modalities. We also observe improvements in performance for extreme positive
and negative emotion classes, when a single-stream model like MMBT is compared
with a text-only transformer model like BERT.
","[{'version': 'v1', 'created': 'Wed, 13 Oct 2021 04:14:49 GMT'}]",2021-10-14,"[['Bose', 'Digbalay', ''], ['Somandepalli', 'Krishna', ''], ['Kundu', 'Souvik', ''], ['Lahiri', 'Rimita', ''], ['Gratch', 'Jonathan', ''], ['Narayanan', 'Shrikanth', '']]"
2012.11960,Kai Chen,"Kai Chen, Meng Niu, Qingcai Chen","A Hierarchical Reasoning Graph Neural Network for The Automatic Scoring
  of Answer Transcriptions in Video Job Interviews","9 pages, 2 figures",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We address the task of automatically scoring the competency of candidates
based on textual features, from the automatic speech recognition (ASR)
transcriptions in the asynchronous video job interview (AVI). The key challenge
is how to construct the dependency relation between questions and answers, and
conduct the semantic level interaction for each question-answer (QA) pair.
However, most of the recent studies in AVI focus on how to represent questions
and answers better, but ignore the dependency information and interaction
between them, which is critical for QA evaluation. In this work, we propose a
Hierarchical Reasoning Graph Neural Network (HRGNN) for the automatic
assessment of question-answer pairs. Specifically, we construct a
sentence-level relational graph neural network to capture the dependency
information of sentences in or between the question and the answer. Based on
these graphs, we employ a semantic-level reasoning graph attention network to
model the interaction states of the current QA session. Finally, we propose a
gated recurrent unit encoder to represent the temporal question-answer pairs
for the final prediction. Empirical results conducted on CHNAT (a real-world
dataset) validate that our proposed model significantly outperforms
text-matching based benchmark models. Ablation studies and experimental results
with 10 random seeds also show the effectiveness and stability of our models.
","[{'version': 'v1', 'created': 'Tue, 22 Dec 2020 12:27:45 GMT'}]",2020-12-23,"[['Chen', 'Kai', ''], ['Niu', 'Meng', ''], ['Chen', 'Qingcai', '']]"
2211.14739,Meihuizi Jia,"Meihuizi Jia, Lei Shen, Xin Shen, Lejian Liao, Meng Chen, Xiaodong He,
  Zhendong Chen, Jiaqi Li","MNER-QG: An End-to-End MRC framework for Multimodal Named Entity
  Recognition with Query Grounding","13 pages, 6 figures, published to AAAI",,,,cs.CV cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multimodal named entity recognition (MNER) is a critical step in information
extraction, which aims to detect entity spans and classify them to
corresponding entity types given a sentence-image pair. Existing methods either
(1) obtain named entities with coarse-grained visual clues from attention
mechanisms, or (2) first detect fine-grained visual regions with toolkits and
then recognize named entities. However, they suffer from improper alignment
between entity types and visual regions or error propagation in the two-stage
manner, which finally imports irrelevant visual information into texts. In this
paper, we propose a novel end-to-end framework named MNER-QG that can
simultaneously perform MRC-based multimodal named entity recognition and query
grounding. Specifically, with the assistance of queries, MNER-QG can provide
prior knowledge of entity types and visual regions, and further enhance
representations of both texts and images. To conduct the query grounding task,
we provide manual annotations and weak supervisions that are obtained via
training a highly flexible visual grounding model with transfer learning. We
conduct extensive experiments on two public MNER datasets, Twitter2015 and
Twitter2017. Experimental results show that MNER-QG outperforms the current
state-of-the-art models on the MNER task, and also improves the query grounding
performance.
","[{'version': 'v1', 'created': 'Sun, 27 Nov 2022 06:10:03 GMT'}]",2022-11-29,"[['Jia', 'Meihuizi', ''], ['Shen', 'Lei', ''], ['Shen', 'Xin', ''], ['Liao', 'Lejian', ''], ['Chen', 'Meng', ''], ['He', 'Xiaodong', ''], ['Chen', 'Zhendong', ''], ['Li', 'Jiaqi', '']]"
1805.07745,Taehoon Kim,Taehoon Kim and Jihoon Yang,"Abstractive Text Classification Using Sequence-to-convolution Neural
  Networks",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We propose a new deep neural network model and its training scheme for text
classification. Our model Sequence-to-convolution Neural Networks(Seq2CNN)
consists of two blocks: Sequential Block that summarizes input texts and
Convolution Block that receives summary of input and classifies it to a label.
Seq2CNN is trained end-to-end to classify various-length texts without
preprocessing inputs into fixed length. We also present Gradual Weight
Shift(GWS) method that stabilizes training. GWS is applied to our model's loss
function. We compared our model with word-based TextCNN trained with different
data preprocessing methods. We obtained significant improvement in
classification accuracy over word-based TextCNN without any ensemble or data
augmentation.
","[{'version': 'v1', 'created': 'Sun, 20 May 2018 09:34:20 GMT'}, {'version': 'v2', 'created': 'Tue, 22 May 2018 03:06:23 GMT'}, {'version': 'v3', 'created': 'Wed, 23 May 2018 14:58:49 GMT'}, {'version': 'v4', 'created': 'Sun, 24 Jun 2018 06:18:53 GMT'}, {'version': 'v5', 'created': 'Sun, 23 Jun 2019 04:37:59 GMT'}, {'version': 'v6', 'created': 'Tue, 2 Jun 2020 22:34:56 GMT'}]",2020-06-04,"[['Kim', 'Taehoon', ''], ['Yang', 'Jihoon', '']]"
2308.13497,Sakayo Toadoum Sari He,Sakayo Toadoum Sari and Angela Fan and Lema Logamou Seknewna,Ngambay-French Neural Machine Translation (sba-Fr),"Accepted at RANLP 2023 - International Workshop NLP tools and
  resources for translation and interpreting applications",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In Africa, and the world at large, there is an increasing focus on developing
Neural Machine Translation (NMT) systems to overcome language barriers. NMT for
Low-resource language is particularly compelling as it involves learning with
limited labelled data. However, obtaining a well-aligned parallel corpus for
low-resource languages can be challenging. The disparity between the
technological advancement of a few global languages and the lack of research on
NMT for local languages in Chad is striking. End-to-end NMT trials on
low-resource Chad languages have not been attempted. Additionally, there is a
dearth of online and well-structured data gathering for research in Natural
Language Processing, unlike some African languages. However, a guided approach
for data gathering can produce bitext data for many Chadian language
translation pairs with well-known languages that have ample data. In this
project, we created the first sba-Fr Dataset, which is a corpus of
Ngambay-to-French translations, and fine-tuned three pre-trained models using
this dataset. Our experiments show that the M2M100 model outperforms other
models with high BLEU scores on both original and original+synthetic data. The
publicly available bitext dataset can be used for research purposes.
","[{'version': 'v1', 'created': 'Fri, 25 Aug 2023 17:13:20 GMT'}]",2023-08-28,"[['Sari', 'Sakayo Toadoum', ''], ['Fan', 'Angela', ''], ['Seknewna', 'Lema Logamou', '']]"
1509.03611,Ella Rabinovich,"Ella Rabinovich, Shuly Wintner, Ofek Luis Lewinsohn",A Parallel Corpus of Translationese,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We describe a set of bilingual English--French and English--German parallel
corpora in which the direction of translation is accurately and reliably
annotated. The corpora are diverse, consisting of parliamentary proceedings,
literary works, transcriptions of TED talks and political commentary. They will
be instrumental for research of translationese and its applications to (human
and machine) translation; specifically, they can be used for the task of
translationese identification, a research direction that enjoys a growing
interest in recent years. To validate the quality and reliability of the
corpora, we replicated previous results of supervised and unsupervised
identification of translationese, and further extended the experiments to
additional datasets and languages.
","[{'version': 'v1', 'created': 'Fri, 11 Sep 2015 19:07:49 GMT'}, {'version': 'v2', 'created': 'Sun, 6 Mar 2016 13:41:11 GMT'}]",2016-03-08,"[['Rabinovich', 'Ella', ''], ['Wintner', 'Shuly', ''], ['Lewinsohn', 'Ofek Luis', '']]"
1611.05010,Kejun Huang,"Kejun Huang, Xiao Fu, Nicholas D. Sidiropoulos",Anchor-Free Correlated Topic Modeling: Identifiability and Algorithm,,,,,stat.ML cs.CL cs.IR cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In topic modeling, many algorithms that guarantee identifiability of the
topics have been developed under the premise that there exist anchor words --
i.e., words that only appear (with positive probability) in one topic.
Follow-up work has resorted to three or higher-order statistics of the data
corpus to relax the anchor word assumption. Reliable estimates of higher-order
statistics are hard to obtain, however, and the identification of topics under
those models hinges on uncorrelatedness of the topics, which can be
unrealistic. This paper revisits topic modeling based on second-order moments,
and proposes an anchor-free topic mining framework. The proposed approach
guarantees the identification of the topics under a much milder condition
compared to the anchor-word assumption, thereby exhibiting much better
robustness in practice. The associated algorithm only involves one
eigen-decomposition and a few small linear programs. This makes it easy to
implement and scale up to very large problem instances. Experiments using the
TDT2 and Reuters-21578 corpus demonstrate that the proposed anchor-free
approach exhibits very favorable performance (measured using coherence,
similarity count, and clustering accuracy metrics) compared to the prior art.
","[{'version': 'v1', 'created': 'Tue, 15 Nov 2016 20:06:40 GMT'}]",2016-11-16,"[['Huang', 'Kejun', ''], ['Fu', 'Xiao', ''], ['Sidiropoulos', 'Nicholas D.', '']]"
2307.00132,Harsha Vardhan N,"N Harsha Vardhan, Manav Chaudhary",iMETRE: Incorporating Markers of Entity Types for Relation Extraction,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Sentence-level relation extraction (RE) aims to identify the relationship
between 2 entities given a contextual sentence. While there have been many
attempts to solve this problem, the current solutions have a lot of room to
improve. In this paper, we approach the task of relationship extraction in the
financial dataset REFinD. Our approach incorporates typed entity markers
representations and various models finetuned on the dataset, which has allowed
us to achieve an F1 score of 69.65% on the validation set. Through this paper,
we discuss various approaches and possible limitations.
","[{'version': 'v1', 'created': 'Fri, 30 Jun 2023 20:54:41 GMT'}]",2023-07-04,"[['Vardhan', 'N Harsha', ''], ['Chaudhary', 'Manav', '']]"
2010.05581,Sicheng Yu,"Sicheng Yu, Yulei Niu, Shuohang Wang, Jing Jiang, Qianru Sun","Counterfactual Variable Control for Robust and Interpretable Question
  Answering",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Deep neural network based question answering (QA) models are neither robust
nor explainable in many cases. For example, a multiple-choice QA model, tested
without any input of question, is surprisingly ""capable"" to predict the most of
correct options. In this paper, we inspect such spurious ""capability"" of QA
models using causal inference. We find the crux is the shortcut correlation,
e.g., unrobust word alignment between passage and options learned by the
models. We propose a novel approach called Counterfactual Variable Control
(CVC) that explicitly mitigates any shortcut correlation and preserves the
comprehensive reasoning for robust QA. Specifically, we leverage multi-branch
architecture that allows us to disentangle robust and shortcut correlations in
the training process of QA. We then conduct two novel CVC inference methods (on
trained models) to capture the effect of comprehensive reasoning as the final
prediction. For evaluation, we conduct extensive experiments using two BERT
backbones on both multi-choice and span-extraction QA benchmarks. The results
show that our CVC achieves high robustness against a variety of adversarial
attacks in QA while maintaining good interpretation ability.
","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 10:09:05 GMT'}]",2020-10-13,"[['Yu', 'Sicheng', ''], ['Niu', 'Yulei', ''], ['Wang', 'Shuohang', ''], ['Jiang', 'Jing', ''], ['Sun', 'Qianru', '']]"
2207.02419,Man Luo,"Man Luo, Sharad Saxena, Swaroop Mishra, Mihir Parmar, Chitta Baral",BioTABQA: Instruction Learning for Biomedical Table Question Answering,BioASQ10 Workshop,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Table Question Answering (TQA) is an important but under-explored task. Most
of the existing QA datasets are in unstructured text format and only few of
them use tables as the context. To the best of our knowledge, none of TQA
datasets exist in the biomedical domain where tables are frequently used to
present information. In this paper, we first curate a table question answering
dataset, BioTABQA, using 22 templates and the context from a biomedical
textbook on differential diagnosis. BioTABQA can not only be used to teach a
model how to answer questions from tables but also evaluate how a model
generalizes to unseen questions, an important scenario for biomedical
applications. To achieve the generalization evaluation, we divide the templates
into 17 training and 5 cross-task evaluations. Then, we develop two baselines
using single and multi-tasks learning on BioTABQA. Furthermore, we explore
instructional learning, a recent technique showing impressive generalizing
performance. Experimental results show that our instruction-tuned model
outperforms single and multi-task baselines on an average by ~23% and ~6%
across various evaluation settings, and more importantly, instruction-tuned
model outperforms baselines by ~5% on cross-tasks.
","[{'version': 'v1', 'created': 'Wed, 6 Jul 2022 03:40:10 GMT'}]",2022-07-07,"[['Luo', 'Man', ''], ['Saxena', 'Sharad', ''], ['Mishra', 'Swaroop', ''], ['Parmar', 'Mihir', ''], ['Baral', 'Chitta', '']]"
2401.01600,Xianjun Yang,"Xianjun Yang, Junfeng Gao, Wenxin Xue, Erik Alexandersson",PLLaMa: An Open-source Large Language Model for Plant Science,Work in progress,,,,cs.CL cs.AI cs.CE cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Large Language Models (LLMs) have exhibited remarkable capabilities in
understanding and interacting with natural language across various sectors.
However, their effectiveness is limited in specialized areas requiring high
accuracy, such as plant science, due to a lack of specific expertise in these
fields. This paper introduces PLLaMa, an open-source language model that
evolved from LLaMa-2. It's enhanced with a comprehensive database, comprising
more than 1.5 million scholarly articles in plant science. This development
significantly enriches PLLaMa with extensive knowledge and proficiency in plant
and agricultural sciences. Our initial tests, involving specific datasets
related to plants and agriculture, show that PLLaMa substantially improves its
understanding of plant science-related topics. Moreover, we have formed an
international panel of professionals, including plant scientists, agricultural
engineers, and plant breeders. This team plays a crucial role in verifying the
accuracy of PLLaMa's responses to various academic inquiries, ensuring its
effective and reliable application in the field. To support further research
and development, we have made the model's checkpoints and source codes
accessible to the scientific community. These resources are available for
download at \url{https://github.com/Xianjun-Yang/PLLaMa}.
","[{'version': 'v1', 'created': 'Wed, 3 Jan 2024 08:06:26 GMT'}]",2024-01-04,"[['Yang', 'Xianjun', ''], ['Gao', 'Junfeng', ''], ['Xue', 'Wenxin', ''], ['Alexandersson', 'Erik', '']]"
1811.05889,Bowen Li,"Bowen Li, Jianpeng Cheng, Yang Liu and Frank Keller","Dependency Grammar Induction with a Neural Variational Transition-based
  Parser",AAAI-19,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Dependency grammar induction is the task of learning dependency syntax
without annotated training data. Traditional graph-based models with global
inference achieve state-of-the-art results on this task but they require
$O(n^3)$ run time. Transition-based models enable faster inference with $O(n)$
time complexity, but their performance still lags behind. In this work, we
propose a neural transition-based parser for dependency grammar induction,
whose inference procedure utilizes rich neural features with $O(n)$ time
complexity. We train the parser with an integration of variational inference,
posterior regularization and variance reduction techniques. The resulting
framework outperforms previous unsupervised transition-based dependency parsers
and achieves performance comparable to graph-based models, both on the English
Penn Treebank and on the Universal Dependency Treebank. In an empirical
comparison, we show that our approach substantially increases parsing speed
over graph-based models.
","[{'version': 'v1', 'created': 'Wed, 14 Nov 2018 16:30:22 GMT'}]",2018-11-15,"[['Li', 'Bowen', ''], ['Cheng', 'Jianpeng', ''], ['Liu', 'Yang', ''], ['Keller', 'Frank', '']]"
1911.09826,Amir Zadeh,"Amir Zadeh, Chengfeng Mao, Kelly Shi, Yiwei Zhang, Paul Pu Liang,
  Soujanya Poria, Louis-Philippe Morency",Factorized Multimodal Transformer for Multimodal Sequential Learning,,,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The complex world around us is inherently multimodal and sequential
(continuous). Information is scattered across different modalities and requires
multiple continuous sensors to be captured. As machine learning leaps towards
better generalization to real world, multimodal sequential learning becomes a
fundamental research area. Arguably, modeling arbitrarily distributed
spatio-temporal dynamics within and across modalities is the biggest challenge
in this research area. In this paper, we present a new transformer model,
called the Factorized Multimodal Transformer (FMT) for multimodal sequential
learning. FMT inherently models the intramodal and intermodal (involving two or
more modalities) dynamics within its multimodal input in a factorized manner.
The proposed factorization allows for increasing the number of self-attentions
to better model the multimodal phenomena at hand; without encountering
difficulties during training (e.g. overfitting) even on relatively low-resource
setups. All the attention mechanisms within FMT have a full time-domain
receptive field which allows them to asynchronously capture long-range
multimodal dynamics. In our experiments we focus on datasets that contain the
three commonly studied modalities of language, vision and acoustic. We perform
a wide range of experiments, spanning across 3 well-studied datasets and 21
distinct labels. FMT shows superior performance over previously proposed
models, setting new state of the art in the studied datasets.
","[{'version': 'v1', 'created': 'Fri, 22 Nov 2019 03:14:32 GMT'}]",2019-11-25,"[['Zadeh', 'Amir', ''], ['Mao', 'Chengfeng', ''], ['Shi', 'Kelly', ''], ['Zhang', 'Yiwei', ''], ['Liang', 'Paul Pu', ''], ['Poria', 'Soujanya', ''], ['Morency', 'Louis-Philippe', '']]"
2312.03729,Stephen Casper,"Kevin Liu, Stephen Casper, Dylan Hadfield-Menell, Jacob Andreas","Cognitive Dissonance: Why Do Language Model Outputs Disagree with
  Internal Representations of Truthfulness?","Accepted to EMNLP, 2024",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Neural language models (LMs) can be used to evaluate the truth of factual
statements in two ways: they can be either queried for statement probabilities,
or probed for internal representations of truthfulness. Past work has found
that these two procedures sometimes disagree, and that probes tend to be more
accurate than LM outputs. This has led some researchers to conclude that LMs
""lie"" or otherwise encode non-cooperative communicative intents. Is this an
accurate description of today's LMs, or can query-probe disagreement arise in
other ways? We identify three different classes of disagreement, which we term
confabulation, deception, and heterogeneity. In many cases, the superiority of
probes is simply attributable to better calibration on uncertain answers rather
than a greater fraction of correct, high-confidence answers. In some cases,
queries and probes perform better on different subsets of inputs, and accuracy
can further be improved by ensembling the two. Code is available at
github.com/lingo-mit/lm-truthfulness.
","[{'version': 'v1', 'created': 'Mon, 27 Nov 2023 18:59:14 GMT'}]",2023-12-08,"[['Liu', 'Kevin', ''], ['Casper', 'Stephen', ''], ['Hadfield-Menell', 'Dylan', ''], ['Andreas', 'Jacob', '']]"
2105.00944,Antonio Bruto da Costa,"Priyanka Sinha, Pabitra Mitra, Antonio Anastasio Bruto da Costa,
  Nikolaos Kekatos",Explaining Outcomes of Multi-Party Dialogues using Causal Learning,,,,,cs.AI cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Multi-party dialogues are common in enterprise social media on technical as
well as non-technical topics. The outcome of a conversation may be positive or
negative. It is important to analyze why a dialogue ends with a particular
sentiment from the point of view of conflict analysis as well as future
collaboration design. We propose an explainable time series mining algorithm
for such analysis. A dialogue is represented as an attributed time series of
occurrences of keywords, EMPATH categories, and inferred sentiments at various
points in its progress. A special decision tree, with decision metrics that
take into account temporal relationships between dialogue events, is used for
predicting the cause of the outcome sentiment. Interpretable rules mined from
the classifier are used to explain the prediction. Experimental results are
presented for the enterprise social media posts in a large company.
","[{'version': 'v1', 'created': 'Mon, 3 May 2021 15:18:53 GMT'}]",2021-05-07,"[['Sinha', 'Priyanka', ''], ['Mitra', 'Pabitra', ''], ['da Costa', 'Antonio Anastasio Bruto', ''], ['Kekatos', 'Nikolaos', '']]"
2211.15363,Xutan Peng,"Xutan Peng, Yipeng Zhang, Jingfeng Yang, Mark Stevenson",On the Security Vulnerabilities of Text-to-SQL Models,ISSRE 2023: Best Paper Candidate,,,,cs.CL cs.CR cs.DB cs.LG cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Although it has been demonstrated that Natural Language Processing (NLP)
algorithms are vulnerable to deliberate attacks, the question of whether such
weaknesses can lead to software security threats is under-explored. To bridge
this gap, we conducted vulnerability tests on Text-to-SQL systems that are
commonly used to create natural language interfaces to databases. We showed
that the Text-to-SQL modules within six commercial applications can be
manipulated to produce malicious code, potentially leading to data breaches and
Denial of Service attacks. This is the first demonstration that NLP models can
be exploited as attack vectors in the wild. In addition, experiments using four
open-source language models verified that straightforward backdoor attacks on
Text-to-SQL systems achieve a 100% success rate without affecting their
performance. The aim of this work is to draw the community's attention to
potential software security issues associated with NLP algorithms and encourage
exploration of methods to mitigate against them.
","[{'version': 'v1', 'created': 'Mon, 28 Nov 2022 14:38:45 GMT'}, {'version': 'v2', 'created': 'Fri, 3 Mar 2023 11:10:16 GMT'}, {'version': 'v3', 'created': 'Thu, 12 Oct 2023 16:12:57 GMT'}]",2023-10-13,"[['Peng', 'Xutan', ''], ['Zhang', 'Yipeng', ''], ['Yang', 'Jingfeng', ''], ['Stevenson', 'Mark', '']]"
1807.07517,Sudip Mittal,"Priyanka Ranade, Sudip Mittal, Anupam Joshi, Karuna Joshi","Using Deep Neural Networks to Translate Multi-lingual Threat
  Intelligence",,,,,cs.CL cs.CR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The multilingual nature of the Internet increases complications in the
cybersecurity community's ongoing efforts to strategically mine threat
intelligence from OSINT data on the web. OSINT sources such as social media,
blogs, and dark web vulnerability markets exist in diverse languages and hinder
security analysts, who are unable to draw conclusions from intelligence in
languages they don't understand. Although third party translation engines are
growing stronger, they are unsuited for private security environments. First,
sensitive intelligence is not a permitted input to third party engines due to
privacy and confidentiality policies. In addition, third party engines produce
generalized translations that tend to lack exclusive cybersecurity terminology.
In this paper, we address these issues and describe our system that enables
threat intelligence understanding across unfamiliar languages. We create a
neural network based system that takes in cybersecurity data in a different
language and outputs the respective English translation. The English
translation can then be understood by an analyst, and can also serve as input
to an AI based cyber-defense system that can take mitigative action. As a proof
of concept, we have created a pipeline which takes Russian threats and
generates its corresponding English, RDF, and vectorized representations. Our
network optimizes translations on specifically, cybersecurity data.
","[{'version': 'v1', 'created': 'Thu, 19 Jul 2018 16:14:08 GMT'}]",2018-07-20,"[['Ranade', 'Priyanka', ''], ['Mittal', 'Sudip', ''], ['Joshi', 'Anupam', ''], ['Joshi', 'Karuna', '']]"
2202.03543,Puyuan Peng,Puyuan Peng and David Harwath,"Self-Supervised Representation Learning for Speech Using Visual
  Grounding and Masked Language Modeling","SAS workshop at AAAI2022, code and model weights available at
  https://github.com/jasonppy/FaST-VGS-Family",,,,eess.AS cs.CL cs.CV cs.LG cs.SD,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we describe our submissions to the ZeroSpeech 2021 Challenge
and SUPERB benchmark. Our submissions are based on the recently proposed
FaST-VGS model, which is a Transformer-based model that learns to associate raw
speech waveforms with semantically related images, all without the use of any
transcriptions of the speech. Additionally, we introduce a novel extension of
this model, FaST-VGS+, which is learned in a multi-task fashion with a masked
language modeling objective in addition to the visual grounding objective. On
ZeroSpeech 2021, we show that our models perform competitively on the ABX task,
outperform all other concurrent submissions on the Syntactic and Semantic
tasks, and nearly match the best system on the Lexical task. On the SUPERB
benchmark, we show that our models also achieve strong performance, in some
cases even outperforming the popular wav2vec2.0 model.
","[{'version': 'v1', 'created': 'Mon, 7 Feb 2022 22:09:54 GMT'}, {'version': 'v2', 'created': 'Wed, 2 Mar 2022 18:02:11 GMT'}]",2022-03-03,"[['Peng', 'Puyuan', ''], ['Harwath', 'David', '']]"
2204.06518,Claudio Angione,"Annalisa Occhipinti, Louis Rogers, Claudio Angione","A pipeline and comparative study of 12 machine learning models for text
  classification","This article has been accepted for publication in Expert Systems with
  Applications, April 2022. Published by Elsevier. All data, models, and code
  used in this work are available on GitHub at
  https://github.com/Angione-Lab/12-machine-learning-models-for-text-classification",,,,cs.IR cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Text-based communication is highly favoured as a communication method,
especially in business environments. As a result, it is often abused by sending
malicious messages, e.g., spam emails, to deceive users into relaying personal
information, including online accounts credentials or banking details. For this
reason, many machine learning methods for text classification have been
proposed and incorporated into the services of most email providers. However,
optimising text classification algorithms and finding the right tradeoff on
their aggressiveness is still a major research problem.
  We present an updated survey of 12 machine learning text classifiers applied
to a public spam corpus. A new pipeline is proposed to optimise hyperparameter
selection and improve the models' performance by applying specific methods
(based on natural language processing) in the preprocessing stage.
  Our study aims to provide a new methodology to investigate and optimise the
effect of different feature sizes and hyperparameters in machine learning
classifiers that are widely used in text classification problems. The
classifiers are tested and evaluated on different metrics including F-score
(accuracy), precision, recall, and run time. By analysing all these aspects, we
show how the proposed pipeline can be used to achieve a good accuracy towards
spam filtering on the Enron dataset, a widely used public email corpus.
Statistical tests and explainability techniques are applied to provide a robust
analysis of the proposed pipeline and interpret the classification outcomes of
the 12 machine learning models, also identifying words that drive the
classification results. Our analysis shows that it is possible to identify an
effective machine learning model to classify the Enron dataset with an F-score
of 94%.
","[{'version': 'v1', 'created': 'Mon, 4 Apr 2022 23:51:22 GMT'}]",2022-04-14,"[['Occhipinti', 'Annalisa', ''], ['Rogers', 'Louis', ''], ['Angione', 'Claudio', '']]"
2103.07659,Donghong Gu,"Jiaqian Wang, Donghong Gu, Chi Yang, Yun Xue, Zhengxin Song, Haoliang
  Zhao, Luwei Xiao","Targeted aspect based multimodal sentiment analysis:an attention capsule
  extraction and multi-head fusion network",,,,,cs.CL cs.MM,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Multimodal sentiment analysis has currently identified its significance in a
variety of domains. For the purpose of sentiment analysis, different aspects of
distinguishing modalities, which correspond to one target, are processed and
analyzed. In this work, we propose the targeted aspect-based multimodal
sentiment analysis (TABMSA) for the first time. Furthermore, an attention
capsule extraction and multi-head fusion network (EF-Net) on the task of TABMSA
is devised. The multi-head attention (MHA) based network and the ResNet-152 are
employed to deal with texts and images, respectively. The integration of MHA
and capsule network aims to capture the interaction among the multimodal
inputs. In addition to the targeted aspect, the information from the context
and the image is also incorporated for sentiment delivered. We evaluate the
proposed model on two manually annotated datasets. the experimental results
demonstrate the effectiveness of our proposed model for this new task.
","[{'version': 'v1', 'created': 'Sat, 13 Mar 2021 09:11:24 GMT'}]",2021-03-16,"[['Wang', 'Jiaqian', ''], ['Gu', 'Donghong', ''], ['Yang', 'Chi', ''], ['Xue', 'Yun', ''], ['Song', 'Zhengxin', ''], ['Zhao', 'Haoliang', ''], ['Xiao', 'Luwei', '']]"
2104.00824,David R Mortensen,"David R. Mortensen, Jordan Picone, Xinjian Li, and Kathleen Siminyu","Tusom2021: A Phonetically Transcribed Speech Dataset from an Endangered
  Language for Universal Phone Recognition Experiments","4 pages, 3 figures",,,,cs.CL cs.SD eess.AS,http://creativecommons.org/licenses/by/4.0/,"  There is growing interest in ASR systems that can recognize phones in a
language-independent fashion. There is additionally interest in building
language technologies for low-resource and endangered languages. However, there
is a paucity of realistic data that can be used to test such systems and
technologies. This paper presents a publicly available, phonetically
transcribed corpus of 2255 utterances (words and short phrases) in the
endangered Tangkhulic language East Tusom (no ISO 639-3 code), a Tibeto-Burman
language variety spoken mostly in India. Because the dataset is transcribed in
terms of phones, rather than phonemes, it is a better match for universal phone
recognition systems than many larger (phonemically transcribed) datasets. This
paper describes the dataset and the methodology used to produce it. It further
presents basic benchmarks of state-of-the-art universal phone recognition
systems on the dataset as baselines for future experiments.
","[{'version': 'v1', 'created': 'Fri, 2 Apr 2021 00:26:10 GMT'}]",2021-04-05,"[['Mortensen', 'David R.', ''], ['Picone', 'Jordan', ''], ['Li', 'Xinjian', ''], ['Siminyu', 'Kathleen', '']]"
1212.0927,Ke Wu,"Ke Wu, Philip Resnik","Two Algorithms for Finding $k$ Shortest Paths of a Weighted Pushdown
  Automaton",,,,,cs.CL cs.DS cs.FL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce efficient algorithms for finding the $k$ shortest paths of a
weighted pushdown automaton (WPDA), a compact representation of a weighted set
of strings with potential applications in parsing and machine translation. Both
of our algorithms are derived from the same weighted deductive logic
description of the execution of a WPDA using different search strategies.
Experimental results show our Algorithm 2 adds very little overhead vs. the
single shortest path algorithm, even with a large $k$.
","[{'version': 'v1', 'created': 'Wed, 5 Dec 2012 03:50:46 GMT'}, {'version': 'v2', 'created': 'Thu, 6 Dec 2012 05:39:15 GMT'}, {'version': 'v3', 'created': 'Tue, 5 Feb 2013 16:35:34 GMT'}]",2013-02-06,"[['Wu', 'Ke', ''], ['Resnik', 'Philip', '']]"
2110.11692,Peng Cui,"Peng Cui, Dongyao Hu, Le Hu",ListReader: Extracting List-form Answers for Opinion Questions,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Question answering (QA) is a high-level ability of natural language
processing. Most extractive ma-chine reading comprehension models focus on
factoid questions (e.g., who, when, where) and restrict the output answer as a
short and continuous span in the original passage. However, in real-world
scenarios, many questions are non-factoid (e.g., how, why) and their answers
are organized in the list format that contains multiple non-contiguous spans.
Naturally, existing extractive models are by design unable to answer such
questions. To address this issue, this paper proposes ListReader, a neural
ex-tractive QA model for list-form answer. In addition to learning the
alignment between the question and content, we introduce a heterogeneous graph
neural network to explicitly capture the associations among candidate segments.
Moreover, our model adopts a co-extraction setting that can extract either
span- or sentence-level answers, allowing better applicability. Two large-scale
datasets of different languages are constructed to support this study.
Experimental results show that our model considerably outperforms various
strong baselines. Further discussions provide an intuitive understanding of how
our model works and where the performance gain comes from.
","[{'version': 'v1', 'created': 'Fri, 22 Oct 2021 10:33:08 GMT'}]",2021-10-25,"[['Cui', 'Peng', ''], ['Hu', 'Dongyao', ''], ['Hu', 'Le', '']]"
2312.05640,Sumedha Rai,"Sumedha Rai, Tong Li, Bella Lyu",Keyword spotting -- Detecting commands in speech using deep learning,,,,,cs.SD cs.AI cs.CL cs.HC eess.AS,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Speech recognition has become an important task in the development of machine
learning and artificial intelligence. In this study, we explore the important
task of keyword spotting using speech recognition machine learning and deep
learning techniques. We implement feature engineering by converting raw
waveforms to Mel Frequency Cepstral Coefficients (MFCCs), which we use as
inputs to our models. We experiment with several different algorithms such as
Hidden Markov Model with Gaussian Mixture, Convolutional Neural Networks and
variants of Recurrent Neural Networks including Long Short-Term Memory and the
Attention mechanism. In our experiments, RNN with BiLSTM and Attention achieves
the best performance with an accuracy of 93.9 %
","[{'version': 'v1', 'created': 'Sat, 9 Dec 2023 19:04:17 GMT'}]",2023-12-12,"[['Rai', 'Sumedha', ''], ['Li', 'Tong', ''], ['Lyu', 'Bella', '']]"
2311.18730,Kshitij Deshpande,"Sudeep Mangalvedhekar, Kshitij Deshpande, Yash Patwardhan, Vedant
  Deshpande and Ravindra Murumkar","Mavericks at ArAIEval Shared Task: Towards a Safer Digital Space --
  Transformer Ensemble Models Tackling Deception and Persuasion","6 pages, 1 figure, accepted at the ArAIEval ArabicNLP workshop, EMNLP
  conference 2023",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we highlight our approach for the ""Arabic AI Tasks Evaluation
(ArAiEval) Shared Task 2023"". We present our approaches for task 1-A and task
2-A of the shared task which focus on persuasion technique detection and
disinformation detection respectively. Detection of persuasion techniques and
disinformation has become imperative to avoid distortion of authentic
information. The tasks use multigenre snippets of tweets and news articles for
the given binary classification problem. We experiment with several
transformer-based models that were pre-trained on the Arabic language. We
fine-tune these state-of-the-art models on the provided dataset. Ensembling is
employed to enhance the performance of the systems. We achieved a micro
F1-score of 0.742 on task 1-A (8th rank on the leaderboard) and 0.901 on task
2-A (7th rank on the leaderboard) respectively.
","[{'version': 'v1', 'created': 'Thu, 30 Nov 2023 17:26:57 GMT'}]",2023-12-01,"[['Mangalvedhekar', 'Sudeep', ''], ['Deshpande', 'Kshitij', ''], ['Patwardhan', 'Yash', ''], ['Deshpande', 'Vedant', ''], ['Murumkar', 'Ravindra', '']]"
2403.01187,Laurestine Bradford,"Laurestine Bradford, Timothy John O'Donnell, Siva Reddy",A Compositional Typed Semantics for Universal Dependencies,"10 pages, 6 figures, 1 table. For related code, see
  https://github.com/McGill-NLP/ud-to-meaning",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Languages may encode similar meanings using different sentence structures.
This makes it a challenge to provide a single set of formal rules that can
derive meanings from sentences in many languages at once. To overcome the
challenge, we can take advantage of language-general connections between
meaning and syntax, and build on cross-linguistically parallel syntactic
structures. We introduce UD Type Calculus, a compositional, principled, and
language-independent system of semantic types and logical forms for lexical
items which builds on a widely-used language-general dependency syntax
framework. We explain the essential features of UD Type Calculus, which all
involve giving dependency relations denotations just like those of words. These
allow UD-TC to derive correct meanings for sentences with a wide range of
syntactic structures by making use of dependency labels. Finally, we present
evaluation results on a large existing corpus of sentences and their logical
forms, showing that UD-TC can produce meanings comparable with our baseline.
","[{'version': 'v1', 'created': 'Sat, 2 Mar 2024 11:58:24 GMT'}]",2024-03-05,"[['Bradford', 'Laurestine', ''], [""O'Donnell"", 'Timothy John', ''], ['Reddy', 'Siva', '']]"
1909.10393,Blake Howald,"Berk Ekmekci, Eleanor Hagerman, Blake Howald","Specificity-Based Sentence Ordering for Multi-Document Extractive Risk
  Summarization",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Risk mining technologies seek to find relevant textual extractions that
capture entity-risk relationships. However, when high volume data sets are
processed, a multitude of relevant extractions can be returned, shifting the
focus to how best to present the results. We provide the details of a risk
mining multi-document extractive summarization system that produces high
quality output by modeling shifts in specificity that are characteristic of
well-formed discourses. In particular, we propose a novel selection algorithm
that alternates between extracts based on human curated or expanded autoencoded
key terms, which exhibit greater specificity or generality as it relates to an
entity-risk relationship. Through this extract ordering, and without the need
for more complex discourse-aware NLP, we induce felicitous shifts in
specificity in the alternating summaries that outperform non-alternating
summaries on automatic ROUGE and BLEU scores, and manual understandability and
preferences evaluations - achieving no statistically significant difference
when compared to human authored summaries.
","[{'version': 'v1', 'created': 'Mon, 23 Sep 2019 14:37:30 GMT'}]",2019-09-24,"[['Ekmekci', 'Berk', ''], ['Hagerman', 'Eleanor', ''], ['Howald', 'Blake', '']]"
2310.05344,Zhilin Wang,"Yi Dong, Zhilin Wang, Makesh Narsimhan Sreedhar, Xianchao Wu, Oleksii
  Kuchaiev","SteerLM: Attribute Conditioned SFT as an (User-Steerable) Alternative to
  RLHF",Findings of EMNLP 2023,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Model alignment with human preferences is an essential step in making Large
Language Models (LLMs) helpful and consistent with human values. It typically
consists of supervised fine-tuning (SFT) and reinforcement learning from human
feedback (RLHF) stages. However, RLHF faces inherent limitations stemming from
a complex training setup and its tendency to align the model with implicit
values that end users cannot control at run-time. Moreover, reward models in
RLHF stage commonly rely on single-dimensional feedback as opposed to explicit,
multifaceted signals that indicate attributes such as helpfulness, humor, and
toxicity. To address these limitations, we propose SteerLM, a supervised
fine-tuning method that empowers end-users to control responses during
inference. SteerLM conditions responses to conform to an explicitly defined
multi-dimensional set of attributes, thereby empowering a steerable AI capable
of generating helpful and high-quality responses while maintaining
customizability. Experiments show that SteerLM trained on open source datasets
generates responses that are preferred by human and automatic evaluators to
many state-of-the-art baselines trained with RLHF while being much easier to
train. Try SteerLM at https://huggingface.co/nvidia/SteerLM-llama2-13B
","[{'version': 'v1', 'created': 'Mon, 9 Oct 2023 02:11:21 GMT'}]",2023-10-10,"[['Dong', 'Yi', ''], ['Wang', 'Zhilin', ''], ['Sreedhar', 'Makesh Narsimhan', ''], ['Wu', 'Xianchao', ''], ['Kuchaiev', 'Oleksii', '']]"
1804.08875,Nikola Nikolov,"Nikola I. Nikolov, Michael Pfeiffer, Richard H.R. Hahnloser",Data-driven Summarization of Scientific Articles,"8 pages, 3 figures. 7th International Workshop on Mining Scientific
  Publications, LREC 2018",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Data-driven approaches to sequence-to-sequence modelling have been
successfully applied to short text summarization of news articles. Such models
are typically trained on input-summary pairs consisting of only a single or a
few sentences, partially due to limited availability of multi-sentence training
data. Here, we propose to use scientific articles as a new milestone for text
summarization: large-scale training data come almost for free with two types of
high-quality summaries at different levels - the title and the abstract. We
generate two novel multi-sentence summarization datasets from scientific
articles and test the suitability of a wide range of existing extractive and
abstractive neural network-based summarization approaches. Our analysis
demonstrates that scientific papers are suitable for data-driven text
summarization. Our results could serve as valuable benchmarks for scaling
sequence-to-sequence models to very long sequences.
","[{'version': 'v1', 'created': 'Tue, 24 Apr 2018 07:40:31 GMT'}]",2018-04-25,"[['Nikolov', 'Nikola I.', ''], ['Pfeiffer', 'Michael', ''], ['Hahnloser', 'Richard H. R.', '']]"
2303.11192,Vil\'em Zouhar,"Vil\'em Zouhar, Sunit Bhattacharya, Ond\v{r}ej Bojar",Multimodal Shannon Game with Images,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The Shannon game has long been used as a thought experiment in linguistics
and NLP, asking participants to guess the next letter in a sentence based on
its preceding context. We extend the game by introducing an optional extra
modality in the form of image information. To investigate the impact of
multimodal information in this game, we use human participants and a language
model (LM, GPT-2). We show that the addition of image information improves both
self-reported confidence and accuracy for both humans and LM. Certain word
classes, such as nouns and determiners, benefit more from the additional
modality information. The priming effect in both humans and the LM becomes more
apparent as the context size (extra modality information + sentence context)
increases. These findings highlight the potential of multimodal information in
improving language understanding and modeling.
","[{'version': 'v1', 'created': 'Mon, 20 Mar 2023 15:22:11 GMT'}]",2023-03-21,"[['Zouhar', 'Vilém', ''], ['Bhattacharya', 'Sunit', ''], ['Bojar', 'Ondřej', '']]"
2403.05216,Arkaitz Zubiaga,"Parisa Jamadi Khiabani, Arkaitz Zubiaga","SocialPET: Socially Informed Pattern Exploiting Training for Few-Shot
  Stance Detection in Social Media",,,,,cs.CL cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Stance detection, as the task of determining the viewpoint of a social media
post towards a target as 'favor' or 'against', has been understudied in the
challenging yet realistic scenario where there is limited labeled data for a
certain target. Our work advances research in few-shot stance detection by
introducing SocialPET, a socially informed approach to leveraging language
models for the task. Our proposed approach builds on the Pattern Exploiting
Training (PET) technique, which addresses classification tasks as cloze
questions through the use of language models. To enhance the approach with
social awareness, we exploit the social network structure surrounding social
media posts. We prove the effectiveness of SocialPET on two stance datasets,
Multi-target and P-Stance, outperforming competitive stance detection models as
well as the base model, PET, where the labeled instances for the target under
study is as few as 100. When we delve into the results, we observe that
SocialPET is comparatively strong in identifying instances of the `against'
class, where baseline models underperform.
","[{'version': 'v1', 'created': 'Fri, 8 Mar 2024 11:00:09 GMT'}]",2024-03-11,"[['Khiabani', 'Parisa Jamadi', ''], ['Zubiaga', 'Arkaitz', '']]"
1704.08893,Merel Scholman,"Vera Demberg, Fatemeh Torabi Asr, Merel Scholman","How compatible are our discourse annotations? Insights from mapping
  RST-DT and PDTB annotations",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Discourse-annotated corpora are an important resource for the community, but
they are often annotated according to different frameworks. This makes
comparison of the annotations difficult, thereby also preventing researchers
from searching the corpora in a unified way, or using all annotated data
jointly to train computational systems. Several theoretical proposals have
recently been made for mapping the relational labels of different frameworks to
each other, but these proposals have so far not been validated against existing
annotations. The two largest discourse relation annotated resources, the Penn
Discourse Treebank and the Rhetorical Structure Theory Discourse Treebank, have
however been annotated on the same text, allowing for a direct comparison of
the annotation layers. We propose a method for automatically aligning the
discourse segments, and then evaluate existing mapping proposals by comparing
the empirically observed against the proposed mappings. Our analysis highlights
the influence of segmentation on subsequent discourse relation labeling, and
shows that while agreement between frameworks is reasonable for explicit
relations, agreement on implicit relations is low. We identify several sources
of systematic discrepancies between the two annotation schemes and discuss
consequences of these discrepancies for future annotation and for the training
of automatic discourse relation labellers.
","[{'version': 'v1', 'created': 'Fri, 28 Apr 2017 12:09:31 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Mar 2018 12:39:50 GMT'}]",2018-03-16,"[['Demberg', 'Vera', ''], ['Asr', 'Fatemeh Torabi', ''], ['Scholman', 'Merel', '']]"
2109.00916,Peter Pol\'ak,Peter Pol\'ak and Ond\v{r}ej Bojar,Coarse-To-Fine And Cross-Lingual ASR Transfer,Accepted to ITAT WAFNL,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  End-to-end neural automatic speech recognition systems achieved recently
state-of-the-art results, but they require large datasets and extensive
computing resources. Transfer learning has been proposed to overcome these
difficulties even across languages, e.g., German ASR trained from an English
model. We experiment with much less related languages, reusing an English model
for Czech ASR. To simplify the transfer, we propose to use an intermediate
alphabet, Czech without accents, and document that it is a highly effective
strategy. The technique is also useful on Czech data alone, in the style of
coarse-to-fine training. We achieve substantial eductions in training time as
well as word error rate (WER).
","[{'version': 'v1', 'created': 'Thu, 2 Sep 2021 13:16:12 GMT'}]",2021-09-03,"[['Polák', 'Peter', ''], ['Bojar', 'Ondřej', '']]"
2304.02623,Zejiang Shen,"Zejiang Shen, Tal August, Pao Siangliulue, Kyle Lo, Jonathan Bragg,
  Jeff Hammerbacher, Doug Downey, Joseph Chee Chang, David Sontag","Beyond Summarization: Designing AI Support for Real-World Expository
  Writing Tasks","3 pages, 1 figure, accepted by The Second Workshop on Intelligent and
  Interactive Writing Assistants",,,,cs.CL cs.HC,http://creativecommons.org/licenses/by/4.0/,"  Large language models have introduced exciting new opportunities and
challenges in designing and developing new AI-assisted writing support tools.
Recent work has shown that leveraging this new technology can transform writing
in many scenarios such as ideation during creative writing, editing support,
and summarization. However, AI-supported expository writing--including
real-world tasks like scholars writing literature reviews or doctors writing
progress notes--is relatively understudied. In this position paper, we argue
that developing AI supports for expository writing has unique and exciting
research challenges and can lead to high real-world impacts. We characterize
expository writing as evidence-based and knowledge-generating: it contains
summaries of external documents as well as new information or knowledge. It can
be seen as the product of authors' sensemaking process over a set of source
documents, and the interplay between reading, reflection, and writing opens up
new opportunities for designing AI support. We sketch three components for AI
support design and discuss considerations for future research.
","[{'version': 'v1', 'created': 'Wed, 5 Apr 2023 17:47:11 GMT'}]",2023-04-06,"[['Shen', 'Zejiang', ''], ['August', 'Tal', ''], ['Siangliulue', 'Pao', ''], ['Lo', 'Kyle', ''], ['Bragg', 'Jonathan', ''], ['Hammerbacher', 'Jeff', ''], ['Downey', 'Doug', ''], ['Chang', 'Joseph Chee', ''], ['Sontag', 'David', '']]"
2306.06345,Shen-Sian Syu,"Shen-sian Syu, Juncheng Xie, Hung-yi Lee","Improving Non-autoregressive Translation Quality with Pretrained
  Language Model, Embedding Distillation and Upsampling Strategy for CTC","12 pages, 6 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Non-autoregressive approaches aim to improve the inference speed of
translation models, particularly those that generate output in a one-pass
forward manner. However, these approaches often suffer from a significant drop
in translation quality compared to autoregressive models. This paper introduces
a series of innovative techniques to enhance the translation quality of
Non-Autoregressive Translation (NAT) models while maintaining a substantial
acceleration in inference speed. We propose fine-tuning Pretrained Multilingual
Language Models (PMLMs) with the CTC loss to train NAT models effectively.
Furthermore, we adopt the MASK insertion scheme for up-sampling instead of
token duplication, and we present an embedding distillation method to further
enhance performance. In our experiments, our model outperforms the baseline
autoregressive model (Transformer \textit{base}) on multiple datasets,
including WMT'14 DE$\leftrightarrow$EN, WMT'16 RO$\leftrightarrow$EN, and
IWSLT'14 DE$\leftrightarrow$EN. Notably, our model achieves better performance
than the baseline autoregressive model on the IWSLT'14 En$\leftrightarrow$De
and WMT'16 En$\leftrightarrow$Ro datasets, even without using distillation data
during training. It is worth highlighting that on the IWSLT'14
DE$\rightarrow$EN dataset, our model achieves an impressive BLEU score of
39.59, setting a new state-of-the-art performance. Additionally, our model
exhibits a remarkable speed improvement of 16.35 times compared to the
autoregressive model.
","[{'version': 'v1', 'created': 'Sat, 10 Jun 2023 05:24:29 GMT'}, {'version': 'v2', 'created': 'Thu, 31 Aug 2023 03:14:47 GMT'}]",2023-09-01,"[['Syu', 'Shen-sian', ''], ['Xie', 'Juncheng', ''], ['Lee', 'Hung-yi', '']]"
2101.00196,Zhengxuan Wu,"Zhengxuan Wu, Desmond C. Ong","On Explaining Your Explanations of BERT: An Empirical Study with
  Sequence Classification",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  BERT, as one of the pretrianed language models, attracts the most attention
in recent years for creating new benchmarks across GLUE tasks via fine-tuning.
One pressing issue is to open up the blackbox and explain the decision makings
of BERT. A number of attribution techniques have been proposed to explain BERT
models, but are often limited to sequence to sequence tasks. In this paper, we
adapt existing attribution methods on explaining decision makings of BERT in
sequence classification tasks. We conduct extensive analyses of four existing
attribution methods by applying them to four different datasets in sentiment
analysis. We compare the reliability and robustness of each method via various
ablation studies. Furthermore, we test whether attribution methods explain
generalized semantics across semantically similar tasks. Our work provides
solid guidance for using attribution methods to explain decision makings of
BERT for downstream classification tasks.
","[{'version': 'v1', 'created': 'Fri, 1 Jan 2021 08:45:32 GMT'}]",2021-01-05,"[['Wu', 'Zhengxuan', ''], ['Ong', 'Desmond C.', '']]"
2401.02038,Yiheng Liu,"Yiheng Liu, Hao He, Tianle Han, Xu Zhang, Mengyuan Liu, Jiaming Tian,
  Yutong Zhang, Jiaqi Wang, Xiaohui Gao, Tianyang Zhong, Yi Pan, Shaochen Xu,
  Zihao Wu, Zhengliang Liu, Xin Zhang, Shu Zhang, Xintao Hu, Tuo Zhang, Ning
  Qiang, Tianming Liu, Bao Ge",Understanding LLMs: A Comprehensive Overview from Training to Inference,"30 pages,6 figures",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The introduction of ChatGPT has led to a significant increase in the
utilization of Large Language Models (LLMs) for addressing downstream tasks.
There's an increasing focus on cost-efficient training and deployment within
this context. Low-cost training and deployment of LLMs represent the future
development trend. This paper reviews the evolution of large language model
training techniques and inference deployment technologies aligned with this
emerging trend. The discussion on training includes various aspects, including
data preprocessing, training architecture, pre-training tasks, parallel
training, and relevant content related to model fine-tuning. On the inference
side, the paper covers topics such as model compression, parallel computation,
memory scheduling, and structural optimization. It also explores LLMs'
utilization and provides insights into their future development.
","[{'version': 'v1', 'created': 'Thu, 4 Jan 2024 02:43:57 GMT'}, {'version': 'v2', 'created': 'Sat, 6 Jan 2024 03:32:08 GMT'}]",2024-01-09,"[['Liu', 'Yiheng', ''], ['He', 'Hao', ''], ['Han', 'Tianle', ''], ['Zhang', 'Xu', ''], ['Liu', 'Mengyuan', ''], ['Tian', 'Jiaming', ''], ['Zhang', 'Yutong', ''], ['Wang', 'Jiaqi', ''], ['Gao', 'Xiaohui', ''], ['Zhong', 'Tianyang', ''], ['Pan', 'Yi', ''], ['Xu', 'Shaochen', ''], ['Wu', 'Zihao', ''], ['Liu', 'Zhengliang', ''], ['Zhang', 'Xin', ''], ['Zhang', 'Shu', ''], ['Hu', 'Xintao', ''], ['Zhang', 'Tuo', ''], ['Qiang', 'Ning', ''], ['Liu', 'Tianming', ''], ['Ge', 'Bao', '']]"
2210.11165,Shaobo Li,"Shaobo Li, Xiaoguang Li, Lifeng Shang, Chengjie Sun, Bingquan Liu,
  Zhenzhou Ji, Xin Jiang and Qun Liu",Pre-training Language Models with Deterministic Factual Knowledge,Accepted at EMNLP 2022,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Previous works show that Pre-trained Language Models (PLMs) can capture
factual knowledge. However, some analyses reveal that PLMs fail to perform it
robustly, e.g., being sensitive to the changes of prompts when extracting
factual knowledge. To mitigate this issue, we propose to let PLMs learn the
deterministic relationship between the remaining context and the masked
content. The deterministic relationship ensures that the masked factual content
can be deterministically inferable based on the existing clues in the context.
That would provide more stable patterns for PLMs to capture factual knowledge
than randomly masking. Two pre-training tasks are further introduced to
motivate PLMs to rely on the deterministic relationship when filling masks.
Specifically, we use an external Knowledge Base (KB) to identify deterministic
relationships and continuously pre-train PLMs with the proposed methods. The
factual knowledge probing experiments indicate that the continuously
pre-trained PLMs achieve better robustness in factual knowledge capturing.
Further experiments on question-answering datasets show that trying to learn a
deterministic relationship with the proposed methods can also help other
knowledge-intensive tasks.
","[{'version': 'v1', 'created': 'Thu, 20 Oct 2022 11:04:09 GMT'}]",2022-10-21,"[['Li', 'Shaobo', ''], ['Li', 'Xiaoguang', ''], ['Shang', 'Lifeng', ''], ['Sun', 'Chengjie', ''], ['Liu', 'Bingquan', ''], ['Ji', 'Zhenzhou', ''], ['Jiang', 'Xin', ''], ['Liu', 'Qun', '']]"
2106.06528,Yi-Lin Tuan,"Yi-Lin Tuan, Connor Pryor, Wenhu Chen, Lise Getoor, William Yang Wang",Local Explanation of Dialogue Response Generation,accepted to NeurIPS 2021,,,,cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In comparison to the interpretation of classification models, the explanation
of sequence generation models is also an important problem, however it has seen
little attention. In this work, we study model-agnostic explanations of a
representative text generation task -- dialogue response generation. Dialog
response generation is challenging with its open-ended sentences and multiple
acceptable responses. To gain insights into the reasoning process of a
generation model, we propose a new method, local explanation of response
generation (LERG) that regards the explanations as the mutual interaction of
segments in input and output sentences. LERG views the sequence prediction as
uncertainty estimation of a human response and then creates explanations by
perturbing the input and calculating the certainty change over the human
response. We show that LERG adheres to desired properties of explanations for
text generation including unbiased approximation, consistency and cause
identification. Empirically, our results show that our method consistently
improves other widely used methods on proposed automatic- and human- evaluation
metrics for this new task by 4.4-12.8%. Our analysis demonstrates that LERG can
extract both explicit and implicit relations between input and output segments.
","[{'version': 'v1', 'created': 'Fri, 11 Jun 2021 17:58:36 GMT'}, {'version': 'v2', 'created': 'Mon, 7 Feb 2022 06:28:59 GMT'}]",2022-02-08,"[['Tuan', 'Yi-Lin', ''], ['Pryor', 'Connor', ''], ['Chen', 'Wenhu', ''], ['Getoor', 'Lise', ''], ['Wang', 'William Yang', '']]"
1802.05322,Adam Nyberg,Adam Nyberg,Classifying movie genres by analyzing text reviews,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper proposes a method for classifying movie genres by only looking at
text reviews. The data used are from Large Movie Review Dataset v1.0 and IMDb.
This paper compared a K-nearest neighbors (KNN) model and a multilayer
perceptron (MLP) that uses tf-idf as input features. The paper also discusses
different evaluation metrics used when doing multi-label classification. For
the data used in this research, the KNN model performed the best with an
accuracy of 55.4\% and a Hamming loss of 0.047.
","[{'version': 'v1', 'created': 'Wed, 14 Feb 2018 21:04:15 GMT'}]",2018-02-16,"[['Nyberg', 'Adam', '']]"
2212.10498,Elron Bandel,"Elron Bandel, Yoav Katz, Noam Slonim, Liat Ein-Dor",SimpleStyle: An Adaptable Style Transfer Approach,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Attribute-controlled text rewriting, also known as text style-transfer, has a
crucial role in regulating attributes and biases of textual training data and a
machine generated text. In this work we present SimpleStyle, a minimalist yet
effective approach for style-transfer composed of two simple ingredients:
controlled denoising and output filtering. Despite the simplicity of our
approach, which can be succinctly described with a few lines of code, it is
competitive with previous state-of-the-art methods both in automatic and in
human evaluation. To demonstrate the adaptability and practical value of our
system beyond academic data, we apply SimpleStyle to transfer a wide range of
text attributes appearing in real-world textual data from social networks.
Additionally, we introduce a novel ""soft noising"" technique that further
improves the performance of our system. We also show that teaching a student
model to generate the output of SimpleStyle can result in a system that
performs style transfer of equivalent quality with only a single greedy-decoded
sample. Finally, we suggest our method as a remedy for the fundamental
incompatible baseline issue that holds progress in the field. We offer our
protocol as a simple yet strong baseline for works that wish to make
incremental advancements in the field of attribute controlled text rewriting.
","[{'version': 'v1', 'created': 'Tue, 20 Dec 2022 18:12:49 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Dec 2022 16:26:36 GMT'}]",2022-12-23,"[['Bandel', 'Elron', ''], ['Katz', 'Yoav', ''], ['Slonim', 'Noam', ''], ['Ein-Dor', 'Liat', '']]"
2111.01398,Hongru Wang,"Hongru Wang, Huimin Wang, Zezhong Wang, Kam-Fai Wong",Integrating Pretrained Language Model for Dialogue Policy Learning,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Reinforcement Learning (RL) has been witnessed its potential for training a
dialogue policy agent towards maximizing the accumulated rewards given from
users. However, the reward can be very sparse for it is usually only provided
at the end of a dialog session, which causes unaffordable interaction
requirements for an acceptable dialog agent. Distinguished from many efforts
dedicated to optimizing the policy and recovering the reward alternatively
which suffers from easily getting stuck in local optima and model collapse, we
decompose the adversarial training into two steps: 1) we integrate a
pre-trained language model as a discriminator to judge whether the current
system action is good enough for the last user action (i.e., \textit{next
action prediction}); 2) the discriminator gives and extra local dense reward to
guide the agent's exploration. The experimental result demonstrates that our
method significantly improves the complete rate (~4.4\%) and success rate
(~8.0\%) of the dialogue system.
","[{'version': 'v1', 'created': 'Tue, 2 Nov 2021 07:16:03 GMT'}]",2021-11-03,"[['Wang', 'Hongru', ''], ['Wang', 'Huimin', ''], ['Wang', 'Zezhong', ''], ['Wong', 'Kam-Fai', '']]"
2305.16426,Isabelle Lorge PhD,Isabelle Lorge and Janet Pierrehumbert,"Not wacky vs. definitely wacky: A study of scalar adverbs in pretrained
  language models","Published in BlackBoxNLP workshop, EMNLP 2023",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Vector space models of word meaning all share the assumption that words
occurring in similar contexts have similar meanings. In such models, words that
are similar in their topical associations but differ in their logical force
tend to emerge as semantically close, creating well-known challenges for NLP
applications that involve logical reasoning. Modern pretrained language models,
such as BERT, RoBERTa and GPT-3 hold the promise of performing better on
logical tasks than classic static word embeddings. However, reports are mixed
about their success. In the current paper, we advance this discussion through a
systematic study of scalar adverbs, an under-explored class of words with
strong logical force. Using three different tasks, involving both naturalistic
social media data and constructed examples, we investigate the extent to which
BERT, RoBERTa, GPT-2 and GPT-3 exhibit general, human-like, knowledge of these
common words. We ask: 1) Do the models distinguish amongst the three semantic
categories of MODALITY, FREQUENCY and DEGREE? 2) Do they have implicit
representations of full scales from maximally negative to maximally positive?
3) How do word frequency and contextual factors impact model performance? We
find that despite capturing some aspects of logical meaning, the models fall
far short of human performance.
","[{'version': 'v1', 'created': 'Thu, 25 May 2023 18:56:26 GMT'}, {'version': 'v2', 'created': 'Sun, 22 Oct 2023 17:06:35 GMT'}]",2023-10-24,"[['Lorge', 'Isabelle', ''], ['Pierrehumbert', 'Janet', '']]"
2402.10481,Yao-Tsung Chen,"Xiaorui Zuo, Yao-Tsung Chen, and Wolfgang Karl H\""ardle",Emoji Driven Crypto Assets Market Reactions,,,,,q-fin.CP cs.AI cs.CL cs.LG q-fin.ST,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In the burgeoning realm of cryptocurrency, social media platforms like
Twitter have become pivotal in influencing market trends and investor
sentiments. In our study, we leverage GPT-4 and a fine-tuned transformer-based
BERT model for a multimodal sentiment analysis, focusing on the impact of emoji
sentiment on cryptocurrency markets. By translating emojis into quantifiable
sentiment data, we correlate these insights with key market indicators like BTC
Price and the VCRIX index. This approach may be fed into the development of
trading strategies aimed at utilizing social media elements to identify and
forecast market trends. Crucially, our findings suggest that strategies based
on emoji sentiment can facilitate the avoidance of significant market downturns
and contribute to the stabilization of returns. This research underscores the
practical benefits of integrating advanced AI-driven analyses into financial
strategies, offering a nuanced perspective on the interplay between digital
communication and market dynamics in an academic context.
","[{'version': 'v1', 'created': 'Fri, 16 Feb 2024 07:05:49 GMT'}]",2024-02-19,"[['Zuo', 'Xiaorui', ''], ['Chen', 'Yao-Tsung', ''], ['Härdle', 'Wolfgang Karl', '']]"
2402.17493,Charles Alba,"Bing Xue, Charles Alba, Joanna Abraham, Thomas Kannampallil, Chenyang
  Lu","Prescribing Large Language Models for Perioperative Care: What's The
  Right Dose for Pre-trained Models?","Supplemental file available at: http://tinyurl.com/mszmjna9 models
  publicly available at:
  https://huggingface.co/cja5553/BJH-perioperative-notes-bioGPT AND
  https://huggingface.co/cja5553/BJH-perioperative-notes-bioGPT",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Postoperative risk predictions can inform effective perioperative care
management and planning. We aimed to assess whether clinical large language
models (LLMs) can predict postoperative risks using clinical texts with various
training strategies. The main cohort involved 84,875 records from Barnes Jewish
Hospital (BJH) system between 2018 and 2021. Methods were replicated on Beth
Israel Deaconess's MIMIC dataset. Both studies had mean duration of follow-up
based on the length of postoperative ICU stay less than 7 days. For the BJH
dataset, outcomes included 30-day mortality, pulmonary embolism (PE) and
pneumonia. Three domain adaptation and finetuning strategies were implemented
for BioGPT, ClinicalBERT and BioClinicalBERT: self-supervised objectives;
incorporating labels with semi-supervised fine-tuning; and foundational
modelling through multi-task learning. Model performance was compared using the
area under the receiver operating characteristic curve (AUROC) and the area
under the precision recall curve (AUPRC) for classification tasks, and mean
squared error (MSE) and R2 for regression tasks. Pre-trained LLMs outperformed
traditional word embeddings, with absolute maximal gains of 38.3% for AUROC and
14% for AUPRC. Adapting models further improved performance: (1)
self-supervised finetuning by 3.2% for AUROC and 1.5% for AUPRC; (2)
semi-supervised finetuning by 1.8% for AUROC and 2% for AUPRC, compared to
self-supervised finetuning; (3) foundational modelling by 3.6% for AUROC and
2.6% for AUPRC, compared to self-supervised finetuning. Pre-trained clinical
LLMs offer opportunities for postoperative risk predictions in unforeseen data,
with peaks in foundational models indicating the potential of task-agnostic
learning towards the generalizability of LLMs in perioperative care.
","[{'version': 'v1', 'created': 'Tue, 27 Feb 2024 13:18:00 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Feb 2024 05:51:15 GMT'}]",2024-02-29,"[['Xue', 'Bing', ''], ['Alba', 'Charles', ''], ['Abraham', 'Joanna', ''], ['Kannampallil', 'Thomas', ''], ['Lu', 'Chenyang', '']]"
2309.06557,Adam Lehavi,"Adam M. Lehavi, William McCormack, Noah Kornfeld and Solomon Glazer",Unsupervised Bias Detection in College Student Newspapers,"7 pages, 5 figures, 3 tables, submitted to AAAI2024",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This paper presents a pipeline with minimal human influence for scraping and
detecting bias on college newspaper archives. This paper introduces a framework
for scraping complex archive sites that automated tools fail to grab data from,
and subsequently generates a dataset of 14 student papers with 23,154 entries.
This data can also then be queried by keyword to calculate bias by comparing
the sentiment of a large language model summary to the original article. The
advantages of this approach are that it is less comparative than reconstruction
bias and requires less labelled data than generating keyword sentiment. Results
are calculated on politically charged words as well as control words to show
how conclusions can be drawn. The complete method facilitates the extraction of
nuanced insights with minimal assumptions and categorizations, paving the way
for a more objective understanding of bias within student newspaper sources.
","[{'version': 'v1', 'created': 'Mon, 11 Sep 2023 06:51:09 GMT'}]",2023-09-14,"[['Lehavi', 'Adam M.', ''], ['McCormack', 'William', ''], ['Kornfeld', 'Noah', ''], ['Glazer', 'Solomon', '']]"
1812.10991,Rudolf Hanel Ass Prof Dr,"Rudolf Hanel, Stefan Thurner","The role of grammar in transition-probabilities of subsequent words in
  English text","8 pages, 3 figures",,,,cs.CL physics.soc-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sentence formation is a highly structured, history-dependent, and
sample-space reducing (SSR) process. While the first word in a sentence can be
chosen from the entire vocabulary, typically, the freedom of choosing
subsequent words gets more and more constrained by grammar and context, as the
sentence progresses. This sample-space reducing property offers a natural
explanation of Zipf's law in word frequencies, however, it fails to capture the
structure of the word-to-word transition probability matrices of English text.
Here we adopt the view that grammatical constraints (such as
subject--predicate--object) locally re-order the word order in sentences that
are sampled with a SSR word generation process. We demonstrate that
superimposing grammatical structure -- as a local word re-ordering
(permutation) process -- on a sample-space reducing process is sufficient to
explain both, word frequencies and word-to-word transition probabilities. We
compare the quality of the grammatically ordered SSR model in reproducing
several test statistics of real texts with other text generation models, such
as the Bernoulli model, the Simon model, and the Monkey typewriting model.
","[{'version': 'v1', 'created': 'Fri, 28 Dec 2018 13:49:49 GMT'}]",2018-12-31,"[['Hanel', 'Rudolf', ''], ['Thurner', 'Stefan', '']]"
2104.15135,Piyawat Lertvittayakumjorn,"Piyawat Lertvittayakumjorn, Francesca Toni",Explanation-Based Human Debugging of NLP Models: A Survey,"Accepted for publication at TACL. This version is a pre-MIT Press
  publication version",,,,cs.CL cs.AI cs.HC cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Debugging a machine learning model is hard since the bug usually involves the
training data and the learning process. This becomes even harder for an opaque
deep learning model if we have no clue about how the model actually works. In
this survey, we review papers that exploit explanations to enable humans to
give feedback and debug NLP models. We call this problem explanation-based
human debugging (EBHD). In particular, we categorize and discuss existing work
along three dimensions of EBHD (the bug context, the workflow, and the
experimental setting), compile findings on how EBHD components affect the
feedback providers, and highlight open problems that could be future research
directions.
","[{'version': 'v1', 'created': 'Fri, 30 Apr 2021 17:53:07 GMT'}, {'version': 'v2', 'created': 'Sat, 25 Sep 2021 01:01:34 GMT'}, {'version': 'v3', 'created': 'Fri, 10 Dec 2021 21:34:18 GMT'}]",2021-12-14,"[['Lertvittayakumjorn', 'Piyawat', ''], ['Toni', 'Francesca', '']]"
2304.07242,Cheng Deng,"Cheng Deng, Jiaxin Ding, Luoyi Fu, Weinan Zhang, Xinbing Wang, Chenghu
  Zhou",Covidia: COVID-19 Interdisciplinary Academic Knowledge Graph,,,,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The pandemic of COVID-19 has inspired extensive works across different
research fields. Existing literature and knowledge platforms on COVID-19 only
focus on collecting papers on biology and medicine, neglecting the
interdisciplinary efforts, which hurdles knowledge sharing and research
collaborations between fields to address the problem. Studying
interdisciplinary researches requires effective paper category classification
and efficient cross-domain knowledge extraction and integration. In this work,
we propose Covidia, COVID-19 interdisciplinary academic knowledge graph to
bridge the gap between knowledge of COVID-19 on different domains. We design
frameworks based on contrastive learning for disciplinary classification, and
propose a new academic knowledge graph scheme for entity extraction, relation
classification and ontology management in accordance with interdisciplinary
researches. Based on Covidia, we also establish knowledge discovery benchmarks
for finding COVID-19 research communities and predicting potential links.
","[{'version': 'v1', 'created': 'Fri, 14 Apr 2023 16:45:38 GMT'}]",2023-04-17,"[['Deng', 'Cheng', ''], ['Ding', 'Jiaxin', ''], ['Fu', 'Luoyi', ''], ['Zhang', 'Weinan', ''], ['Wang', 'Xinbing', ''], ['Zhou', 'Chenghu', '']]"
2303.17466,Yong Cao,"Yong Cao, Li Zhou, Seolhwa Lee, Laura Cabello, Min Chen, Daniel
  Hershcovich","Assessing Cross-Cultural Alignment between ChatGPT and Human Societies:
  An Empirical Study",C3NLP@EACL 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The recent release of ChatGPT has garnered widespread recognition for its
exceptional ability to generate human-like responses in dialogue. Given its
usage by users from various nations and its training on a vast multilingual
corpus that incorporates diverse cultural and societal norms, it is crucial to
evaluate its effectiveness in cultural adaptation. In this paper, we
investigate the underlying cultural background of ChatGPT by analyzing its
responses to questions designed to quantify human cultural differences. Our
findings suggest that, when prompted with American context, ChatGPT exhibits a
strong alignment with American culture, but it adapts less effectively to other
cultural contexts. Furthermore, by using different prompts to probe the model,
we show that English prompts reduce the variance in model responses, flattening
out cultural differences and biasing them towards American culture. This study
provides valuable insights into the cultural implications of ChatGPT and
highlights the necessity of greater diversity and cultural awareness in
language technologies.
","[{'version': 'v1', 'created': 'Thu, 30 Mar 2023 15:43:39 GMT'}, {'version': 'v2', 'created': 'Fri, 31 Mar 2023 15:02:48 GMT'}]",2023-04-03,"[['Cao', 'Yong', ''], ['Zhou', 'Li', ''], ['Lee', 'Seolhwa', ''], ['Cabello', 'Laura', ''], ['Chen', 'Min', ''], ['Hershcovich', 'Daniel', '']]"
2306.02051,Xiaoyan Zhao,"Xiaoyan Zhao, Yang Deng, Min Yang, Lingzhi Wang, Rui Zhang, Hong
  Cheng, Wai Lam, Ying Shen, Ruifeng Xu","A Comprehensive Survey on Deep Learning for Relation Extraction: Recent
  Advances and New Frontiers",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Relation extraction (RE) involves identifying the relations between entities
from unstructured texts. RE serves as the foundation for many natural language
processing (NLP) applications, such as knowledge graph completion, question
answering, and information retrieval. In recent years, deep neural networks
have dominated the field of RE and made noticeable progress. Subsequently, the
large pre-trained language models (PLMs) have taken the state-of-the-art of RE
to a new level. This survey provides a comprehensive review of existing deep
learning techniques for RE. First, we introduce RE resources, including RE
datasets and evaluation metrics. Second, we propose a new taxonomy to
categorize existing works from three perspectives (text representation, context
encoding, and triplet prediction). Third, we discuss several important
challenges faced by RE and summarize potential techniques to tackle these
challenges. Finally, we outline some promising future directions and prospects
in this field. This survey is expected to facilitate researchers' collaborative
efforts to tackle the challenges of real-life RE systems.
","[{'version': 'v1', 'created': 'Sat, 3 Jun 2023 08:39:25 GMT'}, {'version': 'v2', 'created': 'Tue, 6 Jun 2023 12:39:21 GMT'}]",2023-06-07,"[['Zhao', 'Xiaoyan', ''], ['Deng', 'Yang', ''], ['Yang', 'Min', ''], ['Wang', 'Lingzhi', ''], ['Zhang', 'Rui', ''], ['Cheng', 'Hong', ''], ['Lam', 'Wai', ''], ['Shen', 'Ying', ''], ['Xu', 'Ruifeng', '']]"
2305.12233,Dylan Cope,"Dylan Cope, Peter McBurney",A Measure of Explanatory Effectiveness,"Presented at the 1st International Workshop on Trusted Automated
  Decision-Making (TADM) co-located with ETAPS 2021",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In most conversations about explanation and AI, the recipient of the
explanation (the explainee) is suspiciously absent, despite the problem being
ultimately communicative in nature. We pose the problem `explaining AI systems'
in terms of a two-player cooperative game in which each agent seeks to maximise
our proposed measure of explanatory effectiveness. This measure serves as a
foundation for the automated assessment of explanations, in terms of the
effects that any given action in the game has on the internal state of the
explainee.
","[{'version': 'v1', 'created': 'Sat, 20 May 2023 16:52:30 GMT'}]",2023-05-23,"[['Cope', 'Dylan', ''], ['McBurney', 'Peter', '']]"
2303.04226,Yihan Cao,"Yihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu,
  Lichao Sun","A Comprehensive Survey of AI-Generated Content (AIGC): A History of
  Generative AI from GAN to ChatGPT","44 pages, 15 figures",,,,cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, ChatGPT, along with DALL-E-2 and Codex,has been gaining significant
attention from society. As a result, many individuals have become interested in
related resources and are seeking to uncover the background and secrets behind
its impressive performance. In fact, ChatGPT and other Generative AI (GAI)
techniques belong to the category of Artificial Intelligence Generated Content
(AIGC), which involves the creation of digital content, such as images, music,
and natural language, through AI models. The goal of AIGC is to make the
content creation process more efficient and accessible, allowing for the
production of high-quality content at a faster pace. AIGC is achieved by
extracting and understanding intent information from instructions provided by
human, and generating the content according to its knowledge and the intent
information. In recent years, large-scale models have become increasingly
important in AIGC as they provide better intent extraction and thus, improved
generation results. With the growth of data and the size of the models, the
distribution that the model can learn becomes more comprehensive and closer to
reality, leading to more realistic and high-quality content generation. This
survey provides a comprehensive review on the history of generative models, and
basic components, recent advances in AIGC from unimodal interaction and
multimodal interaction. From the perspective of unimodality, we introduce the
generation tasks and relative models of text and image. From the perspective of
multimodality, we introduce the cross-application between the modalities
mentioned above. Finally, we discuss the existing open problems and future
challenges in AIGC.
","[{'version': 'v1', 'created': 'Tue, 7 Mar 2023 20:36:13 GMT'}]",2023-03-09,"[['Cao', 'Yihan', ''], ['Li', 'Siyu', ''], ['Liu', 'Yixin', ''], ['Yan', 'Zhiling', ''], ['Dai', 'Yutong', ''], ['Yu', 'Philip S.', ''], ['Sun', 'Lichao', '']]"
1906.01511,Hongtao Liu,"Xianchen Wang, Hongtao Liu, Peiyi Wang, Fangzhao Wu, Hongyan Xu,
  Wenjun Wang, Xing Xie","Neural Review Rating Prediction with Hierarchical Attentions and Latent
  Factors","4pages, 1 figures",,,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text reviews can provide rich useful semantic information for modeling users
and items, which can benefit rating prediction in recommendation. Different
words and reviews may have different informativeness for users or items.
Besides, different users and items should be personalized. Most existing works
regard all reviews equally or utilize a general attention mechanism. In this
paper, we propose a hierarchical attention model fusing latent factor model for
rating prediction with reviews, which can focus on important words and
informative reviews. Specially, we use the factor vectors of Latent Factor
Model to guide the attention network and combine the factor vectors with
feature representation learned from reviews to predict the final ratings.
Experiments on real-world datasets validate the effectiveness of our approach.
","[{'version': 'v1', 'created': 'Wed, 29 May 2019 14:16:28 GMT'}]",2019-06-05,"[['Wang', 'Xianchen', ''], ['Liu', 'Hongtao', ''], ['Wang', 'Peiyi', ''], ['Wu', 'Fangzhao', ''], ['Xu', 'Hongyan', ''], ['Wang', 'Wenjun', ''], ['Xie', 'Xing', '']]"
2306.01090,Xiuying Chen,"Xiuying Chen, Guodong Long, Chongyang Tao, Mingzhe Li, Xin Gao,
  Chengqi Zhang, Xiangliang Zhang",Improving the Robustness of Summarization Systems with Dual Augmentation,"10 pages, 6 figures, ACL 2023 main coference",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  A robust summarization system should be able to capture the gist of the
document, regardless of the specific word choices or noise in the input. In
this work, we first explore the summarization models' robustness against
perturbations including word-level synonym substitution and noise. To create
semantic-consistent substitutes, we propose a SummAttacker, which is an
efficient approach to generating adversarial samples based on language models.
Experimental results show that state-of-the-art summarization models have a
significant decrease in performance on adversarial and noisy test sets. Next,
we analyze the vulnerability of the summarization systems and explore improving
the robustness by data augmentation. Specifically, the first brittleness factor
we found is the poor understanding of infrequent words in the input.
Correspondingly, we feed the encoder with more diverse cases created by
SummAttacker in the input space. The other factor is in the latent space, where
the attacked inputs bring more variations to the hidden states. Hence, we
construct adversarial decoder input and devise manifold softmixing operation in
hidden space to introduce more diversity. Experimental results on Gigaword and
CNN/DM datasets demonstrate that our approach achieves significant improvements
over strong baselines and exhibits higher robustness on noisy, attacked, and
clean datasets.
","[{'version': 'v1', 'created': 'Thu, 1 Jun 2023 19:04:17 GMT'}]",2023-06-05,"[['Chen', 'Xiuying', ''], ['Long', 'Guodong', ''], ['Tao', 'Chongyang', ''], ['Li', 'Mingzhe', ''], ['Gao', 'Xin', ''], ['Zhang', 'Chengqi', ''], ['Zhang', 'Xiangliang', '']]"
2305.11038,Jiawei Chen,"Jiawei Chen, Yaojie Lu, Hongyu Lin, Jie Lou, Wei Jia, Dai Dai, Hua Wu,
  Boxi Cao, Xianpei Han and Le Sun",Learning In-context Learning for Named Entity Recognition,Accepted to ACL 2023 Main Conference,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Named entity recognition in real-world applications suffers from the
diversity of entity types, the emergence of new entity types, and the lack of
high-quality annotations. To address the above problems, this paper proposes an
in-context learning-based NER approach, which can effectively inject in-context
NER ability into PLMs and recognize entities of novel types on-the-fly using
only a few demonstrative instances. Specifically, we model PLMs as a
meta-function $\mathcal{ \lambda_ {\text{instruction, demonstrations, text}}.
M}$, and a new entity extractor can be implicitly constructed by applying new
instruction and demonstrations to PLMs, i.e., $\mathcal{ (\lambda . M)
}$(instruction, demonstrations) $\to$ $\mathcal{F}$ where $\mathcal{F}$ will be
a new entity extractor, i.e., $\mathcal{F}$: text $\to$ entities. To inject the
above in-context NER ability into PLMs, we propose a meta-function pre-training
algorithm, which pre-trains PLMs by comparing the (instruction,
demonstration)-initialized extractor with a surrogate golden extractor.
Experimental results on 4 few-shot NER datasets show that our method can
effectively inject in-context NER ability into PLMs and significantly
outperforms the PLMs+fine-tuning counterparts.
","[{'version': 'v1', 'created': 'Thu, 18 May 2023 15:31:34 GMT'}, {'version': 'v2', 'created': 'Tue, 23 May 2023 08:22:02 GMT'}, {'version': 'v3', 'created': 'Fri, 26 May 2023 05:44:00 GMT'}]",2023-05-29,"[['Chen', 'Jiawei', ''], ['Lu', 'Yaojie', ''], ['Lin', 'Hongyu', ''], ['Lou', 'Jie', ''], ['Jia', 'Wei', ''], ['Dai', 'Dai', ''], ['Wu', 'Hua', ''], ['Cao', 'Boxi', ''], ['Han', 'Xianpei', ''], ['Sun', 'Le', '']]"
1807.05151,Seid Muhie Yimam,Gregor Wiedemann and Seid Muhie Yimam and Chris Biemann,"New/s/leak 2.0 - Multilingual Information Extraction and Visualization
  for Investigative Journalism",Social Informatics 2018,,,,cs.CL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Investigative journalism in recent years is confronted with two major
challenges: 1) vast amounts of unstructured data originating from large text
collections such as leaks or answers to Freedom of Information requests, and 2)
multi-lingual data due to intensified global cooperation and communication in
politics, business and civil society. Faced with these challenges, journalists
are increasingly cooperating in international networks. To support such
collaborations, we present the new version of new/s/leak 2.0, our open-source
software for content-based searching of leaks. It includes three novel main
features: 1) automatic language detection and language-dependent information
extraction for 40 languages, 2) entity and keyword visualization for efficient
exploration, and 3) decentral deployment for analysis of confidential data from
various formats. We illustrate the new analysis capabilities with an exemplary
case study.
","[{'version': 'v1', 'created': 'Fri, 13 Jul 2018 15:51:31 GMT'}]",2018-07-17,"[['Wiedemann', 'Gregor', ''], ['Yimam', 'Seid Muhie', ''], ['Biemann', 'Chris', '']]"
1810.00647,I\~naki San Vicente Roncal,"I\~naki San Vicente, Xabier Saralegi, Rodrigo Agerri",Real Time Monitoring of Social Media and Digital Press,"Preprint submission, 35 pages (22 + references and Appendices)",,,,cs.CL cs.IR,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Talaia is a platform for monitoring social media and digital press. A
configurable crawler gathers content with respect to user defined domains or
topics. Crawled data is processed by means of the EliXa Sentiment Analysis
system. A Django powered interface provides data visualization for a user-based
analysis of the data. This paper presents the architecture of the system and
describes in detail its different components. To prove the validity of the
approach, two real use cases are accounted for: one in the cultural domain and
one in the political domain. Evaluation for the sentiment analysis task in both
scenarios is also provided, showing the capacity for domain adaptation.
","[{'version': 'v1', 'created': 'Fri, 28 Sep 2018 16:00:20 GMT'}, {'version': 'v2', 'created': 'Tue, 15 Jan 2019 16:56:26 GMT'}]",2019-01-16,"[['Vicente', 'Iñaki San', ''], ['Saralegi', 'Xabier', ''], ['Agerri', 'Rodrigo', '']]"
1611.08765,Jason Mielens,"Liang Sun, Jason Mielens, Jason Baldridge","Fill it up: Exploiting partial dependency annotations in a minimum
  spanning tree parser",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Unsupervised models of dependency parsing typically require large amounts of
clean, unlabeled data plus gold-standard part-of-speech tags. Adding indirect
supervision (e.g. language universals and rules) can help, but we show that
obtaining small amounts of direct supervision - here, partial dependency
annotations - provides a strong balance between zero and full supervision. We
adapt the unsupervised ConvexMST dependency parser to learn from partial
dependencies expressed in the Graph Fragment Language. With less than 24 hours
of total annotation, we obtain 7% and 17% absolute improvement in unlabeled
dependency scores for English and Spanish, respectively, compared to the same
parser using only universal grammar constraints.
","[{'version': 'v1', 'created': 'Sat, 26 Nov 2016 23:39:41 GMT'}]",2016-11-29,"[['Sun', 'Liang', ''], ['Mielens', 'Jason', ''], ['Baldridge', 'Jason', '']]"
2403.05365,Yasaman Boreshban,"Seyed Parsa Neshaei, Yasaman Boreshban, Gholamreza Ghassem-Sani, Seyed
  Abolghasem Mirroshandel","The Impact of Quantization on the Robustness of Transformer-based Text
  Classifiers",,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Transformer-based models have made remarkable advancements in various NLP
areas. Nevertheless, these models often exhibit vulnerabilities when confronted
with adversarial attacks. In this paper, we explore the effect of quantization
on the robustness of Transformer-based models. Quantization usually involves
mapping a high-precision real number to a lower-precision value, aiming at
reducing the size of the model at hand. To the best of our knowledge, this work
is the first application of quantization on the robustness of NLP models. In
our experiments, we evaluate the impact of quantization on BERT and DistilBERT
models in text classification using SST-2, Emotion, and MR datasets. We also
evaluate the performance of these models against TextFooler, PWWS, and PSO
adversarial attacks. Our findings show that quantization significantly improves
(by an average of 18.68%) the adversarial accuracy of the models. Furthermore,
we compare the effect of quantization versus that of the adversarial training
approach on robustness. Our experiments indicate that quantization increases
the robustness of the model by 18.80% on average compared to adversarial
training without imposing any extra computational overhead during training.
Therefore, our results highlight the effectiveness of quantization in improving
the robustness of NLP models.
","[{'version': 'v1', 'created': 'Fri, 8 Mar 2024 14:55:05 GMT'}]",2024-03-11,"[['Neshaei', 'Seyed Parsa', ''], ['Boreshban', 'Yasaman', ''], ['Ghassem-Sani', 'Gholamreza', ''], ['Mirroshandel', 'Seyed Abolghasem', '']]"
1910.09399,Haicheng Tao,"Jorge Agnese, Jonathan Herrera, Haicheng Tao, Xingquan Zhu","A Survey and Taxonomy of Adversarial Neural Networks for Text-to-Image
  Synthesis","Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery.
  2019",,,,cs.CV cs.CL cs.GR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text-to-image synthesis refers to computational methods which translate human
written textual descriptions, in the form of keywords or sentences, into images
with similar semantic meaning to the text. In earlier research, image synthesis
relied mainly on word to image correlation analysis combined with supervised
methods to find best alignment of the visual content matching to the text.
Recent progress in deep learning (DL) has brought a new set of unsupervised
deep learning methods, particularly deep generative models which are able to
generate realistic visual images using suitably trained neural network models.
In this paper, we review the most recent development in the text-to-image
synthesis research domain. Our survey first introduces image synthesis and its
challenges, and then reviews key concepts such as generative adversarial
networks (GANs) and deep convolutional encoder-decoder neural networks (DCNN).
After that, we propose a taxonomy to summarize GAN based text-to-image
synthesis into four major categories: Semantic Enhancement GANs, Resolution
Enhancement GANs, Diversity Enhancement GANS, and Motion Enhancement GANs. We
elaborate the main objective of each group, and further review typical GAN
architectures in each group. The taxonomy and the review outline the techniques
and the evolution of different approaches, and eventually provide a clear
roadmap to summarize the list of contemporaneous solutions that utilize GANs
and DCNNs to generate enthralling results in categories such as human faces,
birds, flowers, room interiors, object reconstruction from edge maps (games)
etc. The survey will conclude with a comparison of the proposed solutions,
challenges that remain unresolved, and future developments in the text-to-image
synthesis domain.
","[{'version': 'v1', 'created': 'Mon, 21 Oct 2019 14:23:14 GMT'}]",2019-10-22,"[['Agnese', 'Jorge', ''], ['Herrera', 'Jonathan', ''], ['Tao', 'Haicheng', ''], ['Zhu', 'Xingquan', '']]"
2308.10354,Zeinab Sadat Taghavi,"Zeinab Sadat Taghavi, Soroush Gooran, Seyed Arshan Dalili, Hamidreza
  Amirzadeh, Mohammad Jalal Nematbakhsh, Hossein Sameti","Imaginations of WALL-E : Reconstructing Experiences with an
  Imagination-Inspired Module for Advanced AI Systems","18 pages,",,,,cs.AI cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  In this paper, we introduce a novel Artificial Intelligence (AI) system
inspired by the philosophical and psychoanalytical concept of imagination as a
``Re-construction of Experiences"". Our AI system is equipped with an
imagination-inspired module that bridges the gap between textual inputs and
other modalities, enriching the derived information based on previously learned
experiences. A unique feature of our system is its ability to formulate
independent perceptions of inputs. This leads to unique interpretations of a
concept that may differ from human interpretations but are equally valid, a
phenomenon we term as ``Interpretable Misunderstanding"". We employ large-scale
models, specifically a Multimodal Large Language Model (MLLM), enabling our
proposed system to extract meaningful information across modalities while
primarily remaining unimodal. We evaluated our system against other large
language models across multiple tasks, including emotion recognition and
question-answering, using a zero-shot methodology to ensure an unbiased
scenario that may happen by fine-tuning. Significantly, our system outperformed
the best Large Language Models (LLM) on the MELD, IEMOCAP, and CoQA datasets,
achieving Weighted F1 (WF1) scores of 46.74%, 25.23%, and Overall F1 (OF1)
score of 17%, respectively, compared to 22.89%, 12.28%, and 7% from the
well-performing LLM. The goal is to go beyond the statistical view of language
processing and tie it to human concepts such as philosophy and psychoanalysis.
This work represents a significant advancement in the development of
imagination-inspired AI systems, opening new possibilities for AI to generate
deep and interpretable information across modalities, thereby enhancing
human-AI interaction.
","[{'version': 'v1', 'created': 'Sun, 20 Aug 2023 20:10:55 GMT'}]",2023-08-22,"[['Taghavi', 'Zeinab Sadat', ''], ['Gooran', 'Soroush', ''], ['Dalili', 'Seyed Arshan', ''], ['Amirzadeh', 'Hamidreza', ''], ['Nematbakhsh', 'Mohammad Jalal', ''], ['Sameti', 'Hossein', '']]"
2306.09968,Guoxing Yang,"Guangyu Wang, Guoxing Yang, Zongxin Du, Longjun Fan, Xiaohu Li","ClinicalGPT: Large Language Models Finetuned with Diverse Medical Data
  and Comprehensive Evaluation",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models have exhibited exceptional performance on various
Natural Language Processing (NLP) tasks, leveraging techniques such as the
pre-training, and instruction fine-tuning. Despite these advances, their
effectiveness in medical applications is limited, due to challenges such as
factual inaccuracies, reasoning abilities, and lack grounding in real-world
experience. In this study, we present ClinicalGPT, a language model explicitly
designed and optimized for clinical scenarios. By incorporating extensive and
diverse real-world data, such as medical records, domain-specific knowledge,
and multi-round dialogue consultations in the training process, ClinicalGPT is
better prepared to handle multiple clinical task. Furthermore, we introduce a
comprehensive evaluation framework that includes medical knowledge
question-answering, medical exams, patient consultations, and diagnostic
analysis of medical records. Our results demonstrate that ClinicalGPT
significantly outperforms other models in these tasks, highlighting the
effectiveness of our approach in adapting large language models to the critical
domain of healthcare.
","[{'version': 'v1', 'created': 'Fri, 16 Jun 2023 16:56:32 GMT'}]",2023-06-19,"[['Wang', 'Guangyu', ''], ['Yang', 'Guoxing', ''], ['Du', 'Zongxin', ''], ['Fan', 'Longjun', ''], ['Li', 'Xiaohu', '']]"
2308.03275,Xiachong Feng,"Xiachong Feng, Xiaocheng Feng, Xiyuan Du, Min-Yen Kan, Bing Qin","Adapter-based Selective Knowledge Distillation for Federated
  Multi-domain Meeting Summarization","This work has been submitted to the IEEE TASLP for possible
  publication. Copyright may be transferred without notice, after which this
  version may no longer be accessible",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Meeting summarization has emerged as a promising technique for providing
users with condensed summaries. However, existing work has focused on training
models on centralized data, neglecting real-world scenarios where meeting data
are infeasible to collect centrally, due to their sensitive nature. This gap
motivates us to explore federated learning for meeting summarization. Two
critical challenges impede progress. First, state-of-the-art summarizers are
based on parameter-heavy pre-trained models. Exchanging such a model's
parameters across clients imposes large bandwidth costs. Second, as real-world
meeting data belong to various domains and are distributed across clients, they
are instances of non-identically and independently distributed (non-IID). IID
assumptions do not hold, which changes which forms of learning algorithms best
apply. To address this, we propose Adapter-based Federated Selective Knowledge
Distillation (AdaFedSelecKD) for training performant client models.
Specifically, we develop an adapter-based summarization model where two
adapters cooperatively facilitate learning using fewer parameters to reduce
communication costs. Then, we devise a selective knowledge distillation
strategy, assisting clients in robustly handling domain-focused modelling on
their own data, while leveraging global parameters based on non-IID data.
Extensive experiments on the QMSum benchmark demonstrate AdaFedSelecKD can
achieve comparable performance with powerful centralized training methods, and
shows its generalizability and robustness.
","[{'version': 'v1', 'created': 'Mon, 7 Aug 2023 03:34:01 GMT'}]",2023-08-08,"[['Feng', 'Xiachong', ''], ['Feng', 'Xiaocheng', ''], ['Du', 'Xiyuan', ''], ['Kan', 'Min-Yen', ''], ['Qin', 'Bing', '']]"
2403.06350,Mohammed Safi Ur Rahman Khan,"Mohammed Safi Ur Rahman Khan, Priyam Mehta, Ananth Sankar, Umashankar
  Kumaravelan, Sumanth Doddapaneni, Suriyaprasaad G, Varun Balan G, Sparsh
  Jain, Anoop Kunchukuttan, Pratyush Kumar, Raj Dabre, Mitesh M. Khapra","IndicLLMSuite: A Blueprint for Creating Pre-training and Fine-Tuning
  Datasets for Indian Languages",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Despite the considerable advancements in English LLMs, the progress in
building comparable models for other languages has been hindered due to the
scarcity of tailored resources. Our work aims to bridge this divide by
introducing an expansive suite of resources specifically designed for the
development of Indic LLMs, covering 22 languages, containing a total of 251B
tokens and 74.8M instruction-response pairs. Recognizing the importance of both
data quality and quantity, our approach combines highly curated manually
verified data, unverified yet valuable data, and synthetic data. We build a
clean, open-source pipeline for curating pre-training data from diverse
sources, including websites, PDFs, and videos, incorporating best practices for
crawling, cleaning, flagging, and deduplication. For instruction-fine tuning,
we amalgamate existing Indic datasets, translate/transliterate English datasets
into Indian languages, and utilize LLaMa2 and Mixtral models to create
conversations grounded in articles from Indian Wikipedia and Wikihow.
Additionally, we address toxicity alignment by generating toxic prompts for
multiple scenarios and then generate non-toxic responses by feeding these toxic
prompts to an aligned LLaMa2 model. We hope that the datasets, tools, and
resources released as a part of this work will not only propel the research and
development of Indic LLMs but also establish an open-source blueprint for
extending such efforts to other languages. The data and other artifacts created
as part of this work are released with permissive licenses.
","[{'version': 'v1', 'created': 'Mon, 11 Mar 2024 00:46:56 GMT'}]",2024-03-12,"[['Khan', 'Mohammed Safi Ur Rahman', ''], ['Mehta', 'Priyam', ''], ['Sankar', 'Ananth', ''], ['Kumaravelan', 'Umashankar', ''], ['Doddapaneni', 'Sumanth', ''], ['G', 'Suriyaprasaad', ''], ['G', 'Varun Balan', ''], ['Jain', 'Sparsh', ''], ['Kunchukuttan', 'Anoop', ''], ['Kumar', 'Pratyush', ''], ['Dabre', 'Raj', ''], ['Khapra', 'Mitesh M.', '']]"
2302.05657,Thyge Enggaard,"Thyge Enggaard (1), August Lohse (1), Morten Axel Pedersen (1 and 2),
  Sune Lehmann (1 and 3) ((1) Copenhagen Center for Social Data Science,
  University of Copenhagen, Denmark, (2) Department of Anthropology, University
  of Copenhagen, Denmark, (3) DTU Compute, Technical University of Denmark,
  Denmark)","Dialectograms: Machine Learning Differences between Discursive
  Communities",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Word embeddings provide an unsupervised way to understand differences in word
usage between discursive communities. A number of recent papers have focused on
identifying words that are used differently by two or more communities. But
word embeddings are complex, high-dimensional spaces and a focus on identifying
differences only captures a fraction of their richness. Here, we take a step
towards leveraging the richness of the full embedding space, by using word
embeddings to map out how words are used differently. Specifically, we describe
the construction of dialectograms, an unsupervised way to visually explore the
characteristic ways in which each community use a focal word. Based on these
dialectograms, we provide a new measure of the degree to which words are used
differently that overcomes the tendency for existing measures to pick out low
frequent or polysemous words. We apply our methods to explore the discourses of
two US political subreddits and show how our methods identify stark affective
polarisation of politicians and political entities, differences in the
assessment of proper political action as well as disagreement about whether
certain issues require political intervention at all.
","[{'version': 'v1', 'created': 'Sat, 11 Feb 2023 11:32:08 GMT'}]",2023-02-14,"[['Enggaard', 'Thyge', '', '1 and 2'], ['Lohse', 'August', '', '1 and 2'], ['Pedersen', 'Morten Axel', '', '1 and 2'], ['Lehmann', 'Sune', '', '1 and 3']]"
2105.11294,Peter Wallis,Peter Wallis,"Introducing the Talk Markup Language (TalkML):Adding a little social
  intelligence to industrial speech interfaces","24 pages, 7 figures, 67 references",,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Virtual Personal Assistants like Siri have great potential but such
developments hit the fundamental problem of how to make computational devices
that understand human speech. Natural language understanding is one of the more
disappointing failures of AI research and it seems there is something we
computer scientists don't get about the nature of language. Of course
philosophers and linguists think quite differently about language and this
paper describes how we have taken ideas from other disciplines and implemented
them. The background to the work is to take seriously the notion of language as
action and look at what people actually do with language using the techniques
of Conversation Analysis. The observation has been that human communication is
(behind the scenes) about the management of social relations as well as the
(foregrounded) passing of information. To claim this is one thing but to
implement it requires a mechanism. The mechanism described here is based on the
notion of language being intentional - we think intentionally, talk about them
and recognise them in others - and cooperative in that we are compelled to help
out. The way we are compelled points to a solution to the ever present problem
of keeping the human on topic. The approach has led to a recent success in
which we significantly improve user satisfaction independent of task
completion. Talk Markup Language (TalkML) is a draft alternative to VoiceXML
that, we propose, greatly simplifies the scripting of interaction by providing
default behaviours for no input and not recognised speech events.
","[{'version': 'v1', 'created': 'Mon, 24 May 2021 14:25:35 GMT'}]",2021-05-25,"[['Wallis', 'Peter', '']]"
2311.01200,Evangelia Gogoulou,"Evangelia Gogoulou, Timoth\'ee Lesort, Magnus Boman, Joakim Nivre",Continual Learning Under Language Shift,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The recent increase in data and model scale for language model pre-training
has led to huge training costs. In scenarios where new data become available
over time, updating a model instead of fully retraining it would therefore
provide significant gains. We study the pros and cons of updating a language
model when new data comes from new languages -- the case of continual learning
under language shift. Starting from a monolingual English language model, we
incrementally add data from Danish, Icelandic, and Norwegian to investigate how
forward and backward transfer effects depend on pre-training order and
characteristics of languages, for three different model sizes. Our results show
that, while forward transfer is largely positive and independent of language
order, backward transfer can be positive or negative depending on the order and
characteristics of new languages. We explore a number of potentially
explanatory factors and find that a combination of language contamination and
syntactic similarity best fits our results.
","[{'version': 'v1', 'created': 'Thu, 2 Nov 2023 12:54:50 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Feb 2024 13:21:45 GMT'}, {'version': 'v3', 'created': 'Mon, 26 Feb 2024 08:20:03 GMT'}]",2024-02-27,"[['Gogoulou', 'Evangelia', ''], ['Lesort', 'Timothée', ''], ['Boman', 'Magnus', ''], ['Nivre', 'Joakim', '']]"
2303.09823,Angel Felipe Magnoss\~ao De Paula,"Angel Felipe Magnoss\~ao de Paula, Imene Bensalem, Paolo Rosso, Wajdi
  Zaghouani","Transformers and Ensemble methods: A solution for Hate Speech Detection
  in Arabic languages","7 pages, 3 tables",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  This paper describes our participation in the shared task of hate speech
detection, which is one of the subtasks of the CERIST NLP Challenge 2022. Our
experiments evaluate the performance of six transformer models and their
combination using 2 ensemble approaches. The best results on the training set,
in a five-fold cross validation scenario, were obtained by using the ensemble
approach based on the majority vote. The evaluation of this approach on the
test set resulted in an F1-score of 0.60 and an Accuracy of 0.86.
","[{'version': 'v1', 'created': 'Fri, 17 Mar 2023 08:02:54 GMT'}]",2023-03-20,"[['de Paula', 'Angel Felipe Magnossão', ''], ['Bensalem', 'Imene', ''], ['Rosso', 'Paolo', ''], ['Zaghouani', 'Wajdi', '']]"
2204.02658,Yingwen Fu,"Yingwen Fu and Jinyi Chen and Nankai Lin and Xixuan Huang and Xinying
  Qiu and Shengyi Jiang","Yunshan Cup 2020: Overview of the Part-of-Speech Tagging Task for
  Low-resourced Languages",,,,,cs.CL,http://creativecommons.org/publicdomain/zero/1.0/,"  The Yunshan Cup 2020 track focused on creating a framework for evaluating
different methods of part-of-speech (POS). There were two tasks for this track:
(1) POS tagging for the Indonesian language, and (2) POS tagging for the Lao
tagging. The Indonesian dataset is comprised of 10000 sentences from Indonesian
news within 29 tags. And the Lao dataset consists of 8000 sentences within 27
tags. 25 teams registered for the task. The methods of participants ranged from
feature-based to neural networks using either classical machine learning
techniques or ensemble methods. The best performing results achieve an accuracy
of 95.82% for Indonesian and 93.03%, showing that neural sequence labeling
models significantly outperform classic feature-based methods and rule-based
methods.
","[{'version': 'v1', 'created': 'Wed, 6 Apr 2022 08:16:22 GMT'}]",2022-04-07,"[['Fu', 'Yingwen', ''], ['Chen', 'Jinyi', ''], ['Lin', 'Nankai', ''], ['Huang', 'Xixuan', ''], ['Qiu', 'Xinying', ''], ['Jiang', 'Shengyi', '']]"
1703.08885,Yusuke Watanabe Dr.,"Yusuke Watanabe, Bhuwan Dhingra, Ruslan Salakhutdinov",Question Answering from Unstructured Text by Retrieval and Comprehension,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Open domain Question Answering (QA) systems must interact with external
knowledge sources, such as web pages, to find relevant information. Information
sources like Wikipedia, however, are not well structured and difficult to
utilize in comparison with Knowledge Bases (KBs). In this work we present a
two-step approach to question answering from unstructured text, consisting of a
retrieval step and a comprehension step. For comprehension, we present an RNN
based attention model with a novel mixture mechanism for selecting answers from
either retrieved articles or a fixed vocabulary. For retrieval we introduce a
hand-crafted model and a neural model for ranking relevant articles. We achieve
state-of-the-art performance on W IKI M OVIES dataset, reducing the error by
40%. Our experimental results further demonstrate the importance of each of the
introduced components.
","[{'version': 'v1', 'created': 'Sun, 26 Mar 2017 23:48:06 GMT'}]",2017-03-28,"[['Watanabe', 'Yusuke', ''], ['Dhingra', 'Bhuwan', ''], ['Salakhutdinov', 'Ruslan', '']]"
1809.01477,Sahib Singh Budhiraja,"Sahib Singh Budhiraja, Vijay Mago",A Supervised Learning Approach For Heading Detection,,,,,cs.IR cs.CL cs.LG stat.ML,http://creativecommons.org/publicdomain/zero/1.0/,"  As the Portable Document Format (PDF) file format increases in popularity,
research in analysing its structure for text extraction and analysis is
necessary. Detecting headings can be a crucial component of classifying and
extracting meaningful data. This research involves training a supervised
learning model to detect headings with features carefully selected through
recursive feature elimination. The best performing classifier had an accuracy
of 96.95%, sensitivity of 0.986 and a specificity of 0.953. This research into
heading detection contributes to the field of PDF based text extraction and can
be applied to the automation of large scale PDF text analysis in a variety of
professional and policy based contexts.
","[{'version': 'v1', 'created': 'Fri, 31 Aug 2018 19:31:05 GMT'}]",2018-09-06,"[['Budhiraja', 'Sahib Singh', ''], ['Mago', 'Vijay', '']]"
2008.06682,Rivindu Weerasekera,"Shamane Siriwardhana, Andrew Reis, Rivindu Weerasekera, Suranga
  Nanayakkara","Jointly Fine-Tuning ""BERT-like"" Self Supervised Models to Improve
  Multimodal Speech Emotion Recognition",Accepted to INTERSPEECH 2020,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multimodal emotion recognition from speech is an important area in affective
computing. Fusing multiple data modalities and learning representations with
limited amounts of labeled data is a challenging task. In this paper, we
explore the use of modality-specific ""BERT-like"" pretrained Self Supervised
Learning (SSL) architectures to represent both speech and text modalities for
the task of multimodal speech emotion recognition. By conducting experiments on
three publicly available datasets (IEMOCAP, CMU-MOSEI, and CMU-MOSI), we show
that jointly fine-tuning ""BERT-like"" SSL architectures achieve state-of-the-art
(SOTA) results. We also evaluate two methods of fusing speech and text
modalities and show that a simple fusion mechanism can outperform more complex
ones when using SSL models that have similar architectural properties to BERT.
","[{'version': 'v1', 'created': 'Sat, 15 Aug 2020 08:54:48 GMT'}]",2020-08-18,"[['Siriwardhana', 'Shamane', ''], ['Reis', 'Andrew', ''], ['Weerasekera', 'Rivindu', ''], ['Nanayakkara', 'Suranga', '']]"
2208.01299,Liangyu Chen,"Yunjie Ji, Liangyu Chen, Chenxiao Dou, Baochang Ma, Xiangang Li","To Answer or Not to Answer? Improving Machine Reading Comprehension
  Model with Span-based Contrastive Learning",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Machine Reading Comprehension with Unanswerable Questions is a difficult NLP
task, challenged by the questions which can not be answered from passages. It
is observed that subtle literal changes often make an answerable question
unanswerable, however, most MRC models fail to recognize such changes. To
address this problem, in this paper, we propose a span-based method of
Contrastive Learning (spanCL) which explicitly contrast answerable questions
with their answerable and unanswerable counterparts at the answer span level.
With spanCL, MRC models are forced to perceive crucial semantic changes from
slight literal differences. Experiments on SQuAD 2.0 dataset show that spanCL
can improve baselines significantly, yielding 0.86-2.14 absolute EM
improvements. Additional experiments also show that spanCL is an effective way
to utilize generated questions.
","[{'version': 'v1', 'created': 'Tue, 2 Aug 2022 08:09:05 GMT'}]",2022-08-03,"[['Ji', 'Yunjie', ''], ['Chen', 'Liangyu', ''], ['Dou', 'Chenxiao', ''], ['Ma', 'Baochang', ''], ['Li', 'Xiangang', '']]"
2309.00254,Varshini Subhash,"Varshini Subhash, Anna Bialas, Weiwei Pan, Finale Doshi-Velez","Why do universal adversarial attacks work on large language models?:
  Geometry might be the answer","2nd AdvML Frontiers Workshop at 40th International Conference on
  Machine Learning, Honolulu, Hawaii, USA, 2023",,,,cs.LG cs.CL cs.CR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transformer based large language models with emergent capabilities are
becoming increasingly ubiquitous in society. However, the task of understanding
and interpreting their internal workings, in the context of adversarial
attacks, remains largely unsolved. Gradient-based universal adversarial attacks
have been shown to be highly effective on large language models and potentially
dangerous due to their input-agnostic nature. This work presents a novel
geometric perspective explaining universal adversarial attacks on large
language models. By attacking the 117M parameter GPT-2 model, we find evidence
indicating that universal adversarial triggers could be embedding vectors which
merely approximate the semantic information in their adversarial training
region. This hypothesis is supported by white-box model analysis comprising
dimensionality reduction and similarity measurement of hidden representations.
We believe this new geometric perspective on the underlying mechanism driving
universal attacks could help us gain deeper insight into the internal workings
and failure modes of LLMs, thus enabling their mitigation.
","[{'version': 'v1', 'created': 'Fri, 1 Sep 2023 05:09:49 GMT'}]",2023-09-04,"[['Subhash', 'Varshini', ''], ['Bialas', 'Anna', ''], ['Pan', 'Weiwei', ''], ['Doshi-Velez', 'Finale', '']]"
1712.00170,Heng Wang,"Heng Wang, Zengchang Qin, Tao Wan","Text Generation Based on Generative Adversarial Nets with Latent
  Variable",,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  In this paper, we propose a model using generative adversarial net (GAN) to
generate realistic text. Instead of using standard GAN, we combine variational
autoencoder (VAE) with generative adversarial net. The use of high-level latent
random variables is helpful to learn the data distribution and solve the
problem that generative adversarial net always emits the similar data. We
propose the VGAN model where the generative model is composed of recurrent
neural network and VAE. The discriminative model is a convolutional neural
network. We train the model via policy gradient. We apply the proposed model to
the task of text generation and compare it to other recent neural network based
models, such as recurrent neural network language model and SeqGAN. We evaluate
the performance of the model by calculating negative log-likelihood and the
BLEU score. We conduct experiments on three benchmark datasets, and results
show that our model outperforms other previous models.
","[{'version': 'v1', 'created': 'Fri, 1 Dec 2017 03:14:51 GMT'}, {'version': 'v2', 'created': 'Wed, 7 Nov 2018 12:27:23 GMT'}]",2018-11-08,"[['Wang', 'Heng', ''], ['Qin', 'Zengchang', ''], ['Wan', 'Tao', '']]"
2310.06271,Ziwei Ji,"Ziwei Ji, Tiezheng Yu, Yan Xu, Nayeon Lee, Etsuko Ishii, Pascale Fung","Towards Mitigating Hallucination in Large Language Models via
  Self-Reflection",Accepted by the findings of EMNLP 2023,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have shown promise for generative and
knowledge-intensive tasks including question-answering (QA) tasks. However, the
practical deployment still faces challenges, notably the issue of
""hallucination"", where models generate plausible-sounding but unfaithful or
nonsensical information. This issue becomes particularly critical in the
medical domain due to the uncommon professional concepts and potential social
risks involved. This paper analyses the phenomenon of hallucination in medical
generative QA systems using widely adopted LLMs and datasets. Our investigation
centers on the identification and comprehension of common problematic answers,
with a specific emphasis on hallucination. To tackle this challenge, we present
an interactive self-reflection methodology that incorporates knowledge
acquisition and answer generation. Through this feedback process, our approach
steadily enhances the factuality, consistency, and entailment of the generated
answers. Consequently, we harness the interactivity and multitasking ability of
LLMs and produce progressively more precise and accurate answers. Experimental
results on both automatic and human evaluation demonstrate the superiority of
our approach in hallucination reduction compared to baselines.
","[{'version': 'v1', 'created': 'Tue, 10 Oct 2023 03:05:44 GMT'}]",2023-10-11,"[['Ji', 'Ziwei', ''], ['Yu', 'Tiezheng', ''], ['Xu', 'Yan', ''], ['Lee', 'Nayeon', ''], ['Ishii', 'Etsuko', ''], ['Fung', 'Pascale', '']]"
2208.00249,Feng Zhou,"Jackie Ayoub, Zifei Wang, Meitang Li, Huizhong Guo, Rini Sherony, Shan
  Bao, Feng Zhou","Cause-and-Effect Analysis of ADAS: A Comparison Study between Literature
  Review and Complaint Data",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Advanced driver assistance systems (ADAS) are designed to improve vehicle
safety. However, it is difficult to achieve such benefits without understanding
the causes and limitations of the current ADAS and their possible solutions.
This study 1) investigated the limitations and solutions of ADAS through a
literature review, 2) identified the causes and effects of ADAS through
consumer complaints using natural language processing models, and 3) compared
the major differences between the two. These two lines of research identified
similar categories of ADAS causes, including human factors, environmental
factors, and vehicle factors. However, academic research focused more on human
factors of ADAS issues and proposed advanced algorithms to mitigate such issues
while drivers complained more of vehicle factors of ADAS failures, which led to
associated top consequences. The findings from these two sources tend to
complement each other and provide important implications for the improvement of
ADAS in the future.
","[{'version': 'v1', 'created': 'Sat, 30 Jul 2022 15:15:58 GMT'}]",2022-08-02,"[['Ayoub', 'Jackie', ''], ['Wang', 'Zifei', ''], ['Li', 'Meitang', ''], ['Guo', 'Huizhong', ''], ['Sherony', 'Rini', ''], ['Bao', 'Shan', ''], ['Zhou', 'Feng', '']]"
2010.03017,Zirui Wang,"Zirui Wang, Zachary C. Lipton, Yulia Tsvetkov","On Negative Interference in Multilingual Models: Findings and A
  Meta-Learning Treatment",Published as a main conference paper at EMNLP 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Modern multilingual models are trained on concatenated text from multiple
languages in hopes of conferring benefits to each (positive transfer), with the
most pronounced benefits accruing to low-resource languages. However, recent
work has shown that this approach can degrade performance on high-resource
languages, a phenomenon known as negative interference. In this paper, we
present the first systematic study of negative interference. We show that,
contrary to previous belief, negative interference also impacts low-resource
languages. While parameters are maximally shared to learn language-universal
structures, we demonstrate that language-specific parameters do exist in
multilingual models and they are a potential cause of negative interference.
Motivated by these observations, we also present a meta-learning algorithm that
obtains better cross-lingual transferability and alleviates negative
interference, by adding language-specific layers as meta-parameters and
training them in a manner that explicitly improves shared layers'
generalization on all languages. Overall, our results show that negative
interference is more common than previously known, suggesting new directions
for improving multilingual representations.
","[{'version': 'v1', 'created': 'Tue, 6 Oct 2020 20:48:58 GMT'}]",2020-10-08,"[['Wang', 'Zirui', ''], ['Lipton', 'Zachary C.', ''], ['Tsvetkov', 'Yulia', '']]"
2107.00368,Razieh Baradaran,Razieh Baradaran and Hossein Amirkhani,"Ensemble Learning-Based Approach for Improving Generalization Capability
  of Machine Reading Comprehension Systems",,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Machine Reading Comprehension (MRC) is an active field in natural language
processing with many successful developed models in recent years. Despite their
high in-distribution accuracy, these models suffer from two issues: high
training cost and low out-of-distribution accuracy. Even though some approaches
have been presented to tackle the generalization problem, they have high,
intolerable training costs. In this paper, we investigate the effect of
ensemble learning approach to improve generalization of MRC systems without
retraining a big model. After separately training the base models with
different structures on different datasets, they are ensembled using weighting
and stacking approaches in probabilistic and non-probabilistic settings. Three
configurations are investigated including heterogeneous, homogeneous, and
hybrid on eight datasets and six state-of-the-art models. We identify the
important factors in the effectiveness of ensemble methods. Also, we compare
the robustness of ensemble and fine-tuned models against data distribution
shifts. The experimental results show the effectiveness and robustness of the
ensemble approach in improving the out-of-distribution accuracy of MRC systems,
especially when the base models are similar in accuracies.
","[{'version': 'v1', 'created': 'Thu, 1 Jul 2021 11:11:17 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Jul 2021 17:28:31 GMT'}]",2021-07-16,"[['Baradaran', 'Razieh', ''], ['Amirkhani', 'Hossein', '']]"
2006.05213,Sanghyun Yoo,"Sanghyun Yoo, Young-Seok Kim, Kang Hyun Lee, Kuhwan Jeong, Junhwi
  Choi, Hoshik Lee, Young Sang Choi",Graph-Aware Transformer: Is Attention All Graphs Need?,,,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Graphs are the natural data structure to represent relational and structural
information in many domains. To cover the broad range of graph-data
applications including graph classification as well as graph generation, it is
desirable to have a general and flexible model consisting of an encoder and a
decoder that can handle graph data. Although the representative encoder-decoder
model, Transformer, shows superior performance in various tasks especially of
natural language processing, it is not immediately available for graphs due to
their non-sequential characteristics. To tackle this incompatibility, we
propose GRaph-Aware Transformer (GRAT), the first Transformer-based model which
can encode and decode whole graphs in end-to-end fashion. GRAT is featured with
a self-attention mechanism adaptive to the edge information and an
auto-regressive decoding mechanism based on the two-path approach consisting of
sub-graph encoding path and node-and-edge generation path for each decoding
step. We empirically evaluated GRAT on multiple setups including encoder-based
tasks such as molecule property predictions on QM9 datasets and
encoder-decoder-based tasks such as molecule graph generation in the organic
molecule synthesis domain. GRAT has shown very promising results including
state-of-the-art performance on 4 regression tasks in QM9 benchmark.
","[{'version': 'v1', 'created': 'Tue, 9 Jun 2020 12:13:56 GMT'}]",2020-06-11,"[['Yoo', 'Sanghyun', ''], ['Kim', 'Young-Seok', ''], ['Lee', 'Kang Hyun', ''], ['Jeong', 'Kuhwan', ''], ['Choi', 'Junhwi', ''], ['Lee', 'Hoshik', ''], ['Choi', 'Young Sang', '']]"
2403.06591,Ruoxi Xu,"Ruoxi Xu, Hongyu Lin, Xianpei Han, Le Sun, Yingfei Sun",Academically intelligent LLMs are not necessarily socially intelligent,,,,,cs.CL cs.CY,http://creativecommons.org/licenses/by/4.0/,"  The academic intelligence of large language models (LLMs) has made remarkable
progress in recent times, but their social intelligence performance remains
unclear. Inspired by established human social intelligence frameworks,
particularly Daniel Goleman's social intelligence theory, we have developed a
standardized social intelligence test based on real-world social scenarios to
comprehensively assess the social intelligence of LLMs, termed as the
Situational Evaluation of Social Intelligence (SESI). We conducted an extensive
evaluation with 13 recent popular and state-of-art LLM agents on SESI. The
results indicate the social intelligence of LLMs still has significant room for
improvement, with superficially friendliness as a primary reason for errors.
Moreover, there exists a relatively low correlation between the social
intelligence and academic intelligence exhibited by LLMs, suggesting that
social intelligence is distinct from academic intelligence for LLMs.
Additionally, while it is observed that LLMs can't ``understand'' what social
intelligence is, their social intelligence, similar to that of humans, is
influenced by social factors.
","[{'version': 'v1', 'created': 'Mon, 11 Mar 2024 10:35:53 GMT'}]",2024-03-12,"[['Xu', 'Ruoxi', ''], ['Lin', 'Hongyu', ''], ['Han', 'Xianpei', ''], ['Sun', 'Le', ''], ['Sun', 'Yingfei', '']]"
1503.09144,David Martins de Matos,"Ant\'onio Lopes and David Martins de Matos and Vera Cabarr\~ao and
  Ricardo Ribeiro and Helena Moniz and Isabel Trancoso and Ana Isabel Mata","Towards Using Machine Translation Techniques to Induce Multilingual
  Lexica of Discourse Markers",6 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Discourse markers are universal linguistic events subject to language
variation. Although an extensive literature has already reported language
specific traits of these events, little has been said on their cross-language
behavior and on building an inventory of multilingual lexica of discourse
markers. This work describes new methods and approaches for the description,
classification, and annotation of discourse markers in the specific domain of
the Europarl corpus. The study of discourse markers in the context of
translation is crucial due to the idiomatic nature of these structures.
Multilingual lexica together with the functional analysis of such structures
are useful tools for the hard task of translating discourse markers into
possible equivalents from one language to another. Using Daniel Marcu's
validated discourse markers for English, extracted from the Brown Corpus, our
purpose is to build multilingual lexica of discourse markers for other
languages, based on machine translation techniques. The major assumption in
this study is that the usage of a discourse marker is independent of the
language, i.e., the rhetorical function of a discourse marker in a sentence in
one language is equivalent to the rhetorical function of the same discourse
marker in another language.
","[{'version': 'v1', 'created': 'Tue, 31 Mar 2015 17:56:07 GMT'}]",2015-04-01,"[['Lopes', 'António', ''], ['de Matos', 'David Martins', ''], ['Cabarrão', 'Vera', ''], ['Ribeiro', 'Ricardo', ''], ['Moniz', 'Helena', ''], ['Trancoso', 'Isabel', ''], ['Mata', 'Ana Isabel', '']]"
1111.5293,Pramod Sukhadeve,Sanjay K. Dwivedi and Pramod P. Sukhadeve,Rule based Part of speech Tagger for Homoeopathy Clinical realm,,,,,cs.CL,http://creativecommons.org/licenses/by/3.0/,"  A tagger is a mandatory segment of most text scrutiny systems, as it
consigned a s yntax class (e.g., noun, verb, adjective, and adverb) to every
word in a sentence. In this paper, we present a simple part of speech tagger
for homoeopathy clinical language. This paper reports about the anticipated
part of speech tagger for homoeopathy clinical language. It exploit standard
pattern for evaluating sentences, untagged clinical corpus of 20085 words is
used, from which we had selected 125 sentences (2322 tokens). The problem of
tagging in natural language processing is to find a way to tag every word in a
text as a meticulous part of speech. The basic idea is to apply a set of rules
on clinical sentences and on each word, Accuracy is the leading factor in
evaluating any POS tagger so the accuracy of proposed tagger is also conversed.
","[{'version': 'v1', 'created': 'Sun, 13 Nov 2011 18:19:15 GMT'}]",2011-11-23,"[['Dwivedi', 'Sanjay K.', ''], ['Sukhadeve', 'Pramod P.', '']]"
2109.11136,Dongqi Wang,"Dongqi Wang, Haoran Wei, Zhirui Zhang, Shujian Huang, Jun Xie, Jiajun
  Chen","Non-Parametric Online Learning from Human Feedback for Neural Machine
  Translation","Accepted to the 36th AAAI Conference on Artificial Intelligence (AAAI
  2022)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We study the problem of online learning with human feedback in the
human-in-the-loop machine translation, in which the human translators revise
the machine-generated translations and then the corrected translations are used
to improve the neural machine translation (NMT) system. However, previous
methods require online model updating or additional translation memory networks
to achieve high-quality performance, making them inflexible and inefficient in
practice. In this paper, we propose a novel non-parametric online learning
method without changing the model structure. This approach introduces two
k-nearest-neighbor (knn) modules: one module memorizes the human feedback,
which is the correct sentences provided by human translators, while the other
balances the usage of the history human feedback and original NMT models
adaptively. Experiments conducted on EMEA and JRC-Acquis benchmarks demonstrate
that our proposed method obtains substantial improvements on translation
accuracy and achieves better adaptation performance with less repeating human
correction operations.
","[{'version': 'v1', 'created': 'Thu, 23 Sep 2021 04:26:15 GMT'}, {'version': 'v2', 'created': 'Mon, 13 Dec 2021 09:33:45 GMT'}, {'version': 'v3', 'created': 'Tue, 14 Dec 2021 03:41:47 GMT'}]",2021-12-15,"[['Wang', 'Dongqi', ''], ['Wei', 'Haoran', ''], ['Zhang', 'Zhirui', ''], ['Huang', 'Shujian', ''], ['Xie', 'Jun', ''], ['Chen', 'Jiajun', '']]"
2310.11638,Linhao Luo,"Linhao Luo, Thuy-Trang Vu, Dinh Phung, Gholamreza Haffari",Systematic Assessment of Factual Knowledge in Large Language Models,Accepted by EMNLP 2023 Findings,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Previous studies have relied on existing question-answering benchmarks to
evaluate the knowledge stored in large language models (LLMs). However, this
approach has limitations regarding factual knowledge coverage, as it mostly
focuses on generic domains which may overlap with the pretraining data. This
paper proposes a framework to systematically assess the factual knowledge of
LLMs by leveraging knowledge graphs (KGs). Our framework automatically
generates a set of questions and expected answers from the facts stored in a
given KG, and then evaluates the accuracy of LLMs in answering these questions.
We systematically evaluate the state-of-the-art LLMs with KGs in generic and
specific domains. The experiment shows that ChatGPT is consistently the top
performer across all domains. We also find that LLMs performance depends on the
instruction finetuning, domain and question complexity and is prone to
adversarial context.
","[{'version': 'v1', 'created': 'Wed, 18 Oct 2023 00:20:50 GMT'}, {'version': 'v2', 'created': 'Fri, 20 Oct 2023 05:33:19 GMT'}, {'version': 'v3', 'created': 'Mon, 30 Oct 2023 12:05:31 GMT'}]",2023-10-31,"[['Luo', 'Linhao', ''], ['Vu', 'Thuy-Trang', ''], ['Phung', 'Dinh', ''], ['Haffari', 'Gholamreza', '']]"
2403.04771,Zheng Hui,"Lin Ai, Zheng Hui, Zizhou Liu, Julia Hirschberg",QASE Enhanced PLMs: Improved Control in Text Generation for MRC,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  To address the challenges of out-of-control generation in generative models
for machine reading comprehension (MRC), we introduce the Question-Attended
Span Extraction (QASE) module. Integrated during the fine-tuning of pre-trained
generative language models (PLMs), QASE enables these PLMs to match SOTA
extractive methods and outperform leading LLMs like GPT-4 in MRC tasks, without
significant increases in computational costs.
","[{'version': 'v1', 'created': 'Mon, 26 Feb 2024 05:34:16 GMT'}]",2024-03-11,"[['Ai', 'Lin', ''], ['Hui', 'Zheng', ''], ['Liu', 'Zizhou', ''], ['Hirschberg', 'Julia', '']]"
2105.03143,Mohamed Seghir Hadj Ameur,"Mohamed Seghir Hadj Ameur, Hassina Aliane","AraCOVID19-MFH: Arabic COVID-19 Multi-label Fake News and Hate Speech
  Detection Dataset",,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Along with the COVID-19 pandemic, an ""infodemic"" of false and misleading
information has emerged and has complicated the COVID-19 response efforts.
Social networking sites such as Facebook and Twitter have contributed largely
to the spread of rumors, conspiracy theories, hate, xenophobia, racism, and
prejudice. To combat the spread of fake news, researchers around the world have
and are still making considerable efforts to build and share COVID-19 related
research articles, models, and datasets. This paper releases ""AraCOVID19-MFH"" a
manually annotated multi-label Arabic COVID-19 fake news and hate speech
detection dataset. Our dataset contains 10,828 Arabic tweets annotated with 10
different labels. The labels have been designed to consider some aspects
relevant to the fact-checking task, such as the tweet's check worthiness,
positivity/negativity, and factuality. To confirm our annotated dataset's
practical utility, we used it to train and evaluate several classification
models and reported the obtained results. Though the dataset is mainly designed
for fake news detection, it can also be used for hate speech detection,
opinion/news classification, dialect identification, and many other tasks.
","[{'version': 'v1', 'created': 'Fri, 7 May 2021 09:52:44 GMT'}]",2021-05-10,"[['Ameur', 'Mohamed Seghir Hadj', ''], ['Aliane', 'Hassina', '']]"
2205.07938,Simon DeDeo,Robin W. Na and Simon DeDeo,"The Diversity of Argument-Making in the Wild: from Assumptions and
  Definitions to Causation and Anecdote in Reddit's ""Change My View""","7 pages, 5 tables. Accepted as paper with oral presentation to CogSci
  2022, Toronto. Proceedings of the Annual Meeting of the Cognitive Science
  Society, 44",,,,cs.CL cs.SI q-bio.NC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  What kinds of arguments do people make, and what effect do they have on
others? Normative constraints on argument-making are as old as philosophy
itself, but little is known about the diversity of arguments made in practice.
We use NLP tools to extract patterns of argument-making from the Reddit site
""Change My View"" (r/CMV). This reveals six distinct argument patterns: not just
the familiar deductive and inductive forms, but also arguments about
definitions, relevance, possibility and cause, and personal experience. Data
from r/CMV also reveal differences in efficacy: personal experience and, to a
lesser extent, arguments about causation and examples, are most likely to shift
a person's view, while arguments about relevance are the least. Finally, our
methods reveal a gradient of argument-making preferences among users: a
two-axis model, of ""personal--impersonal"" and ""concrete--abstract"", can account
for nearly 80% of the strategy variance between individuals.
","[{'version': 'v1', 'created': 'Mon, 16 May 2022 18:39:21 GMT'}]",2022-12-12,"[['Na', 'Robin W.', ''], ['DeDeo', 'Simon', '']]"
2011.11400,Feng Qi,Feng Qi,Language guided machine action,"10 pages, 4 figures",,,,cs.AI cs.CL q-bio.NC,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Here we build a hierarchical modular network called Language guided machine
action (LGMA), whose modules process information stream mimicking human
cortical network that allows to achieve multiple general tasks such as language
guided action, intention decomposition and mental simulation before action
execution etc. LGMA contains 3 main systems: (1) primary sensory system that
multimodal sensory information of vision, language and sensorimotor. (2)
association system involves and Broca modules to comprehend and synthesize
language, BA14/40 module to translate between sensorimotor and language,
midTemporal module to convert between language and vision, and superior
parietal lobe to integrate attended visual object and arm state into cognitive
map for future spatial actions. Pre-supplementary motor area (pre-SMA) can
converts high level intention into sequential atomic actions, while SMA can
integrate these atomic actions, current arm and attended object state into
sensorimotor vector to apply corresponding torques on arm via pre-motor and
primary motor of arm to achieve the intention. The high-level executive system
contains PFC that does explicit inference and guide voluntary action based on
language, while BG is the habitual action control center.
","[{'version': 'v1', 'created': 'Mon, 23 Nov 2020 13:49:02 GMT'}]",2020-11-24,"[['Qi', 'Feng', '']]"
1605.05172,Taraka Rama Kasicheyanula,Taraka Rama,"Siamese convolutional networks based on phonetic features for cognate
  identification",,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  In this paper, we explore the use of convolutional networks (ConvNets) for
the purpose of cognate identification. We compare our architecture with binary
classifiers based on string similarity measures on different language families.
Our experiments show that convolutional networks achieve competitive results
across concepts and across language families at the task of cognate
identification.
","[{'version': 'v1', 'created': 'Tue, 17 May 2016 14:07:43 GMT'}, {'version': 'v2', 'created': 'Sat, 2 Jul 2016 12:29:08 GMT'}]",2016-07-05,"[['Rama', 'Taraka', '']]"
2109.07194,Yoshinobu Hagiwara Dr.,"Yoshinobu Hagiwara, Kazuma Furukawa, Akira Taniguchi, and Tadahiro
  Taniguchi","Multiagent Multimodal Categorization for Symbol Emergence: Emergent
  Communication via Interpersonal Cross-modal Inference","27 pages, 5 figures, 12 tables",,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper describes a computational model of multiagent multimodal
categorization that realizes emergent communication. We clarify whether the
computational model can reproduce the following functions in a symbol emergence
system, comprising two agents with different sensory modalities playing a
naming game. (1) Function for forming a shared lexical system that comprises
perceptual categories and corresponding signs, formed by agents through
individual learning and semiotic communication between agents. (2) Function to
improve the categorization accuracy in an agent via semiotic communication with
another agent, even when some sensory modalities of each agent are missing. (3)
Function that an agent infers unobserved sensory information based on a sign
sampled from another agent in the same manner as cross-modal inference. We
propose an interpersonal multimodal Dirichlet mixture (Inter-MDM), which is
derived by dividing an integrative probabilistic generative model, which is
obtained by integrating two Dirichlet mixtures (DMs). The Markov chain Monte
Carlo algorithm realizes emergent communication. The experimental results
demonstrated that Inter-MDM enables agents to form multimodal categories and
appropriately share signs between agents. It is shown that emergent
communication improves categorization accuracy, even when some sensory
modalities are missing. Inter-MDM enables an agent to predict unobserved
information based on a shared sign.
","[{'version': 'v1', 'created': 'Wed, 15 Sep 2021 10:20:54 GMT'}]",2021-09-16,"[['Hagiwara', 'Yoshinobu', ''], ['Furukawa', 'Kazuma', ''], ['Taniguchi', 'Akira', ''], ['Taniguchi', 'Tadahiro', '']]"
2305.19396,Phat Do,"Phat Do, Matt Coler, Jelske Dijkstra, Esther Klabbers","Resource-Efficient Fine-Tuning Strategies for Automatic MOS Prediction
  in Text-to-Speech for Low-Resource Languages",Accepted at INTERSPEECH 2023,,,,eess.AS cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We train a MOS prediction model based on wav2vec 2.0 using the open-access
data sets BVCC and SOMOS. Our test with neural TTS data in the low-resource
language (LRL) West Frisian shows that pre-training on BVCC before fine-tuning
on SOMOS leads to the best accuracy for both fine-tuned and zero-shot
prediction. Further fine-tuning experiments show that using more than 30
percent of the total data does not lead to significant improvements. In
addition, fine-tuning with data from a single listener shows promising
system-level accuracy, supporting the viability of one-participant pilot tests.
These findings can all assist the resource-conscious development of TTS for
LRLs by progressing towards better zero-shot MOS prediction and informing the
design of listening tests, especially in early-stage evaluation.
","[{'version': 'v1', 'created': 'Tue, 30 May 2023 20:19:56 GMT'}]",2023-06-01,"[['Do', 'Phat', ''], ['Coler', 'Matt', ''], ['Dijkstra', 'Jelske', ''], ['Klabbers', 'Esther', '']]"
2201.11294,Vidhur Kumar,"Neha Deshpande, Nicholas Farris, and Vidhur Kumar",Highly Generalizable Models for Multilingual Hate Speech Detection,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Hate speech detection has become an important research topic within the past
decade. More private corporations are needing to regulate user generated
content on different platforms across the globe. In this paper, we introduce a
study of multilingual hate speech classification. We compile a dataset of 11
languages and resolve different taxonomies by analyzing the combined data with
binary labels: hate speech or not hate speech. Defining hate speech in a single
way across different languages and datasets may erase cultural nuances to the
definition, therefore, we utilize language agnostic embeddings provided by
LASER and MUSE in order to develop models that can use a generalized definition
of hate speech across datasets. Furthermore, we evaluate prior state of the art
methodologies for hate speech detection under our expanded dataset. We conduct
three types of experiments for a binary hate speech classification task:
Multilingual-Train Monolingual-Test, MonolingualTrain Monolingual-Test and
Language-Family-Train Monolingual Test scenarios to see if performance
increases for each language due to learning more from other language data.
","[{'version': 'v1', 'created': 'Thu, 27 Jan 2022 03:09:38 GMT'}]",2022-01-28,"[['Deshpande', 'Neha', ''], ['Farris', 'Nicholas', ''], ['Kumar', 'Vidhur', '']]"
2401.17882,Yuan Li,"Yuan Li, Yue Huang, Yuli Lin, Siyuan Wu, Yao Wan and Lichao Sun","I Think, Therefore I am: Benchmarking Awareness of Large Language Models
  Using AwareBench",,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Do large language models (LLMs) exhibit any forms of awareness similar to
humans? In this paper, we introduce AwareBench, a benchmark designed to
evaluate awareness in LLMs. Drawing from theories in psychology and philosophy,
we define awareness in LLMs as the ability to understand themselves as AI
models and to exhibit social intelligence. Subsequently, we categorize
awareness in LLMs into five dimensions, including capability, mission, emotion,
culture, and perspective. Based on this taxonomy, we create a dataset called
AwareEval, which contains binary, multiple-choice, and open-ended questions to
assess LLMs' understandings of specific awareness dimensions. Our experiments,
conducted on 13 LLMs, reveal that the majority of them struggle to fully
recognize their capabilities and missions while demonstrating decent social
intelligence. We conclude by connecting awareness of LLMs with AI alignment and
safety, emphasizing its significance to the trustworthy and ethical development
of LLMs. Our dataset and code are available at
https://github.com/HowieHwong/Awareness-in-LLM.
","[{'version': 'v1', 'created': 'Wed, 31 Jan 2024 14:41:23 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Feb 2024 09:47:38 GMT'}]",2024-02-19,"[['Li', 'Yuan', ''], ['Huang', 'Yue', ''], ['Lin', 'Yuli', ''], ['Wu', 'Siyuan', ''], ['Wan', 'Yao', ''], ['Sun', 'Lichao', '']]"
2210.04878,Davide Locatelli,"Francesco Cazzaro, Davide Locatelli, Ariadna Quattoni, Xavier Carreras","Translate First Reorder Later: Leveraging Monotonicity in Semantic
  Parsing","Accepted at Findings of ACL: EACL 2023. 8 pages, 4 figures, 4 tables",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Prior work in semantic parsing has shown that conventional seq2seq models
fail at compositional generalization tasks. This limitation led to a resurgence
of methods that model alignments between sentences and their corresponding
meaning representations, either implicitly through latent variables or
explicitly by taking advantage of alignment annotations. We take the second
direction and propose TPOL, a two-step approach that first translates input
sentences monotonically and then reorders them to obtain the correct output.
This is achieved with a modular framework comprising a Translator and a
Reorderer component. We test our approach on two popular semantic parsing
datasets. Our experiments show that by means of the monotonic translations,
TPOL can learn reliable lexico-logical patterns from aligned data,
significantly improving compositional generalization both over conventional
seq2seq models, as well as over other approaches that exploit gold alignments.
","[{'version': 'v1', 'created': 'Mon, 10 Oct 2022 17:50:42 GMT'}, {'version': 'v2', 'created': 'Mon, 6 Feb 2023 12:26:37 GMT'}]",2023-02-07,"[['Cazzaro', 'Francesco', ''], ['Locatelli', 'Davide', ''], ['Quattoni', 'Ariadna', ''], ['Carreras', 'Xavier', '']]"
2109.14184,Annie Chen,"Annie T. Chen, Camille Lyans Cole","Reflexivity in Issues of Scale and Representation in a Digital
  Humanities Project","6th Workshop on Visualization for the Digital Humanities (VIS4DH
  2021). http://www.vis4dh.org/",,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  In this paper, we explore issues that we have encountered in developing a
pipeline that combines natural language processing with data analysis and
visualization techniques. The characteristics of the corpus - being comprised
of diaries of a single person spanning several decades - present both
conceptual challenges in terms of issues of representation, and affordances as
a source for historical research. We consider these issues in a team context
with a particular focus on the generation and interpretation of visualizations.
","[{'version': 'v1', 'created': 'Wed, 29 Sep 2021 04:06:51 GMT'}]",2021-09-30,"[['Chen', 'Annie T.', ''], ['Cole', 'Camille Lyans', '']]"
1910.04345,Wanzheng Zhu,"Wanzheng Zhu, Hongyu Gong, Jiaming Shen, Chao Zhang, Jingbo Shang,
  Suma Bhat, Jiawei Han",FUSE: Multi-Faceted Set Expansion by Coherent Clustering of Skip-grams,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Set expansion aims to expand a small set of seed entities into a complete set
of relevant entities. Most existing approaches assume the input seed set is
unambiguous and completely ignore the multi-faceted semantics of seed entities.
As a result, given the seed set {""Canon"", ""Sony"", ""Nikon""}, previous models
return one mixed set of entities that are either Camera Brands or Japanese
Companies. In this paper, we study the task of multi-faceted set expansion,
which aims to capture all semantic facets in the seed set and return multiple
sets of entities, one for each semantic facet. We propose an unsupervised
framework, FUSE, which consists of three major components: (1) facet discovery
module: identifies all semantic facets of each seed entity by extracting and
clustering its skip-grams, and (2) facet fusion module: discovers shared
semantic facets of the entire seed set by an optimization formulation, and (3)
entity expansion module: expands each semantic facet by utilizing a masked
language model with pre-trained BERT models. Extensive experiments demonstrate
that FUSE can accurately identify multiple semantic facets of the seed set and
generate quality entities for each facet.
","[{'version': 'v1', 'created': 'Thu, 10 Oct 2019 03:06:46 GMT'}, {'version': 'v2', 'created': 'Tue, 22 Oct 2019 22:12:29 GMT'}, {'version': 'v3', 'created': 'Thu, 18 Jun 2020 15:30:06 GMT'}]",2020-06-19,"[['Zhu', 'Wanzheng', ''], ['Gong', 'Hongyu', ''], ['Shen', 'Jiaming', ''], ['Zhang', 'Chao', ''], ['Shang', 'Jingbo', ''], ['Bhat', 'Suma', ''], ['Han', 'Jiawei', '']]"
2206.01818,Ruijie Wang,"Ruijie Wang, Luca Rossetto, Michael Cochez, Abraham Bernstein","QAGCN: Answering Multi-Relation Questions via Single-Step Implicit
  Reasoning over Knowledge Graphs",,,,,cs.AI cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multi-relation question answering (QA) is a challenging task, where given
questions usually require long reasoning chains in KGs that consist of multiple
relations. Recently, methods with explicit multi-step reasoning over KGs have
been prominently used in this task and have demonstrated promising performance.
Examples include methods that perform stepwise label propagation through KG
triples and methods that navigate over KG triples based on reinforcement
learning. A main weakness of these methods is that their reasoning mechanisms
are usually complex and difficult to implement or train. In this paper, we
argue that multi-relation QA can be achieved via end-to-end single-step
implicit reasoning, which is simpler, more efficient, and easier to adopt. We
propose QAGCN -- a Question-Aware Graph Convolutional Network (GCN)-based
method that includes a novel GCN architecture with controlled
question-dependent message propagation for the implicit reasoning. Extensive
experiments have been conducted, where QAGCN achieved competitive and even
superior performance compared to state-of-the-art explicit-reasoning methods.
","[{'version': 'v1', 'created': 'Fri, 3 Jun 2022 21:01:48 GMT'}, {'version': 'v2', 'created': 'Fri, 8 Dec 2023 19:58:28 GMT'}]",2023-12-12,"[['Wang', 'Ruijie', ''], ['Rossetto', 'Luca', ''], ['Cochez', 'Michael', ''], ['Bernstein', 'Abraham', '']]"
2210.14328,Aaron Mueller,"Aaron Mueller, Yu Xia, Tal Linzen","Causal Analysis of Syntactic Agreement Neurons in Multilingual Language
  Models",Accepted to CoNLL 2022,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Structural probing work has found evidence for latent syntactic information
in pre-trained language models. However, much of this analysis has focused on
monolingual models, and analyses of multilingual models have employed
correlational methods that are confounded by the choice of probing tasks. In
this study, we causally probe multilingual language models (XGLM and
multilingual BERT) as well as monolingual BERT-based models across various
languages; we do this by performing counterfactual perturbations on neuron
activations and observing the effect on models' subject-verb agreement
probabilities. We observe where in the model and to what extent syntactic
agreement is encoded in each language. We find significant neuron overlap
across languages in autoregressive multilingual language models, but not masked
language models. We also find two distinct layer-wise effect patterns and two
distinct sets of neurons used for syntactic agreement, depending on whether the
subject and verb are separated by other tokens. Finally, we find that
behavioral analyses of language models are likely underestimating how sensitive
masked language models are to syntactic information.
","[{'version': 'v1', 'created': 'Tue, 25 Oct 2022 20:43:36 GMT'}]",2022-10-27,"[['Mueller', 'Aaron', ''], ['Xia', 'Yu', ''], ['Linzen', 'Tal', '']]"
1604.00100,Kushal Arora,Kushal Arora and Anand Rangarajan,A Compositional Approach to Language Modeling,submitted to ACL 2016,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Traditional language models treat language as a finite state automaton on a
probability space over words. This is a very strong assumption when modeling
something inherently complex such as language. In this paper, we challenge this
by showing how the linear chain assumption inherent in previous work can be
translated into a sequential composition tree. We then propose a new model that
marginalizes over all possible composition trees thereby removing any
underlying structural assumptions. As the partition function of this new model
is intractable, we use a recently proposed sentence level evaluation metric
Contrastive Entropy to evaluate our model. Given this new evaluation metric, we
report more than 100% improvement across distortion levels over current state
of the art recurrent neural network based language models.
","[{'version': 'v1', 'created': 'Fri, 1 Apr 2016 01:51:34 GMT'}]",2016-04-04,"[['Arora', 'Kushal', ''], ['Rangarajan', 'Anand', '']]"
1906.00048,Colin Cherry,Colin Cherry and George Foster,"Thinking Slow about Latency Evaluation for Simultaneous Machine
  Translation",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Simultaneous machine translation attempts to translate a source sentence
before it is finished being spoken, with applications to translation of spoken
language for live streaming and conversation. Since simultaneous systems trade
quality to reduce latency, having an effective and interpretable latency metric
is crucial. We introduce a variant of the recently proposed Average Lagging
(AL) metric, which we call Differentiable Average Lagging (DAL). It
distinguishes itself by being differentiable and internally consistent to its
underlying mathematical model.
","[{'version': 'v1', 'created': 'Fri, 31 May 2019 19:57:49 GMT'}]",2019-06-04,"[['Cherry', 'Colin', ''], ['Foster', 'George', '']]"
2310.08372,Boyang Xue,"Boyang Xue and Weichao Wang and Hongru Wang and Fei Mi and Rui Wang
  and Yasheng Wang and Lifeng Shang and Xin Jiang and Qun Liu and Kam-Fai Wong","Improving Factual Consistency for Knowledge-Grounded Dialogue Systems
  via Knowledge Enhancement and Alignment",EMNLP2023 Findings,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pretrained language models (PLMs) based knowledge-grounded dialogue systems
are prone to generate responses that are factually inconsistent with the
provided knowledge source. In such inconsistent responses, the dialogue models
fail to accurately express the external knowledge they rely upon. Inspired by
previous work which identified that feed-forward networks (FFNs) within
Transformers are responsible for factual knowledge expressions, we investigate
two methods to efficiently improve the factual expression capability {of FFNs}
by knowledge enhancement and alignment respectively. We first propose
\textsc{K-Dial}, which {explicitly} introduces {extended FFNs in Transformers
to enhance factual knowledge expressions} given the specific patterns of
knowledge-grounded dialogue inputs. Additionally, we apply the reinforcement
learning for factual consistency (RLFC) method to implicitly adjust FFNs'
expressions in responses by aligning with gold knowledge for the factual
consistency preference. To comprehensively assess the factual consistency and
dialogue quality of responses, we employ extensive automatic measures and human
evaluations including sophisticated fine-grained NLI-based metrics.
Experimental results on WoW and CMU\_DoG datasets demonstrate that our methods
efficiently enhance the ability of the FFN module to convey factual knowledge,
validating the efficacy of improving factual consistency for knowledge-grounded
dialogue systems.
","[{'version': 'v1', 'created': 'Thu, 12 Oct 2023 14:44:05 GMT'}, {'version': 'v2', 'created': 'Mon, 16 Oct 2023 01:47:05 GMT'}, {'version': 'v3', 'created': 'Fri, 3 Nov 2023 07:26:42 GMT'}]",2023-11-06,"[['Xue', 'Boyang', ''], ['Wang', 'Weichao', ''], ['Wang', 'Hongru', ''], ['Mi', 'Fei', ''], ['Wang', 'Rui', ''], ['Wang', 'Yasheng', ''], ['Shang', 'Lifeng', ''], ['Jiang', 'Xin', ''], ['Liu', 'Qun', ''], ['Wong', 'Kam-Fai', '']]"
1912.03063,Corentin Kervadec,"Corentin Kervadec (LIRIS), Grigory Antipov, Moez Baccouche, Christian
  Wolf (LIRIS)","Weak Supervision helps Emergence of Word-Object Alignment and improves
  Vision-Language Tasks",,,,,cs.CV cs.CL cs.LG cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The large adoption of the self-attention (i.e. transformer model) and
BERT-like training principles has recently resulted in a number of high
performing models on a large panoply of vision-and-language problems (such as
Visual Question Answering (VQA), image retrieval, etc.). In this paper we claim
that these State-Of-The-Art (SOTA) approaches perform reasonably well in
structuring information inside a single modality but, despite their impressive
performances , they tend to struggle to identify fine-grained inter-modality
relationships. Indeed, such relations are frequently assumed to be implicitly
learned during training from application-specific losses, mostly cross-entropy
for classification. While most recent works provide inductive bias for
inter-modality relationships via cross attention modules, in this work, we
demonstrate (1) that the latter assumption does not hold, i.e. modality
alignment does not necessarily emerge automatically, and (2) that adding weak
supervision for alignment between visual objects and words improves the quality
of the learned models on tasks requiring reasoning. In particular , we
integrate an object-word alignment loss into SOTA vision-language reasoning
models and evaluate it on two tasks VQA and Language-driven Comparison of
Images. We show that the proposed fine-grained inter-modality supervision
significantly improves performance on both tasks. In particular, this new
learning signal allows obtaining SOTA-level performances on GQA dataset (VQA
task) with pre-trained models without finetuning on the task, and a new SOTA on
NLVR2 dataset (Language-driven Comparison of Images). Finally, we also
illustrate the impact of the contribution on the models reasoning by
visualizing attention distributions.
","[{'version': 'v1', 'created': 'Fri, 6 Dec 2019 11:04:08 GMT'}]",2019-12-09,"[['Kervadec', 'Corentin', '', 'LIRIS'], ['Antipov', 'Grigory', '', 'LIRIS'], ['Baccouche', 'Moez', '', 'LIRIS'], ['Wolf', 'Christian', '', 'LIRIS']]"
2104.01807,Tadahiro Taniguchi,"Asuka Moritani, Ryo Ozaki, Shoki Sakamoto, Hirokazu Kameoka, Tadahiro
  Taniguchi",StarGAN-based Emotional Voice Conversion for Japanese Phrases,Submitted to Interspeech 2021,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper shows that StarGAN-VC, a spectral envelope transformation method
for non-parallel many-to-many voice conversion (VC), is capable of emotional VC
(EVC). Although StarGAN-VC has been shown to enable speaker identity
conversion, its capability for EVC for Japanese phrases has not been clarified.
In this paper, we describe the direct application of StarGAN-VC to an EVC task
with minimal fundamental frequency and aperiodicity processing. Through
subjective evaluation experiments, we evaluated the performance of our
StarGAN-EVC system in terms of its ability to achieve EVC for Japanese phrases.
The subjective evaluation is conducted in terms of subjective classification
and mean opinion score of neutrality and similarity. In addition, the
interdependence between the source and target emotional domains was
investigated from the perspective of the quality of EVC.
","[{'version': 'v1', 'created': 'Mon, 5 Apr 2021 08:08:42 GMT'}]",2021-04-06,"[['Moritani', 'Asuka', ''], ['Ozaki', 'Ryo', ''], ['Sakamoto', 'Shoki', ''], ['Kameoka', 'Hirokazu', ''], ['Taniguchi', 'Tadahiro', '']]"
2010.05269,"Mika H\""am\""al\""ainen","Khalid Alnajjar, Mika H\""am\""al\""ainen, Niko Partanen, Jack Rueter",Automated Prediction of Medieval Arabic Diacritics,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This study uses a character level neural machine translation approach trained
on a long short-term memory-based bi-directional recurrent neural network
architecture for diacritization of Medieval Arabic. The results improve from
the online tool used as a baseline. A diacritization model have been published
openly through an easy to use Python package available on PyPi and Zenodo. We
have found that context size should be considered when optimizing a feasible
prediction model.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 15:21:01 GMT'}]",2020-10-13,"[['Alnajjar', 'Khalid', ''], ['Hämäläinen', 'Mika', ''], ['Partanen', 'Niko', ''], ['Rueter', 'Jack', '']]"
2402.14818,Muhammad Maaz Mr,"Muhammad Maaz, Hanoona Rasheed, Abdelrahman Shaker, Salman Khan,
  Hisham Cholakal, Rao M. Anwer, Tim Baldwin, Michael Felsberg, Fahad S. Khan",PALO: A Polyglot Large Multimodal Model for 5B People,Technical Report of PALO,,,,cs.CL cs.CV,http://creativecommons.org/licenses/by/4.0/,"  In pursuit of more inclusive Vision-Language Models (VLMs), this study
introduces a Large Multilingual Multimodal Model called PALO. PALO offers
visual reasoning capabilities in 10 major languages, including English,
Chinese, Hindi, Spanish, French, Arabic, Bengali, Russian, Urdu, and Japanese,
that span a total of ~5B people (65% of the world population). Our approach
involves a semi-automated translation approach to adapt the multimodal
instruction dataset from English to the target languages using a fine-tuned
Large Language Model, thereby ensuring high linguistic fidelity while allowing
scalability due to minimal manual effort. The incorporation of diverse
instruction sets helps us boost overall performance across multiple languages
especially those that are underrepresented like Hindi, Arabic, Bengali, and
Urdu. The resulting models are trained across three scales (1.7B, 7B and 13B
parameters) to show the generalization and scalability where we observe
substantial improvements compared to strong baselines. We also propose the
first multilingual multimodal benchmark for the forthcoming approaches to
evaluate their vision-language reasoning capabilities across languages. Code:
https://github.com/mbzuai-oryx/PALO.
","[{'version': 'v1', 'created': 'Thu, 22 Feb 2024 18:59:58 GMT'}, {'version': 'v2', 'created': 'Tue, 5 Mar 2024 11:22:07 GMT'}]",2024-03-06,"[['Maaz', 'Muhammad', ''], ['Rasheed', 'Hanoona', ''], ['Shaker', 'Abdelrahman', ''], ['Khan', 'Salman', ''], ['Cholakal', 'Hisham', ''], ['Anwer', 'Rao M.', ''], ['Baldwin', 'Tim', ''], ['Felsberg', 'Michael', ''], ['Khan', 'Fahad S.', '']]"
2302.07267,Peter S. Park,"Peter S. Park, Philipp Schoenegger, Chongyang Zhu",Diminished Diversity-of-Thought in a Standard Large Language Model,"67 pages (42-page main text, 25-page SI); 12 visualizations (four
  tables and three figures in the main text, five figures in the SI);
  additional exploratory follow-up study varied the demographic details
  preceding the prompt; preregistered OSF database is available at
  https://osf.io/dzp8t/",,,,cs.HC cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We test whether Large Language Models (LLMs) can be used to simulate human
participants in social-science studies. To do this, we run replications of 14
studies from the Many Labs 2 replication project with OpenAI's text-davinci-003
model, colloquially known as GPT3.5. Based on our pre-registered analyses, we
find that among the eight studies we could analyse, our GPT sample replicated
37.5% of the original results and 37.5% of the Many Labs 2 results. However, we
were unable to analyse the remaining six studies due to an unexpected
phenomenon we call the ""correct answer"" effect. Different runs of GPT3.5
answered nuanced questions probing political orientation, economic preference,
judgement, and moral philosophy with zero or near-zero variation in responses:
with the supposedly ""correct answer."" In one exploratory follow-up study, we
found that a ""correct answer"" was robust to changing the demographic details
that precede the prompt. In another, we found that most but not all ""correct
answers"" were robust to changing the order of answer choices. One of our most
striking findings occurred in our replication of the Moral Foundations Theory
survey results, where we found GPT3.5 identifying as a political conservative
in 99.6% of the cases, and as a liberal in 99.3% of the cases in the
reverse-order condition. However, both self-reported 'GPT conservatives' and
'GPT liberals' showed right-leaning moral foundations. Our results cast doubts
on the validity of using LLMs as a general replacement for human participants
in the social sciences. Our results also raise concerns that a hypothetical
AI-led future may be subject to a diminished diversity-of-thought.
","[{'version': 'v1', 'created': 'Mon, 13 Feb 2023 17:57:50 GMT'}, {'version': 'v2', 'created': 'Thu, 16 Feb 2023 15:10:23 GMT'}, {'version': 'v3', 'created': 'Sun, 12 Mar 2023 17:32:22 GMT'}, {'version': 'v4', 'created': 'Wed, 29 Mar 2023 23:30:35 GMT'}, {'version': 'v5', 'created': 'Wed, 19 Apr 2023 22:43:55 GMT'}, {'version': 'v6', 'created': 'Wed, 13 Sep 2023 07:44:42 GMT'}]",2023-09-14,"[['Park', 'Peter S.', ''], ['Schoenegger', 'Philipp', ''], ['Zhu', 'Chongyang', '']]"
2204.06092,Ivan Stelmakh,"Ivan Stelmakh, Yi Luan, Bhuwan Dhingra, Ming-Wei Chang",ASQA: Factoid Questions Meet Long-Form Answers,"A minor bug in computing the ROUGE score was fixed. The fix **did
  not** result in any changes in observations and conclusions",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  An abundance of datasets and availability of reliable evaluation metrics have
resulted in strong progress in factoid question answering (QA). This progress,
however, does not easily transfer to the task of long-form QA, where the goal
is to answer questions that require in-depth explanations. The hurdles include
(i) a lack of high-quality data, and (ii) the absence of a well-defined notion
of the answer's quality. In this work, we address these problems by (i)
releasing a novel dataset and a task that we call ASQA (Answer Summaries for
Questions which are Ambiguous); and (ii) proposing a reliable metric for
measuring performance on ASQA. Our task focuses on factoid questions that are
ambiguous, that is, have different correct answers depending on interpretation.
Answers to ambiguous questions should synthesize factual information from
multiple sources into a long-form summary that resolves the ambiguity. In
contrast to existing long-form QA tasks (such as ELI5), ASQA admits a clear
notion of correctness: a user faced with a good summary should be able to
answer different interpretations of the original ambiguous question. We use
this notion of correctness to define an automated metric of performance for
ASQA. Our analysis demonstrates an agreement between this metric and human
judgments, and reveals a considerable gap between human performance and strong
baselines.
","[{'version': 'v1', 'created': 'Tue, 12 Apr 2022 21:58:44 GMT'}, {'version': 'v2', 'created': 'Sun, 22 Jan 2023 14:25:40 GMT'}]",2023-01-24,"[['Stelmakh', 'Ivan', ''], ['Luan', 'Yi', ''], ['Dhingra', 'Bhuwan', ''], ['Chang', 'Ming-Wei', '']]"
2306.01337,Yiran Wu,"Yiran Wu, Feiran Jia, Shaokun Zhang, Hangyu Li, Erkang Zhu, Yue Wang,
  Yin Tat Lee, Richard Peng, Qingyun Wu, and Chi Wang",An Empirical Study on Challenging Math Problem Solving with GPT-4,"Fix minor errors, update github link",,,,cs.CL stat.ML,http://creativecommons.org/licenses/by/4.0/,"  Employing Large Language Models (LLMs) to address mathematical problems is an
intriguing research endeavor, considering the abundance of math problems
expressed in natural language across numerous science and engineering fields.
While several prior works have investigated solving elementary mathematics
using LLMs, this work explores the frontier of using GPT-4 for solving more
complex and challenging math problems. We evaluate various ways of using GPT-4.
Some of them are adapted from existing work, and one is MathChat, a
conversational problem-solving framework newly proposed in this work. We
perform the evaluation on difficult high school competition problems from the
MATH dataset, which shows the advantage of the proposed conversational
approach.
","[{'version': 'v1', 'created': 'Fri, 2 Jun 2023 08:02:15 GMT'}, {'version': 'v2', 'created': 'Thu, 8 Jun 2023 02:34:35 GMT'}]",2023-06-09,"[['Wu', 'Yiran', ''], ['Jia', 'Feiran', ''], ['Zhang', 'Shaokun', ''], ['Li', 'Hangyu', ''], ['Zhu', 'Erkang', ''], ['Wang', 'Yue', ''], ['Lee', 'Yin Tat', ''], ['Peng', 'Richard', ''], ['Wu', 'Qingyun', ''], ['Wang', 'Chi', '']]"
2306.02307,Daniel Rotem,"Daniel Rotem, Michael Hassid, Jonathan Mamou, Roy Schwartz","Finding the SWEET Spot: Analysis and Improvement of Adaptive Inference
  in Low Resource Settings",Proceedings of ACL 2023,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Adaptive inference is a simple method for reducing inference costs. The
method works by maintaining multiple classifiers of different capacities, and
allocating resources to each test instance according to its difficulty. In this
work, we compare the two main approaches for adaptive inference, Early-Exit and
Multi-Model, when training data is limited. First, we observe that for models
with the same architecture and size, individual Multi-Model classifiers
outperform their Early-Exit counterparts by an average of 2.3%. We show that
this gap is caused by Early-Exit classifiers sharing model parameters during
training, resulting in conflicting gradient updates of model weights. We find
that despite this gap, Early-Exit still provides a better speed-accuracy
trade-off due to the overhead of the Multi-Model approach. To address these
issues, we propose SWEET (Separating Weights in Early Exit Transformers), an
Early-Exit fine-tuning method that assigns each classifier its own set of
unique model weights, not updated by other classifiers. We compare SWEET's
speed-accuracy curve to standard Early-Exit and Multi-Model baselines and find
that it outperforms both methods at fast speeds while maintaining comparable
scores to Early-Exit at slow speeds. Moreover, SWEET individual classifiers
outperform Early-Exit ones by 1.1% on average. SWEET enjoys the benefits of
both methods, paving the way for further reduction of inference costs in NLP.
","[{'version': 'v1', 'created': 'Sun, 4 Jun 2023 09:16:39 GMT'}]",2023-06-06,"[['Rotem', 'Daniel', ''], ['Hassid', 'Michael', ''], ['Mamou', 'Jonathan', ''], ['Schwartz', 'Roy', '']]"
1405.0546,Antti Puurula,"Antti Puurula, Jesse Read, Albert Bifet",Kaggle LSHTC4 Winning Solution,Kaggle LSHTC winning solution description,,,,cs.AI cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Our winning submission to the 2014 Kaggle competition for Large Scale
Hierarchical Text Classification (LSHTC) consists mostly of an ensemble of
sparse generative models extending Multinomial Naive Bayes. The
base-classifiers consist of hierarchically smoothed models combining document,
label, and hierarchy level Multinomials, with feature pre-processing using
variants of TF-IDF and BM25. Additional diversification is introduced by
different types of folds and random search optimization for different measures.
The ensemble algorithm optimizes macroFscore by predicting the documents for
each label, instead of the usual prediction of labels per document. Scores for
documents are predicted by weighted voting of base-classifier outputs with a
variant of Feature-Weighted Linear Stacking. The number of documents per label
is chosen using label priors and thresholding of vote scores. This document
describes the models and software used to build our solution. Reproducing the
results for our solution can be done by running the scripts included in the
Kaggle package. A package omitting precomputed result files is also
distributed. All code is open source, released under GNU GPL 2.0, and GPL 3.0
for Weka and Meka dependencies.
","[{'version': 'v1', 'created': 'Sat, 3 May 2014 01:41:27 GMT'}, {'version': 'v2', 'created': 'Fri, 9 May 2014 04:57:19 GMT'}]",2014-05-12,"[['Puurula', 'Antti', ''], ['Read', 'Jesse', ''], ['Bifet', 'Albert', '']]"
0809.4530,Olena Medelyan,"Olena Medelyan, David Milne, Catherine Legg and Ian H. Witten",Mining Meaning from Wikipedia,"An extensive survey of re-using information in Wikipedia in natural
  language processing, information retrieval and extraction and ontology
  building. Accepted for publication in International Journal of Human-Computer
  Studies",,,ISSN 1177-777X,cs.AI cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Wikipedia is a goldmine of information; not just for its many readers, but
also for the growing community of researchers who recognize it as a resource of
exceptional scale and utility. It represents a vast investment of manual effort
and judgment: a huge, constantly evolving tapestry of concepts and relations
that is being applied to a host of tasks.
  This article provides a comprehensive description of this work. It focuses on
research that extracts and makes use of the concepts, relations, facts and
descriptions found in Wikipedia, and organizes the work into four broad
categories: applying Wikipedia to natural language processing; using it to
facilitate information retrieval and information extraction; and as a resource
for ontology building. The article addresses how Wikipedia is being used as is,
how it is being improved and adapted, and how it is being combined with other
structures to create entirely new resources. We identify the research groups
and individuals involved, and how their work has developed in the last few
years. We provide a comprehensive list of the open-source software they have
produced.
","[{'version': 'v1', 'created': 'Fri, 26 Sep 2008 04:47:19 GMT'}, {'version': 'v2', 'created': 'Sun, 10 May 2009 01:51:15 GMT'}]",2009-05-10,"[['Medelyan', 'Olena', ''], ['Milne', 'David', ''], ['Legg', 'Catherine', ''], ['Witten', 'Ian H.', '']]"
2103.14302,Jaeyun Song,"Jaeyun Song, Hajin Shim, Eunho Yang",Mutually-Constrained Monotonic Multihead Attention for Online ASR,Accepted at IEEE ICASSP 2021,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the feature of real-time decoding, Monotonic Multihead Attention
(MMA) shows comparable performance to the state-of-the-art offline methods in
machine translation and automatic speech recognition (ASR) tasks. However, the
latency of MMA is still a major issue in ASR and should be combined with a
technique that can reduce the test latency at inference time, such as
head-synchronous beam search decoding, which forces all non-activated heads to
activate after a small fixed delay from the first head activation. In this
paper, we remove the discrepancy between training and test phases by
considering, in the training of MMA, the interactions across multiple heads
that will occur in the test time. Specifically, we derive the expected
alignments from monotonic attention by considering the boundaries of other
heads and reflect them in the learning process. We validate our proposed method
on the two standard benchmark datasets for ASR and show that our approach, MMA
with the mutually-constrained heads from the training stage, provides better
performance than baselines.
","[{'version': 'v1', 'created': 'Fri, 26 Mar 2021 07:33:25 GMT'}]",2021-03-29,"[['Song', 'Jaeyun', ''], ['Shim', 'Hajin', ''], ['Yang', 'Eunho', '']]"
2211.05121,Yingyi Ma,"Yingyi Ma, Zhe Liu, Xuedong Zhang",Adaptive Multi-Corpora Language Model Training for Speech Recognition,,,,,eess.AS cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural network language model (NNLM) plays an essential role in automatic
speech recognition (ASR) systems, especially in adaptation tasks when text-only
data is available. In practice, an NNLM is typically trained on a combination
of data sampled from multiple corpora. Thus, the data sampling strategy is
important to the adaptation performance. Most existing works focus on designing
static sampling strategies. However, each corpus may show varying impacts at
different NNLM training stages. In this paper, we introduce a novel adaptive
multi-corpora training algorithm that dynamically learns and adjusts the
sampling probability of each corpus along the training process. The algorithm
is robust to corpora sizes and domain relevance. Compared with static sampling
strategy baselines, the proposed approach yields remarkable improvement by
achieving up to relative 7% and 9% word error rate (WER) reductions on
in-domain and out-of-domain adaptation tasks, respectively.
","[{'version': 'v1', 'created': 'Wed, 9 Nov 2022 06:54:50 GMT'}]",2022-11-11,"[['Ma', 'Yingyi', ''], ['Liu', 'Zhe', ''], ['Zhang', 'Xuedong', '']]"
2402.16617,Howard Yen,"Howard Yen, Tianyu Gao, Danqi Chen",Long-Context Language Modeling with Parallel Context Encoding,Code and data are available at https://github.com/princeton-nlp/CEPE,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Extending large language models (LLMs) to process longer inputs is crucial
for numerous applications. However, the considerable computational cost of
transformers, coupled with limited generalization of positional encoding,
restricts the size of their context window. We introduce Context Expansion with
Parallel Encoding (CEPE), a framework that can be applied to any existing
decoder-only LLMs to extend their context window. CEPE adopts a small encoder
to process long inputs chunk by chunk and enables the frozen decoder to
leverage additional contexts via cross-attention. CEPE is efficient,
generalizable, and versatile: trained with 8K-token documents, CEPE extends the
context window of LLAMA-2 to 128K tokens, offering 10x the throughput with only
1/6 of the memory. CEPE yields strong performance on language modeling and
in-context learning. CEPE also excels in retrieval-augmented applications,
while existing long-context models degenerate with retrieved contexts. We
further introduce a CEPE variant that can extend the context window of
instruction-tuned models with only unlabeled data, and showcase its
effectiveness on LLAMA-2-CHAT, leading to a strong instruction-following model
that can leverage very long context on downstream tasks.
","[{'version': 'v1', 'created': 'Mon, 26 Feb 2024 14:47:35 GMT'}]",2024-02-27,"[['Yen', 'Howard', ''], ['Gao', 'Tianyu', ''], ['Chen', 'Danqi', '']]"
2305.13112,Xiaolei Wang,"Xiaolei Wang, Xinyu Tang, Wayne Xin Zhao, Jingyuan Wang, Ji-Rong Wen","Rethinking the Evaluation for Conversational Recommendation in the Era
  of Large Language Models",Accepted by EMNLP 2023,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The recent success of large language models (LLMs) has shown great potential
to develop more powerful conversational recommender systems (CRSs), which rely
on natural language conversations to satisfy user needs. In this paper, we
embark on an investigation into the utilization of ChatGPT for conversational
recommendation, revealing the inadequacy of the existing evaluation protocol.
It might over-emphasize the matching with the ground-truth items or utterances
generated by human annotators, while neglecting the interactive nature of being
a capable CRS. To overcome the limitation, we further propose an interactive
Evaluation approach based on LLMs named iEvaLM that harnesses LLM-based user
simulators. Our evaluation approach can simulate various interaction scenarios
between users and systems. Through the experiments on two publicly available
CRS datasets, we demonstrate notable improvements compared to the prevailing
evaluation protocol. Furthermore, we emphasize the evaluation of
explainability, and ChatGPT showcases persuasive explanation generation for its
recommendations. Our study contributes to a deeper comprehension of the
untapped potential of LLMs for CRSs and provides a more flexible and
easy-to-use evaluation framework for future research endeavors. The codes and
data are publicly available at https://github.com/RUCAIBox/iEvaLM-CRS.
","[{'version': 'v1', 'created': 'Mon, 22 May 2023 15:12:43 GMT'}, {'version': 'v2', 'created': 'Fri, 3 Nov 2023 02:49:46 GMT'}]",2023-11-06,"[['Wang', 'Xiaolei', ''], ['Tang', 'Xinyu', ''], ['Zhao', 'Wayne Xin', ''], ['Wang', 'Jingyuan', ''], ['Wen', 'Ji-Rong', '']]"
2210.14353,Victor Zhong,"Victor Zhong, Weijia Shi, Wen-tau Yih, Luke Zettlemoyer","RoMQA: A Benchmark for Robust, Multi-evidence, Multi-answer Question
  Answering","The source code and evaluation for RoMQA are at
  https://github.com/facebookresearch/romqa",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We introduce RoMQA, the first benchmark for robust, multi-evidence,
multi-answer question answering (QA). RoMQA contains clusters of questions that
are derived from related constraints mined from the Wikidata knowledge graph.
RoMQA evaluates robustness of QA models to varying constraints by measuring
worst-case performance within each question cluster. Compared to prior QA
datasets, RoMQA has more human-written questions that require reasoning over
more evidence text and have, on average, many more correct answers. In
addition, human annotators rate RoMQA questions as more natural or likely to be
asked by people. We evaluate state-of-the-art large language models in
zero-shot, few-shot, and fine-tuning settings, and find that RoMQA is
challenging: zero-shot and few-shot models perform similarly to naive
baselines, while supervised retrieval methods perform well below gold evidence
upper bounds. Moreover, existing models are not robust to variations in
question constraints, but can be made more robust by tuning on clusters of
related questions. Our results show that RoMQA is a challenging benchmark for
large language models, and provides a quantifiable test to build more robust QA
methods.
","[{'version': 'v1', 'created': 'Tue, 25 Oct 2022 21:39:36 GMT'}, {'version': 'v2', 'created': 'Tue, 15 Nov 2022 17:30:07 GMT'}]",2022-11-16,"[['Zhong', 'Victor', ''], ['Shi', 'Weijia', ''], ['Yih', 'Wen-tau', ''], ['Zettlemoyer', 'Luke', '']]"
2304.12202,Ilias Chalkidis,Ilias Chalkidis,"ChatGPT may Pass the Bar Exam soon, but has a Long Way to Go for the
  LexGLUE benchmark",Working paper,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Following the hype around OpenAI's ChatGPT conversational agent, the last
straw in the recent development of Large Language Models (LLMs) that
demonstrate emergent unprecedented zero-shot capabilities, we audit the latest
OpenAI's GPT-3.5 model, `gpt-3.5-turbo', the first available ChatGPT model, in
the LexGLUE benchmark in a zero-shot fashion providing examples in a templated
instruction-following format. The results indicate that ChatGPT achieves an
average micro-F1 score of 47.6% across LexGLUE tasks, surpassing the baseline
guessing rates. Notably, the model performs exceptionally well in some
datasets, achieving micro-F1 scores of 62.8% and 70.2% in the ECtHR B and
LEDGAR datasets, respectively. The code base and model predictions are
available for review on https://github.com/coastalcph/zeroshot_lexglue.
","[{'version': 'v1', 'created': 'Thu, 9 Mar 2023 16:42:29 GMT'}]",2023-04-25,"[['Chalkidis', 'Ilias', '']]"
1911.10460,Shizhe Chen,"Shizhe Chen, Bei Liu, Jianlong Fu, Ruihua Song, Qin Jin, Pingping Lin,
  Xiaoyu Qi, Chunting Wang and Jin Zhou","Neural Storyboard Artist: Visualizing Stories with Coherent Image
  Sequences",ACM MM 2019,,,,cs.LG cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A storyboard is a sequence of images to illustrate a story containing
multiple sentences, which has been a key process to create different story
products. In this paper, we tackle a new multimedia task of automatic
storyboard creation to facilitate this process and inspire human artists.
Inspired by the fact that our understanding of languages is based on our past
experience, we propose a novel inspire-and-create framework with a
story-to-image retriever that selects relevant cinematic images for inspiration
and a storyboard creator that further refines and renders images to improve the
relevancy and visual consistency. The proposed retriever dynamically employs
contextual information in the story with hierarchical attentions and applies
dense visual-semantic matching to accurately retrieve and ground images. The
creator then employs three rendering steps to increase the flexibility of
retrieved images, which include erasing irrelevant regions, unifying styles of
images and substituting consistent characters. We carry out extensive
experiments on both in-domain and out-of-domain visual story datasets. The
proposed model achieves better quantitative performance than the
state-of-the-art baselines for storyboard creation. Qualitative visualizations
and user studies further verify that our approach can create high-quality
storyboards even for stories in the wild.
","[{'version': 'v1', 'created': 'Sun, 24 Nov 2019 05:06:41 GMT'}]",2019-12-02,"[['Chen', 'Shizhe', ''], ['Liu', 'Bei', ''], ['Fu', 'Jianlong', ''], ['Song', 'Ruihua', ''], ['Jin', 'Qin', ''], ['Lin', 'Pingping', ''], ['Qi', 'Xiaoyu', ''], ['Wang', 'Chunting', ''], ['Zhou', 'Jin', '']]"
1707.07835,Ajinkya Kale,"Ajinkya Kale, Thrivikrama Taula, Sanjika Hewavitharana, Amit
  Srivastava",Towards Semantic Query Segmentation,,,,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Query Segmentation is one of the critical components for understanding users'
search intent in Information Retrieval tasks. It involves grouping tokens in
the search query into meaningful phrases which help downstream tasks like
search relevance and query understanding. In this paper, we propose a novel
approach to segment user queries using distributed query embeddings. Our key
contribution is a supervised approach to the segmentation task using
low-dimensional feature vectors for queries, getting rid of traditional hand
tuned and heuristic NLP features which are quite expensive.
  We benchmark on a 50,000 human-annotated web search engine query corpus
achieving comparable accuracy to state-of-the-art techniques. The advantage of
our technique is its fast and does not use external knowledge-base like
Wikipedia for score boosting. This helps us generalize our approach to other
domains like eCommerce without any fine-tuning. We demonstrate the
effectiveness of this method on another 50,000 human-annotated eCommerce query
corpus from eBay search logs. Our approach is easy to implement and generalizes
well across different search domains proving the power of low-dimensional
embeddings in query segmentation task, opening up a new direction of research
for this problem.
","[{'version': 'v1', 'created': 'Tue, 25 Jul 2017 06:57:39 GMT'}]",2017-07-26,"[['Kale', 'Ajinkya', ''], ['Taula', 'Thrivikrama', ''], ['Hewavitharana', 'Sanjika', ''], ['Srivastava', 'Amit', '']]"
2402.17954,Giuseppe Attanasio,"Giuseppe Attanasio, Beatrice Savoldi, Dennis Fucci, Dirk Hovy","Multilingual Speech Models for Automatic Speech Recognition Exhibit
  Gender Performance Gaps","19 pages. Code and artifacts at
  https://github.com/g8a9/multilingual-asr-gender-gap",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Current voice recognition approaches use multi-task, multilingual models for
speech tasks like Automatic Speech Recognition (ASR) to make them applicable to
many languages without substantial changes. However, broad language coverage
can still mask performance gaps within languages, for example, across genders.
We systematically evaluate multilingual ASR systems on gendered performance
gaps. Using two popular models on three datasets in 19 languages across seven
language families, we find clear gender disparities. However, the advantaged
group varies between languages. While there are no significant differences
across groups in phonetic variables (pitch, speaking rate, etc.), probing the
model's internal states reveals a negative correlation between probe
performance and the gendered performance gap. I.e., the easier to distinguish
speaker gender in a language, the more the models favor female speakers. Our
results show that group disparities remain unsolved despite great progress on
multi-tasking and multilinguality. We provide first valuable insights for
evaluating gender gaps in multilingual ASR systems. We release all code and
artifacts at https://github.com/g8a9/multilingual-asr-gender-gap.
","[{'version': 'v1', 'created': 'Wed, 28 Feb 2024 00:24:29 GMT'}]",2024-02-29,"[['Attanasio', 'Giuseppe', ''], ['Savoldi', 'Beatrice', ''], ['Fucci', 'Dennis', ''], ['Hovy', 'Dirk', '']]"
2107.04734,Ankita Pasad,"Ankita Pasad, Ju-Chieh Chou, Karen Livescu",Layer-wise Analysis of a Self-supervised Speech Representation Model,"Accepted to ASRU 2021. Code:
  https://github.com/ankitapasad/layerwise-analysis",,,,cs.CL cs.LG eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently proposed self-supervised learning approaches have been successful
for pre-training speech representation models. The utility of these learned
representations has been observed empirically, but not much has been studied
about the type or extent of information encoded in the pre-trained
representations themselves. Developing such insights can help understand the
capabilities and limits of these models and enable the research community to
more efficiently develop their usage for downstream applications. In this work,
we begin to fill this gap by examining one recent and successful pre-trained
model (wav2vec 2.0), via its intermediate representation vectors, using a suite
of analysis tools. We use the metrics of canonical correlation, mutual
information, and performance on simple downstream tasks with non-parametric
probes, in order to (i) query for acoustic and linguistic information content,
(ii) characterize the evolution of information across model layers, and (iii)
understand how fine-tuning the model for automatic speech recognition (ASR)
affects these observations. Our findings motivate modifying the fine-tuning
protocol for ASR, which produces improved word error rates in a low-resource
setting.
","[{'version': 'v1', 'created': 'Sat, 10 Jul 2021 02:13:25 GMT'}, {'version': 'v2', 'created': 'Sat, 9 Oct 2021 02:44:07 GMT'}, {'version': 'v3', 'created': 'Sat, 3 Dec 2022 07:04:55 GMT'}]",2022-12-06,"[['Pasad', 'Ankita', ''], ['Chou', 'Ju-Chieh', ''], ['Livescu', 'Karen', '']]"
2005.14576,"Dieter Schn\""app","Susanne Arndt, Dieter Schn\""app","Harbsafe-162. A Domain-Specific Data Set for the Intrinsic Evaluation of
  Semantic Representations for Terminological Data",,,,,cs.IR cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  The article presents Harbsafe-162, a domain-specific data set for evaluating
distributional semantic models. It originates from a cooperation by Technische
Universit\""at Braunschweig and the German Commission for Electrical, Electronic
& Information Technologies of DIN and VDE, the Harbsafe project. One objective
of the project is to apply distributional semantic models to terminological
entries, that is, complex lexical data comprising of at least one or several
terms, term phrases and a definition. This application is needed to solve a
more complex problem: the harmonization of terminologies of standards and
standards bodies (i.e. resolution of doublettes and inconsistencies). Due to a
lack of evaluation data sets for terminological entries, the creation of
Harbsafe-162 was a necessary step towards harmonization assistance.
Harbsafe-162 covers data from nine electrotechnical standards in the domain of
functional safety, IT security, and dependability. An intrinsic evaluation
method in the form of a similarity rating task has been applied in which two
linguists and three domain experts from standardization participated. The data
set is used to evaluate a specific implementation of an established sentence
embedding model. This implementation proves to be satisfactory for the
domain-specific data so that further implementations for harmonization
assistance may be brought forward by the project. Considering recent criticism
on intrinsic evaluation methods, the article concludes with an evaluation of
Harbsafe-162 and joins a more general discussion about the nature of similarity
rating tasks. Harbsafe-162 has been made available for the community.
","[{'version': 'v1', 'created': 'Fri, 29 May 2020 13:56:31 GMT'}]",2020-06-01,"[['Arndt', 'Susanne', ''], ['Schnäpp', 'Dieter', '']]"
2106.08007,Masaru Isonuma,"Masaru Isonuma, Junichiro Mori, Danushka Bollegala, Ichiro Sakata","Unsupervised Abstractive Opinion Summarization by Generating Sentences
  with Tree-Structured Topic Guidance","accepted to TACL, pre-MIT Press publication version",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  This paper presents a novel unsupervised abstractive summarization method for
opinionated texts. While the basic variational autoencoder-based models assume
a unimodal Gaussian prior for the latent code of sentences, we alternate it
with a recursive Gaussian mixture, where each mixture component corresponds to
the latent code of a topic sentence and is mixed by a tree-structured topic
distribution. By decoding each Gaussian component, we generate sentences with
tree-structured topic guidance, where the root sentence conveys generic
content, and the leaf sentences describe specific topics. Experimental results
demonstrate that the generated topic sentences are appropriate as a summary of
opinionated texts, which are more informative and cover more input contents
than those generated by the recent unsupervised summarization model
(Bra\v{z}inskas et al., 2020). Furthermore, we demonstrate that the variance of
latent Gaussians represents the granularity of sentences, analogous to Gaussian
word embedding (Vilnis and McCallum, 2015).
","[{'version': 'v1', 'created': 'Tue, 15 Jun 2021 09:37:04 GMT'}]",2021-06-16,"[['Isonuma', 'Masaru', ''], ['Mori', 'Junichiro', ''], ['Bollegala', 'Danushka', ''], ['Sakata', 'Ichiro', '']]"
2012.01295,Jing Su,"Jing Su, Chenghua Lin, Mian Zhou, Qingyun Dai, Haoyu Lv","Generating Descriptions for Sequential Images with Local-Object
  Attention and Global Semantic Context Modelling",Accepted by INLG 2018,,,,cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we propose an end-to-end CNN-LSTM model for generating
descriptions for sequential images with a local-object attention mechanism. To
generate coherent descriptions, we capture global semantic context using a
multi-layer perceptron, which learns the dependencies between sequential
images. A paralleled LSTM network is exploited for decoding the sequence
descriptions. Experimental results show that our model outperforms the baseline
across three different evaluation metrics on the datasets published by
Microsoft.
","[{'version': 'v1', 'created': 'Wed, 2 Dec 2020 16:07:32 GMT'}]",2020-12-03,"[['Su', 'Jing', ''], ['Lin', 'Chenghua', ''], ['Zhou', 'Mian', ''], ['Dai', 'Qingyun', ''], ['Lv', 'Haoyu', '']]"
2008.08113,Rishika Agarwal,"Rishika Agarwal, Xiaochuan Niu, Pranay Dighe, Srikanth Vishnubhotla,
  Sameer Badaskar, Devang Naik","Complementary Language Model and Parallel Bi-LRNN for False Trigger
  Mitigation",,,,,eess.AS cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  False triggers in voice assistants are unintended invocations of the
assistant, which not only degrade the user experience but may also compromise
privacy. False trigger mitigation (FTM) is a process to detect the false
trigger events and respond appropriately to the user. In this paper, we propose
a novel solution to the FTM problem by introducing a parallel ASR decoding
process with a special language model trained from ""out-of-domain"" data
sources. Such language model is complementary to the existing language model
optimized for the assistant task. A bidirectional lattice RNN (Bi-LRNN)
classifier trained from the lattices generated by the complementary language
model shows a $38.34\%$ relative reduction of the false trigger (FT) rate at
the fixed rate of $0.4\%$ false suppression (FS) of correct invocations,
compared to the current Bi-LRNN model. In addition, we propose to train a
parallel Bi-LRNN model based on the decoding lattices from both language
models, and examine various ways of implementation. The resulting model leads
to further reduction in the false trigger rate by $10.8\%$.
","[{'version': 'v1', 'created': 'Tue, 18 Aug 2020 18:21:33 GMT'}]",2020-08-20,"[['Agarwal', 'Rishika', ''], ['Niu', 'Xiaochuan', ''], ['Dighe', 'Pranay', ''], ['Vishnubhotla', 'Srikanth', ''], ['Badaskar', 'Sameer', ''], ['Naik', 'Devang', '']]"
2209.02842,Xinjian Li,"Xinjian Li, Florian Metze, David R Mortensen, Alan W Black, Shinji
  Watanabe",ASR2K: Speech Recognition for Around 2000 Languages without Audio,INTERSPEECH 2022,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Most recent speech recognition models rely on large supervised datasets,
which are unavailable for many low-resource languages. In this work, we present
a speech recognition pipeline that does not require any audio for the target
language. The only assumption is that we have access to raw text datasets or a
set of n-gram statistics. Our speech pipeline consists of three components:
acoustic, pronunciation, and language models. Unlike the standard pipeline, our
acoustic and pronunciation models use multilingual models without any
supervision. The language model is built using n-gram statistics or the raw
text dataset. We build speech recognition for 1909 languages by combining it
with Crubadan: a large endangered languages n-gram database. Furthermore, we
test our approach on 129 languages across two datasets: Common Voice and CMU
Wilderness dataset. We achieve 50% CER and 74% WER on the Wilderness dataset
with Crubadan statistics only and improve them to 45% CER and 69% WER when
using 10000 raw text utterances.
","[{'version': 'v1', 'created': 'Tue, 6 Sep 2022 22:48:29 GMT'}]",2022-09-08,"[['Li', 'Xinjian', ''], ['Metze', 'Florian', ''], ['Mortensen', 'David R', ''], ['Black', 'Alan W', ''], ['Watanabe', 'Shinji', '']]"
2306.08818,Jiefu Ou,"Jiefu Ou, Benno Krojer and Daniel Fried",Pragmatic Inference with a CLIP Listener for Contrastive Captioning,"Findings of ACL 2023, fixed some references",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We propose a simple yet effective and robust method for contrastive
captioning: generating discriminative captions that distinguish target images
from very similar alternative distractor images. Our approach is built on a
pragmatic inference procedure that formulates captioning as a reference game
between a speaker, which produces possible captions describing the target, and
a listener, which selects the target given the caption. Unlike previous methods
that derive both speaker and listener distributions from a single captioning
model, we leverage an off-the-shelf CLIP model to parameterize the listener.
Compared with captioner-only pragmatic models, our method benefits from rich
vision language alignment representations from CLIP when reasoning over
distractors. Like previous methods for discriminative captioning, our method
uses a hyperparameter to control the tradeoff between the informativity (how
likely captions are to allow a human listener to discriminate the target image)
and the fluency of the captions. However, we find that our method is
substantially more robust to the value of this hyperparameter than past
methods, which allows us to automatically optimize the captions for
informativity - outperforming past methods for discriminative captioning by 11%
to 15% accuracy in human evaluations
","[{'version': 'v1', 'created': 'Thu, 15 Jun 2023 02:22:28 GMT'}]",2023-06-16,"[['Ou', 'Jiefu', ''], ['Krojer', 'Benno', ''], ['Fried', 'Daniel', '']]"
2111.06310,Yingbo Gao,"Zijian Yang, Yingbo Gao, Alexander Gerstenberger, Jintao Jiang, Ralf
  Schl\""uter, Hermann Ney",Self-Normalized Importance Sampling for Neural Language Modeling,Accepted at INTERSPEECH 2022,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  To mitigate the problem of having to traverse over the full vocabulary in the
softmax normalization of a neural language model, sampling-based training
criteria are proposed and investigated in the context of large vocabulary
word-based neural language models. These training criteria typically enjoy the
benefit of faster training and testing, at a cost of slightly degraded
performance in terms of perplexity and almost no visible drop in word error
rate. While noise contrastive estimation is one of the most popular choices,
recently we show that other sampling-based criteria can also perform well, as
long as an extra correction step is done, where the intended class posterior
probability is recovered from the raw model outputs. In this work, we propose
self-normalized importance sampling. Compared to our previous work, the
criteria considered in this work are self-normalized and there is no need to
further conduct a correction step. Through self-normalized language model
training as well as lattice rescoring experiments, we show that our proposed
self-normalized importance sampling is competitive in both research-oriented
and production-oriented automatic speech recognition tasks.
","[{'version': 'v1', 'created': 'Thu, 11 Nov 2021 16:57:53 GMT'}, {'version': 'v2', 'created': 'Fri, 17 Jun 2022 09:42:59 GMT'}]",2022-06-20,"[['Yang', 'Zijian', ''], ['Gao', 'Yingbo', ''], ['Gerstenberger', 'Alexander', ''], ['Jiang', 'Jintao', ''], ['Schlüter', 'Ralf', ''], ['Ney', 'Hermann', '']]"
2204.09564,Subba Reddy Oota,"Subba Reddy Oota, Jashn Arora, Manish Gupta, Raju S. Bapi",Cross-view Brain Decoding,"11 pages, 10 figures",,,,q-bio.NC cs.AI cs.CL cs.CV cs.LG eess.IV,http://creativecommons.org/licenses/by/4.0/,"  How the brain captures the meaning of linguistic stimuli across multiple
views is still a critical open question in neuroscience. Consider three
different views of the concept apartment: (1) picture (WP) presented with the
target word label, (2) sentence (S) using the target word, and (3) word cloud
(WC) containing the target word along with other semantically related words.
Unlike previous efforts, which focus only on single view analysis, in this
paper, we study the effectiveness of brain decoding in a zero-shot cross-view
learning setup. Further, we propose brain decoding in the novel context of
cross-view-translation tasks like image captioning (IC), image tagging (IT),
keyword extraction (KE), and sentence formation (SF). Using extensive
experiments, we demonstrate that cross-view zero-shot brain decoding is
practical leading to ~0.68 average pairwise accuracy across view pairs. Also,
the decoded representations are sufficiently detailed to enable high accuracy
for cross-view-translation tasks with following pairwise accuracy: IC (78.0),
IT (83.0), KE (83.7) and SF (74.5). Analysis of the contribution of different
brain networks reveals exciting cognitive insights: (1) A high percentage of
visual voxels are involved in image captioning and image tagging tasks, and a
high percentage of language voxels are involved in the sentence formation and
keyword extraction tasks. (2) Zero-shot accuracy of the model trained on S view
and tested on WC view is better than same-view accuracy of the model trained
and tested on WC view.
","[{'version': 'v1', 'created': 'Mon, 18 Apr 2022 10:43:11 GMT'}]",2022-04-21,"[['Oota', 'Subba Reddy', ''], ['Arora', 'Jashn', ''], ['Gupta', 'Manish', ''], ['Bapi', 'Raju S.', '']]"
2012.10235,Zhihong Shao,"Zhihong Shao, Zitao Liu, Jiyong Zhang, Zhongqin Wu, Minlie Huang","AdvExpander: Generating Natural Language Adversarial Examples by
  Expanding Text",Work in progress,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Adversarial examples are vital to expose the vulnerability of machine
learning models. Despite the success of the most popular substitution-based
methods which substitutes some characters or words in the original examples,
only substitution is insufficient to uncover all robustness issues of models.
In this paper, we present AdvExpander, a method that crafts new adversarial
examples by expanding text, which is complementary to previous
substitution-based methods. We first utilize linguistic rules to determine
which constituents to expand and what types of modifiers to expand with. We
then expand each constituent by inserting an adversarial modifier searched from
a CVAE-based generative model which is pre-trained on a large scale corpus. To
search adversarial modifiers, we directly search adversarial latent codes in
the latent space without tuning the pre-trained parameters. To ensure that our
adversarial examples are label-preserving for text matching, we also constrain
the modifications with a heuristic rule. Experiments on three classification
tasks verify the effectiveness of AdvExpander and the validity of our
adversarial examples. AdvExpander crafts a new type of adversarial examples by
text expansion, thereby promising to reveal new robustness issues.
","[{'version': 'v1', 'created': 'Fri, 18 Dec 2020 13:50:17 GMT'}]",2020-12-21,"[['Shao', 'Zhihong', ''], ['Liu', 'Zitao', ''], ['Zhang', 'Jiyong', ''], ['Wu', 'Zhongqin', ''], ['Huang', 'Minlie', '']]"
2212.00196,Hamish Ivison,"Hamish Ivison and Noah A. Smith and Hannaneh Hajishirzi and Pradeep
  Dasigi",Data-Efficient Finetuning Using Cross-Task Nearest Neighbors,Findings of ACL 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Obtaining labeled data to train a model for a task of interest is often
expensive. Prior work shows training models on multitask data augmented with
task descriptions (prompts) effectively transfers knowledge to new tasks.
Towards efficiently building task-specific models, we assume access to a small
number (32-1000) of unlabeled target-task examples and use those to retrieve
the most similar labeled examples from a large pool of multitask data augmented
with prompts. Compared to the current practice of finetuning models on
uniformly sampled prompted multitask data (e.g.: FLAN, T0), our approach of
finetuning on cross-task nearest neighbors is significantly more
data-efficient. Using only 2% of the data from the P3 pool without any labeled
target-task data, our models outperform strong baselines trained on all
available data by 3-30% on 12 out of 14 datasets representing held-out tasks
including legal and scientific document QA. Similarly, models trained on
cross-task nearest neighbors from SuperNaturalInstructions, representing about
5% of the pool, obtain comparable performance to state-of-the-art models on 12
held-out tasks from that pool. Moreover, the models produced by our approach
also provide a better initialization than single multitask finetuned models for
few-shot finetuning on target-task data, as shown by a 2-23% relative
improvement over few-shot finetuned T0-3B models on 8 datasets.
","[{'version': 'v1', 'created': 'Thu, 1 Dec 2022 00:53:04 GMT'}, {'version': 'v2', 'created': 'Wed, 24 May 2023 22:27:47 GMT'}]",2023-05-26,"[['Ivison', 'Hamish', ''], ['Smith', 'Noah A.', ''], ['Hajishirzi', 'Hannaneh', ''], ['Dasigi', 'Pradeep', '']]"
2105.11447,Ethan Perez,"Ethan Perez, Douwe Kiela, Kyunghyun Cho",True Few-Shot Learning with Language Models,Code at https://github.com/ethanjperez/true_few_shot,,,,cs.CL cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pretrained language models (LMs) perform well on many tasks even when
learning from a few examples, but prior work uses many held-out examples to
tune various aspects of learning, such as hyperparameters, training objectives,
and natural language templates (""prompts""). Here, we evaluate the few-shot
ability of LMs when such held-out examples are unavailable, a setting we call
true few-shot learning. We test two model selection criteria, cross-validation
and minimum description length, for choosing LM prompts and hyperparameters in
the true few-shot setting. On average, both marginally outperform random
selection and greatly underperform selection based on held-out examples.
Moreover, selection criteria often prefer models that perform significantly
worse than randomly-selected ones. We find similar results even when taking
into account our uncertainty in a model's true performance during selection, as
well as when varying the amount of computation and number of examples used for
selection. Overall, our findings suggest that prior work significantly
overestimated the true few-shot ability of LMs given the difficulty of few-shot
model selection.
","[{'version': 'v1', 'created': 'Mon, 24 May 2021 17:55:51 GMT'}]",2021-05-25,"[['Perez', 'Ethan', ''], ['Kiela', 'Douwe', ''], ['Cho', 'Kyunghyun', '']]"
2304.10464,Yiduo Guo,"Yiduo Guo, Yaobo Liang, Chenfei Wu, Wenshan Wu, Dongyan Zhao, Nan Duan",Learning to Plan with Natural Language,"Large Language Model, Learning from feedback, Planning and Reasoning",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) have shown remarkable performance in various
basic natural language tasks. For completing the complex task, we still need a
plan for the task to guide LLMs to generate the specific solutions step by
step. LLMs can directly generate task plans, but these plans may still contain
factual errors or are incomplete. A high-quality task plan contains correct
step-by-step solutions for solving all situations and behavioral instructions
for avoiding mistakes. To obtain it, we propose the Learning to Plan method,
which involves two phases: (1) In the first learning task plan phase, it
iteratively updates the task plan with new step-by-step solutions and
behavioral instructions, which are obtained by prompting LLMs to derive from
training error feedback. (2) In the subsequent test phase, the LLM uses the
learned task plan to guide the inference of LLM on the test set. We demonstrate
the effectiveness of our method on the five different reasoning type tasks (8
datasets). Further, our analysis experiment shows that the task plan learned by
one LLM can directly guide another LLM to improve its performance, which
reveals a new transfer learning paradigm. We release the code at
\url{https://github.com/Eureka6174/LearnNLPlan}
","[{'version': 'v1', 'created': 'Thu, 20 Apr 2023 17:09:12 GMT'}, {'version': 'v2', 'created': 'Sun, 23 Apr 2023 11:04:30 GMT'}, {'version': 'v3', 'created': 'Mon, 29 May 2023 01:12:18 GMT'}, {'version': 'v4', 'created': 'Wed, 13 Dec 2023 02:08:50 GMT'}]",2023-12-14,"[['Guo', 'Yiduo', ''], ['Liang', 'Yaobo', ''], ['Wu', 'Chenfei', ''], ['Wu', 'Wenshan', ''], ['Zhao', 'Dongyan', ''], ['Duan', 'Nan', '']]"
2402.16482,Han Liu,"Han Liu, Liantang Li",On Languaging a Simulation Engine,,,,,cs.AI cs.CE cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Language model intelligence is revolutionizing the way we program materials
simulations. However, the diversity of simulation scenarios renders it
challenging to precisely transform human language into a tailored simulator.
Here, using three functionalized types of language model, we propose a
language-to-simulation (Lang2Sim) framework that enables interactive navigation
on languaging a simulation engine, by taking a scenario instance of water
sorption in porous matrices. Unlike line-by-line coding of a target simulator,
the language models interpret each simulator as an assembly of invariant tool
function and its variant input-output pair. Lang2Sim enables the precise
transform of textual description by functionalizing and sequentializing the
language models of, respectively, rationalizing the tool categorization,
customizing its input-output combinations, and distilling the simulator input
into executable format. Importantly, depending on its functionalized type, each
language model features a distinct processing of chat history to best balance
its memory limit and information completeness, thus leveraging the model
intelligence to unstructured nature of human request. Overall, this work
establishes language model as an intelligent platform to unlock the era of
languaging a simulation engine.
","[{'version': 'v1', 'created': 'Mon, 26 Feb 2024 11:01:54 GMT'}]",2024-02-27,"[['Liu', 'Han', ''], ['Li', 'Liantang', '']]"
1904.09131,Antonin Delpeuch,Antonin Delpeuch,OpenTapioca: Lightweight Entity Linking for Wikidata,to appear in proceedings of the Wikidata Workshop 2020,,,,cs.CL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  We propose a simple Named Entity Linking system that can be trained from
Wikidata only. This demonstrates the strengths and weaknesses of this data
source for this task and provides an easily reproducible baseline to compare
other systems against. Our model is lightweight to train, to run and to keep
synchronous with Wikidata in real time.
","[{'version': 'v1', 'created': 'Fri, 19 Apr 2019 09:44:22 GMT'}, {'version': 'v2', 'created': 'Tue, 24 Nov 2020 17:50:32 GMT'}]",2020-11-25,"[['Delpeuch', 'Antonin', '']]"
2107.05684,Paul Rodrigues,"Evan Williams, Paul Rodrigues, Sieu Tran","Accenture at CheckThat! 2021: Interesting claim identification and
  ranking with contextually sensitive lexical training data augmentation","To Appear As: Evan Williams, Paul Rodrigues, Sieu Tran. Accenture at
  CheckThat! 2021: Interesting claim identification and ranking with
  contextually sensitive lexical training data augmentation. In: Faggioli et
  al. Working Notes of CLEF 2021-Conference and Labs of the Evaluation Forum.
  Bucharest, Romania. 21-24 September 2021",,,,cs.CL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  This paper discusses the approach used by the Accenture Team for CLEF2021
CheckThat! Lab, Task 1, to identify whether a claim made in social media would
be interesting to a wide audience and should be fact-checked. Twitter training
and test data were provided in English, Arabic, Spanish, Turkish, and
Bulgarian. Claims were to be classified (check-worthy/not check-worthy) and
ranked in priority order for the fact-checker. Our method used deep neural
network transformer models with contextually sensitive lexical augmentation
applied on the supplied training datasets to create additional training
samples. This augmentation approach improved the performance for all languages.
Overall, our architecture and data augmentation pipeline produced the best
submitted system for Arabic, and performance scales according to the quantity
of provided training data for English, Spanish, Turkish, and Bulgarian. This
paper investigates the deep neural network architectures for each language as
well as the provided data to examine why the approach worked so effectively for
Arabic, and discusses additional data augmentation measures that should could
be useful to this problem.
","[{'version': 'v1', 'created': 'Mon, 12 Jul 2021 18:46:47 GMT'}]",2021-07-14,"[['Williams', 'Evan', ''], ['Rodrigues', 'Paul', ''], ['Tran', 'Sieu', '']]"
1710.08963,Patrick Perry,Patrick O. Perry and Kenneth Benoit,Scaling Text with the Class Affinity Model,"30 pages, 9 figures",,,,stat.ML cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Probabilistic methods for classifying text form a rich tradition in machine
learning and natural language processing. For many important problems, however,
class prediction is uninteresting because the class is known, and instead the
focus shifts to estimating latent quantities related to the text, such as
affect or ideology. We focus on one such problem of interest, estimating the
ideological positions of 55 Irish legislators in the 1991 D\'ail confidence
vote. To solve the D\'ail scaling problem and others like it, we develop a text
modeling framework that allows actors to take latent positions on a ""gray""
spectrum between ""black"" and ""white"" polar opposites. We are able to validate
results from this model by measuring the influences exhibited by individual
words, and we are able to quantify the uncertainty in the scaling estimates by
using a sentence-level block bootstrap. Applying our method to the D\'ail
debate, we are able to scale the legislators between extreme pro-government and
pro-opposition in a way that reveals nuances in their speeches not captured by
their votes or party affiliations.
","[{'version': 'v1', 'created': 'Tue, 24 Oct 2017 19:38:20 GMT'}]",2017-10-26,"[['Perry', 'Patrick O.', ''], ['Benoit', 'Kenneth', '']]"
2306.11252,Cihan Xiao,"Cihan Xiao, Henry Li Xinyuan, Jinyi Yang, Dongji Gao, Matthew Wiesner,
  Kevin Duh, Sanjeev Khudanpur",HK-LegiCoST: Leveraging Non-Verbatim Transcripts for Speech Translation,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We introduce HK-LegiCoST, a new three-way parallel corpus of
Cantonese-English translations, containing 600+ hours of Cantonese audio, its
standard traditional Chinese transcript, and English translation, segmented and
aligned at the sentence level. We describe the notable challenges in corpus
preparation: segmentation, alignment of long audio recordings, and
sentence-level alignment with non-verbatim transcripts. Such transcripts make
the corpus suitable for speech translation research when there are significant
differences between the spoken and written forms of the source language. Due to
its large size, we are able to demonstrate competitive speech translation
baselines on HK-LegiCoST and extend them to promising cross-corpus results on
the FLEURS Cantonese subset. These results deliver insights into speech
recognition and translation research in languages for which non-verbatim or
``noisy'' transcription is common due to various factors, including vernacular
and dialectal speech.
","[{'version': 'v1', 'created': 'Tue, 20 Jun 2023 03:09:32 GMT'}]",2023-06-21,"[['Xiao', 'Cihan', ''], ['Xinyuan', 'Henry Li', ''], ['Yang', 'Jinyi', ''], ['Gao', 'Dongji', ''], ['Wiesner', 'Matthew', ''], ['Duh', 'Kevin', ''], ['Khudanpur', 'Sanjeev', '']]"
2202.00535,Jishnu Ray Chowdhury,"Jishnu Ray Chowdhury, Yong Zhuang, Shuyi Wang","Novelty Controlled Paraphrase Generation with Retrieval Augmented
  Conditional Prompt Tuning",Accepted by AAAI 2022 (Oral),,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Paraphrase generation is a fundamental and long-standing task in natural
language processing. In this paper, we concentrate on two contributions to the
task: (1) we propose Retrieval Augmented Prompt Tuning (RAPT) as a
parameter-efficient method to adapt large pre-trained language models for
paraphrase generation; (2) we propose Novelty Conditioned RAPT (NC-RAPT) as a
simple model-agnostic method of using specialized prompt tokens for controlled
paraphrase generation with varying levels of lexical novelty. By conducting
extensive experiments on four datasets, we demonstrate the effectiveness of the
proposed approaches for retaining the semantic content of the original text
while inducing lexical novelty in the generation.
","[{'version': 'v1', 'created': 'Tue, 1 Feb 2022 16:26:36 GMT'}, {'version': 'v2', 'created': 'Sat, 12 Mar 2022 07:46:54 GMT'}]",2022-03-15,"[['Chowdhury', 'Jishnu Ray', ''], ['Zhuang', 'Yong', ''], ['Wang', 'Shuyi', '']]"
2002.00760,Dou Yan Liu Goodman,Dou Goodman and Lv Zhonghou and Wang minghua,"FastWordBug: A Fast Method To Generate Adversarial Text Against NLP
  Applications",,,,,cs.CL cs.CR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we present a novel algorithm, FastWordBug, to efficiently
generate small text perturbations in a black-box setting that forces a
sentiment analysis or text classification mode to make an incorrect prediction.
By combining the part of speech attributes of words, we propose a scoring
method that can quickly identify important words that affect text
classification. We evaluate FastWordBug on three real-world text datasets and
two state-of-the-art machine learning models under black-box setting. The
results show that our method can significantly reduce the accuracy of the
model, and at the same time, we can call the model as little as possible, with
the highest attack efficiency. We also attack two popular real-world cloud
services of NLP, and the results show that our method works as well.
","[{'version': 'v1', 'created': 'Fri, 31 Jan 2020 07:39:45 GMT'}]",2020-02-04,"[['Goodman', 'Dou', ''], ['Zhonghou', 'Lv', ''], ['minghua', 'Wang', '']]"
2012.15484,Kiran Ramnath,Kiran Ramnath and Mark Hasegawa-Johnson,"Seeing is Knowing! Fact-based Visual Question Answering using Knowledge
  Graph Embeddings",17 pages,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Fact-based Visual Question Answering (FVQA), a challenging variant of VQA,
requires a QA-system to include facts from a diverse knowledge graph (KG) in
its reasoning process to produce an answer. Large KGs, especially common-sense
KGs, are known to be incomplete, i.e., not all non-existent facts are always
incorrect. Therefore, being able to reason over incomplete KGs for QA is a
critical requirement in real-world applications that has not been addressed
extensively in the literature. We develop a novel QA architecture that allows
us to reason over incomplete KGs, something current FVQA state-of-the-art
(SOTA) approaches lack due to their critical reliance on fact retrieval. We use
KG Embeddings, a technique widely used for KG completion, for the downstream
task of FVQA. We also employ a new image representation technique we call
'Image-as-Knowledge' to enable this capability, alongside a simple one-step
CoAttention mechanism to attend to text and image during QA. Our FVQA
architecture is faster during inference time, being O(m), as opposed to
existing FVQA SOTA methods which are O(N log N), where m = number of vertices,
N = number of edges = O(m^2). KG embeddings are shown to hold complementary
information to word embeddings: a combination of both metrics permits
performance comparable to SOTA methods in the standard answer retrieval task,
and significantly better (26% absolute) in the proposed missing-edge reasoning
task.
","[{'version': 'v1', 'created': 'Thu, 31 Dec 2020 07:24:55 GMT'}, {'version': 'v2', 'created': 'Fri, 18 Jun 2021 18:20:46 GMT'}]",2021-06-22,"[['Ramnath', 'Kiran', ''], ['Hasegawa-Johnson', 'Mark', '']]"
2307.05228,Ahmad Rashid,"Runcheng Liu, Ahmad Rashid, Ivan Kobyzev, Mehdi Rezagholizadeh and
  Pascal Poupart",Attribute Controlled Dialogue Prompting,Accepted at ACL 2023 In Findings,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Prompt-tuning has become an increasingly popular parameter-efficient method
for adapting large pretrained language models to downstream tasks. However,
both discrete prompting and continuous prompting assume fixed prompts for all
data samples within a task, neglecting the fact that inputs vary greatly in
some tasks such as open-domain dialogue generation. In this paper, we present a
novel, instance-specific prompt-tuning algorithm for dialogue generation.
Specifically, we generate prompts based on instance-level control code, rather
than the conversation history, to explore their impact on controlled dialogue
generation. Experiments on popular open-domain dialogue datasets, evaluated on
both automated metrics and human evaluation, demonstrate that our method is
superior to prompting baselines and comparable to fine-tuning with only 5%-6%
of total parameters.
","[{'version': 'v1', 'created': 'Tue, 11 Jul 2023 12:48:55 GMT'}]",2023-07-12,"[['Liu', 'Runcheng', ''], ['Rashid', 'Ahmad', ''], ['Kobyzev', 'Ivan', ''], ['Rezagholizadeh', 'Mehdi', ''], ['Poupart', 'Pascal', '']]"
1709.00389,Jian Tang,"Jian Tang, Yue Wang, Kai Zheng, Qiaozhu Mei",End-to-end Learning for Short Text Expansion,KDD'2017,,,,cs.CL cs.IR,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Effectively making sense of short texts is a critical task for many real
world applications such as search engines, social media services, and
recommender systems. The task is particularly challenging as a short text
contains very sparse information, often too sparse for a machine learning
algorithm to pick up useful signals. A common practice for analyzing short text
is to first expand it with external information, which is usually harvested
from a large collection of longer texts. In literature, short text expansion
has been done with all kinds of heuristics. We propose an end-to-end solution
that automatically learns how to expand short text to optimize a given learning
task. A novel deep memory network is proposed to automatically find relevant
information from a collection of longer documents and reformulate the short
text through a gating mechanism. Using short text classification as a
demonstrating task, we show that the deep memory network significantly
outperforms classical text expansion methods with comprehensive experiments on
real world data sets.
","[{'version': 'v1', 'created': 'Wed, 30 Aug 2017 04:24:06 GMT'}]",2017-09-04,"[['Tang', 'Jian', ''], ['Wang', 'Yue', ''], ['Zheng', 'Kai', ''], ['Mei', 'Qiaozhu', '']]"
1904.03713,Natalie Parde,Natalie Parde and Rodney D. Nielsen,AI Meets Austen: Towards Human-Robot Discussions of Literary Metaphor,"Accepted to the 20th International Conference on Artificial
  Intelligence in Education (AIED 2019)",,,,cs.HC cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Artificial intelligence is revolutionizing formal education, fueled by
innovations in learning assessment, content generation, and instructional
delivery. Informal, lifelong learning settings have been the subject of less
attention. We provide a proof-of-concept for an embodied book discussion
companion, designed to stimulate conversations with readers about particularly
creative metaphors in fiction literature. We collect ratings from 26
participants, each of whom discuss Jane Austen's ""Pride and Prejudice"" with the
robot across one or more sessions, and find that participants rate their
interactions highly. This suggests that companion robots could be an
interesting entryway for the promotion of lifelong learning and cognitive
exercise in future applications.
","[{'version': 'v1', 'created': 'Sun, 7 Apr 2019 19:01:32 GMT'}]",2019-04-09,"[['Parde', 'Natalie', ''], ['Nielsen', 'Rodney D.', '']]"
2305.14878,Vikas Raunak,"Vikas Raunak, Amr Sharaf, Yiren Wang, Hany Hassan Awadallah, Arul
  Menezes",Leveraging GPT-4 for Automatic Translation Post-Editing,EMNLP Findings 2023,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  While Neural Machine Translation (NMT) represents the leading approach to
Machine Translation (MT), the outputs of NMT models still require translation
post-editing to rectify errors and enhance quality under critical settings. In
this work, we formalize the task of direct translation post-editing with Large
Language Models (LLMs) and explore the use of GPT-4 to automatically post-edit
NMT outputs across several language pairs. Our results demonstrate that GPT-4
is adept at translation post-editing, producing meaningful and trustworthy
edits to translations that help improve its general quality as well as remove
different classes of major errors in translations. In particular, human
evaluations on assessing edit trustworthiness show that GPT-4 exhibits a large
improvement over the prior state-of-the-art LLM. Notably, we improve upon
state-of-the-art performance on WMT-22 English-Chinese, English-German,
Chinese-English and German-English language pairs using GPT-4 based
post-editing, as evaluated by state-of-the-art MT quality metrics. However, we
also show that GPT-4 could produce hallucinated edits, thereby urging caution
in its use as an expert translation post-editor.
","[{'version': 'v1', 'created': 'Wed, 24 May 2023 08:30:05 GMT'}, {'version': 'v2', 'created': 'Mon, 23 Oct 2023 23:18:18 GMT'}]",2023-10-25,"[['Raunak', 'Vikas', ''], ['Sharaf', 'Amr', ''], ['Wang', 'Yiren', ''], ['Awadallah', 'Hany Hassan', ''], ['Menezes', 'Arul', '']]"
1905.12926,Ke Wang,"Ke Wang, Hang Hua, Xiaojun Wan","Controllable Unsupervised Text Attribute Transfer via Editing Entangled
  Latent Representation",Neurips 2019 camera ready,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Unsupervised text attribute transfer automatically transforms a text to alter
a specific attribute (e.g. sentiment) without using any parallel data, while
simultaneously preserving its attribute-independent content. The dominant
approaches are trying to model the content-independent attribute separately,
e.g., learning different attributes' representations or using multiple
attribute-specific decoders. However, it may lead to inflexibility from the
perspective of controlling the degree of transfer or transferring over multiple
aspects at the same time. To address the above problems, we propose a more
flexible unsupervised text attribute transfer framework which replaces the
process of modeling attribute with minimal editing of latent representations
based on an attribute classifier. Specifically, we first propose a
Transformer-based autoencoder to learn an entangled latent representation for a
discrete text, then we transform the attribute transfer task to an optimization
problem and propose the Fast-Gradient-Iterative-Modification algorithm to edit
the latent representation until conforming to the target attribute. Extensive
experimental results demonstrate that our model achieves very competitive
performance on three public data sets. Furthermore, we also show that our model
can not only control the degree of transfer freely but also allow to transfer
over multiple aspects at the same time.
","[{'version': 'v1', 'created': 'Thu, 30 May 2019 09:32:03 GMT'}, {'version': 'v2', 'created': 'Thu, 12 Dec 2019 14:27:26 GMT'}]",2019-12-13,"[['Wang', 'Ke', ''], ['Hua', 'Hang', ''], ['Wan', 'Xiaojun', '']]"
2101.02346,Amirmohammad Kazameini,"Yang Li, Amirmohammad Kazameini, Yash Mehta, Erik Cambria",Multitask Learning for Emotion and Personality Detection,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  In recent years, deep learning-based automated personality trait detection
has received a lot of attention, especially now, due to the massive digital
footprints of an individual. Moreover, many researchers have demonstrated that
there is a strong link between personality traits and emotions. In this paper,
we build on the known correlation between personality traits and emotional
behaviors, and propose a novel multitask learning framework, SoGMTL that
simultaneously predicts both of them. We also empirically evaluate and discuss
different information-sharing mechanisms between the two tasks. To ensure the
high quality of the learning process, we adopt a MAML-like framework for model
optimization. Our more computationally efficient CNN-based multitask model
achieves the state-of-the-art performance across multiple famous personality
and emotion datasets, even outperforming Language Model based models.
","[{'version': 'v1', 'created': 'Thu, 7 Jan 2021 03:09:55 GMT'}]",2021-01-08,"[['Li', 'Yang', ''], ['Kazameini', 'Amirmohammad', ''], ['Mehta', 'Yash', ''], ['Cambria', 'Erik', '']]"
2111.00653,Boyan Xu,"Ruichu Cai, Jinjie Yuan, Boyan Xu, Zhifeng Hao",SADGA: Structure-Aware Dual Graph Aggregation Network for Text-to-SQL,"Paper accepted at the 35th Conference on Neural Information
  Processing Systems (NeurIPS 2021)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Text-to-SQL task, aiming to translate the natural language of the
questions into SQL queries, has drawn much attention recently. One of the most
challenging problems of Text-to-SQL is how to generalize the trained model to
the unseen database schemas, also known as the cross-domain Text-to-SQL task.
The key lies in the generalizability of (i) the encoding method to model the
question and the database schema and (ii) the question-schema linking method to
learn the mapping between words in the question and tables/columns in the
database schema. Focusing on the above two key issues, we propose a
Structure-Aware Dual Graph Aggregation Network (SADGA) for cross-domain
Text-to-SQL. In SADGA, we adopt the graph structure to provide a unified
encoding model for both the natural language question and database schema.
Based on the proposed unified modeling, we further devise a structure-aware
aggregation method to learn the mapping between the question-graph and
schema-graph. The structure-aware aggregation method is featured with Global
Graph Linking, Local Graph Linking, and Dual-Graph Aggregation Mechanism. We
not only study the performance of our proposal empirically but also achieved
3rd place on the challenging Text-to-SQL benchmark Spider at the time of
writing.
","[{'version': 'v1', 'created': 'Mon, 1 Nov 2021 01:50:28 GMT'}, {'version': 'v2', 'created': 'Sat, 4 Dec 2021 08:58:18 GMT'}, {'version': 'v3', 'created': 'Mon, 17 Jan 2022 13:04:31 GMT'}]",2022-01-19,"[['Cai', 'Ruichu', ''], ['Yuan', 'Jinjie', ''], ['Xu', 'Boyan', ''], ['Hao', 'Zhifeng', '']]"
2111.13861,Zhenhua Wang,"Zhenhua Wang, Ming Ren, Dong Gao",A New Multifractal-based Deep Learning Model for Text Mining,,,,,cs.LG cs.CL cs.NE,http://creativecommons.org/licenses/by/4.0/,"  In this world full of uncertainty, where the fabric of existence weaves
patterns of complexity, multifractal emerges as beacons of insight,
illuminating them. As we delve into the realm of text mining that underpins
various natural language processing applications and powers a range of
intelligent services, we recognize that behind the veil of text lies a
manifestation of human thought and cognition, intricately intertwined with the
complexities. Building upon the foundation of perceiving text as a complex
system, this study embarks on a journey to unravel the hidden treasures within,
armed with the proposed multifractal method that deciphers the multifractal
attributes embedded within the text landscape. This endeavor culminates in the
birth of our novel model, which also harnesses the power of the proposed
activation function to facilitate nonlinear information transmission within its
neural network architecture. The success on experiments anchored in real-world
technical reports covering the extraction of technical term and classification
of hazard events, stands as a testament to our endeavors. This research venture
not only expands our understanding of text mining but also opens new horizons
for knowledge discovery across various domains.
","[{'version': 'v1', 'created': 'Sat, 27 Nov 2021 10:22:29 GMT'}, {'version': 'v2', 'created': 'Fri, 1 Sep 2023 00:05:04 GMT'}]",2023-09-04,"[['Wang', 'Zhenhua', ''], ['Ren', 'Ming', ''], ['Gao', 'Dong', '']]"
2003.03072,Chan Hee Song,"Chan Hee Song, Dawn Lawrie, Tim Finin, James Mayfield",Improving Neural Named Entity Recognition with Gazetteers,Short version accepted to the 33rd FLAIRS conference,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The goal of this work is to improve the performance of a neural named entity
recognition system by adding input features that indicate a word is part of a
name included in a gazetteer. This article describes how to generate gazetteers
from the Wikidata knowledge graph as well as how to integrate the information
into a neural NER system. Experiments reveal that the approach yields
performance gains in two distinct languages: a high-resource, word-based
language, English and a high-resource, character-based language, Chinese.
Experiments were also performed in a low-resource language, Russian on a newly
annotated Russian NER corpus from Reddit tagged with four core types and twelve
extended types. This article reports a baseline score. It is a longer version
of a paper in the 33rd FLAIRS conference (Song et al. 2020).
","[{'version': 'v1', 'created': 'Fri, 6 Mar 2020 08:29:37 GMT'}]",2020-03-09,"[['Song', 'Chan Hee', ''], ['Lawrie', 'Dawn', ''], ['Finin', 'Tim', ''], ['Mayfield', 'James', '']]"
2403.05846,Michael Toker,"Michael Toker, Hadas Orgad, Mor Ventura, Dana Arad, Yonatan Belinkov",Diffusion Lens: Interpreting Text Encoders in Text-to-Image Pipelines,Project webpage: tokeron.github.io/DiffusionLensWeb,,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text-to-image diffusion models (T2I) use a latent representation of a text
prompt to guide the image generation process. However, the process by which the
encoder produces the text representation is unknown. We propose the Diffusion
Lens, a method for analyzing the text encoder of T2I models by generating
images from its intermediate representations. Using the Diffusion Lens, we
perform an extensive analysis of two recent T2I models. Exploring compound
prompts, we find that complex scenes describing multiple objects are composed
progressively and more slowly compared to simple scenes; Exploring knowledge
retrieval, we find that representation of uncommon concepts requires further
computation compared to common concepts, and that knowledge retrieval is
gradual across layers. Overall, our findings provide valuable insights into the
text encoder component in T2I pipelines.
","[{'version': 'v1', 'created': 'Sat, 9 Mar 2024 09:11:49 GMT'}]",2024-03-12,"[['Toker', 'Michael', ''], ['Orgad', 'Hadas', ''], ['Ventura', 'Mor', ''], ['Arad', 'Dana', ''], ['Belinkov', 'Yonatan', '']]"
1703.00096,Zhenyao Zhu,"Hairong Liu, Zhenyao Zhu, Xiangang Li, Sanjeev Satheesh","Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence
  Labelling",Published at ICML 2017,,,,cs.CL cs.LG cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Most existing sequence labelling models rely on a fixed decomposition of a
target sequence into a sequence of basic units. These methods suffer from two
major drawbacks: 1) the set of basic units is fixed, such as the set of words,
characters or phonemes in speech recognition, and 2) the decomposition of
target sequences is fixed. These drawbacks usually result in sub-optimal
performance of modeling sequences. In this pa- per, we extend the popular CTC
loss criterion to alleviate these limitations, and propose a new loss function
called Gram-CTC. While preserving the advantages of CTC, Gram-CTC automatically
learns the best set of basic units (grams), as well as the most suitable
decomposition of tar- get sequences. Unlike CTC, Gram-CTC allows the model to
output variable number of characters at each time step, which enables the model
to capture longer term dependency and improves the computational efficiency. We
demonstrate that the proposed Gram-CTC improves CTC in terms of both
performance and efficiency on the large vocabulary speech recognition task at
multiple scales of data, and that with Gram-CTC we can outperform the
state-of-the-art on a standard speech benchmark.
","[{'version': 'v1', 'created': 'Wed, 1 Mar 2017 00:59:17 GMT'}, {'version': 'v2', 'created': 'Sat, 12 Aug 2017 00:02:26 GMT'}]",2017-08-15,"[['Liu', 'Hairong', ''], ['Zhu', 'Zhenyao', ''], ['Li', 'Xiangang', ''], ['Satheesh', 'Sanjeev', '']]"
